#\!/usr/bin/env python3
"""
AI ì§€ì›ì ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
"""

import os
import sys
sys.path.append('.')

from core.ai_candidate_model import AICandidateModel
from core.llm_manager import LLMProvider

def test_ai_candidate():
    """AI ì§€ì›ì ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª AI ì§€ì›ì ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # 1. ëª¨ë¸ ì´ˆê¸°í™”
        ai_candidate = AICandidateModel()
        print("âœ… AI ì§€ì›ì ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ")
        
        # 2. AI ì´ë¦„ í…ŒìŠ¤íŠ¸
        ai_name = ai_candidate.get_ai_name(LLMProvider.OPENAI_GPT35)
        print(f"âœ… AI ì´ë¦„: {ai_name}")
        
        # 3. í˜ë¥´ì†Œë‚˜ ë¦¬ìŠ¤íŠ¸ í™•ì¸
        available_personas = list(ai_candidate.candidate_personas.keys())
        print(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ í˜ë¥´ì†Œë‚˜: {available_personas}")
        
        # 4. AI ë©´ì ‘ ì‹œì‘ í…ŒìŠ¤íŠ¸
        ai_session_id = ai_candidate.start_ai_interview("naver", "ë°±ì—”ë“œ ê°œë°œì")
        print(f"âœ… AI ë©´ì ‘ ì„¸ì…˜ ì‹œì‘: {ai_session_id}")
        
        # 5. ì²« ë²ˆì§¸ ì§ˆë¬¸ ìƒì„± í…ŒìŠ¤íŠ¸
        first_question = ai_candidate.get_ai_next_question(ai_session_id)
        if first_question:
            print(f"âœ… ì²« ë²ˆì§¸ ì§ˆë¬¸ ìƒì„± ì„±ê³µ")
            print(f"   - íƒ€ì…: {first_question['question_type']}")
            print(f"   - ë‚´ìš©: {first_question['question_content'][:50]}...")
            print(f"   - ì§„í–‰ë¥ : {first_question['progress']}")
        else:
            print("âŒ ì²« ë²ˆì§¸ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨")
            
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_ai_candidate()