#!/usr/bin/env python3
"""
AI ì§€ì›ì ëª¨ë¸ ë°ëª¨ ìŠ¤í¬ë¦½íŠ¸
ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ê³  ì‹œì—°í•  ìˆ˜ ìˆëŠ” í†µí•© ë°ëª¨
"""

import os
import sys
import time
import json
from typing import List, Dict, Any
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

from core.ai_candidate_model import AICandidateModel, AnswerRequest, AnswerResponse
from core.llm_manager import LLMProvider
from core.answer_quality_controller import QualityLevel
from core.interview_system import QuestionType
from core.ai_candidate_config import get_config

class AICandidateDemo:
    """AI ì§€ì›ì ë°ëª¨ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.ai_candidate = None
        self.config = get_config()
        
    def setup(self) -> bool:
        """ë°ëª¨ ì´ˆê¸° ì„¤ì •"""
        print("ğŸ¤– AI ì§€ì›ì ëª¨ë¸ ë°ëª¨ ì‹œìŠ¤í…œ")
        print("=" * 60)
        
        # .env íŒŒì¼ì—ì„œ API í‚¤ ìë™ ë¡œë“œ
        api_key = os.getenv('OPENAI_API_KEY')
        
        if not api_key:
            print("âš ï¸ .env íŒŒì¼ì—ì„œ OPENAI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            api_key = input("ğŸ”‘ OpenAI API í‚¤ë¥¼ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            if not api_key:
                print("âŒ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                return False
        else:
            print(f"âœ… .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ ì™„ë£Œ (ë 4ìë¦¬: ...{api_key[-4:]})")
        
        # AI ì§€ì›ì ëª¨ë¸ ì´ˆê¸°í™”
        try:
            self.ai_candidate = AICandidateModel(api_key)
            print("âœ… AI ì§€ì›ì ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
        except Exception as e:
            print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def show_main_menu(self):
        """ë©”ì¸ ë©”ë‰´ í‘œì‹œ"""
        print("\n" + "=" * 60)
        print("ğŸ¯ AI ì§€ì›ì ë°ëª¨ ë©”ë‰´")
        print("=" * 60)
        print("1. ê¸°ë³¸ ë‹µë³€ ìƒì„± í…ŒìŠ¤íŠ¸")
        print("2. í’ˆì§ˆ ë ˆë²¨ë³„ ë‹µë³€ ë¹„êµ")
        print("3. ë‹¤ì¤‘ LLM ëª¨ë¸ ë¹„êµ")
        print("4. íšŒì‚¬ë³„ í˜ë¥´ì†Œë‚˜ ë¹„êµ")
        print("5. ì „ì²´ ë©´ì ‘ ì‹œë®¬ë ˆì´ì…˜")
        print("6. ì„¤ì • ê´€ë¦¬")
        print("7. í˜ë¥´ì†Œë‚˜ ì •ë³´ ì¡°íšŒ")
        print("0. ì¢…ë£Œ")
        print("=" * 60)
    
    def run_basic_answer_test(self):
        """ê¸°ë³¸ ë‹µë³€ ìƒì„± í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“ ê¸°ë³¸ ë‹µë³€ ìƒì„± í…ŒìŠ¤íŠ¸")
        print("-" * 40)
        
        # íšŒì‚¬ ì„ íƒ
        companies = self.ai_candidate.get_available_companies()
        print(f"ì‚¬ìš© ê°€ëŠ¥í•œ íšŒì‚¬: {', '.join(companies)}")
        
        company_id = input("íšŒì‚¬ë¥¼ ì„ íƒí•˜ì„¸ìš”: ").strip()
        if company_id not in companies:
            print("âŒ ì˜ëª»ëœ íšŒì‚¬ ì„ íƒ")
            return
        
        # ì§ˆë¬¸ ì…ë ¥
        questions = [
            "ê°„ë‹¨í•œ ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”.",
            "ìš°ë¦¬ íšŒì‚¬ì— ì§€ì›í•œ ë™ê¸°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "ê°€ì¥ ìì‹  ìˆëŠ” ê¸°ìˆ  ìŠ¤íƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ì–´ë ¤ì› ë˜ ê²½í—˜ì´ ìˆë‚˜ìš”?",
            "ì§ì ‘ ì…ë ¥"
        ]
        
        print("\nì§ˆë¬¸ì„ ì„ íƒí•˜ê±°ë‚˜ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”:")
        for i, q in enumerate(questions, 1):
            print(f"{i}. {q}")
        
        choice = input("ì„ íƒ (1-5): ").strip()
        
        if choice == "5":
            question_content = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            question_type = QuestionType.HR
        else:
            try:
                idx = int(choice) - 1
                question_content = questions[idx]
                question_types = [QuestionType.INTRO, QuestionType.MOTIVATION, 
                                QuestionType.TECH, QuestionType.COLLABORATION]
                question_type = question_types[idx] if idx < 4 else QuestionType.HR
            except (ValueError, IndexError):
                print("âŒ ì˜ëª»ëœ ì„ íƒ")
                return
        
        # ë‹µë³€ ìƒì„±
        request = AnswerRequest(
            question_content=question_content,
            question_type=question_type,
            question_intent="ì§€ì›ì ì—­ëŸ‰ í‰ê°€",
            company_id=company_id,
            position="ë°±ì—”ë“œ ê°œë°œì",
            quality_level=QualityLevel.GOOD,
            llm_provider=LLMProvider.OPENAI_GPT4O_MINI
        )
        
        print(f"\nğŸ”„ ë‹µë³€ ìƒì„± ì¤‘...")
        start_time = time.time()
        
        response = self.ai_candidate.generate_answer(request)
        
        generation_time = time.time() - start_time
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nâœ… ë‹µë³€ ìƒì„± ì™„ë£Œ (ì´ {generation_time:.2f}ì´ˆ)")
        print("=" * 60)
        print(f"ğŸ¢ íšŒì‚¬: {company_id}")
        print(f"ğŸ‘¤ í˜ë¥´ì†Œë‚˜: {response.persona_name}")
        print(f"ğŸ“Š í’ˆì§ˆ ë ˆë²¨: {response.quality_level.value}ì ")
        print(f"ğŸ¯ ì‹ ë¢°ë„: {response.confidence_score}")
        print(f"â±ï¸ ì‘ë‹µ ì‹œê°„: {response.response_time:.2f}ì´ˆ")
        print("=" * 60)
        print(f"â“ ì§ˆë¬¸: {question_content}")
        print(f"ğŸ’¬ ë‹µë³€:\n{response.answer_content}")
        print("=" * 60)
        
        if response.error:
            print(f"âŒ ì˜¤ë¥˜: {response.error}")
    
    def run_quality_comparison(self):
        """í’ˆì§ˆ ë ˆë²¨ë³„ ë‹µë³€ ë¹„êµ"""
        print("\nğŸ“Š í’ˆì§ˆ ë ˆë²¨ë³„ ë‹µë³€ ë¹„êµ")
        print("-" * 40)
        
        # ê¸°ë³¸ ì„¤ì •
        companies = self.ai_candidate.get_available_companies()
        if not companies:
            print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ íšŒì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        company_id = companies[0]  # ì²« ë²ˆì§¸ íšŒì‚¬ ì‚¬ìš©
        question_content = "ê°€ì¥ ìì‹ ìˆëŠ” ê¸°ìˆ  ìŠ¤íƒê³¼ ê´€ë ¨ í”„ë¡œì íŠ¸ ê²½í—˜ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”."
        
        # ë¹„êµí•  í’ˆì§ˆ ë ˆë²¨
        quality_levels = [QualityLevel.EXCELLENT, QualityLevel.GOOD, QualityLevel.AVERAGE, QualityLevel.POOR]
        
        print(f"íšŒì‚¬: {company_id}")
        print(f"ì§ˆë¬¸: {question_content}")
        print(f"ë¹„êµ í’ˆì§ˆ ë ˆë²¨: {[f'{q.value}ì ' for q in quality_levels]}")
        
        input("\nê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
        
        # ê° í’ˆì§ˆ ë ˆë²¨ë³„ ë‹µë³€ ìƒì„±
        results = {}
        for level in quality_levels:
            print(f"\nğŸ”„ {level.value}ì  ìˆ˜ì¤€ ë‹µë³€ ìƒì„± ì¤‘...")
            
            request = AnswerRequest(
                question_content=question_content,
                question_type=QuestionType.TECH,
                question_intent="ê¸°ìˆ ì  ì—­ëŸ‰ ë° í”„ë¡œì íŠ¸ ê²½í—˜ í‰ê°€",
                company_id=company_id,
                position="ë°±ì—”ë“œ ê°œë°œì",
                quality_level=level,
                llm_provider=LLMProvider.OPENAI_GPT4O_MINI
            )
            
            response = self.ai_candidate.generate_answer(request)
            results[level] = response
        
        # ê²°ê³¼ ë¹„êµ ì¶œë ¥
        print("\n" + "=" * 80)
        print("ğŸ“Š í’ˆì§ˆ ë ˆë²¨ë³„ ë‹µë³€ ë¹„êµ ê²°ê³¼")
        print("=" * 80)
        
        for level, response in results.items():
            print(f"\nğŸ¯ {level.value}ì  ìˆ˜ì¤€ ({level.name})")
            print(f"ì‹ ë¢°ë„: {response.confidence_score} | ì‘ë‹µì‹œê°„: {response.response_time:.2f}ì´ˆ | ê¸¸ì´: {len(response.answer_content)}ì")
            print(f"ë‹µë³€: {response.answer_content[:200]}...")
            print("-" * 80)
    
    def run_llm_comparison(self):
        """ë‹¤ì¤‘ LLM ëª¨ë¸ ë¹„êµ"""
        print("\nğŸ”§ ë‹¤ì¤‘ LLM ëª¨ë¸ ë¹„êµ")
        print("-" * 40)
        
        # í™œì„±í™”ëœ ëª¨ë¸ í™•ì¸
        enabled_models = self.config.get_enabled_models()
        available_models = [m for m in enabled_models if m in [LLMProvider.OPENAI_GPT4O_MINI, LLMProvider.OPENAI_GPT35]]
        
        if len(available_models) < 2:
            print("âŒ ë¹„êµí•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. (ìµœì†Œ 2ê°œ í•„ìš”)")
            print(f"í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥: {[m.value for m in available_models]}")
            return
        
        # ê¸°ë³¸ ì„¤ì •
        companies = self.ai_candidate.get_available_companies()
        company_id = companies[0] if companies else "naver"
        question_content = "íŒ€ì—ì„œ ê°ˆë“±ì´ ìˆì—ˆì„ ë•Œ ì–´ë–»ê²Œ í•´ê²°í–ˆë‚˜ìš”?"
        
        print(f"íšŒì‚¬: {company_id}")
        print(f"ì§ˆë¬¸: {question_content}")
        print(f"ë¹„êµ ëª¨ë¸: {[m.value for m in available_models]}")
        
        input("\nê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
        
        # ê° ëª¨ë¸ë³„ ë‹µë³€ ìƒì„±
        results = {}
        for model in available_models:
            print(f"\nğŸ”„ {model.value} ëª¨ë¸ ë‹µë³€ ìƒì„± ì¤‘...")
            
            request = AnswerRequest(
                question_content=question_content,
                question_type=QuestionType.COLLABORATION,
                question_intent="í˜‘ì—… ë° ê°ˆë“± í•´ê²° ëŠ¥ë ¥ í‰ê°€",
                company_id=company_id,
                position="ë°±ì—”ë“œ ê°œë°œì",
                quality_level=QualityLevel.GOOD,
                llm_provider=model
            )
            
            response = self.ai_candidate.generate_answer(request)
            results[model] = response
        
        # ê²°ê³¼ ë¹„êµ ì¶œë ¥
        print("\n" + "=" * 80)
        print("ğŸ”§ LLM ëª¨ë¸ë³„ ë‹µë³€ ë¹„êµ ê²°ê³¼")
        print("=" * 80)
        
        for model, response in results.items():
            print(f"\nğŸ¤– {model.value}")
            print(f"ì‹ ë¢°ë„: {response.confidence_score} | ì‘ë‹µì‹œê°„: {response.response_time:.2f}ì´ˆ | ê¸¸ì´: {len(response.answer_content)}ì")
            print(f"ë‹µë³€: {response.answer_content[:300]}...")
            print("-" * 80)
    
    def run_persona_comparison(self):
        """íšŒì‚¬ë³„ í˜ë¥´ì†Œë‚˜ ë¹„êµ"""
        print("\nğŸ¢ íšŒì‚¬ë³„ í˜ë¥´ì†Œë‚˜ ë¹„êµ")
        print("-" * 40)
        
        companies = self.ai_candidate.get_available_companies()
        if len(companies) < 2:
            print("âŒ ë¹„êµí•  íšŒì‚¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            return
        
        question_content = "ìš°ë¦¬ íšŒì‚¬ì— ì§€ì›í•œ ë™ê¸°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
        
        print(f"ì§ˆë¬¸: {question_content}")
        print(f"ë¹„êµ íšŒì‚¬: {companies}")
        
        input("\nê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
        
        # ê° íšŒì‚¬ë³„ ë‹µë³€ ìƒì„±
        results = {}
        for company in companies[:3]:  # ìµœëŒ€ 3ê°œ íšŒì‚¬
            print(f"\nğŸ”„ {company} í˜ë¥´ì†Œë‚˜ ë‹µë³€ ìƒì„± ì¤‘...")
            
            request = AnswerRequest(
                question_content=question_content,
                question_type=QuestionType.MOTIVATION,
                question_intent="ì§€ì› ë™ê¸° ë° íšŒì‚¬ ì´í•´ë„ í‰ê°€",
                company_id=company,
                position="ë°±ì—”ë“œ ê°œë°œì",
                quality_level=QualityLevel.GOOD,
                llm_provider=LLMProvider.OPENAI_GPT4O_MINI
            )
            
            response = self.ai_candidate.generate_answer(request)
            results[company] = response
        
        # ê²°ê³¼ ë¹„êµ ì¶œë ¥
        print("\n" + "=" * 80)
        print("ğŸ¢ íšŒì‚¬ë³„ í˜ë¥´ì†Œë‚˜ ë‹µë³€ ë¹„êµ ê²°ê³¼")
        print("=" * 80)
        
        for company, response in results.items():
            print(f"\nğŸ¢ {company} - {response.persona_name}")
            print(f"ì‹ ë¢°ë„: {response.confidence_score} | ì‘ë‹µì‹œê°„: {response.response_time:.2f}ì´ˆ")
            print(f"ë‹µë³€: {response.answer_content}")
            print("-" * 80)
    
    def run_full_interview_simulation(self):
        """ì „ì²´ ë©´ì ‘ ì‹œë®¬ë ˆì´ì…˜"""
        print("\nğŸ­ ì „ì²´ ë©´ì ‘ ì‹œë®¬ë ˆì´ì…˜")
        print("-" * 40)
        
        # íšŒì‚¬ ì„ íƒ
        companies = self.ai_candidate.get_available_companies()
        print(f"ì‚¬ìš© ê°€ëŠ¥í•œ íšŒì‚¬: {', '.join(companies)}")
        
        company_id = input("íšŒì‚¬ë¥¼ ì„ íƒí•˜ì„¸ìš”: ").strip()
        if company_id not in companies:
            print("âŒ ì˜ëª»ëœ íšŒì‚¬ ì„ íƒ")
            return
        
        # ë©´ì ‘ ì§ˆë¬¸ ì„¸íŠ¸
        interview_questions = [
            ("ê°„ë‹¨í•œ ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”.", QuestionType.INTRO),
            (f"ìš°ë¦¬ íšŒì‚¬ì— ì§€ì›í•œ ë™ê¸°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?", QuestionType.MOTIVATION),
            ("ê°€ì¥ ìì‹  ìˆëŠ” ê¸°ìˆ  ìŠ¤íƒê³¼ í”„ë¡œì íŠ¸ ê²½í—˜ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.", QuestionType.TECH),
            ("íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ê°ˆë“±ì„ í•´ê²°í•œ ê²½í—˜ì´ ìˆë‚˜ìš”?", QuestionType.COLLABORATION),
            ("ê°œë°œìë¡œì„œ ê°€ì¥ ì–´ë ¤ì› ë˜ ë¬¸ì œë¥¼ ì–´ë–»ê²Œ í•´ê²°í–ˆë‚˜ìš”?", QuestionType.TECH)
        ]
        
        print(f"\nğŸ¯ {company_id} ë©´ì ‘ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘")
        print(f"ì´ {len(interview_questions)}ê°œ ì§ˆë¬¸")
        
        input("ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
        
        responses = []
        total_time = 0
        
        for i, (question, q_type) in enumerate(interview_questions, 1):
            print(f"\n{'='*60}")
            print(f"ì§ˆë¬¸ {i}/{len(interview_questions)}")
            print(f"{'='*60}")
            print(f"â“ {question}")
            
            # ë‹µë³€ ìƒì„±
            request = AnswerRequest(
                question_content=question,
                question_type=q_type,
                question_intent=f"{q_type.value} ì—­ëŸ‰ í‰ê°€",
                company_id=company_id,
                position="ë°±ì—”ë“œ ê°œë°œì",
                quality_level=QualityLevel.GOOD,
                llm_provider=LLMProvider.OPENAI_GPT4O_MINI
            )
            
            print("ğŸ”„ ë‹µë³€ ìƒì„± ì¤‘...")
            response = self.ai_candidate.generate_answer(request)
            responses.append(response)
            total_time += response.response_time
            
            print(f"ğŸ’¬ {response.persona_name}:")
            print(f"{response.answer_content}")
            print(f"\nğŸ“Š í‰ê°€: ì‹ ë¢°ë„ {response.confidence_score}, ì‘ë‹µì‹œê°„ {response.response_time:.2f}ì´ˆ")
            
            if i < len(interview_questions):
                input("\në‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
        
        # ë©´ì ‘ ê²°ê³¼ ìš”ì•½
        print(f"\n{'='*80}")
        print("ğŸ­ ë©´ì ‘ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ìš”ì•½")
        print(f"{'='*80}")
        print(f"ğŸ¢ íšŒì‚¬: {company_id}")
        print(f"ğŸ‘¤ í˜ë¥´ì†Œë‚˜: {responses[0].persona_name}")
        print(f"ğŸ“Š í‰ê·  ì‹ ë¢°ë„: {sum(r.confidence_score for r in responses) / len(responses):.2f}")
        print(f"â±ï¸ ì´ ì‘ë‹µ ì‹œê°„: {total_time:.2f}ì´ˆ")
        print(f"ğŸ“ ë‹µë³€ ìˆ˜: {len(responses)}ê°œ")
        print(f"ğŸ’¬ í‰ê·  ë‹µë³€ ê¸¸ì´: {sum(len(r.answer_content) for r in responses) // len(responses)}ì")
    
    def show_persona_info(self):
        """í˜ë¥´ì†Œë‚˜ ì •ë³´ ì¡°íšŒ"""
        print("\nğŸ‘¤ í˜ë¥´ì†Œë‚˜ ì •ë³´ ì¡°íšŒ")
        print("-" * 40)
        
        companies = self.ai_candidate.get_available_companies()
        
        for company in companies:
            summary = self.ai_candidate.get_persona_summary(company)
            if summary:
                print(f"\nğŸ¢ {company.upper()}")
                print(f"ì´ë¦„: {summary.get('name', 'N/A')}")
                print(f"ê²½ë ¥: {summary.get('career_years', 'N/A')}ë…„")
                print(f"ì§ì±…: {summary.get('position', 'N/A')}")
                print(f"ì£¼ìš” ê¸°ìˆ : {', '.join(summary.get('main_skills', [])[:3])}")
                print(f"í•µì‹¬ ê°•ì : {', '.join(summary.get('key_strengths', [])[:2])}")
                print(f"ë©´ì ‘ ìŠ¤íƒ€ì¼: {summary.get('interview_style', 'N/A')}")
                print("-" * 50)
    
    def manage_settings(self):
        """ì„¤ì • ê´€ë¦¬"""
        print("\nâš™ï¸ ì„¤ì • ê´€ë¦¬")
        print("-" * 40)
        
        # í˜„ì¬ ì„¤ì • ìš”ì•½
        summary = self.config.get_config_summary()
        print("ğŸ“Š í˜„ì¬ ì„¤ì •:")
        for key, value in summary.items():
            print(f"  {key}: {value}")
        
        # ì„¤ì • ìœ íš¨ì„± ê²€ì¦
        warnings = self.config.validate_config()
        if warnings:
            print("\nâš ï¸ ì„¤ì • ê²½ê³ :")
            for warning in warnings:
                print(f"  - {warning}")
        
        print("\nì„¤ì • ì˜µì…˜:")
        print("1. ëª¨ë¸ í™œì„±í™”/ë¹„í™œì„±í™”")
        print("2. í’ˆì§ˆ ì„¤ì • ë³€ê²½")
        print("3. ì„¤ì • ì €ì¥")
        print("4. ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì´ˆê¸°í™”")
        print("0. ëŒì•„ê°€ê¸°")
        
        choice = input("ì„ íƒ: ").strip()
        
        if choice == "1":
            self._manage_model_settings()
        elif choice == "2":
            self._manage_quality_settings()
        elif choice == "3":
            self.config.save_config()
            print("âœ… ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        elif choice == "4":
            confirm = input("ì •ë§ ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì´ˆê¸°í™”í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
            if confirm.lower() == 'y':
                self.config.reset_to_defaults()
    
    def _manage_model_settings(self):
        """ëª¨ë¸ ì„¤ì • ê´€ë¦¬"""
        print("\nğŸ¤– ëª¨ë¸ ì„¤ì • ê´€ë¦¬")
        
        for provider in LLMProvider:
            setting = self.config.get_model_setting(provider)
            if setting:
                status = "âœ… í™œì„±í™”" if setting.enabled else "âŒ ë¹„í™œì„±í™”"
                print(f"{provider.value}: {status}")
        
        provider_name = input("\në³€ê²½í•  ëª¨ë¸ (ì˜ˆ: openai_gpt4o_mini): ").strip()
        try:
            provider = LLMProvider(provider_name)
            action = input("í™œì„±í™”(e)/ë¹„í™œì„±í™”(d): ").strip().lower()
            
            if action == 'e':
                self.config.enable_model(provider)
            elif action == 'd':
                self.config.disable_model(provider)
        except ValueError:
            print("âŒ ì˜ëª»ëœ ëª¨ë¸ëª…ì…ë‹ˆë‹¤.")
    
    def _manage_quality_settings(self):
        """í’ˆì§ˆ ì„¤ì • ê´€ë¦¬"""
        print("\nğŸ“Š í’ˆì§ˆ ì„¤ì • ê´€ë¦¬")
        print(f"í˜„ì¬ ê¸°ë³¸ í’ˆì§ˆ ë ˆë²¨: {self.config.quality_settings.default_level.value}")
        
        try:
            new_level = int(input("ìƒˆ ê¸°ë³¸ í’ˆì§ˆ ë ˆë²¨ (1-10): "))
            if 1 <= new_level <= 10:
                self.config.update_quality_setting(default_level=new_level)
            else:
                print("âŒ 1-10 ë²”ìœ„ì˜ ê°’ì„ ì…ë ¥í•˜ì„¸ìš”.")
        except ValueError:
            print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    
    def run(self):
        """ë°ëª¨ ì‹¤í–‰"""
        if not self.setup():
            return
        
        while True:
            try:
                self.show_main_menu()
                choice = input("\nì„ íƒí•˜ì„¸ìš”: ").strip()
                
                if choice == "0":
                    print("ğŸ‘‹ ë°ëª¨ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                elif choice == "1":
                    self.run_basic_answer_test()
                elif choice == "2":
                    self.run_quality_comparison()
                elif choice == "3":
                    self.run_llm_comparison()
                elif choice == "4":
                    self.run_persona_comparison()
                elif choice == "5":
                    self.run_full_interview_simulation()
                elif choice == "6":
                    self.manage_settings()
                elif choice == "7":
                    self.show_persona_info()
                else:
                    print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
                
                input("\në©”ì¸ ë©”ë‰´ë¡œ ëŒì•„ê°€ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ë°ëª¨ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                input("ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

if __name__ == "__main__":
    demo = AICandidateDemo()
    demo.run()