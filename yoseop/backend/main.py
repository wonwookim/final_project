"""
FastAPI ê¸°ë°˜ AI ë©´ì ‘ ì‹œìŠ¤í…œ
Flaskì—ì„œ FastAPIë¡œ ë³€í™˜ëœ ê³ ì„±ëŠ¥ ë¹„ë™ê¸° ì›¹ ì„œë²„
"""

from fastapi import FastAPI, HTTPException, UploadFile, File, Depends, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, FileResponse
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import asyncio
import os
import sys
import json
from datetime import datetime
import uuid
from pathlib import Path
import time

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# LLM ì‹œìŠ¤í…œ ì„í¬íŠ¸ (ìƒˆë¡œìš´ êµ¬ì¡°)
from llm.core.config import config
from llm.core.logging_config import interview_logger, performance_logger
from llm.core.personalized_system import PersonalizedInterviewSystem
from llm.core.document_processor import DocumentProcessor, UserProfile
from llm.core.constants import ALLOWED_FILE_EXTENSIONS, MAX_FILE_SIZE
from llm.core.ai_candidate_model import AICandidateModel, AnswerRequest
from llm.core.answer_quality_controller import QualityLevel
from llm.core.interview_system import QuestionType, QuestionAnswer
from llm.core.llm_manager import LLMProvider
# UnifiedInterviewSession ì œê±° - ì›ë˜ ì„¤ê³„ ë³µêµ¬

# íšŒì‚¬ ì´ë¦„ ë§¤í•‘
COMPANY_NAME_MAP = {
    "ë„¤ì´ë²„": "naver",
    "ì¹´ì¹´ì˜¤": "kakao", 
    "ë¼ì¸": "line",
    "ì¿ íŒ¡": "coupang",
    "ë°°ë‹¬ì˜ë¯¼ì¡±": "baemin",
    "ë‹¹ê·¼ë§ˆì¼“": "daangn", 
    "í† ìŠ¤": "toss"
}

def get_company_id(company_name: str) -> str:
    """íšŒì‚¬ ì´ë¦„ì„ IDë¡œ ë³€í™˜"""
    return COMPANY_NAME_MAP.get(company_name, company_name.lower())

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="Beta-GO Interview API",
    description="AI ê¸°ë°˜ ê°œì¸í™”ëœ ë©´ì ‘ ì‹œìŠ¤í…œ",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ê°œë°œ í™˜ê²½ì—ì„œë§Œ ì‚¬ìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì •ì  íŒŒì¼ ì„œë¹™ (React ë¹Œë“œ íŒŒì¼)
# app.mount("/static", StaticFiles(directory="../demo_react"), name="static")

# ì „ì—­ ìƒíƒœ ê´€ë¦¬ - ë‹¨ìˆœí™”
class ApplicationState:
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœ ê´€ë¦¬ - ê¸°ì¡´ Flask ë°©ì‹ ìœ ì§€"""
    def __init__(self):
        self.document_processor = DocumentProcessor()
        self.personalized_system = PersonalizedInterviewSystem()  # ê¸°ì¡´ core ê·¸ëŒ€ë¡œ ì‚¬ìš©
        self.ai_candidate_model = AICandidateModel()  # AI ë‹µë³€ìš©

# ì „ì—­ ìƒíƒœ ì¸ìŠ¤í„´ìŠ¤
app_state = ApplicationState()

# Pydantic ëª¨ë¸ ì •ì˜
class InterviewSettings(BaseModel):
    """ë©´ì ‘ ì„¤ì • ëª¨ë¸"""
    company: str
    position: str
    mode: str
    difficulty: str = "ì¤‘ê°„"
    candidate_name: str
    documents: Optional[List[str]] = None

class QuestionRequest(BaseModel):
    """ì§ˆë¬¸ ìš”ì²­ ëª¨ë¸"""
    session_id: str
    question_index: int

class AnswerSubmission(BaseModel):
    """ë‹µë³€ ì œì¶œ ëª¨ë¸"""
    session_id: str
    question_id: str
    answer: str
    time_spent: int

class InterviewResult(BaseModel):
    """ë©´ì ‘ ê²°ê³¼ ëª¨ë¸"""
    session_id: str
    total_score: int
    category_scores: Dict[str, int]
    detailed_feedback: List[Dict]
    recommendations: List[str]

# ì˜ì¡´ì„± ì£¼ì…
def get_app_state():
    return app_state

# API ì—”ë“œí¬ì¸íŠ¸

@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ - API ì •ë³´ ë°˜í™˜"""
    return {
        "message": "Beta-GO Interview API",
        "version": "2.0.0",
        "status": "running",
        "docs": "/docs",
        "health": "/health"
    }

@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {"status": "healthy", "timestamp": datetime.now()}

@app.post("/api/interview/start")
async def start_interview(
    settings: InterviewSettings,
    state: ApplicationState = Depends(get_app_state)
):
    """ë©´ì ‘ ì‹œì‘ - ê¸°ì¡´ core ê¸°ëŠ¥ ì§ì ‘ ì‚¬ìš©"""
    try:
        # íšŒì‚¬ ID ë³€í™˜
        company_id = get_company_id(settings.company)
        
        # ë¬¸ì„œ ê¸°ë°˜ í”„ë¡œí•„ ìƒì„± (ê¸°ì¡´ ë°©ì‹)
        if settings.documents:
            profile = await generate_personalized_profile(settings.documents, state)
        else:
            # ê¸°ë³¸ í”„ë¡œí•„ ìƒì„±
            from core.document_processor import UserProfile
            profile = UserProfile(
                name=settings.candidate_name,
                background={"career_years": "1", "current_position": "ì‹ ì…"},
                technical_skills=[],
                projects=[],
                experiences=[],
                strengths=["í•™ìŠµëŠ¥ë ¥", "ì—´ì •"],
                keywords=["ì‹ ì…", "ê°œë°œ"],
                career_goal="ì „ë¬¸ ê°œë°œìë¡œ ì„±ì¥",
                unique_points=["ë¹ ë¥¸ ì ì‘ë ¥"]
            )
        
        # PersonalizedInterviewSystemìœ¼ë¡œ ë©´ì ‘ ì‹œì‘ (ê¸°ì¡´ core ê·¸ëŒ€ë¡œ)
        session_id = state.personalized_system.start_personalized_interview(
            company_id=company_id,
            position=settings.position,
            candidate_name=settings.candidate_name,
            user_profile=profile
        )
        
        interview_logger.info(f"ë©´ì ‘ ì‹œì‘ - ì„¸ì…˜ ID: {session_id}")
        
        return {
            "session_id": session_id,
            "message": "ë©´ì ‘ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
        }
        
    except Exception as e:
        interview_logger.error(f"ë©´ì ‘ ì‹œì‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë©´ì ‘ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/api/interview/upload")
async def upload_document(
    file: UploadFile = File(...),
    state: ApplicationState = Depends(get_app_state)
):
    """ë¬¸ì„œ ì—…ë¡œë“œ ë° ë¶„ì„"""
    try:
        # íŒŒì¼ ê²€ì¦
        if not file.filename.lower().endswith(tuple(ALLOWED_FILE_EXTENSIONS)):
            raise HTTPException(status_code=400, detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
        
        # íŒŒì¼ ì €ì¥
        upload_dir = Path("uploads")
        upload_dir.mkdir(exist_ok=True)
        
        file_path = upload_dir / f"{uuid.uuid4()}_{file.filename}"
        
        with open(file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        # ë¬¸ì„œ ë¶„ì„
        analyzed_content = await analyze_document_async(file_path, state)
        
        return {
            "file_id": str(file_path),
            "analyzed_content": analyzed_content,
            "message": "ë¬¸ì„œ ì—…ë¡œë“œ ë° ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
        }
        
    except Exception as e:
        interview_logger.error(f"ë¬¸ì„œ ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë¬¸ì„œ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.get("/api/interview/question")
async def get_next_question(
    session_id: str,
    state: ApplicationState = Depends(get_app_state)
):
    """ë‹¤ìŒ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸° - ê¸°ì¡´ core ê¸°ëŠ¥ ì§ì ‘ ì‚¬ìš©"""
    try:
        # PersonalizedInterviewSystemì—ì„œ ì§ì ‘ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°
        question_data = state.personalized_system.get_next_question(session_id)
        
        if not question_data:
            return {"completed": True, "message": "ëª¨ë“  ì§ˆë¬¸ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."}
        
        # ì§„í–‰ë¥  ì •ë³´ ê³„ì‚°
        session = state.personalized_system.get_session(session_id)
        if session:
            current_index = len(session.conversation_history)
            total_questions = len(session.question_plan)
            progress = (current_index / total_questions) * 100 if total_questions > 0 else 0
        else:
            current_index = 0
            total_questions = 10
            progress = 0
        
        return {
            "question": {
                "id": question_data["question_id"],
                "question": question_data["question_content"],
                "category": question_data["question_type"],
                "time_limit": question_data.get("time_limit", 120),
                "keywords": question_data.get("keywords", [])
            },
            "question_index": current_index,
            "total_questions": total_questions,
            "progress": progress
        }
        
    except Exception as e:
        interview_logger.error(f"ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ì§ˆë¬¸ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/api/interview/answer")
async def submit_answer(
    answer_data: AnswerSubmission,
    state: ApplicationState = Depends(get_app_state)
):
    """ë‹µë³€ ì œì¶œ - ê¸°ì¡´ core í‰ê°€ ì‹œìŠ¤í…œ ì‚¬ìš©"""
    try:
        # PersonalizedInterviewSystemì˜ ê¸°ì¡´ submit_answer ì‚¬ìš© (í‰ê°€ í¬í•¨)
        result = state.personalized_system.submit_answer(answer_data.session_id, answer_data.answer)
        
        if "error" in result:
            raise HTTPException(status_code=500, detail=result["error"])
        
        # ê¸°ì¡´ coreì—ì„œ ë°˜í™˜í•˜ëŠ” ê²°ê³¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        return {
            "status": result.get("status", "success"),
            "message": result.get("message", "ë‹µë³€ì´ ì„±ê³µì ìœ¼ë¡œ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤."),
            "question": result.get("question"),
            "answered_count": result.get("answered_count", 0),
            "total_questions": result.get("total_questions", 0)
        }
        
    except Exception as e:
        interview_logger.error(f"ë‹µë³€ ì œì¶œ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë‹µë³€ ì œì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.get("/api/interview/results/{session_id}")
async def get_interview_results(
    session_id: str,
    state: ApplicationState = Depends(get_app_state)
):
    """ë©´ì ‘ ê²°ê³¼ ì¡°íšŒ"""
    try:
        session_mapping = state.get_session_mapping(session_id)
        if not session_mapping:
            raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ê²°ê³¼ ìƒì„±
        results = await generate_interview_results(session_mapping, state)
        
        return results
        
    except Exception as e:
        interview_logger.error(f"ê²°ê³¼ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ê²°ê³¼ë¥¼ ì¡°íšŒí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# AI ê²½ìŸ ëª¨ë“œ ì—”ë“œí¬ì¸íŠ¸ - web/app.py ë°©ì‹ìœ¼ë¡œ êµ¬í˜„
@app.post("/api/interview/ai/start")
async def start_ai_competition(
    settings: InterviewSettings,
    state: ApplicationState = Depends(get_app_state)
):
    """AI ì§€ì›ìì™€ì˜ ê²½ìŸ ë©´ì ‘ ì‹œì‘ - web/app.pyì™€ ë™ì¼í•œ ë°©ì‹"""
    try:
        interview_logger.info("AI ë¹„êµ ë©´ì ‘ ì‹œì‘")
        
        # ê¸°ë³¸ í”„ë¡œí•„ ìƒì„±
        from core.document_processor import UserProfile
        quick_profile = UserProfile(
            name=settings.candidate_name,
            background={"career_years": "3", "current_position": "ê°œë°œì"},
            technical_skills=["Python", "JavaScript"],
            projects=[],
            experiences=[],
            strengths=["ë¬¸ì œí•´ê²°", "ì†Œí†µ"],
            keywords=["ê°œë°œ", "ê¸°ìˆ "],
            career_goal="ì„±ì¥í•˜ëŠ” ê°œë°œì",
            unique_points=["ì—´ì •ì ì¸ í•™ìŠµ"]
        )
        
        # ì‚¬ìš©ì ì„¸ì…˜ ì‹œì‘ ë¨¼ì € (PersonalizedInterviewSystem ì‚¬ìš©)
        company_id = get_company_id(settings.company)
        import uuid
        
        # ì™„ì „ ê³ ìœ í•œ ì„¸ì…˜ ID ìƒì„± (ì‚¬ìš©ììš©)
        user_unique_id = str(uuid.uuid4())[:8]  # 8ìë¦¬ ê³ ìœ  ID
        user_unique_position = f"USER_{settings.position.replace(' ', '_')}_{user_unique_id}"
        
        print(f"ğŸ” ì‚¬ìš©ì ì„¸ì…˜ ìƒì„± ì¤‘ - ì´ë¦„: {settings.candidate_name}")
        user_session_id = state.personalized_system.start_personalized_interview(
            company_id=company_id,
            position=user_unique_position,  # ì‚¬ìš©ì ì „ìš© í¬ì§€ì…˜ëª…
            candidate_name=settings.candidate_name,  # ì‚¬ìš©ì ì‹¤ì œ ì´ë¦„
            user_profile=quick_profile
        )
        print(f"âœ… ì‚¬ìš©ì ì„¸ì…˜ ìƒì„± ì™„ë£Œ - ID: {user_session_id}")
        
        # ì‚¬ìš©ì ì²« ì§ˆë¬¸ ìƒì„±í•´ì„œ í™•ì¸
        user_first_question = state.personalized_system.get_next_question(user_session_id)
        print(f"ğŸ” ì‚¬ìš©ì ì„¸ì…˜ì—ì„œ ì§ˆë¬¸ ìš”ì²­: {user_session_id}")
        print(f"ğŸ“ ìƒì„±ëœ ì‚¬ìš©ì ì§ˆë¬¸: {user_first_question}")
        
        # AI ì„¸ì…˜ ì‹œì‘ (ì™„ì „íˆ ë‹¤ë¥¸ ì„¸ì…˜ IDë¡œ)
        from core.document_processor import UserProfile
        
        # ì™„ì „ ê³ ìœ í•œ ì„¸ì…˜ ID ìƒì„± (AIìš©)
        ai_unique_id = str(uuid.uuid4())[:8]  # 8ìë¦¬ ê³ ìœ  ID
        ai_unique_position = f"AI_{settings.position.replace(' ', '_')}_{ai_unique_id}"
        
        ai_profile = UserProfile(
            name="ì¶˜ì‹ì´",
            background={
                "career_years": "3",
                "current_position": "AI ì§€ì›ì",
                "education": ["AI ëŒ€í•™êµ ì¡¸ì—…"]
            },
            technical_skills=["Python", "AI", "Machine Learning"],
            projects=[{
                "name": "AI ë©´ì ‘ ì‹œìŠ¤í…œ",
                "description": "AI ê¸°ë°˜ ë©´ì ‘ ì‹œìŠ¤í…œ ê°œë°œ",
                "tech_stack": ["Python", "AI"]
            }],
            experiences=[{
                "company": "AI Corp",
                "position": "AI ê°œë°œì",
                "period": "3ë…„"
            }],
            strengths=["ë¹ ë¥¸ í•™ìŠµ", "ë¬¸ì œí•´ê²°"],
            keywords=["AI", "ê°œë°œ", "ë©´ì ‘"],
            career_goal="AI ì „ë¬¸ê°€",
            unique_points=["AI íŠ¹í™”"]
        )
        
        print(f"ğŸ” AI ì„¸ì…˜ ìƒì„± ì¤‘ - ì´ë¦„: ì¶˜ì‹ì´")
        ai_session_id = state.personalized_system.start_personalized_interview(
            company_id=company_id,
            position=ai_unique_position,  # AI ì „ìš© í¬ì§€ì…˜ëª…
            candidate_name="ì¶˜ì‹ì´",  # AI ì´ë¦„
            user_profile=ai_profile
        )
        print(f"âœ… AI ì„¸ì…˜ ìƒì„± ì™„ë£Œ - ID: {ai_session_id}")
        
        # AI ì²« ì§ˆë¬¸ ìƒì„±í•´ì„œ í™•ì¸
        ai_first_question = state.personalized_system.get_next_question(ai_session_id)
        print(f"ğŸ“ ìƒì„±ëœ AI ì§ˆë¬¸: {ai_first_question}")
        
        # ì‚¬ìš©ì ì„¸ì…˜ ì¬í™•ì¸ (AI ì„¸ì…˜ ìƒì„± í›„)
        user_recheck_question = state.personalized_system.get_next_question(user_session_id)
        print(f"ğŸ” ì‚¬ìš©ì ì„¸ì…˜ ì¬í™•ì¸: {user_recheck_question}")
        
        # ì„¸ì…˜ ë¶„ë¦¬ ê²€ì¦
        print(f"ğŸ” ì„¸ì…˜ ë¶„ë¦¬ ê²€ì¦:")
        print(f"   - ì‚¬ìš©ì ì„¸ì…˜ ID: {user_session_id}")
        print(f"   - AI ì„¸ì…˜ ID: {ai_session_id}")
        print(f"   - ì„¸ì…˜ ë¶„ë¦¬ë¨: {user_session_id != ai_session_id}")
        
        # AI ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
        from core.llm_manager import LLMProvider
        ai_name = state.ai_candidate_model.get_ai_name(LLMProvider.OPENAI_GPT4O_MINI)
        
        # ëœë¤ìœ¼ë¡œ ì‹œì‘ì ê²°ì • (50% í™•ë¥ )
        import random
        starts_with_user = random.choice([True, False])
        initial_phase = 'user_turn' if starts_with_user else 'ai_turn'
        
        # ë¹„êµ ì„¸ì…˜ ìƒì„±
        comparison_session_id = f"comp_{user_session_id}"
        
        # ì „ì—­ ìƒíƒœì— ë¹„êµ ì„¸ì…˜ ì €ì¥
        if not hasattr(state, 'comparison_sessions'):
            state.comparison_sessions = {}
            
        state.comparison_sessions[comparison_session_id] = {
            'user_session_id': user_session_id,
            'ai_session_id': ai_session_id,
            'current_question_index': 1,
            'current_phase': initial_phase,
            'total_questions': 20,
            'user_name': settings.candidate_name,
            'ai_name': ai_name,
            'user_answers': [],
            'ai_answers': [],
            'starts_with_user': starts_with_user
        }
        
        print(f"âœ… ë¹„êµ ë©´ì ‘ ì„¸ì…˜ ìƒì„±: {comparison_session_id}")
        print(f"ğŸ² ì‹œì‘ì: {'ì‚¬ìš©ì' if starts_with_user else 'AI'}")
        
        if starts_with_user:
            # ì‚¬ìš©ìë¶€í„° ì‹œì‘
            print(f"ğŸ” ì‚¬ìš©ì ì„¸ì…˜ì—ì„œ ì§ˆë¬¸ ìš”ì²­: {user_session_id}")
            user_question = state.personalized_system.get_next_question(user_session_id)
            print(f"ğŸ“ ìƒì„±ëœ ì‚¬ìš©ì ì§ˆë¬¸: {user_question}")
            
            if user_question:
                return {
                    "session_id": user_session_id,
                    "comparison_session_id": comparison_session_id,
                    "user_session_id": user_session_id,
                    "ai_session_id": ai_session_id,
                    "question": user_question,
                    "current_phase": "user_turn",
                    "current_respondent": settings.candidate_name,
                    "question_index": 1,
                    "total_questions": 20,
                    "ai_name": ai_name,
                    "starts_with_user": True,
                    "message": f"{settings.candidate_name}ë‹˜ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤"
                }
            else:
                raise HTTPException(status_code=500, detail="ì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        else:
            # AIë¶€í„° ì‹œì‘
            return {
                "session_id": user_session_id,
                "comparison_session_id": comparison_session_id,
                "user_session_id": user_session_id,
                "ai_session_id": ai_session_id,
                "current_phase": "ai_turn",
                "current_respondent": ai_name,
                "question_index": 1,
                "total_questions": 20,
                "ai_name": ai_name,
                "user_name": settings.candidate_name,
                "starts_with_user": False,
                "message": f"{ai_name}ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤"
            }
        
    except Exception as e:
        interview_logger.error(f"AI ê²½ìŸ ë©´ì ‘ ì‹œì‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"AI ê²½ìŸ ë©´ì ‘ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.get("/api/interview/ai-answer/{session_id}/{question_id}")
async def get_ai_answer(
    session_id: str,
    question_id: str,
    state: ApplicationState = Depends(get_app_state)
):
    """AI ì§€ì›ìì˜ ë‹µë³€ ìƒì„± - ê¸°ì¡´ core ê¸°ëŠ¥ ì§ì ‘ ì‚¬ìš©"""
    try:
        # URL ë””ì½”ë”©
        import urllib.parse
        decoded_session_id = urllib.parse.unquote(session_id)
        print(f"ğŸ” AI ë‹µë³€ ìƒì„± ìš”ì²­ - session_id: {decoded_session_id}, question_id: {question_id}")
        
        # ê°„ë‹¨í•œ ë°©ë²•ìœ¼ë¡œ ì¶˜ì‹ì´ ë‹µë³€ ìƒì„±
        # íšŒì‚¬ì™€ í¬ì§€ì…˜ì„ ì„¸ì…˜ IDì—ì„œ íŒŒì‹±
        session_parts = decoded_session_id.split('_')
        company_id = session_parts[0] if len(session_parts) > 0 else "naver"
        position = "_".join(session_parts[1:-1]) if len(session_parts) > 2 else "ë°±ì—”ë“œ ê°œë°œ"
        
        print(f"ğŸ“‹ íŒŒì‹±ëœ ì •ë³´ - company: {company_id}, position: {position}")
        
        # ì¶˜ì‹ì´ ì „ìš© AI ì„¸ì…˜ ì‹œì‘í•˜ê³  ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°
        ai_session_id = state.ai_candidate_model.start_ai_interview(company_id, position)
        
        # ì¶˜ì‹ì´ì—ê²Œ ì¤„ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸° (AI ì „ìš©, question_id ê¸°ë°˜ìœ¼ë¡œ ìˆœì„œ ë§ì¶¤)
        ai_question_data = state.ai_candidate_model.get_ai_next_question(ai_session_id)
        
        if ai_question_data:
            question_content = ai_question_data["question_content"]
            question_intent = ai_question_data["question_intent"]
            question_type = ai_question_data["question_type"]
        else:
            # question_id ê¸°ë°˜ í´ë°± ì§ˆë¬¸ (ì¶˜ì‹ì´ìš©) - ê°•ì œ íƒ€ì… ì„¤ì •
            if question_id == "q_1":
                question_content = "ì¶˜ì‹ì´, ìê¸°ì†Œê°œë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
                question_intent = "ì§€ì›ìì˜ ê¸°ë³¸ ì •ë³´ì™€ ì„±ê²©, ì—­ëŸ‰ì„ íŒŒì•…"
                question_type = "INTRO"
            elif question_id == "q_2":
                question_content = f"ì¶˜ì‹ì´ê»˜ì„œ ë„¤ì´ë²„ì— ì§€ì›í•˜ê²Œ ëœ ë™ê¸°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
                question_intent = "íšŒì‚¬ì— ëŒ€í•œ ê´€ì‹¬ë„ì™€ ì§€ì› ë™ê¸° íŒŒì•…"
                question_type = "MOTIVATION"
            else:
                question_content = "ì¶˜ì‹ì´ì— ëŒ€í•´ ë” ì•Œë ¤ì£¼ì„¸ìš”."
                question_intent = "ì¼ë°˜ì ì¸ í‰ê°€"
                question_type = "HR"
        
        # ê°•ì œë¡œ q_1ì€ INTROë¡œ ì„¤ì •
        if question_id == "q_1":
            question_type = "INTRO"
        elif question_id == "q_2":
            question_type = "MOTIVATION"
        
        # coreì˜ ê¸°ì¡´ ë‹µë³€ ìƒì„± ê¸°ëŠ¥ ì‚¬ìš©
        from core.ai_candidate_model import AnswerRequest
        from core.interview_system import QuestionType
        from core.answer_quality_controller import QualityLevel
        from core.llm_manager import LLMProvider
        
        # QuestionType ë§¤í•‘
        question_type_map = {
            "INTRO": QuestionType.INTRO,
            "MOTIVATION": QuestionType.MOTIVATION,
            "HR": QuestionType.HR,
            "TECH": QuestionType.TECH,
            "COLLABORATION": QuestionType.COLLABORATION
        }
        
        # ë‹µë³€ ìš”ì²­ ìƒì„±
        print(f"ğŸ¯ ì§ˆë¬¸ íƒ€ì… ë§¤í•‘: {question_type} â†’ {question_type_map.get(question_type, QuestionType.HR)}")
        print(f"ğŸ¯ ì§ˆë¬¸ ë‚´ìš©: {question_content}")
        
        answer_request = AnswerRequest(
            question_content=question_content,
            question_type=question_type_map.get(question_type, QuestionType.HR),
            question_intent=question_intent,
            company_id=company_id,
            position=position,
            quality_level=QualityLevel.GOOD,  # ì¶˜ì‹ì´ëŠ” ì¢‹ì€ í’ˆì§ˆë¡œ
            llm_provider=LLMProvider.OPENAI_GPT4O_MINI
        )
        
        # AI ë‹µë³€ ìƒì„± (ê¸°ì¡´ core ê¸°ëŠ¥)
        ai_answer = state.ai_candidate_model.generate_answer(answer_request)
        
        if not ai_answer:
            raise HTTPException(status_code=500, detail="AI ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        print(f"âœ… AI ë‹µë³€ ìƒì„± ì™„ë£Œ: {ai_answer.answer_content[:50]}...")
        
        return {
            "question": question_content,
            "questionType": question_type,
            "questionIntent": question_intent,
            "answer": ai_answer.answer_content,
            "time_spent": 60,
            "score": 85,
            "quality_level": ai_answer.quality_level.value,
            "persona_name": ai_answer.persona_name
        }
        
    except Exception as e:
        interview_logger.error(f"AI ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"AI ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# ë¹„êµ ë©´ì ‘ ì—”ë“œí¬ì¸íŠ¸ë“¤
class ComparisonAnswerSubmission(BaseModel):
    """ë¹„êµ ë©´ì ‘ ë‹µë³€ ì œì¶œ ëª¨ë¸"""
    comparison_session_id: str
    answer: str

class AITurnRequest(BaseModel):
    """AI í„´ ì²˜ë¦¬ ìš”ì²­ ëª¨ë¸"""
    comparison_session_id: str
    step: str = "question"  # "question" ë˜ëŠ” "answer"

@app.post("/api/interview/comparison/user-turn")
async def submit_comparison_user_turn(
    answer_data: ComparisonAnswerSubmission,
    state: ApplicationState = Depends(get_app_state)
):
    """ë¹„êµ ë©´ì ‘ ì‚¬ìš©ì í„´ ë‹µë³€ ì œì¶œ - web/app.pyì™€ ë™ì¼í•œ ë°©ì‹"""
    try:
        comparison_session_id = answer_data.comparison_session_id
        answer = answer_data.answer
        
        if not all([comparison_session_id, answer]):
            raise HTTPException(status_code=400, detail="ëª¨ë“  í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ë¹„êµ ì„¸ì…˜ í™•ì¸
        if not hasattr(state, 'comparison_sessions'):
            raise HTTPException(status_code=404, detail="ë¹„êµ ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
        comp_session = state.comparison_sessions.get(comparison_session_id)
        if not comp_session:
            raise HTTPException(status_code=404, detail="ë¹„êµ ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        if comp_session['current_phase'] != 'user_turn':
            raise HTTPException(status_code=400, detail="í˜„ì¬ ì‚¬ìš©ì í„´ì´ ì•„ë‹™ë‹ˆë‹¤")
        
        # ì‚¬ìš©ì ë‹µë³€ ì œì¶œ (ê¸°ì¡´ core ì‹œìŠ¤í…œ ì‚¬ìš©)
        system_result = state.personalized_system.submit_answer(comp_session['user_session_id'], answer)
        
        # ë‹µë³€ ì €ì¥
        comp_session['user_answers'].append({
            'question_index': comp_session['current_question_index'],
            'answer': answer
        })
        
        # AI í„´ìœ¼ë¡œ ì „í™˜
        comp_session['current_phase'] = 'ai_turn'
        
        # ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸° (ì œì¶œ í›„ ìƒì„±ëœ ì§ˆë¬¸)
        next_user_question = None
        if system_result and system_result.get('question'):
            next_user_question = system_result['question']
        else:
            # system_resultì— ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
            next_user_question = state.personalized_system.get_next_question(comp_session['user_session_id'])
        
        return {
            "status": "success",
            "message": "ì‚¬ìš©ì ë‹µë³€ì´ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤",
            "next_phase": "ai_turn",
            "submission_result": system_result,
            "next_user_question": next_user_question  # ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ê°€
        }
        
    except HTTPException:
        raise
    except Exception as e:
        interview_logger.error(f"ì‚¬ìš©ì í„´ ì œì¶œ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë‹µë³€ ì œì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/api/interview/comparison/ai-turn")
async def process_comparison_ai_turn(
    ai_turn_data: AITurnRequest,
    state: ApplicationState = Depends(get_app_state)
):
    """ë¹„êµ ë©´ì ‘ AI í„´ ì²˜ë¦¬ - web/app.pyì™€ ë™ì¼í•œ ë°©ì‹"""
    try:
        comparison_session_id = ai_turn_data.comparison_session_id
        step = ai_turn_data.step
        
        if not comparison_session_id:
            raise HTTPException(status_code=400, detail="ë¹„êµ ì„¸ì…˜ IDê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ë¹„êµ ì„¸ì…˜ í™•ì¸
        if not hasattr(state, 'comparison_sessions'):
            raise HTTPException(status_code=404, detail="ë¹„êµ ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
        comp_session = state.comparison_sessions.get(comparison_session_id)
        if not comp_session:
            raise HTTPException(status_code=404, detail="ë¹„êµ ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        if comp_session['current_phase'] != 'ai_turn':
            raise HTTPException(status_code=400, detail="í˜„ì¬ AI í„´ì´ ì•„ë‹™ë‹ˆë‹¤")
        
        ai_session_id = comp_session['ai_session_id']
        
        if step == 'question':
            # 1ë‹¨ê³„: AI ì§ˆë¬¸ë§Œ ìƒì„± (PersonalizedInterviewSystem ì‚¬ìš©)
            ai_question = state.personalized_system.get_next_question(ai_session_id)
            
            if not ai_question:
                raise HTTPException(status_code=500, detail="AI ì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # ì§ˆë¬¸ì„ ì„¸ì…˜ì— ì„ì‹œ ì €ì¥
            comp_session['temp_ai_question'] = ai_question
            
            return {
                "status": "success",
                "step": "question_generated",
                "ai_question": ai_question,
                "message": "AI ì§ˆë¬¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. 2-3ì´ˆ í›„ ë‹µë³€ì´ ìƒì„±ë©ë‹ˆë‹¤."
            }
            
        elif step == 'answer':
            # 2ë‹¨ê³„: AI ë‹µë³€ ìƒì„± (ì„ì‹œ ì €ì¥ëœ ì§ˆë¬¸ ì‚¬ìš©)
            ai_question = comp_session.get('temp_ai_question')
            if not ai_question:
                raise HTTPException(status_code=400, detail="ì €ì¥ëœ AI ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤")
            
            # AI ë‹µë³€ì„ PersonalizedInterviewSystemì„ í†µí•´ ìƒì„±
            # ë¨¼ì € AICandidateModelë¡œ ë‹µë³€ ìƒì„±
            try:
                from core.ai_candidate_model import AnswerRequest
                from core.interview_system import QuestionType
                from core.answer_quality_controller import QualityLevel
                from core.llm_manager import LLMProvider
                
                # QuestionType ë§¤í•‘
                question_type_map = {
                    "ìê¸°ì†Œê°œ": QuestionType.INTRO,
                    "ì§€ì›ë™ê¸°": QuestionType.MOTIVATION,
                    "INTRO": QuestionType.INTRO,
                    "MOTIVATION": QuestionType.MOTIVATION,
                    "HR": QuestionType.HR,
                    "TECH": QuestionType.TECH,
                    "COLLABORATION": QuestionType.COLLABORATION
                }
                
                # AI ë‹µë³€ ìš”ì²­ ìƒì„±
                answer_request = AnswerRequest(
                    question_content=ai_question["question_content"],
                    question_type=question_type_map.get(ai_question["question_type"], QuestionType.HR),
                    question_intent=ai_question["question_intent"],
                    company_id=comp_session.get('user_session_id', 'naver').split('_')[0],  # company ì¶”ì¶œ
                    position="AIì§€ì›ì",
                    quality_level=QualityLevel.GOOD,
                    llm_provider=LLMProvider.OPENAI_GPT4O_MINI
                )
                
                # AI ë‹µë³€ ìƒì„±
                ai_answer_response = state.ai_candidate_model.generate_answer(answer_request)
                
                # PersonalizedInterviewSystemì— ë‹µë³€ ì œì¶œ (ê°„ë‹¨í•œ ë¬¸ìì—´ ë‹µë³€ë§Œ)
                submission_result = state.personalized_system.submit_answer(ai_session_id, ai_answer_response.answer_content)
                
            except Exception as e:
                print(f"âŒ AI ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
                raise HTTPException(status_code=500, detail=f"AI ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            
            if ai_answer_response.error:
                raise HTTPException(status_code=500, detail=f"AI ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {ai_answer_response.error}")
            
            # ë‹µë³€ ì €ì¥
            comp_session['ai_answers'].append({
                'question_index': comp_session['current_question_index'],
                'question': ai_question['question_content'],
                'answer': ai_answer_response.answer_content
            })
            
            # ì„ì‹œ ì§ˆë¬¸ ì‚­ì œ
            if 'temp_ai_question' in comp_session:
                del comp_session['temp_ai_question']
            
            # ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ì§„í–‰
            comp_session['current_question_index'] += 1
            
            # ë©´ì ‘ ì™„ë£Œ í™•ì¸
            if comp_session['current_question_index'] > comp_session['total_questions']:
                comp_session['current_phase'] = 'completed'
                return {
                    "status": "success",
                    "step": "answer_generated",
                    "interview_status": "completed",
                    "ai_question": ai_question,
                    "ai_answer": {
                        "content": ai_answer_response.answer_content,
                        "persona_name": ai_answer_response.persona_name,
                        "confidence": ai_answer_response.confidence_score
                    },
                    "message": "ë¹„êµ ë©´ì ‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤"
                }
            else:
                # ë‹¤ìŒ ì‚¬ìš©ì í„´ ì¤€ë¹„
                comp_session['current_phase'] = 'user_turn'
                
                # ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°
                next_user_question = state.personalized_system.get_next_question(comp_session['user_session_id'])
                
                print(f"ğŸ” AI í„´ ì™„ë£Œ í›„ ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸: {next_user_question}")
                
                return {
                    "status": "success",
                    "step": "answer_generated", 
                    "interview_status": "continue",
                    "ai_question": ai_question,
                    "ai_answer": {
                        "content": ai_answer_response.answer_content,
                        "persona_name": ai_answer_response.persona_name,
                        "confidence": ai_answer_response.confidence_score
                    },
                    "next_user_question": next_user_question,
                    "next_phase": "user_turn",
                    "current_question_index": comp_session['current_question_index']
                }
        else:
            raise HTTPException(status_code=400, detail="ìœ íš¨í•˜ì§€ ì•Šì€ step ê°’ì…ë‹ˆë‹¤")
            
    except HTTPException:
        raise
    except Exception as e:
        interview_logger.error(f"AI í„´ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"AI í„´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.get("/api/interview/history")
async def get_interview_history(
    user_id: Optional[str] = None,
    state: ApplicationState = Depends(get_app_state)
):
    """ë©´ì ‘ ê¸°ë¡ ì¡°íšŒ"""
    try:
        # ì™„ë£Œëœ ì„¸ì…˜ë“¤ í•„í„°ë§ - ì›ë˜ ì„¤ê³„ ë³µêµ¬
        completed_sessions = []
        
        # PersonalizedInterviewSystemì˜ ì™„ë£Œëœ ì„¸ì…˜ë“¤ ê°€ì ¸ì˜¤ê¸°
        for session_id, session in state.personalized_system.sessions.items():
            if session.is_completed():
                completed_sessions.append({
                    "session_id": session_id,
                    "settings": {
                        "company": session.company_id,
                        "position": session.position,
                        "user_name": session.candidate_name
                    },
                    "completed_at": session.created_at,
                    "total_score": 85,  # ê¸°ë³¸ê°’
                    "type": "personalized"
                })
        
        return {
            "total_interviews": len(completed_sessions),
            "interviews": completed_sessions
        }
        
    except Exception as e:
        interview_logger.error(f"ê¸°ë¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ê¸°ë¡ì„ ì¡°íšŒí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# í—¬í¼ í•¨ìˆ˜ë“¤

async def generate_personalized_profile(documents: List[str], state: ApplicationState) -> Dict:
    """ë¬¸ì„œ ê¸°ë°˜ ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„±"""
    try:
        doc_processor = state.document_processor
        profile = None
        
        for doc_path in documents:
            if os.path.exists(doc_path):
                profile = await asyncio.to_thread(doc_processor.process_document, doc_path)
                break
        
        if not profile:
            # ê¸°ë³¸ í”„ë¡œí•„ ìƒì„±
            profile = {
                "name": "ì§€ì›ì",
                "background": {"career_years": 3, "education": "ëŒ€í•™êµ ì¡¸ì—…"},
                "technical_skills": ["Java", "Spring", "MySQL"],
                "projects": [{"name": "ì›¹ ì„œë¹„ìŠ¤ ê°œë°œ", "description": "ë°±ì—”ë“œ API ê°œë°œ"}],
                "experiences": [{"company": "ì´ì „ íšŒì‚¬", "role": "ë°±ì—”ë“œ ê°œë°œì", "duration": "2ë…„"}],
                "strengths": ["ë¬¸ì œí•´ê²°ëŠ¥ë ¥", "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜"],
                "keywords": ["ê°œë°œ", "í˜‘ì—…", "ì„±ì¥"],
                "career_goal": "ì‹œë‹ˆì–´ ê°œë°œìë¡œ ì„±ì¥",
                "unique_points": ["ë¹ ë¥¸ í•™ìŠµ ëŠ¥ë ¥"]
            }
        
        return profile
        
    except Exception as e:
        interview_logger.error(f"í”„ë¡œí•„ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return None

async def generate_personalized_questions(profile: Dict, settings: InterviewSettings, state: ApplicationState) -> List[Dict]:
    """ê°œì¸í™”ëœ ì§ˆë¬¸ ìƒì„±"""
    try:
        personalized_system = state.personalized_system
        
        # ê°œì¸í™”ëœ ë©´ì ‘ ì‹œì‘
        session_id = await asyncio.to_thread(
            personalized_system.start_personalized_interview,
            settings.company,
            settings.position,
            profile.get('name', 'ì§€ì›ì'),
            profile
        )
        
        questions = []
        question_count = 0
        max_questions = 15  # ìµœëŒ€ ì§ˆë¬¸ ìˆ˜
        
        while question_count < max_questions:
            try:
                question_data = await asyncio.to_thread(
                    personalized_system.get_next_question,
                    session_id
                )
                
                if not question_data or 'question_content' not in question_data:
                    break
                
                # ê³ ìœ í•œ ID ìƒì„±
                import uuid
                unique_id = f"q{question_count + 1}_{uuid.uuid4().hex[:8]}"
                
                question = {
                    "id": unique_id,
                    "question": question_data['question_content'],
                    "category": question_data.get('question_intent', 'ê¸°ë³¸'),
                    "time_limit": 180,
                    "keywords": question_data.get('keywords', []),
                    "personalized": question_data.get('personalized', False),
                    "progress": question_data.get('progress', 0)
                }
                
                print(f"ğŸ“ ì§ˆë¬¸ #{question_count + 1} ìƒì„±: ID={unique_id}, Q={question_data['question_content'][:50]}...")
                questions.append(question)
                question_count += 1
                
            except Exception as e:
                interview_logger.error(f"ì§ˆë¬¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")
                break
        
        # ìµœì†Œ ì§ˆë¬¸ ìˆ˜ ë³´ì¥
        if len(questions) < 5:
            standard_questions, _ = await generate_standard_interview_questions(settings, state)
            questions.extend(standard_questions[len(questions):])
        
        return questions[:max_questions], session_id
        
    except Exception as e:
        interview_logger.error(f"ê°œì¸í™” ì§ˆë¬¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return await generate_basic_questions(settings, state), None

async def generate_standard_interview_questions(settings: InterviewSettings, state: ApplicationState):
    """í‘œì¤€ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (Fixed + LLM ì¡°í•©)"""
    try:
        personalized_system = state.personalized_system
        company_id = get_company_id(settings.company)
        
        # DocumentProcessorì˜ UserProfile í˜•ì‹ìœ¼ë¡œ ìƒì„±
        from core.document_processor import UserProfile
        
        basic_profile = UserProfile(
            name=settings.user_name,
            background={"career_years": 3, "education": "ëŒ€í•™êµ ì¡¸ì—…"},
            technical_skills=["Java", "Python", "JavaScript"],
            projects=[{"name": "ì›¹ ê°œë°œ í”„ë¡œì íŠ¸", "description": "ê¸°ë³¸ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ"}],
            experiences=[{"company": "ì´ì „ íšŒì‚¬", "role": "ê°œë°œì", "duration": "2ë…„"}],
            strengths=["ë¬¸ì œí•´ê²°", "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜"],
            keywords=["ê°œë°œ", "í˜‘ì—…", "ì„±ì¥"],
            career_goal="ì‹œë‹ˆì–´ ê°œë°œìë¡œ ì„±ì¥",
            unique_points=["ë¹ ë¥¸ í•™ìŠµ ëŠ¥ë ¥"]
        )
        
        # PersonalizedInterviewSystemìœ¼ë¡œ ì§ˆë¬¸ ìƒì„±
        session_id = await asyncio.to_thread(
            personalized_system.start_personalized_interview,
            company_id,
            settings.position,
            settings.user_name,
            basic_profile
        )
        
        questions = []
        question_count = 0
        max_questions = 10
        
        print(f"ğŸš€ PersonalizedInterviewSystem ì§ˆë¬¸ ìƒì„± ì‹œì‘ - session_id: {session_id}")
        
        while question_count < max_questions:
            try:
                print(f"ğŸ”„ ì§ˆë¬¸ #{question_count + 1} ìƒì„± ì‹œë„ ì¤‘...")
                question_data = await asyncio.to_thread(
                    personalized_system.get_next_question,
                    session_id
                )
                
                print(f"ğŸ“ ì§ˆë¬¸ ë°ì´í„° ë°›ìŒ: {question_data}")
                
                if not question_data or 'question_content' not in question_data:
                    print(f"âŒ ì§ˆë¬¸ ë°ì´í„° ì—†ìŒ ë˜ëŠ” invalid: {question_data}")
                    break
                
                # ê³ ìœ í•œ ID ìƒì„±
                import uuid
                unique_id = f"q{question_count + 1}_{uuid.uuid4().hex[:8]}"
                
                question = {
                    "id": unique_id,
                    "question": question_data['question_content'],
                    "category": question_data.get('question_intent', 'ê¸°ë³¸'),
                    "time_limit": 180,
                    "keywords": question_data.get('keywords', []),
                    "personalized": question_data.get('personalized', False),
                    "progress": question_data.get('progress', 0)
                }
                
                print(f"ğŸ“ ì§ˆë¬¸ #{question_count + 1} ìƒì„±: ID={unique_id}, Q={question_data['question_content'][:50]}...")
                questions.append(question)
                question_count += 1
                
            except Exception as e:
                interview_logger.error(f"í‘œì¤€ ì§ˆë¬¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")
                break
        
        # ìµœì†Œ ì§ˆë¬¸ ìˆ˜ ë³´ì¥ (ì¤‘ë³µ ì œê±°)
        if len(questions) < 5:
            basic_questions = await generate_basic_questions(settings, state)
            
            # ê¸°ì¡´ ì§ˆë¬¸ ë‚´ìš©ê³¼ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ì§ˆë¬¸ë§Œ ì¶”ê°€
            existing_questions = {q["question"].lower() for q in questions}
            
            for basic_q in basic_questions:
                if len(questions) >= 10:  # ìµœëŒ€ 10ê°œ ì œí•œ
                    break
                if basic_q["question"].lower() not in existing_questions:
                    questions.append(basic_q)
        
        return questions[:max_questions], session_id
        
    except Exception as e:
        interview_logger.error(f"í‘œì¤€ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return await generate_basic_questions(settings, state), None

async def generate_basic_questions(settings: InterviewSettings, state: ApplicationState) -> List[Dict]:
    """ê¸°ë³¸ ì§ˆë¬¸ ìƒì„± (Fallback)"""
    import uuid
    # ê¸°ë³¸ ì§ˆë¬¸ í…œí”Œë¦¿ (ê³ ìœ  ID ìƒì„±)
    base_questions = [
        {
            "id": f"basic_{uuid.uuid4().hex[:8]}_1",
            "question": "ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”.",
            "category": "ê¸°ë³¸",
            "time_limit": 120,
            "keywords": ["ê²½í—˜", "ê¸°ìˆ ", "ì—­í• ", "í”„ë¡œì íŠ¸", "ì„±ê³¼"]
        },
        {
            "id": f"basic_{uuid.uuid4().hex[:8]}_2",
            "question": f"{settings.company}ì— ì§€ì›í•œ ì´ìœ ê°€ ë¬´ì—‡ì¸ê°€ìš”?",
            "category": "ë™ê¸°",
            "time_limit": 90,
            "keywords": ["ê´€ì‹¬", "ê¸°ì—¬", "ì„±ì¥", "ë¹„ì „", "ëª©í‘œ"]
        },
        {
            "id": f"basic_{uuid.uuid4().hex[:8]}_3",
            "question": "ê°€ì¥ ì–´ë ¤ì› ë˜ ê¸°ìˆ ì  ë¬¸ì œë¥¼ ì–´ë–»ê²Œ í•´ê²°í–ˆë‚˜ìš”?",
            "category": "ê¸°ìˆ ",
            "time_limit": 180,
            "keywords": ["ë¬¸ì œ", "í•´ê²°", "ì ‘ê·¼", "ê²°ê³¼", "í•™ìŠµ"]
        },
        {
            "id": f"basic_{uuid.uuid4().hex[:8]}_4",
            "question": "íŒ€ì›Œí¬ ê²½í—˜ì— ëŒ€í•´ ë§ì”€í•´ì£¼ì„¸ìš”.",
            "category": "í˜‘ì—…",
            "time_limit": 120,
            "keywords": ["í˜‘ì—…", "ì†Œí†µ", "ê°ˆë“±", "í•´ê²°", "ì„±ê³¼"]
        },
        {
            "id": f"basic_{uuid.uuid4().hex[:8]}_5",
            "question": "5ë…„ í›„ ìì‹ ì˜ ëª¨ìŠµì„ ì–´ë–»ê²Œ ê·¸ë¦¬ê³  ìˆë‚˜ìš”?",
            "category": "ë¯¸ë˜",
            "time_limit": 90,
            "keywords": ["ëª©í‘œ", "ê³„íš", "ì„±ì¥", "ì „ë¬¸ì„±", "ë¹„ì „"]
        }
    ]
    
    return base_questions

async def analyze_document_async(file_path: Path, state: ApplicationState) -> Dict:
    """ë¬¸ì„œ ë¶„ì„ (ë¹„ë™ê¸°)"""
    try:
        result = await asyncio.get_event_loop().run_in_executor(
            None,
            state.document_processor.process_document,
            str(file_path)
        )
        return result
    except Exception as e:
        interview_logger.error(f"ë¬¸ì„œ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return {}

async def evaluate_answer_async(answer_record: Dict, session: Dict, state: ApplicationState):
    """ë‹µë³€ í‰ê°€ (ë¹„ë™ê¸°)"""
    try:
        # AI í‰ê°€ ìˆ˜í–‰
        evaluation = await asyncio.get_event_loop().run_in_executor(
            None,
            state.ai_candidate_model.evaluate_answer,
            answer_record["answer"]
        )
        
        # í‰ê°€ ê²°ê³¼ ì €ì¥
        answer_record["evaluation"] = evaluation
        
        interview_logger.info(f"ë‹µë³€ í‰ê°€ ì™„ë£Œ", question_id=answer_record["question_id"])
        
    except Exception as e:
        interview_logger.error(f"ë‹µë³€ í‰ê°€ ì˜¤ë¥˜: {str(e)}")

def calculate_basic_score(answer: str, time_spent: int) -> int:
    """ê¸°ë³¸ ì ìˆ˜ ê³„ì‚°"""
    score = 0
    
    # ë‹µë³€ ê¸¸ì´ ì ìˆ˜ (30ì )
    answer_length = len(answer)
    if answer_length > 200:
        score += 30
    elif answer_length > 100:
        score += 20
    elif answer_length > 50:
        score += 10
    
    # ì‹œê°„ í™œìš© ì ìˆ˜ (30ì )
    time_ratio = time_spent / 120  # ê¸°ë³¸ 2ë¶„ ê°€ì •
    if time_ratio > 0.7:
        score += 30
    elif time_ratio > 0.5:
        score += 20
    elif time_ratio > 0.3:
        score += 10
    
    # ê¸°ë³¸ ì ìˆ˜ (40ì )
    score += 40
    
    return min(score, 100)

async def generate_interview_results(session_mapping: Dict[str, str], state: ApplicationState) -> Dict:
    """ë©´ì ‘ ê²°ê³¼ ìƒì„± - ì›ë˜ ì„¤ê³„ ë³µêµ¬"""
    try:
        human_session_id = session_mapping["human_session_id"]
        human_session = state.personalized_system.get_session(human_session_id)
        
        if not human_session:
            raise ValueError("ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ê¸°ë³¸ ê²°ê³¼ ìƒì„±
        answers = human_session.question_answers
        total_score = 85  # ê¸°ë³¸ê°’
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ (ê°„ë‹¨ ë²„ì „)
        category_scores = {
            "ì¸ì‚¬": 80,
            "ê¸°ìˆ ": 85, 
            "í˜‘ì—…": 90
        }
        
        # ìƒì„¸ í”¼ë“œë°± (ê°„ë‹¨ ë²„ì „)
        detailed_feedback = []
        for qa in answers:
            feedback = {
                "question": qa.question_content,
                "answer": qa.answer_content,
                "score": 85,
                "feedback": "ì˜ ë‹µë³€í•˜ì…¨ìŠµë‹ˆë‹¤.",
                "strengths": ["êµ¬ì²´ì ì¸ ì„¤ëª…"],
                "improvements": ["ë” ìì„¸í•œ ì˜ˆì‹œ"]
            }
            detailed_feedback.append(feedback)
        
        # ì¶”ì²œì‚¬í•­
        recommendations = [
            "êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ ë” ë§ì´ ì¤€ë¹„í•˜ì„¸ìš”",
            "ê¸°ìˆ ì  ê¹Šì´ë¥¼ ë” ë³´ì™„í•˜ì„¸ìš”", 
            "íšŒì‚¬ì— ëŒ€í•œ ì´í•´ë„ë¥¼ ë†’ì´ì„¸ìš”"
        ]
        
        return {
            "session_id": human_session_id,
            "total_score": total_score,
            "category_scores": category_scores,
            "detailed_feedback": detailed_feedback,
            "recommendations": recommendations,
            "interview_info": {
                "company": human_session.company_id,
                "position": human_session.position,
                "user_name": human_session.candidate_name
            }
        }
        
    except Exception as e:
        interview_logger.error(f"ê²°ê³¼ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        raise

async def get_ai_candidate_info(company: str, quality_level: int, state: ApplicationState) -> Dict:
    """AI ì§€ì›ì ì •ë³´ ì¡°íšŒ"""
    try:
        # íšŒì‚¬ë³„ AI ì§€ì›ì ë°ì´í„° ë¡œë“œ
        companies_data_path = Path("data/companies_data.json")
        if companies_data_path.exists():
            with open(companies_data_path, 'r', encoding='utf-8') as f:
                companies_data = json.load(f)
            
            # companies_data êµ¬ì¡°ê°€ list í˜•íƒœì¼ ìˆ˜ ìˆìŒ
            companies_list = companies_data.get("companies", []) if isinstance(companies_data.get("companies"), list) else []
            company_data = next((c for c in companies_list if c.get("id") == company.lower()), {})
            ai_personas = company_data.get("ai_personas", [])
            
            if ai_personas:
                persona = ai_personas[0]  # ì²« ë²ˆì§¸ AI ì§€ì›ì ì‚¬ìš©
                return {
                    "name": persona.get("name", "ì¶˜ì‹ì´"),
                    "experience": persona.get("experience", "3ë…„"),
                    "specialties": persona.get("specialties", ["ê°œë°œ", "ë¬¸ì œí•´ê²°"]),
                    "quality_level": quality_level,
                    "quality_description": get_quality_description(quality_level),
                    "avatar": "ğŸ¤–",
                    "company": company
                }
        
        # ê¸°ë³¸ AI ì§€ì›ì ì •ë³´
        return {
            "name": "ì¶˜ì‹ì´",
            "experience": "3ë…„",
            "specialties": ["ë°±ì—”ë“œ ê°œë°œ", "ì‹œìŠ¤í…œ ì„¤ê³„"],
            "quality_level": quality_level,
            "quality_description": get_quality_description(quality_level),
            "avatar": "ğŸ¤–",
            "company": company
        }
        
    except Exception as e:
        interview_logger.error(f"AI ì§€ì›ì ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return {
            "name": "ì¶˜ì‹ì´",
            "experience": "3ë…„",
            "specialties": ["ê°œë°œ"],
            "quality_level": quality_level,
            "quality_description": "ì¤‘ê¸‰",
            "avatar": "ğŸ¤–",
            "company": company
        }

def get_quality_description(level: int) -> str:
    """í’ˆì§ˆ ë ˆë²¨ ì„¤ëª…"""
    quality_map = {
        1: "ë§¤ìš° ë¶€ì¡±í•¨",
        2: "ë¶€ì¡±í•¨", 
        3: "ë³´í†µ ì´í•˜",
        4: "ë³´í†µ",
        5: "ë³´í†µ ì´ìƒ",
        6: "ì¢‹ìŒ",
        7: "ë§¤ìš° ì¢‹ìŒ",
        8: "ìš°ìˆ˜í•¨",
        9: "ë§¤ìš° ìš°ìˆ˜í•¨",
        10: "ìµœê³  ìˆ˜ì¤€"
    }
    return quality_map.get(level, "ë³´í†µ")

# ë‹µë³€ í‰ê°€
async def evaluate_answer_async(answer: str, question: Dict, session_id: str, state: ApplicationState):
    """ë¹„ë™ê¸° ë‹µë³€ í‰ê°€"""
    try:
        # PersonalizedInterviewSystemì„ ì‚¬ìš©í•œ ì‹¤ì œ í‰ê°€
        session = state.get_session(session_id)
        personalized_session_id = session.get("personalized_session_id")
        
        if personalized_session_id:
            personalized_system = state.personalized_system
            
            # ë‹µë³€ ì œì¶œ ë° í‰ê°€
            evaluation = await asyncio.to_thread(
                personalized_system.submit_answer,
                personalized_session_id,
                question['id'],
                answer
            )
            
            if evaluation:
                return {
                    "score": evaluation.get('score', 70),
                    "feedback": evaluation.get('feedback', 'ë‹µë³€ì´ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤.'),
                    "detailed_evaluation": evaluation.get('detailed_feedback', 'í‰ê°€ ì™„ë£Œ'),
                    "strengths": evaluation.get('strengths', []),
                    "improvements": evaluation.get('improvements', []),
                    "category_scores": evaluation.get('category_scores', {})
                }
        
        # ê¸°ë³¸ í‰ê°€ ë¡œì§
        score = 70
        if len(answer) > 100:
            score += 10
        if any(keyword in answer for keyword in question.get('keywords', [])):
            score += 15
        
        return {
            "score": min(score, 100),
            "feedback": "ë‹µë³€ì´ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "detailed_evaluation": "ê¸°ë³¸ í‰ê°€ ì™„ë£Œ",
            "strengths": ["ë‹µë³€ ì œì¶œ ì™„ë£Œ"],
            "improvements": ["ë” ìì„¸í•œ ì„¤ëª… ì¶”ê°€"],
            "category_scores": {}
        }
        
    except Exception as e:
        interview_logger.error(f"ë‹µë³€ í‰ê°€ ì˜¤ë¥˜: {str(e)}")
        return {
            "score": 0,
            "feedback": "í‰ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "detailed_evaluation": "ì˜¤ë¥˜",
            "strengths": [],
            "improvements": [],
            "category_scores": {}
        }

if __name__ == "__main__":
    import uvicorn
    
    print("ğŸš€ Beta-GO Interview FastAPI ì‹œì‘!")
    print("ğŸ“± ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8000 ì ‘ì†")
    print("ğŸ“š API ë¬¸ì„œ: http://localhost:8000/docs")
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )