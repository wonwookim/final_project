#!/usr/bin/env python3
"""
AI ì§€ì›ì ì„¤ì • ê´€ë¦¬ ëª¨ë“ˆ
LLM ëª¨ë¸ ì„¤ì •, ë‹µë³€ í’ˆì§ˆ ì¡°ì ˆ, í˜ë¥´ì†Œë‚˜ ì„¤ì • ë“±ì„ ì¤‘ì•™ ê´€ë¦¬
"""

import json
import os
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from enum import Enum

from .llm_manager import LLMProvider
from .answer_quality_controller import QualityLevel

@dataclass
class ModelSettings:
    """LLM ëª¨ë¸ë³„ ì„¤ì •"""
    provider: LLMProvider
    enabled: bool = True
    api_key: Optional[str] = None
    max_tokens: int = 600
    temperature: float = 0.7
    timeout: float = 30.0
    custom_params: Dict[str, Any] = None

@dataclass
class QualitySettings:
    """í’ˆì§ˆ ì„¤ì •"""
    default_level: QualityLevel = QualityLevel.GOOD
    min_answer_length: int = 50
    max_answer_length: int = 500
    enable_post_processing: bool = True
    quality_check_enabled: bool = True

@dataclass
class PersonaSettings:
    """í˜ë¥´ì†Œë‚˜ ì„¤ì •"""
    use_real_personas: bool = True
    fallback_to_default: bool = True
    persona_data_path: str = "llm/data/candidate_personas.json"
    enable_persona_validation: bool = True

@dataclass
class AnswerSettings:
    """ë‹µë³€ ìƒì„± ì„¤ì •"""
    include_confidence_score: bool = True
    enable_answer_comparison: bool = True
    max_retries: int = 3
    enable_fallback_answers: bool = True
    answer_cache_enabled: bool = True
    cache_duration_minutes: int = 60

@dataclass
class LoggingSettings:
    """ë¡œê¹… ì„¤ì •"""
    log_level: str = "INFO"
    log_requests: bool = True
    log_responses: bool = True
    log_performance: bool = True
    log_file_path: str = "logs/ai_candidate.log"

class AICandidateConfig:
    """AI ì§€ì›ì ì„¤ì • ê´€ë¦¬ì"""
    
    def __init__(self, config_file: str = "config/ai_candidate_config.json"):
        self.config_file = config_file
        self.model_settings: Dict[LLMProvider, ModelSettings] = {}
        self.quality_settings = QualitySettings()
        self.persona_settings = PersonaSettings()
        self.answer_settings = AnswerSettings()
        self.logging_settings = LoggingSettings()
        
        # ê¸°ë³¸ ì„¤ì • ì´ˆê¸°í™”
        self._initialize_default_settings()
        
        # ì„¤ì • íŒŒì¼ì—ì„œ ë¡œë“œ
        self.load_config()
    
    def _initialize_default_settings(self):
        """ê¸°ë³¸ ì„¤ì • ì´ˆê¸°í™”"""
        
        # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
        default_models = {
            LLMProvider.OPENAI_GPT4O_MINI: ModelSettings(
                provider=LLMProvider.OPENAI_GPT4O_MINI,
                enabled=True,
                max_tokens=600,
                temperature=0.7,
                timeout=30.0
            ),
            LLMProvider.OPENAI_GPT4: ModelSettings(
                provider=LLMProvider.OPENAI_GPT4,
                enabled=False,  # ê¸°ë³¸ì ìœ¼ë¡œ ë¹„í™œì„±í™” (ë¹„ìš© ë•Œë¬¸)
                max_tokens=800,
                temperature=0.6,
                timeout=45.0
            ),
            LLMProvider.OPENAI_GPT35: ModelSettings(
                provider=LLMProvider.OPENAI_GPT35,
                enabled=True,
                max_tokens=500,
                temperature=0.8,
                timeout=25.0
            ),
            LLMProvider.GOOGLE_GEMINI_PRO: ModelSettings(
                provider=LLMProvider.GOOGLE_GEMINI_PRO,
                enabled=False,  # API ë¯¸êµ¬í˜„
                max_tokens=700,
                temperature=0.7,
                timeout=35.0
            ),
            LLMProvider.KT_BELIEF: ModelSettings(
                provider=LLMProvider.KT_BELIEF,
                enabled=False,  # API ë¯¸êµ¬í˜„
                max_tokens=600,
                temperature=0.7,
                timeout=40.0
            )
        }
        
        self.model_settings = default_models
    
    def load_config(self) -> bool:
        """ì„¤ì • íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œ"""
        try:
            if not os.path.exists(self.config_file):
                self.save_config()  # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ íŒŒì¼ ìƒì„±
                return True
            
            with open(self.config_file, 'r', encoding='utf-8') as f:
                config_data = json.load(f)
            
            # ëª¨ë¸ ì„¤ì • ë¡œë“œ
            if 'model_settings' in config_data:
                for provider_name, settings in config_data['model_settings'].items():
                    try:
                        provider = LLMProvider(provider_name)
                        self.model_settings[provider] = ModelSettings(
                            provider=provider,
                            enabled=settings.get('enabled', True),
                            api_key=settings.get('api_key'),
                            max_tokens=settings.get('max_tokens', 600),
                            temperature=settings.get('temperature', 0.7),
                            timeout=settings.get('timeout', 30.0),
                            custom_params=settings.get('custom_params')
                        )
                    except ValueError:
                        print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” LLM Provider: {provider_name}")
            
            # í’ˆì§ˆ ì„¤ì • ë¡œë“œ
            if 'quality_settings' in config_data:
                qs = config_data['quality_settings']
                self.quality_settings = QualitySettings(
                    default_level=QualityLevel(qs.get('default_level', 8)),
                    min_answer_length=qs.get('min_answer_length', 50),
                    max_answer_length=qs.get('max_answer_length', 500),
                    enable_post_processing=qs.get('enable_post_processing', True),
                    quality_check_enabled=qs.get('quality_check_enabled', True)
                )
            
            # í˜ë¥´ì†Œë‚˜ ì„¤ì • ë¡œë“œ
            if 'persona_settings' in config_data:
                ps = config_data['persona_settings']
                self.persona_settings = PersonaSettings(
                    use_real_personas=ps.get('use_real_personas', True),
                    fallback_to_default=ps.get('fallback_to_default', True),
                    persona_data_path=ps.get('persona_data_path', "llm/data/candidate_personas.json"),
                    enable_persona_validation=ps.get('enable_persona_validation', True)
                )
            
            # ë‹µë³€ ì„¤ì • ë¡œë“œ
            if 'answer_settings' in config_data:
                ans = config_data['answer_settings']
                self.answer_settings = AnswerSettings(
                    include_confidence_score=ans.get('include_confidence_score', True),
                    enable_answer_comparison=ans.get('enable_answer_comparison', True),
                    max_retries=ans.get('max_retries', 3),
                    enable_fallback_answers=ans.get('enable_fallback_answers', True),
                    answer_cache_enabled=ans.get('answer_cache_enabled', True),
                    cache_duration_minutes=ans.get('cache_duration_minutes', 60)
                )
            
            # ë¡œê¹… ì„¤ì • ë¡œë“œ
            if 'logging_settings' in config_data:
                ls = config_data['logging_settings']
                self.logging_settings = LoggingSettings(
                    log_level=ls.get('log_level', "INFO"),
                    log_requests=ls.get('log_requests', True),
                    log_responses=ls.get('log_responses', True),
                    log_performance=ls.get('log_performance', True),
                    log_file_path=ls.get('log_file_path', "logs/ai_candidate.log")
                )
            
            print(f"âœ… ì„¤ì • íŒŒì¼ì—ì„œ ë¡œë“œ ì™„ë£Œ: {self.config_file}")
            return True
            
        except Exception as e:
            print(f"âŒ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def save_config(self) -> bool:
        """í˜„ì¬ ì„¤ì •ì„ íŒŒì¼ì— ì €ì¥"""
        try:
            # ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(os.path.dirname(self.config_file), exist_ok=True)
            
            config_data = {
                "model_settings": {
                    provider.value: {
                        "enabled": settings.enabled,
                        "api_key": settings.api_key,
                        "max_tokens": settings.max_tokens,
                        "temperature": settings.temperature,
                        "timeout": settings.timeout,
                        "custom_params": settings.custom_params
                    }
                    for provider, settings in self.model_settings.items()
                },
                "quality_settings": {
                    "default_level": self.quality_settings.default_level.value,
                    "min_answer_length": self.quality_settings.min_answer_length,
                    "max_answer_length": self.quality_settings.max_answer_length,
                    "enable_post_processing": self.quality_settings.enable_post_processing,
                    "quality_check_enabled": self.quality_settings.quality_check_enabled
                },
                "persona_settings": {
                    "use_real_personas": self.persona_settings.use_real_personas,
                    "fallback_to_default": self.persona_settings.fallback_to_default,
                    "persona_data_path": self.persona_settings.persona_data_path,
                    "enable_persona_validation": self.persona_settings.enable_persona_validation
                },
                "answer_settings": {
                    "include_confidence_score": self.answer_settings.include_confidence_score,
                    "enable_answer_comparison": self.answer_settings.enable_answer_comparison,
                    "max_retries": self.answer_settings.max_retries,
                    "enable_fallback_answers": self.answer_settings.enable_fallback_answers,
                    "answer_cache_enabled": self.answer_settings.answer_cache_enabled,
                    "cache_duration_minutes": self.answer_settings.cache_duration_minutes
                },
                "logging_settings": {
                    "log_level": self.logging_settings.log_level,
                    "log_requests": self.logging_settings.log_requests,
                    "log_responses": self.logging_settings.log_responses,
                    "log_performance": self.logging_settings.log_performance,
                    "log_file_path": self.logging_settings.log_file_path
                }
            }
            
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… ì„¤ì • íŒŒì¼ ì €ì¥ ì™„ë£Œ: {self.config_file}")
            return True
            
        except Exception as e:
            print(f"âŒ ì„¤ì • ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def update_model_setting(self, provider: LLMProvider, **kwargs) -> bool:
        """ëª¨ë¸ ì„¤ì • ì—…ë°ì´íŠ¸"""
        try:
            if provider not in self.model_settings:
                print(f"âš ï¸ ëª¨ë¸ {provider.value}ì´ ë“±ë¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return False
            
            settings = self.model_settings[provider]
            
            for key, value in kwargs.items():
                if hasattr(settings, key):
                    setattr(settings, key, value)
                    print(f"âœ… {provider.value} {key} ì„¤ì •ì„ {value}ë¡œ ë³€ê²½")
                else:
                    print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì„¤ì • í•­ëª©: {key}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì„¤ì • ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def set_api_key(self, provider: LLMProvider, api_key: str) -> bool:
        """API í‚¤ ì„¤ì •"""
        return self.update_model_setting(provider, api_key=api_key)
    
    def enable_model(self, provider: LLMProvider) -> bool:
        """ëª¨ë¸ í™œì„±í™”"""
        return self.update_model_setting(provider, enabled=True)
    
    def disable_model(self, provider: LLMProvider) -> bool:
        """ëª¨ë¸ ë¹„í™œì„±í™”"""
        return self.update_model_setting(provider, enabled=False)
    
    def get_enabled_models(self) -> List[LLMProvider]:
        """í™œì„±í™”ëœ ëª¨ë¸ ëª©ë¡"""
        return [provider for provider, settings in self.model_settings.items() 
                if settings.enabled]
    
    def get_model_setting(self, provider: LLMProvider) -> Optional[ModelSettings]:
        """ëª¨ë¸ ì„¤ì • ì¡°íšŒ"""
        return self.model_settings.get(provider)
    
    def update_quality_setting(self, **kwargs) -> bool:
        """í’ˆì§ˆ ì„¤ì • ì—…ë°ì´íŠ¸"""
        try:
            for key, value in kwargs.items():
                if hasattr(self.quality_settings, key):
                    if key == 'default_level' and isinstance(value, int):
                        value = QualityLevel(value)
                    setattr(self.quality_settings, key, value)
                    print(f"âœ… í’ˆì§ˆ ì„¤ì • {key}ë¥¼ {value}ë¡œ ë³€ê²½")
                else:
                    print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” í’ˆì§ˆ ì„¤ì • í•­ëª©: {key}")
            return True
        except Exception as e:
            print(f"âŒ í’ˆì§ˆ ì„¤ì • ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def update_persona_setting(self, **kwargs) -> bool:
        """í˜ë¥´ì†Œë‚˜ ì„¤ì • ì—…ë°ì´íŠ¸"""
        try:
            for key, value in kwargs.items():
                if hasattr(self.persona_settings, key):
                    setattr(self.persona_settings, key, value)
                    print(f"âœ… í˜ë¥´ì†Œë‚˜ ì„¤ì • {key}ë¥¼ {value}ë¡œ ë³€ê²½")
                else:
                    print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” í˜ë¥´ì†Œë‚˜ ì„¤ì • í•­ëª©: {key}")
            return True
        except Exception as e:
            print(f"âŒ í˜ë¥´ì†Œë‚˜ ì„¤ì • ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def update_answer_setting(self, **kwargs) -> bool:
        """ë‹µë³€ ì„¤ì • ì—…ë°ì´íŠ¸"""
        try:
            for key, value in kwargs.items():
                if hasattr(self.answer_settings, key):
                    setattr(self.answer_settings, key, value)
                    print(f"âœ… ë‹µë³€ ì„¤ì • {key}ë¥¼ {value}ë¡œ ë³€ê²½")
                else:
                    print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë‹µë³€ ì„¤ì • í•­ëª©: {key}")
            return True
        except Exception as e:
            print(f"âŒ ë‹µë³€ ì„¤ì • ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def get_config_summary(self) -> Dict[str, Any]:
        """ì„¤ì • ìš”ì•½ ì •ë³´"""
        enabled_models = self.get_enabled_models()
        
        return {
            "enabled_models": [model.value for model in enabled_models],
            "default_quality_level": self.quality_settings.default_level.value,
            "persona_data_path": self.persona_settings.persona_data_path,
            "answer_cache_enabled": self.answer_settings.answer_cache_enabled,
            "logging_enabled": self.logging_settings.log_requests,
            "config_file": self.config_file
        }
    
    def validate_config(self) -> List[str]:
        """ì„¤ì • ìœ íš¨ì„± ê²€ì¦"""
        warnings = []
        
        # í™œì„±í™”ëœ ëª¨ë¸ì´ ìˆëŠ”ì§€ í™•ì¸
        enabled_models = self.get_enabled_models()
        if not enabled_models:
            warnings.append("í™œì„±í™”ëœ LLM ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # API í‚¤ í™•ì¸
        for provider in enabled_models:
            settings = self.model_settings[provider]
            if not settings.api_key and provider.value.startswith('openai'):
                warnings.append(f"{provider.value} ëª¨ë¸ì˜ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # í˜ë¥´ì†Œë‚˜ íŒŒì¼ í™•ì¸
        if self.persona_settings.use_real_personas:
            if not os.path.exists(self.persona_settings.persona_data_path):
                warnings.append(f"í˜ë¥´ì†Œë‚˜ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.persona_settings.persona_data_path}")
        
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ í™•ì¸
        log_dir = os.path.dirname(self.logging_settings.log_file_path)
        if log_dir and not os.path.exists(log_dir):
            warnings.append(f"ë¡œê·¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {log_dir}")
        
        return warnings
    
    def reset_to_defaults(self):
        """ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì´ˆê¸°í™”"""
        self._initialize_default_settings()
        self.quality_settings = QualitySettings()
        self.persona_settings = PersonaSettings()
        self.answer_settings = AnswerSettings()
        self.logging_settings = LoggingSettings()
        print("âœ… ëª¨ë“  ì„¤ì •ì´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ì „ì—­ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤
_global_config = None

def get_config() -> AICandidateConfig:
    """ì „ì—­ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _global_config
    if _global_config is None:
        _global_config = AICandidateConfig()
    return _global_config

def reload_config():
    """ì„¤ì • ì¬ë¡œë“œ"""
    global _global_config
    _global_config = None
    return get_config()

if __name__ == "__main__":
    # AI ì§€ì›ì ì„¤ì • ê´€ë¦¬ í…ŒìŠ¤íŠ¸
    print("âš™ï¸ AI ì§€ì›ì ì„¤ì • ê´€ë¦¬ í…ŒìŠ¤íŠ¸")
    
    # ì„¤ì • ìƒì„± ë° ë¡œë“œ
    config = AICandidateConfig("config/test_ai_candidate_config.json")
    
    # í˜„ì¬ ì„¤ì • í™•ì¸
    print(f"\nğŸ“Š í˜„ì¬ ì„¤ì • ìš”ì•½:")
    summary = config.get_config_summary()
    for key, value in summary.items():
        print(f"  {key}: {value}")
    
    # ì„¤ì • ìœ íš¨ì„± ê²€ì¦
    warnings = config.validate_config()
    if warnings:
        print(f"\nâš ï¸ ì„¤ì • ê²½ê³ ì‚¬í•­:")
        for warning in warnings:
            print(f"  - {warning}")
    else:
        print(f"\nâœ… ì„¤ì •ì´ ìœ íš¨í•©ë‹ˆë‹¤.")
    
    # ëª¨ë¸ ì„¤ì • ì—…ë°ì´íŠ¸ í…ŒìŠ¤íŠ¸
    print(f"\nğŸ”§ ì„¤ì • ì—…ë°ì´íŠ¸ í…ŒìŠ¤íŠ¸:")
    
    # API í‚¤ ì„¤ì • (ì‹¤ì œë¡œëŠ” ì…ë ¥ë°›ì•„ì•¼ í•¨)
    # config.set_api_key(LLMProvider.OPENAI_GPT4O_MINI, "test-api-key")
    
    # í’ˆì§ˆ ì„¤ì • ë³€ê²½
    config.update_quality_setting(default_level=9, max_answer_length=600)
    
    # ë‹µë³€ ì„¤ì • ë³€ê²½
    config.update_answer_setting(max_retries=5, cache_duration_minutes=120)
    
    # ë³€ê²½ëœ ì„¤ì • ì €ì¥
    config.save_config()
    
    print(f"\nğŸ’¾ ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ì „ì—­ ì„¤ì • í…ŒìŠ¤íŠ¸
    print(f"\nğŸŒ ì „ì—­ ì„¤ì • í…ŒìŠ¤íŠ¸:")
    global_config = get_config()
    print(f"ì „ì—­ ì„¤ì • í™œì„±í™”ëœ ëª¨ë¸: {global_config.get_enabled_models()}")
    
    # ì„¤ì • íŒŒì¼ ì •ë¦¬ (í…ŒìŠ¤íŠ¸ìš©)
    import os
    if os.path.exists("config/test_ai_candidate_config.json"):
        os.remove("config/test_ai_candidate_config.json")
        print("ğŸ—‘ï¸ í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼ ì‚­ì œ ì™„ë£Œ")