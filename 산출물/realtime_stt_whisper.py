import os
import asyncio
import aiohttp
import sounddevice as sd
import numpy as np
from scipy.io.wavfile import write
from dotenv import load_dotenv

# .envì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# OpenAI Whisper API endpoint
OPENAI_WHISPER_URL = "https://api.openai.com/v1/audio/transcriptions"

# ì˜¤ë””ì˜¤ ë…¹ìŒ íŒŒë¼ë¯¸í„°
SAMPLE_RATE = 16000
CHANNELS = 1
DTYPE = 'int16'

async def speech_to_text_whisper(audio_path: str) -> str:
    """ë…¹ìŒëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ OpenAI Whisperë¡œ ë³€í™˜"""
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
    }
    form = aiohttp.FormData()
    form.add_field('file', open(audio_path, 'rb'), filename=os.path.basename(audio_path), content_type='audio/wav')
    form.add_field('model', 'whisper-1')
    form.add_field('response_format', 'json')
    form.add_field('language', 'ko')  # í•œêµ­ì–´ ì¸ì‹ (í•„ìš”ì‹œ ë³€ê²½)

    async with aiohttp.ClientSession() as session:
        async with session.post(OPENAI_WHISPER_URL, headers=headers, data=form) as resp:
            if resp.status == 200:
                result = await resp.json()
                return result.get('text', '')
            else:
                print(f"Whisper API ì˜¤ë¥˜: {resp.status}")
                return ""

def record_audio_until_stop(output_path: str = "user_input.wav"):
    print("ì—”í„°ë¥¼ ëˆ„ë¥´ë©´ ë…¹ìŒ ì‹œì‘, ë‹µë³€ì´ ëë‚˜ë©´ ë‹¤ì‹œ ì—”í„°ë¥¼ ëˆ„ë¥´ì„¸ìš”.")
    input("â–¶ ë‹µë³€ì„ ì‹œì‘í•˜ë ¤ë©´ ì—”í„°ë¥¼ ëˆ„ë¥´ì„¸ìš”...")
    print("ğŸ™ï¸ ë…¹ìŒ ì¤‘... ë‹µë³€ì„ ë‹¤ í•˜ì…¨ìœ¼ë©´ ì—”í„°ë¥¼ ë‹¤ì‹œ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

    audio_list = []

    def callback(indata, frames, time, status):
        audio_list.append(indata.copy())

    stream = sd.InputStream(samplerate=SAMPLE_RATE, channels=CHANNELS, dtype=DTYPE, callback=callback)
    with stream:
        input()  # ìœ ì €ê°€ ì—”í„° ëˆ„ë¥¼ ë•Œê¹Œì§€ ëŒ€ê¸°

    audio_np = np.concatenate(audio_list, axis=0)
    write(output_path, SAMPLE_RATE, audio_np)
    print(f"ğŸ’¾ ì˜¤ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {output_path}")
    return output_path

async def main():
    print("ì‹¤ì‹œê°„ ìŒì„± ì…ë ¥ì„ Whisperë¡œ í…ìŠ¤íŠ¸ ë³€í™˜í•©ë‹ˆë‹¤.")

    num_questions = 15  # ì§ˆë¬¸ ê°œìˆ˜ë§Œí¼ ë°˜ë³µ, ì§ˆë¬¸ ê°œìˆ˜ê°€ ë³€í•˜ë©´ ì¶”í›„ì— ìˆ˜ì •

    for idx in range(num_questions):
        print(f"\n[{idx+1}/{num_questions}] ë‹µë³€ì„ ë…¹ìŒí•˜ì„¸ìš”.")
        audio_path = record_audio_until_stop(output_path=f"user_input_{idx+1:02d}.wav")
        text = await speech_to_text_whisper(audio_path)
        text = text.strip()
        # íŒŒì¼ì— "ë²ˆí˜¸: ë‹µë³€" í˜•íƒœë¡œ (ë‹µë³€ì´ ì—†ìœ¼ë©´ ë²ˆí˜¸: )
        with open("recognized_texts_whisper.txt", "a", encoding="utf-8") as f:
            f.write(f"{idx+1}: {text}\n")
        print(f"ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸: {text if text else '[ê³µë°±]'}")

if __name__ == "__main__":
    asyncio.run(main())