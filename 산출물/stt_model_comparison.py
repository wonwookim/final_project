import os
from dotenv import load_dotenv

# ============================
# ğŸ”¹ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# ============================
load_dotenv()

ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")
NAVER_INVOKE_URL = os.getenv("NAVER_INVOKE_URL")
QWEN_API_KEY = os.getenv("QWEN_API_KEY")
TENCENT_SECRET_ID = os.getenv("TENCENT_SECRET_ID")
TENCENT_SECRET_KEY = os.getenv("TENCENT_SECRET_KEY")
TENCENT_REGION = os.getenv("TENCENT_REGION")  # ê¸°ë³¸ê°’: ì„œìš¸ ë¦¬ì „

# ============================
# ğŸ”¹ Whisper ë³€í™˜ í•¨ìˆ˜ (ë¯¸êµ­)
# ============================
import openai
import os
import re
from dotenv import load_dotenv

client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

async def transcribe_whisper(audio_path, language="ko"):
    try:
        with open(audio_path, "rb") as audio_file:
            response = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language=language,
                response_format="text"
            )

        text = response.strip()

        # êµ¬ë‘ì  ì œê±°
        text_no_punct = re.sub(r'[^\w\s\uAC00-\uD7A3]', '', text)

        return text_no_punct

    except Exception as e:
        print(f"OpenAI Whisper API ì˜¤ë¥˜ ({audio_path}): {e}")
        return ""

# ============================
# ğŸ”¹ ElevenLabs ë³€í™˜ í•¨ìˆ˜ (ìœ ëŸ½)
# ============================
from elevenlabs import ElevenLabs

def transcribe_elevenlabs(audio_path, language="ko"):
    try:
        client = ElevenLabs(api_key = ELEVENLABS_API_KEY)
        with open(audio_path, "rb") as f:
            resp = client.speech_to_text.convert(
                file=f,
                model_id="scribe_v1",
                language_code=language,
                diarize=False,
                tag_audio_events=False
            )
        # âœ… ì‘ë‹µ ê°ì²´ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
        if hasattr(resp, "text"):
            text = resp.text.strip()
        elif hasattr(resp, "to_dict"):
            text = resp.to_dict().get("text", "").strip()
        else:
            text = str(resp).strip()

        # 2) êµ¬ë‘ì  ì œê±°: ì•ŒíŒŒë²³Â·ìˆ«ìÂ·ì–¸ë”ìŠ¤ì½”ì–´(\w), ê³µë°±(\s), í•œê¸€(\uAC00-\uD7A3)ë§Œ ë‚¨ê¹€
        text_no_punct = re.sub(r'[^\w\s\uAC00-\uD7A3]', '', text)

        return text_no_punct

    except Exception as e:
        print(f"ElevenLabs ì˜¤ë¥˜ ({audio_path}): {e}")
        return ""


# ============================
# ğŸ”¹ Naver Clova STT ë³€í™˜ í•¨ìˆ˜ (í•œêµ­)
# ============================
import requests

def transcribe_clova(audio_path):
    url = "https://naveropenapi.apigw.ntruss.com/recog/v1/stt"
    headers = {
        "X-NCP-APIGW-API-KEY-ID": NAVER_CLIENT_ID,
        "X-NCP-APIGW-API-KEY":    NAVER_CLIENT_SECRET,
        "Content-Type":           "application/octet-stream",
    }
    params = {"lang": "Kor"}  # ë°˜ë“œì‹œ Kor ëŒ€ë¬¸ìë¡œ

    with open(audio_path, "rb") as f:
        resp = requests.post(
            url,
            headers=headers,
            params=params,
            data=f,
            timeout=30
        )

    if resp.status_code != 200:
        return ""  # ì—¬ì „íˆ 404ë‚˜ì˜¤ë©´ URLì´ ì˜ëª»ëœ ê²ƒì´ë‹ˆ ë°”ë¡œ í™•ì¸

    # ì„±ê³µ ì‹œ JSON íŒŒì‹±
    try:
        return resp.json().get("text", "").strip()
    except ValueError:
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ, plain text ë¡œ ë¦¬í„´
        return resp.text.strip()

# ============================
# ğŸ”¹ Tencent Cloud STT ë³€í™˜ í•¨ìˆ˜ (ì¤‘êµ­)
# ============================
from tencentcloud.common import credential
from tencentcloud.common.profile.client_profile import ClientProfile
from tencentcloud.common.profile.http_profile import HttpProfile
from tencentcloud.asr.v20190614 import asr_client, models
import base64
import re
import json

def transcribe_tencent(audio_path, language="ko"):
    try:
        cred = credential.Credential(TENCENT_SECRET_ID, TENCENT_SECRET_KEY)
        http_profile = HttpProfile()
        http_profile.endpoint = "asr.tencentcloudapi.com"

        client_profile = ClientProfile()
        client_profile.httpProfile = http_profile
        client = asr_client.AsrClient(cred, TENCENT_REGION, client_profile)

        with open(audio_path, "rb") as audio_file:
            audio_data = audio_file.read()

        req = models.SentenceRecognitionRequest()
        params = {
            "ProjectId": 0,
            "SubServiceType": 2,
            "EngSerViceType": "16k_ko",
            "SourceType": 1,
            "VoiceFormat": "m4a",
            "UsrAudioKey": "session_123",
            "Data": base64.b64encode(audio_data).decode()
        }
        req.from_json_string(json.dumps(params))

        resp = client.SentenceRecognition(req)
        text = resp.Result.strip()

        # êµ¬ë‘ì  ì œê±°
        text_no_punct = re.sub(r'[^\w\s\uAC00-\uD7A3]', '', text)

        return text_no_punct

    except Exception as e:
        print(f"Tencent Cloud STT ì˜¤ë¥˜ ({audio_path}): {e}")
        return ""

# ============================
# ğŸ”¹ QWEN STT ë³€í™˜ í•¨ìˆ˜ (ì¤‘êµ­)
# ============================
import requests

def transcribe_qwen(audio_path, language="ko"):
    QWEN_ENDPOINT = "https://api.qwen.ai/v1/stt"  # ì‹¤ì œ endpointë¡œ ë³€ê²½í•´ì•¼ í•¨

    headers = {
        "Authorization": f"Bearer {QWEN_API_KEY}",
        "Accept": "application/json",
    }

    with open(audio_path, "rb") as audio_file:
        files = {"file": (os.path.basename(audio_path), audio_file, "audio/wav")}
        data = {"language": language}

        try:
            response = requests.post(
                QWEN_ENDPOINT,
                headers=headers,
                files=files,
                data=data,
                timeout=30
            )
            response.raise_for_status()
            result = response.json()

            # APIì˜ ì‘ë‹µ êµ¬ì¡°ì— ë”°ë¼ ì¡°ì • í•„ìš”
            text = result.get("text", "").strip()

            # êµ¬ë‘ì  ì œê±°
            text_no_punct = re.sub(r'[^\w\s\uAC00-\uD7A3]', '', text)

            return text_no_punct

        except requests.RequestException as e:
            print(f"Qwen API ì˜¤ë¥˜ ({audio_path}): {e}")
            return ""

        except ValueError as e:
            print(f"Qwen API JSON ì˜¤ë¥˜ ({audio_path}): {e}")
            return ""

# ============================
# ğŸ”¹ í‰ê°€ ìœ í‹¸
# ============================
import jiwer

def evaluate_wer(reference: str, hypothesis: str) -> float:
    """
    - reference, hypothesis ì–‘ìª½ì´ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° WER=0.0
    - reference ë¹ˆ ë¬¸ìì—´ì´ì§€ë§Œ hypothesis non-emptyì¸ ê²½ìš° WER=1.0
    - ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ jiwer.wer() ê²°ê³¼ ê·¸ëŒ€ë¡œ ë°˜í™˜
    """
    # 1) ë‘˜ ë‹¤ ë¹ˆ ë¬¸ìì—´ â†’ í‹€ë¦° ê²Œ ì—†ìœ¼ë¯€ë¡œ 0.0
    if not reference and not hypothesis:
        return 0.0

    # 2) reference ë¹ˆ ë¬¸ìì—´ë§Œ â†’ ëª¨ë“  ë‹¨ì–´ê°€ insertion, WER=1.0ë¡œ ê°„ì£¼
    if not reference:
        return 1.0

    # 3) hypothesis ë¹ˆ ë¬¸ìì—´ë§Œ â†’ ëª¨ë“  ë‹¨ì–´ê°€ deletion, WER=1.0
    if not hypothesis:
        return 1.0

    # 4) ì •ìƒ ì¼€ì´ìŠ¤
    try:
        return jiwer.wer(reference, hypothesis)
    except Exception as e:
        # í•„ìš”í•˜ë‹¤ë©´ ë¡œê¹…
        print(f"WER ê³„ì‚° ì˜¤ë¥˜: {e}")
        # ì—ëŸ¬ ë‚¬ì„ ë•Œ fallback ê°’â€”ì›í•˜ì‹œë©´ ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë˜ì ¸ë„ ë¬´ë°©
        return 1.0

from jiwer import process_words

def evaluate_accuracy(reference: str, hypothesis: str) -> float:
    """
    ASR ì •í™•ë„ = hits / (hits + substitutions + deletions)
    (reference ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš°ì—” 0.0, ë‘˜ ë‹¤ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš°ì—” 1.0)
    """
    # 1) ë‘˜ ë‹¤ ë¹ˆ ë¬¸ìì—´ â†’ 1.0
    if not reference and not hypothesis:
        return 1.0

    # 2) referenceë§Œ ë¹ˆ ë¬¸ìì—´ â†’ 0.0
    if not reference:
        return 0.0

    # 3) process_words ë¡œ word-level í†µê³„ ì¶”ì¶œ
    result = process_words(reference, hypothesis)
    hits = result.hits
    subs = result.substitutions
    dels = result.deletions

    # 4) ì •í™•ë„ ê³„ì‚°
    N = hits + subs + dels
    return hits / N

# ============================
# ğŸ”¹ ë°°ì¹˜ í‰ê°€ íŒŒì´í”„ë¼ì¸
# ============================
async def batch_evaluate(folder_path, language="ko"):
    results = []
    wav_files = [f for f in os.listdir(folder_path) if f.endswith(".m4a")]
    total = len(wav_files)
    print(f"ì´ {total}ê°œ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘â€¦")

    for idx, fname in enumerate(wav_files, 1):
        base = fname[:-4]
        audio = os.path.join(folder_path, fname)
        txt   = os.path.join(folder_path, base + ".txt")
        if not os.path.exists(txt):
            print(f"âš ï¸ {base}.txt ì—†ìŒ, ìŠ¤í‚µ")
            continue

        with open(txt, "r", encoding="utf-8") as f:
            ref = f.read().strip()

        # 1) Whisper
        print(f"  ğŸ¤ [{idx}/{total}] {base} - Whisper ì²˜ë¦¬ ì¤‘...")
        hyp_wh = await transcribe_whisper(audio, language)
        
        # 2) ElevenLabs
        print(f"  ğŸ¤ [{idx}/{total}] {base} - ElevenLabs ì²˜ë¦¬ ì¤‘...")
        hyp_el = transcribe_elevenlabs(audio, language)
        
        # 3) Naver Clova
        print(f"  ğŸ¤ [{idx}/{total}] {base} - Clova ì²˜ë¦¬ ì¤‘...")
        hyp_cv = transcribe_clova(audio)

        # # 4) Qwen API
        # print(f"  ğŸ¤ [{idx}/{total}] {base} - Qwen API ì²˜ë¦¬ ì¤‘...")
        # hyp_qwen = transcribe_qwen(audio, language)

        # 5) Tencent Cloud
        print(f"  ğŸ¤ [{idx}/{total}] {base} - Tencent Cloud ì²˜ë¦¬ ì¤‘...")
        hyp_tc = transcribe_tencent(audio, language)
        
        wer_wh = evaluate_wer(ref, hyp_wh)
        wer_el = evaluate_wer(ref, hyp_el)
        wer_cv = evaluate_wer(ref, hyp_cv)
        # wer_qwen = evaluate_wer(ref, hyp_qwen)
        wer_tc = evaluate_wer(ref, hyp_tc)

        acc_wh = evaluate_accuracy(ref, hyp_wh)
        acc_el = evaluate_accuracy(ref, hyp_el)
        acc_cv = evaluate_accuracy(ref, hyp_cv)
        # acc_qwen = evaluate_accuracy(ref, hyp_qwen)
        acc_tc = evaluate_accuracy(ref, hyp_tc)

        results.append({
            "file": base,
            "reference": ref,
            "whisper": {"text": hyp_wh, "wer": wer_wh, "acc": acc_wh},
            "elevenlabs": {"text": hyp_el, "wer": wer_el, "acc": acc_el},
            "clova": {"text": hyp_cv, "wer": wer_cv, "acc": acc_cv},
            # "qwen": {"text": hyp_qwen, "wer": wer_qwen, "acc": acc_qwen}
            "tencent": {"text": hyp_tc, "wer": wer_tc, "acc": acc_tc}
        })

        # ê²°ê³¼ ì¶œë ¥
        print(f"[{idx}/{total}] {base} ì™„ë£Œ â†’ WER Whisper:{wer_wh:.2f}, ElevenLabs:{wer_el:.2f}, Clova:{wer_cv:.2f}, Tencent:{wer_tc:.2f}")


    # ê²°ê³¼ ì €ì¥
    from datetime import datetime
    import json

    if results:
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        out = f"stt_compare_{ts}.json"
        with open(out, "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ê²°ê³¼: {out}")
    else:
        print("âŒ ì²˜ë¦¬ëœ íŒŒì¼ ì—†ìŒ")

    return results

# ============================
# ğŸ”¹ ì‹¤í–‰ë¶€
# ============================
import asyncio

if __name__ == "__main__":
    base_dir = os.path.dirname(os.path.abspath(__file__))
    data_dir = os.path.join(base_dir, "data")
    print("STT ëª¨ë¸ ë¹„êµ ì‹œì‘")
    
    # Tencent Cloud ASR ì œí•œ í™•ì¸
    # check_tencent_asr_limits()
    # print()
    
    asyncio.run(batch_evaluate(data_dir))