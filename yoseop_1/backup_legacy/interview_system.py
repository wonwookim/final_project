import json
import openai
import os
from typing import List, Dict, Any, Optional
import time
from datetime import datetime
from dataclasses import dataclass
from enum import Enum
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class QuestionType(Enum):
    INTRO = "ìê¸°ì†Œê°œ"
    MOTIVATION = "ì§€ì›ë™ê¸°"
    MOTIVE = "ë™ê¸°"
    HR = "ì¸ì‚¬"
    TECH = "ê¸°ìˆ "
    COLLABORATION = "í˜‘ì—…"
    FOLLOWUP = "ì‹¬í™”"
    GENERAL = "ì¼ë°˜"
    BASIC = "ê¸°ë³¸"
    FUTURE = "ë¯¸ë˜"

@dataclass
class QuestionAnswer:
    question_id: str
    question_type: QuestionType
    question_content: str
    answer_content: str
    timestamp: datetime
    question_intent: str = ""
    individual_score: int = 0
    individual_feedback: str = ""

class InterviewSession:
    def __init__(self, company_id: str, position: str, candidate_name: str):
        self.company_id = company_id
        self.position = position
        self.candidate_name = candidate_name
        self.conversation_history: List[QuestionAnswer] = []
        self.current_question_count = 0
        self.session_id = f"{company_id}_{position.replace(' ', '_')}_{int(time.time())}"
        self.created_at = datetime.now()
        
        # ê³ ì •ëœ ì§ˆë¬¸ ìˆœì„œ (ì´ 20ê°œ ì§ˆë¬¸)
        self.question_plan = [
            # ê¸°ë³¸ ì§ˆë¬¸ (2ê°œ)
            {"type": QuestionType.INTRO, "fixed": True},
            {"type": QuestionType.MOTIVATION, "fixed": True},
            
            # ì¸ì‚¬ ì˜ì—­ (6ê°œ)
            {"type": QuestionType.HR, "fixed": False},
            {"type": QuestionType.HR, "fixed": False},
            {"type": QuestionType.HR, "fixed": False},
            {"type": QuestionType.HR, "fixed": False},
            {"type": QuestionType.HR, "fixed": False},
            {"type": QuestionType.HR, "fixed": False},
            
            # ê¸°ìˆ  ì˜ì—­ (8ê°œ)
            {"type": QuestionType.TECH, "fixed": False},
            {"type": QuestionType.TECH, "fixed": False},
            {"type": QuestionType.TECH, "fixed": False},
            {"type": QuestionType.TECH, "fixed": False},
            {"type": QuestionType.TECH, "fixed": False},
            {"type": QuestionType.TECH, "fixed": False},
            {"type": QuestionType.TECH, "fixed": False},
            {"type": QuestionType.TECH, "fixed": False},
            
            # í˜‘ì—… ì˜ì—­ (3ê°œ)
            {"type": QuestionType.COLLABORATION, "fixed": False},
            {"type": QuestionType.COLLABORATION, "fixed": False},
            {"type": QuestionType.COLLABORATION, "fixed": False},
            
            # ì‹¬í™” ì§ˆë¬¸ (1ê°œ)
            {"type": QuestionType.FOLLOWUP, "fixed": False}
        ]
        
    def add_qa_pair(self, qa_pair: QuestionAnswer):
        self.conversation_history.append(qa_pair)
        self.current_question_count += 1
        
    def get_next_question_plan(self) -> Optional[Dict]:
        if self.current_question_count < len(self.question_plan):
            return self.question_plan[self.current_question_count]
        return None
        
    def is_complete(self) -> bool:
        return self.current_question_count >= len(self.question_plan)
        
    def get_conversation_context(self) -> str:
        context = f"ë©´ì ‘ ì§„í–‰ ìƒí™©: {self.current_question_count}/{len(self.question_plan)}\n"
        context += f"ì§€ì›ì: {self.candidate_name}ë‹˜\n"
        context += f"ì§€ì› ì§êµ°: {self.position}\n\n"
        
        if self.conversation_history:
            context += "ì´ì „ ëŒ€í™” ë‚´ìš©:\n"
            for i, qa in enumerate(self.conversation_history, 1):
                context += f"{i}. [{qa.question_type.value}] {qa.question_content}\n"
                context += f"   ë‹µë³€: {qa.answer_content}\n\n"
        
        return context

class FinalInterviewSystem:
    def __init__(self, api_key: str = None, companies_data_path: str = "llm/shared/data/companies_data.json"):
        # API í‚¤ ìë™ ë¡œë“œ
        if not api_key:
            api_key = os.getenv('OPENAI_API_KEY')
        
        if not api_key:
            raise ValueError("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ ì§ì ‘ ì „ë‹¬í•˜ì„¸ìš”.")
        
        self.client = openai.OpenAI(api_key=api_key)
        self.companies_data = self._load_companies_data(companies_data_path)
        self.sessions: Dict[str, InterviewSession] = {}
        
    def _load_companies_data(self, path: str) -> Dict[str, Any]:
        try:
            with open(path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"ê¸°ì—… ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
            return {"companies": []}
    
    def get_company_data(self, company_id: str) -> Dict[str, Any]:
        for company in self.companies_data["companies"]:
            if company["id"] == company_id:
                return company
        return None
    
    def list_companies(self) -> List[Dict[str, str]]:
        return [{"id": company["id"], "name": company["name"]} 
                for company in self.companies_data["companies"]]
    
    def start_interview(self, company_id: str, position: str, candidate_name: str) -> str:
        company_data = self.get_company_data(company_id)
        if not company_data:
            raise ValueError(f"íšŒì‚¬ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {company_id}")
        
        session = InterviewSession(company_id, position, candidate_name)
        self.sessions[session.session_id] = session
        
        return session.session_id
    
    def get_next_question(self, session_id: str) -> Optional[Dict[str, Any]]:
        session = self.sessions.get(session_id)
        if not session or session.is_complete():
            return None
        
        company_data = self.get_company_data(session.company_id)
        question_plan = session.get_next_question_plan()
        
        if not question_plan:
            return None
        
        # ì§ˆë¬¸ ìƒì„±
        question_content, question_intent = self._generate_next_question(
            session, company_data, question_plan["type"], question_plan["fixed"]
        )
        
        return {
            "question_id": f"q_{session.current_question_count + 1}",
            "question_type": question_plan["type"].value,
            "question_content": question_content,
            "question_intent": question_intent,
            "progress": f"{session.current_question_count + 1}/{len(session.question_plan)}",
            "personalized": False  # í‘œì¤€ ë©´ì ‘ ì‹œìŠ¤í…œì€ ê°œì¸í™”ë˜ì§€ ì•ŠìŒ
        }
    
    def _generate_next_question(self, session: InterviewSession, company_data: Dict[str, Any], 
                               question_type: QuestionType, is_fixed: bool) -> tuple[str, str]:
        
        # ì²« ë‘ ì§ˆë¬¸ì€ ì™„ì „íˆ ê³ ì •
        if question_type == QuestionType.INTRO:
            return (
                f"{session.candidate_name}ë‹˜, ì•ˆë…•í•˜ì„¸ìš”. ê°„ë‹¨í•œ ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.",
                "ì§€ì›ìì˜ ê¸°ë³¸ ë°°ê²½, ê²½ë ¥, ì„±ê²©ì„ íŒŒì•…í•˜ì—¬ ë©´ì ‘ ë¶„ìœ„ê¸°ë¥¼ ì¡°ì„±"
            )
        elif question_type == QuestionType.MOTIVATION:
            return (
                f"{session.candidate_name}ë‹˜ê»˜ì„œ {company_data['name']}ì— ì§€ì›í•˜ê²Œ ëœ ë™ê¸°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                "íšŒì‚¬ì— ëŒ€í•œ ê´€ì‹¬ë„, ì§€ì› ì˜ì§€, íšŒì‚¬ ì´í•´ë„ë¥¼ í‰ê°€"
            )
        
        # ë‚˜ë¨¸ì§€ ì§ˆë¬¸ë“¤ì€ ë™ì  ìƒì„±
        context = session.get_conversation_context()
        
        if question_type == QuestionType.HR:
            prompt = self._create_hr_question_prompt(company_data, context, session.candidate_name)
        elif question_type == QuestionType.TECH:
            prompt = self._create_tech_question_prompt(company_data, context, session.position, session.candidate_name)
        elif question_type == QuestionType.COLLABORATION:
            prompt = self._create_collaboration_question_prompt(company_data, context, session.candidate_name)
        elif question_type == QuestionType.FOLLOWUP:
            prompt = self._create_followup_question_prompt(company_data, context, session.candidate_name)
        else:
            return f"{session.candidate_name}ë‹˜ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ìŠµë‹ˆë‹¤.", "ì¼ë°˜ì ì¸ ì§ˆë¬¸"
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": f"ë‹¹ì‹ ì€ {company_data['name']}ì˜ ë©´ì ‘ê´€ì…ë‹ˆë‹¤. ì§€ì›ìë¥¼ ì¡´ì¤‘í•˜ë©° ~ë‹˜ìœ¼ë¡œ í˜¸ì¹­í•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=300,
                temperature=0.7
            )
            
            result = response.choices[0].message.content.strip()
            
            if "ì˜ë„:" in result:
                parts = result.split("ì˜ë„:")
                question_content = parts[0].strip()
                question_intent = parts[1].strip() if len(parts) > 1 else ""
            else:
                question_content = result
                question_intent = f"{question_type.value} ì—­ëŸ‰ í‰ê°€"
            
            return question_content, question_intent
            
        except Exception as e:
            print(f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return self._get_fallback_question(question_type, session.candidate_name), f"{question_type.value} ê¸°ë³¸ ì§ˆë¬¸"
    
    def _create_hr_question_prompt(self, company_data: Dict[str, Any], context: str, candidate_name: str) -> str:
        return f"""
{context}

{candidate_name}ë‹˜ì˜ ì¸ì‚¬ ì˜ì—­(ê°œì¸ì  íŠ¹ì„±, ì„±ê²©, ê°€ì¹˜ê´€, ì„±ì¥ ì˜ì§€)ì„ í‰ê°€í•˜ëŠ” ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

=== ê¸°ì—… ì •ë³´ ===
- ì¸ì¬ìƒ: {company_data['talent_profile']}
- í•µì‹¬ ì—­ëŸ‰: {', '.join(company_data['core_competencies'])}

í˜‘ì—…ê³¼ êµ¬ë¶„ë˜ëŠ” ê°œì¸ì  ì¸¡ë©´ì— ì§‘ì¤‘í•˜ì„¸ìš”.
ê°„ê²°í•œ ì§ˆë¬¸ í•˜ë‚˜ë§Œ ìƒì„±í•˜ì„¸ìš”.

í˜•ì‹:
ì§ˆë¬¸ ë‚´ìš©
ì˜ë„: ì´ ì§ˆë¬¸ì˜ í‰ê°€ ëª©ì 
"""
    
    def _create_tech_question_prompt(self, company_data: Dict[str, Any], context: str, position: str, candidate_name: str) -> str:
        return f"""
{context}

{candidate_name}ë‹˜ì˜ ê¸°ìˆ  ì—­ëŸ‰ì„ í‰ê°€í•˜ëŠ” ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

=== ê¸°ìˆ  ì •ë³´ ===
- ì§êµ°: {position}
- ê¸°ìˆ  ì¤‘ì : {', '.join(company_data['tech_focus'])}

êµ¬ì²´ì ì´ê³  ì‹¤ë¬´ ì¤‘ì‹¬ì˜ ì§ˆë¬¸ í•˜ë‚˜ë§Œ ìƒì„±í•˜ì„¸ìš”.

í˜•ì‹:
ì§ˆë¬¸ ë‚´ìš©
ì˜ë„: ì´ ì§ˆë¬¸ì˜ í‰ê°€ ëª©ì 
"""
    
    def _create_collaboration_question_prompt(self, company_data: Dict[str, Any], context: str, candidate_name: str) -> str:
        return f"""
{context}

{candidate_name}ë‹˜ì˜ í˜‘ì—… ëŠ¥ë ¥(íŒ€ì›Œí¬, ì†Œí†µ, ê°ˆë“± í•´ê²°, í˜‘ì—… í”„ë¡œì„¸ìŠ¤)ì„ í‰ê°€í•˜ëŠ” ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ì¸ì‚¬ ì§ˆë¬¸ê³¼ êµ¬ë¶„ë˜ëŠ” ì‹¤ì œ í˜‘ì—… ê²½í—˜ì— ì§‘ì¤‘í•˜ì„¸ìš”.
ê°„ê²°í•œ ì§ˆë¬¸ í•˜ë‚˜ë§Œ ìƒì„±í•˜ì„¸ìš”.

í˜•ì‹:
ì§ˆë¬¸ ë‚´ìš©
ì˜ë„: ì´ ì§ˆë¬¸ì˜ í‰ê°€ ëª©ì 
"""
    
    def _create_followup_question_prompt(self, company_data: Dict[str, Any], context: str, candidate_name: str) -> str:
        return f"""
{context}

{candidate_name}ë‹˜ì˜ ì´ì „ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ê°€ì¥ í¥ë¯¸ë¡œìš´ ë¶€ë¶„ì„ ê¹Šì´ íŒŒê³ ë“œëŠ” ì‹¬í™” ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

- êµ¬ì²´ì ì¸ ì‚¬ë¡€ë‚˜ ê²½í—˜ì˜ ë””í…Œì¼ ìš”êµ¬
- ì‚¬ê³  ê³¼ì •ì´ë‚˜ ì˜ì‚¬ê²°ì • ë°°ê²½ íƒêµ¬
- ê²°ê³¼ì™€ í•™ìŠµí•œ ì  í™•ì¸

í˜•ì‹:
ì§ˆë¬¸ ë‚´ìš©
ì˜ë„: ì´ ì§ˆë¬¸ì˜ í‰ê°€ ëª©ì 
"""
    
    def _get_fallback_question(self, question_type: QuestionType, candidate_name: str) -> str:
        fallback_questions = {
            QuestionType.INTRO: f"{candidate_name}ë‹˜, ê°„ë‹¨í•œ ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.",
            QuestionType.MOTIVATION: f"{candidate_name}ë‹˜ì´ ì €í¬ íšŒì‚¬ì— ì§€ì›í•˜ê²Œ ëœ ë™ê¸°ê°€ ê¶ê¸ˆí•©ë‹ˆë‹¤.",
            QuestionType.HR: f"{candidate_name}ë‹˜ì˜ ì¥ì ê³¼ ì„±ì¥í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            QuestionType.TECH: f"{candidate_name}ë‹˜ì˜ ê¸°ìˆ ì  ê²½í—˜ì— ëŒ€í•´ ë§ì”€í•´ ì£¼ì„¸ìš”.",
            QuestionType.COLLABORATION: f"{candidate_name}ë‹˜ì˜ íŒ€ í˜‘ì—… ê²½í—˜ì„ ê³µìœ í•´ ì£¼ì„¸ìš”.",
            QuestionType.FOLLOWUP: f"{candidate_name}ë‹˜ì´ ê°€ì¥ ìì‹  ìˆëŠ” ê²½í—˜ì„ ë” ìì„¸íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”."
        }
        return fallback_questions.get(question_type, f"{candidate_name}ë‹˜, ë³¸ì¸ì— ëŒ€í•´ ë§ì”€í•´ ì£¼ì„¸ìš”.")
    
    def submit_answer(self, session_id: str, answer_content: str, current_question_data: Dict[str, str] = None) -> Dict[str, Any]:
        session = self.sessions.get(session_id)
        if not session:
            return {"error": "ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        
        print(f"DEBUG: submit_answer í˜¸ì¶œ - ì„¸ì…˜: {session_id}, í˜„ì¬ ì§ˆë¬¸ ìˆ˜: {session.current_question_count}, ì „ì²´ ì§ˆë¬¸ ìˆ˜: {len(session.question_plan)}")
        
        # í˜„ì¬ ì§ˆë¬¸ ê³„íš ê°€ì ¸ì˜¤ê¸° (ì§ˆë¬¸ì„ ë‹¤ì‹œ ìƒì„±í•˜ì§€ ì•Šê³ )
        current_question_plan = session.get_next_question_plan()
        if not current_question_plan:
            print(f"DEBUG: í˜„ì¬ ì§ˆë¬¸ ê³„íšì´ ì—†ìŒ - ë©´ì ‘ ì™„ë£Œ")
            return {
                "status": "interview_complete",
                "message": "ë©´ì ‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. í‰ê°€ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.",
                "total_questions": session.current_question_count
            }
        
        # í˜„ì¬ ì§ˆë¬¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° - ì‹¤ì œ ì§ˆë¬¸ì„ ë‹¤ì‹œ ìƒì„±í•˜ì—¬ ì €ì¥
        company_data = self.get_company_data(session.company_id)
        question_content, question_intent = self._generate_next_question(
            session, company_data, current_question_plan["type"], current_question_plan.get("fixed", False)
        )
        
        question_id = f"q_{session.current_question_count + 1}"
        question_type = current_question_plan["type"]
        
        # ì§ˆë¬¸-ë‹µë³€ ìŒ ìƒì„± (ì‹¤ì œ ë‚´ìš©ìœ¼ë¡œ)
        qa_pair = QuestionAnswer(
            question_id=question_id,
            question_type=question_type,
            question_content=question_content,
            answer_content=answer_content,
            timestamp=datetime.now(),
            question_intent=question_intent
        )
        
        # ì„¸ì…˜ì— ì¶”ê°€ (ì´ ê³¼ì •ì—ì„œ current_question_countê°€ ì¦ê°€)
        session.add_qa_pair(qa_pair)
        
        print(f"DEBUG: ë‹µë³€ ì¶”ê°€ ì™„ë£Œ - ìƒˆë¡œìš´ í˜„ì¬ ì§ˆë¬¸ ìˆ˜: {session.current_question_count}")
        
        # ë©´ì ‘ ì™„ë£Œ ì—¬ë¶€ í™•ì¸
        if session.is_complete():
            print(f"DEBUG: ë©´ì ‘ ì™„ë£Œ - {session.current_question_count}/{len(session.question_plan)}")
            return {
                "status": "interview_complete",
                "message": "ë©´ì ‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. í‰ê°€ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.",
                "total_questions": session.current_question_count
            }
        
        # ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±
        print(f"DEBUG: ë‹¤ìŒ ì§ˆë¬¸ ìƒì„± ì‹œë„...")
        next_question = self.get_next_question(session_id)
        if next_question:
            print(f"DEBUG: ë‹¤ìŒ ì§ˆë¬¸ ìƒì„± ì„±ê³µ: {next_question.get('question_content', '')[:50]}...")
            return {
                "status": "next_question",
                "question": next_question,
                "answered_count": session.current_question_count
            }
        else:
            print(f"DEBUG: ë‹¤ìŒ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨ - ë©´ì ‘ ì™„ë£Œ")
            return {
                "status": "interview_complete",
                "message": "ë©´ì ‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. í‰ê°€ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.",
                "total_questions": session.current_question_count
            }
    
    def evaluate_interview(self, session_id: str) -> Dict[str, Any]:
        """ë©´ì ‘ ì „ì²´ í‰ê°€ (ë°°ì¹˜ ì²˜ë¦¬ë¡œ ìµœì í™”)"""
        session = self.sessions.get(session_id)
        if not session:
            return {"error": "ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        
        company_data = self.get_company_data(session.company_id)
        
        # 1. ë°°ì¹˜ í‰ê°€ë¡œ ëª¨ë“  ë‹µë³€ì„ í•œ ë²ˆì— í‰ê°€
        batch_evaluation = self._evaluate_batch_answers(session, company_data)
        
        individual_feedbacks = []
        total_score = 0
        category_scores = {}
        
        for i, qa in enumerate(session.conversation_history):
            # ë°°ì¹˜ í‰ê°€ ê²°ê³¼ì—ì„œ ê°œë³„ í‰ê°€ ì¶”ì¶œ
            if i < len(batch_evaluation.get('individual_scores', [])):
                individual_eval = batch_evaluation['individual_scores'][i]
                qa.individual_score = individual_eval.get('score', 50)
                qa.individual_feedback = individual_eval.get('feedback', 'í‰ê°€ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
            else:
                # í´ë°±: ê¸°ë³¸ í‰ê°€
                qa.individual_score = 50
                qa.individual_feedback = "ê¸°ë³¸ í‰ê°€ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤."
            
            individual_feedbacks.append({
                "question_number": len(individual_feedbacks) + 1,
                "question_type": qa.question_type.value,
                "question": qa.question_content,
                "question_intent": qa.question_intent,
                "answer": qa.answer_content,
                "score": qa.individual_score,
                "feedback": qa.individual_feedback,
                "personalized": False  # í‘œì¤€ ë©´ì ‘ ì‹œìŠ¤í…œì€ ê°œì¸í™”ë˜ì§€ ì•ŠìŒ
            })
            
            total_score += qa.individual_score
            
            # ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ê³„ì‚°
            category = qa.question_type.value
            if category not in category_scores:
                category_scores[category] = []
            category_scores[category].append(qa.individual_score)
        
        # ì „ì²´ í‰ê·  ê³„ì‚°
        overall_score = int(total_score / len(session.conversation_history))
        
        # ì¹´í…Œê³ ë¦¬ë³„ í‰ê· 
        for category in category_scores:
            category_scores[category] = int(sum(category_scores[category]) / len(category_scores[category]))
        
        # 2. ë°°ì¹˜ í‰ê°€ì—ì„œ ì¢…í•© í‰ê°€ ì¶”ì¶œ
        overall_evaluation = batch_evaluation.get('overall_evaluation', {
            "strengths": ["ê¸°ë³¸ ê°•ì "],
            "improvements": ["ê¸°ë³¸ ê°œì„ ì‚¬í•­"],
            "recommendation": "ë³´ì™„ í›„ ì¬ê²€í† ",
            "next_steps": "ì¶”ê°€ ë©´ì ‘ ì§„í–‰",
            "overall_assessment": f"ì „ì²´ {overall_score}ì  ìˆ˜ì¤€ì˜ ë©´ì ‘ ê²°ê³¼ì…ë‹ˆë‹¤."
        })
        
        return {
            "session_id": session_id,
            "company": company_data["name"],
            "position": session.position,
            "candidate": session.candidate_name,
            "individual_feedbacks": individual_feedbacks,
            "evaluation": {
                "overall_score": overall_score,
                "category_scores": category_scores,
                **overall_evaluation
            },
            "completed_at": datetime.now().isoformat()
        }
    
    def _evaluate_single_answer(self, qa: QuestionAnswer, company_data: Dict[str, Any]) -> Dict[str, Any]:
        """ê°œë³„ ë‹µë³€ í‰ê°€ (ë§¤ìš° ì—„ê²©í•œ ê¸°ì¤€)"""
        
        answer = qa.answer_content.strip()
        
        # ë§¤ìš° ì—„ê²©í•œ ê²€ì¦
        if len(answer) < 5:
            return {
                "score": 10,
                "feedback": f"ğŸ“ ì§ˆë¬¸ ì˜ë„: {qa.question_intent}\n\nğŸ’¬ í‰ê°€: ë‹µë³€ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìµœì†Œí•œì˜ ì„¤ëª…ë„ ì—†ìŠµë‹ˆë‹¤.\n\nğŸ”§ ê°œì„  ë°©ë²•: êµ¬ì²´ì ì¸ ê²½í—˜ì´ë‚˜ ìƒê°ì„ 3-4ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”."
            }
        
        # ìˆ«ìë‚˜ ë‹¨ìˆœ ë‹µë³€ ê²€ì¦
        if answer.isdigit() or answer in [".", "ì—†ìŒ", "ëª¨ë¦„", "pass", "1", "2", "3", "4", "5"]:
            return {
                "score": 5,
                "feedback": f"ğŸ“ ì§ˆë¬¸ ì˜ë„: {qa.question_intent}\n\nğŸ’¬ í‰ê°€: ìˆ«ìë‚˜ ë‹¨ìˆœ ë‹µë³€ì€ ë©´ì ‘ì— ì ì ˆí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n\nğŸ”§ ê°œì„  ë°©ë²•: ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ íŒŒì•…í•˜ê³  êµ¬ì²´ì ì¸ ê²½í—˜ê³¼ ìƒê°ì„ ê³µìœ í•´ ì£¼ì„¸ìš”."
            }
        
        # ë„ˆë¬´ ì§§ì€ ë‹µë³€
        if len(answer) < 20:
            return {
                "score": 20,
                "feedback": f"ğŸ“ ì§ˆë¬¸ ì˜ë„: {qa.question_intent}\n\nğŸ’¬ í‰ê°€: ë‹µë³€ì´ ë„ˆë¬´ ê°„ë‹¨í•©ë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.\n\nğŸ”§ ê°œì„  ë°©ë²•: ê²½í—˜ ì‚¬ë¡€, êµ¬ì²´ì ì¸ ì˜ˆì‹œ, ë³¸ì¸ì˜ ìƒê°ì„ í¬í•¨í•´ì„œ ë‹µë³€í•´ ì£¼ì„¸ìš”."
            }
        
        prompt = f"""
ë‹¤ìŒ ë©´ì ‘ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë§¤ìš° ì—„ê²©í•˜ê²Œ í‰ê°€í•´ì£¼ì„¸ìš”.

=== ì§ˆë¬¸ ì •ë³´ ===
ì§ˆë¬¸ ìœ í˜•: {qa.question_type.value}
ì§ˆë¬¸: {qa.question_content}
ì§ˆë¬¸ ì˜ë„: {qa.question_intent}

=== ì§€ì›ì ë‹µë³€ ===
{answer}

=== í‰ê°€ ê¸°ì¤€ (ë§¤ìš° ì—„ê²©) ===
- 0ì : ë‹µë³€ ê±°ë¶€, ë¬´ì˜ë¯¸í•œ ë‹µë³€, ìˆ«ìë§Œ ì…ë ¥
- 20-35ì : ë„ˆë¬´ ì§§ê±°ë‚˜ ì„±ì˜ì—†ëŠ” ë‹µë³€
- 35-50ì : ê¸°ë³¸ì ì´ì§€ë§Œ í‘œë©´ì ì´ê³  êµ¬ì²´ì„± ë¶€ì¡±
- 50-65ì : ì ì ˆí•˜ì§€ë§Œ í‰ë²”í•˜ê³  ê¹Šì´ ë¶€ì¡±
- 65-75ì : êµ¬ì²´ì ì´ê³  ì¢‹ì€ ë‹µë³€
- 75-85ì : ë§¤ìš° êµ¬ì²´ì ì´ê³  ì¸ìƒì ì¸ ë‹µë³€
- 85-95ì : íƒì›”í•˜ê³  ê¹Šì´ ìˆëŠ” ë‹µë³€
- 95-100ì : ì™„ë²½í•˜ê³  ê°ë™ì ì¸ ë‹µë³€

í‰ê°€ ìš”ì†Œ:
1. ì§ˆë¬¸ ì˜ë„ ì´í•´ë„ - ë‹µë³€ì´ ì§ˆë¬¸ì˜ í•µì‹¬ì„ ì •í™•íˆ íŒŒì•…í–ˆëŠ”ê°€?
2. êµ¬ì²´ì„± - ì‹¤ì œ ê²½í—˜ê³¼ ì‚¬ë¡€ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?
3. ê¹Šì´ - í‘œë©´ì ì´ì§€ ì•Šê³  ê¹Šì´ ìˆëŠ” ì‚¬ê³ ê°€ ë“œëŸ¬ë‚˜ëŠ”ê°€?
4. ë…¼ë¦¬ì„± - ë‹µë³€ì´ ë…¼ë¦¬ì ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆëŠ”ê°€?
5. ì„±ì°° - ê°œì¸ì  í•™ìŠµì´ë‚˜ ì„±ì¥ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?

í”¼ë“œë°± ì‘ì„± ì‹œ:
- ì§ˆë¬¸ ì˜ë„ë¥¼ ëª…í™•íˆ ì„¤ëª…
- ë‹µë³€ì˜ ì¢‹ì€ ì ê³¼ ë¶€ì¡±í•œ ì ì„ êµ¬ì²´ì ìœ¼ë¡œ ì§€ì 
- ê°œì„  ë°©ë²•ì„ ì‹¤ì§ˆì ìœ¼ë¡œ ì œì•ˆ

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
  "score": ì ìˆ˜,
  "feedback": "ğŸ“ ì§ˆë¬¸ ì˜ë„: {qa.question_intent}\\n\\nğŸ’¬ í‰ê°€: êµ¬ì²´ì ì¸ í‰ê°€ ë‚´ìš© (ì¢‹ì€ ì , ë¶€ì¡±í•œ ì  í¬í•¨)\\n\\nğŸ”§ ê°œì„  ë°©ë²•: ì‹¤ì§ˆì ì´ê³  êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ"
}}
"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë§¤ìš° ì—„ê²©í•œ ë©´ì ‘ í‰ê°€ìì…ë‹ˆë‹¤. ë†’ì€ ê¸°ì¤€ìœ¼ë¡œ ì •í™•í•˜ê²Œ í‰ê°€í•˜ê³ , êµ¬ì²´ì ì´ê³  ê±´ì„¤ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=500,
                temperature=0.3
            )
            
            result = response.choices[0].message.content.strip()
            
            # JSON íŒŒì‹±
            start_idx = result.find('{')
            end_idx = result.rfind('}') + 1
            
            if start_idx != -1 and end_idx != -1:
                json_str = result[start_idx:end_idx]
                evaluation = json.loads(json_str)
                
                # ì ìˆ˜ê°€ ë„ˆë¬´ ë†’ìœ¼ë©´ ê°•ì œë¡œ ì¡°ì •
                if evaluation["score"] > 80 and len(answer) < 100:
                    evaluation["score"] = min(evaluation["score"], 60)
                
                return evaluation
            else:
                raise ValueError("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            print(f"ê°œë³„ í‰ê°€ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # ê¸°ë³¸ ì—„ê²©í•œ í‰ê°€
            if len(answer) < 30:
                score = 25
            elif len(answer) < 100:
                score = 45
            else:
                score = 55
            
            return {
                "score": score,
                "feedback": f"ğŸ“ ì§ˆë¬¸ ì˜ë„: {qa.question_intent}\n\nğŸ’¬ í‰ê°€: ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ê¸°ë³¸ í‰ê°€ë¥¼ ì ìš©í–ˆìŠµë‹ˆë‹¤.\n\nğŸ”§ ê°œì„  ë°©ë²•: ë” êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•´ ì£¼ì„¸ìš”."
            }
    
    def _generate_overall_evaluation(self, session: InterviewSession, company_data: Dict[str, Any], overall_score: int) -> Dict[str, Any]:
        """ì¢…í•© í‰ê°€ ìƒì„±"""
        
        conversation_summary = ""
        for qa in session.conversation_history:
            conversation_summary += f"[{qa.question_type.value}] {qa.question_content}\në‹µë³€: {qa.answer_content}\nê°œë³„ ì ìˆ˜: {qa.individual_score}ì \n\n"
        
        prompt = f"""
{company_data['name']} {session.position} ë©´ì ‘ ì¢…í•© í‰ê°€ë¥¼ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.

=== ì§€ì›ì ì •ë³´ ===
- ì´ë¦„: {session.candidate_name}ë‹˜
- ì§€ì› ì§êµ°: {session.position}
- ì „ì²´ í‰ê·  ì ìˆ˜: {overall_score}ì 

=== ë©´ì ‘ ë‚´ìš© ===
{conversation_summary}

=== ê¸°ì—… ìš”êµ¬ì‚¬í•­ ===
- ì¸ì¬ìƒ: {company_data['talent_profile']}
- í•µì‹¬ ì—­ëŸ‰: {', '.join(company_data['core_competencies'])}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSON ì‘ë‹µ:
{{
  "strengths": ["êµ¬ì²´ì ì¸ ê°•ì 1", "êµ¬ì²´ì ì¸ ê°•ì 2", "êµ¬ì²´ì ì¸ ê°•ì 3"],
  "improvements": ["êµ¬ì²´ì ì¸ ê°œì„ ì 1", "êµ¬ì²´ì ì¸ ê°œì„ ì 2", "êµ¬ì²´ì ì¸ ê°œì„ ì 3"],
  "recommendation": "ì±„ìš© ì¶”ì²œ ì—¬ë¶€ì™€ êµ¬ì²´ì ì¸ ì´ìœ ",
  "next_steps": "ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ",
  "overall_assessment": "ì „ì²´ì ì¸ í‰ê°€ ìš”ì•½"
}}
"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": f"{company_data['name']} ë©´ì ‘ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=600,
                temperature=0.3
            )
            
            result = response.choices[0].message.content.strip()
            
            start_idx = result.find('{')
            end_idx = result.rfind('}') + 1
            
            if start_idx != -1 and end_idx != -1:
                json_str = result[start_idx:end_idx]
                return json.loads(json_str)
            
        except Exception as e:
            print(f"ì¢…í•© í‰ê°€ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        # ì ìˆ˜ì— ë”°ë¥¸ ê¸°ë³¸ í‰ê°€
        if overall_score >= 70:
            recommendation = "ë‹¤ìŒ ë‹¨ê³„ ì§„í–‰ ê³ ë ¤"
            next_steps = "ì‹¤ë¬´ì§„ ë©´ì ‘ ì§„í–‰"
        elif overall_score >= 50:
            recommendation = "ë³´ì™„ í›„ ì¬ê²€í† "
            next_steps = "ê²½í—˜ ë³´ì™„ í›„ ì¬ì§€ì›"
        else:
            recommendation = "í˜„ì¬ ê¸°ì¤€ ë¯¸ë‹¬"
            next_steps = "ì¶©ë¶„í•œ ì¤€ë¹„ í›„ ì¬ì§€ì›"
        
        return {
            "strengths": ["ë©´ì ‘ ì°¸ì—¬", "ê¸°ë³¸ ì†Œí†µ", "ì„±ì‹¤í•¨"],
            "improvements": ["êµ¬ì²´ì  ì‚¬ë¡€ ì œì‹œ", "ë‹µë³€ ê¹Šì´", "ì „ë¬¸ì„± í–¥ìƒ"],
            "recommendation": recommendation,
            "next_steps": next_steps,
            "overall_assessment": f"ì „ì²´ {overall_score}ì  ìˆ˜ì¤€ì˜ ë©´ì ‘ ê²°ê³¼ì…ë‹ˆë‹¤."
        }
    
    def _evaluate_batch_answers(self, session: InterviewSession, company_data: Dict[str, Any]) -> Dict[str, Any]:
        """ë°°ì¹˜ ì²˜ë¦¬ë¡œ ëª¨ë“  ë‹µë³€ì„ í•œ ë²ˆì— í‰ê°€ (ì†ë„ ìµœì í™”)"""
        
        # ëª¨ë“  ì§ˆë¬¸ê³¼ ë‹µë³€ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
        qa_summary = ""
        for i, qa in enumerate(session.conversation_history, 1):
            qa_summary += f"""
ì§ˆë¬¸ {i}: [{qa.question_type.value}] {qa.question_content}
ì˜ë„: {qa.question_intent}
ë‹µë³€: {qa.answer_content}
---
"""
        
        # ë°°ì¹˜ í‰ê°€ í”„ë¡¬í”„íŠ¸ (ê°„ì†Œí™”)
        batch_prompt = f"""
ë‹¤ìŒì€ {company_data['name']} {session.position} ë©´ì ‘ì˜ ì „ì²´ ì§ˆë¬¸ê³¼ ë‹µë³€ì…ë‹ˆë‹¤.

=== ë©´ì ‘ ë‚´ìš© ===
{qa_summary}

=== í‰ê°€ ìš”êµ¬ì‚¬í•­ ===
ê° ë‹µë³€ì„ 0-100ì ìœ¼ë¡œ í‰ê°€í•˜ê³  ê°„ë‹¨í•œ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”.
ì „ì²´ ì¢…í•© í‰ê°€ë„ í•¨ê»˜ ì œê³µí•˜ì„¸ìš”.

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
  "individual_scores": [
    {{"score": ì ìˆ˜, "feedback": "ê°„ë‹¨í•œ í”¼ë“œë°±"}},
    ...
  ],
  "overall_evaluation": {{
    "strengths": ["ê°•ì 1", "ê°•ì 2", "ê°•ì 3"],
    "improvements": ["ê°œì„ ì 1", "ê°œì„ ì 2", "ê°œì„ ì 3"],
    "recommendation": "ìµœì¢… ì¶”ì²œ",
    "next_steps": "ë‹¤ìŒ ë‹¨ê³„",
    "overall_assessment": "ì „ì²´ í‰ê°€ ìš”ì•½"
  }}
}}
"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": f"ë‹¹ì‹ ì€ {company_data['name']}ì˜ ë©´ì ‘ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¹ ë¥´ê³  ì •í™•í•˜ê²Œ í‰ê°€í•˜ì„¸ìš”."},
                    {"role": "user", "content": batch_prompt}
                ],
                max_tokens=1500,
                temperature=0.3
            )
            
            result = response.choices[0].message.content.strip()
            
            # JSON íŒŒì‹±
            start_idx = result.find('{')
            end_idx = result.rfind('}') + 1
            
            if start_idx != -1 and end_idx != -1:
                json_str = result[start_idx:end_idx]
                return json.loads(json_str)
            else:
                raise ValueError("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            print(f"ë°°ì¹˜ í‰ê°€ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # í´ë°±: ê¸°ë³¸ í‰ê°€ ìƒì„±
            return {
                "individual_scores": [{"score": 50, "feedback": "ê¸°ë³¸ í‰ê°€ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤."} for _ in session.conversation_history],
                "overall_evaluation": {
                    "strengths": ["ë©´ì ‘ ì°¸ì—¬", "ê¸°ë³¸ ì†Œí†µ"],
                    "improvements": ["êµ¬ì²´ì  ì‚¬ë¡€ ì œì‹œ", "ë‹µë³€ ê¹Šì´"],
                    "recommendation": "ë³´ì™„ í›„ ì¬ê²€í† ",
                    "next_steps": "ì¶”ê°€ ë©´ì ‘ ì§„í–‰",
                    "overall_assessment": "ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ê¸°ë³¸ í‰ê°€ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤."
                }
            }

if __name__ == "__main__":
    print("ğŸ¯ ìµœì¢… ë©´ì ‘ ì‹œìŠ¤í…œ")
    print("=" * 50)
    
    # ìë™ìœ¼ë¡œ .envì—ì„œ API í‚¤ ë¡œë“œ
    system = FinalInterviewSystem()
    
    companies = system.list_companies()
    print("\nğŸ“‹ ì„ íƒ ê°€ëŠ¥í•œ íšŒì‚¬:")
    for i, company in enumerate(companies, 1):
        print(f"{i}. {company['name']}")
    
    while True:
        try:
            choice = int(input("\níšŒì‚¬ë¥¼ ì„ íƒí•˜ì„¸ìš” (ë²ˆí˜¸): ")) - 1
            if 0 <= choice < len(companies):
                selected_company = companies[choice]
                break
            else:
                print("ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        except ValueError:
            print("ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    
    position = input("ì§êµ°ì„ ì…ë ¥í•˜ì„¸ìš”: ")
    candidate_name = input("ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”: ")
    
    print(f"\nğŸš€ {selected_company['name']} {position} ë©´ì ‘ì„ ì‹œì‘í•©ë‹ˆë‹¤!")
    print(f"ğŸ‘‹ {candidate_name}ë‹˜, í™˜ì˜í•©ë‹ˆë‹¤.")
    
    try:
        session_id = system.start_interview(selected_company['id'], position, candidate_name)
        
        current_question = system.get_next_question(session_id)
        
        while current_question:
            print(f"\n{'='*70}")
            print(f"ğŸ“ [{current_question['question_type']}] ì§ˆë¬¸ {current_question['progress']}")
            print(f"ğŸ¯ ì§ˆë¬¸ ì˜ë„: {current_question['question_intent']}")
            print("-" * 70)
            print(f"â“ {current_question['question_content']}")
            print("="*70)
            
            answer = input("\nğŸ’¬ ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”: ")
            
            result = system.submit_answer(session_id, answer)
            
            if result['status'] == 'interview_complete':
                print(f"\nâœ… {result['message']}")
                break
            elif result['status'] == 'next_question':
                current_question = result['question']
            else:
                print("âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                break
        
        print("\nğŸ”„ ìµœì¢… í‰ê°€ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤...")
        evaluation = system.evaluate_interview(session_id)
        
        print(f"\n{'='*70}")
        print(f"ğŸ“Š {evaluation['company']} ë©´ì ‘ ê²°ê³¼")
        print("="*70)
        
        eval_data = evaluation['evaluation']
        print(f"ğŸ¯ ì „ì²´ ì ìˆ˜: {eval_data['overall_score']}/100")
        
        print("\nğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜:")
        for category, score in eval_data['category_scores'].items():
            print(f"  â€¢ {category}: {score}/100")
        
        print("\nğŸ“ ê°œë³„ ë‹µë³€ í‰ê°€:")
        for feedback in evaluation['individual_feedbacks']:
            print(f"\n{feedback['question_number']}. [{feedback['question_type']}] ì ìˆ˜: {feedback['score']}/100")
            print(f"   ì§ˆë¬¸: {feedback['question']}")
            print(f"   ë‹µë³€: {feedback['answer']}")
            print(f"   í‰ê°€: {feedback['feedback']}")
        
        print(f"\nğŸ’ª ì£¼ìš” ê°•ì :")
        for strength in eval_data['strengths']:
            print(f"  âœ… {strength}")
        
        print(f"\nğŸ”§ ê°œì„  í•„ìš” ì‚¬í•­:")
        for improvement in eval_data['improvements']:
            print(f"  ğŸ”¨ {improvement}")
        
        print(f"\nğŸ¯ ìµœì¢… ì¶”ì²œ: {eval_data['recommendation']}")
        print(f"ğŸš€ ë‹¤ìŒ ë‹¨ê³„: {eval_data['next_steps']}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")