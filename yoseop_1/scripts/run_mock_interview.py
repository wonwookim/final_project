
import asyncio
import sys
import os
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œë¥¼ ì‹œìŠ¤í…œ ê²½ë¡œì— ì¶”ê°€í•˜ì—¬ ëª¨ë“ˆ ì„í¬íŠ¸
current_dir = os.path.dirname(os.path.abspath(__file__))
yoseop_1_root = os.path.abspath(os.path.join(current_dir, '..'))
sys.path.insert(0, yoseop_1_root)

# backend.servicesê°€ ì•„ë‹Œ servicesë¡œ ë°”ë¡œ ì ‘ê·¼í•˜ê¸° ìœ„í•´ ê²½ë¡œ ì¶”ê°€
backend_root = os.path.join(yoseop_1_root, 'backend')
sys.path.insert(0, backend_root)

from services.interview_service import InterviewService

async def run_mock_interview():
    """
    Orchestratorì™€ InterviewServiceë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ì˜ ë©´ì ‘ì„ ì‹¤í–‰í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸.
    """
    print("="*80)
    print("ğŸš€ ëª¨ì˜ ë©´ì ‘ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    print("="*80)

    interview_service = InterviewService()

    # 1. ë©´ì ‘ ì‹œì‘ ì„¤ì •
    mock_settings = {
        "company": "ì¹´ì¹´ì˜¤",
        "position": "ë°±ì—”ë“œ ê°œë°œì",
        "candidate_name": "í™ê¸¸ë™"
    }
    print(f"ğŸ“‹ ë©´ì ‘ ì„¤ì •: {mock_settings}")

    # 2. ë©´ì ‘ ì‹œì‘
    # start_ai_competitionì€ ì²« í„´ì„ ìë™ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.
    print("\n--- 1ï¸âƒ£ ë©´ì ‘ ì‹œì‘ ë° ì²« í„´ ì§„í–‰ ---")
    result = await interview_service.start_ai_competition(mock_settings)
    print(f"\n[ë©´ì ‘ ì‹œì‘ ê²°ê³¼]:\n{json.dumps(result, indent=2, ensure_ascii=False)}")

    if "error" in result:
        print(f"\nâŒ ë©´ì ‘ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {result['error']}")
        return

    session_id = result.get("session_id")
    if not session_id:
        print("\nâŒ ì„¸ì…˜ IDë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\nâœ… ë©´ì ‘ ì„¸ì…˜ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. Session ID: {session_id}")

    # 3. ë©´ì ‘ í„´ ì§„í–‰ (3í„´ ì‹œë®¬ë ˆì´ì…˜)
    for i in range(2, 5): # 2, 3, 4í„´
        print("\n" + "="*80)
        print(f"--- {i}ë²ˆì§¸ í„´ ì§„í–‰ ---")
        print("="*80)

        # í˜„ì¬ ì§ˆë¬¸ í™•ì¸
        current_question = result.get("question") or result.get("next_question")
        if not current_question:
             print("í˜„ì¬ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. ë©´ì ‘ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
             break
        print(f"â“ ë©´ì ‘ê´€ ì§ˆë¬¸: {current_question}")

        # ë‹¤ìŒ ì•¡ì…˜ í™•ì¸
        next_action = result.get("next_action")
        print(f"ğŸ‘‰ ë‹¤ìŒ ì•¡ì…˜: {next_action}")

        if next_action == "user_should_answer":
            # ì‚¬ìš©ì ë‹µë³€ ì œì¶œ
            user_answer = f"ì €ëŠ” {i}ë²ˆì§¸ í„´ì˜ ì‚¬ìš©ì ë‹µë³€ì…ë‹ˆë‹¤. ì´ ì§ˆë¬¸ì— ëŒ€í•´ ê¹Šì´ ìƒê°í•´ ë³´ì•˜ìŠµë‹ˆë‹¤."
            print(f"\nğŸ‘¤ ì‚¬ìš©ì ë‹µë³€ ì œì¶œ: {user_answer}")
            result = await interview_service.submit_user_answer(session_id, user_answer, time_spent=15.5)
            print(f"\n[ì‚¬ìš©ì ë‹µë³€ ì œì¶œ í›„ ê²°ê³¼]:\n{json.dumps(result, indent=2, ensure_ascii=False)}")

        elif next_action == "waiting_for_user_answer":
            # AIê°€ ë¨¼ì € ë‹µë³€í•œ ê²½ìš°
            ai_answer = result.get("ai_answer")
            print(f"\nğŸ¤– AI í›„ë³´ì ë‹µë³€: {ai_answer}")
            user_answer = f"ì €ëŠ” {i}ë²ˆì§¸ í„´ì˜ ì‚¬ìš©ì ë‹µë³€ì…ë‹ˆë‹¤. AIì˜ ë‹µë³€ì„ ë“£ê³  ì œ ìƒê°ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤."
            print(f"\nğŸ‘¤ ì‚¬ìš©ì ë‹µë³€ ì œì¶œ: {user_answer}")
            result = await interview_service.submit_user_answer(session_id, user_answer, time_spent=20.0)
            print(f"\n[ì‚¬ìš©ì ë‹µë³€ ì œì¶œ í›„ ê²°ê³¼]:\n{json.dumps(result, indent=2, ensure_ascii=False)}")

        elif next_action == "interview_completed":
            print("\nğŸ ë©´ì ‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            break
        
        else:
            # ì˜ˆìƒì¹˜ ëª»í•œ ìƒíƒœì¼ ê²½ìš°, ê·¸ëƒ¥ ë‹¤ìŒ í„´ìœ¼ë¡œ ì§„í–‰
            print(f"\nâš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì•¡ì…˜({next_action})ì…ë‹ˆë‹¤. ë‹¤ìŒ í„´ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
            result = await interview_service.continue_interview_flow(session_id)
            print(f"\n[ë‹¤ìŒ í„´ ì§„í–‰ ê²°ê³¼]:\n{json.dumps(result, indent=2, ensure_ascii=False)}")

        if "error" in result:
            print(f"\nâŒ ë©´ì ‘ ì§„í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {result['error']}")
            break

    print("\n" + "="*80)
    print("ğŸ‰ ëª¨ì˜ ë©´ì ‘ ì‹œë®¬ë ˆì´ì…˜ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("="*80)

    # ìµœì¢… ë©´ì ‘ ê¸°ë¡ í™•ì¸
    orchestrator = interview_service.active_orchestrators.get(session_id)
    if orchestrator:
        print("\n--- ìµœì¢… QA ê¸°ë¡ ---")
        print(json.dumps(orchestrator.state['qa_history'], indent=2, ensure_ascii=False))


if __name__ == "__main__":
    # Windowsì—ì„œ aiohttp ê´€ë ¨ ì´ë²¤íŠ¸ ë£¨í”„ ì •ì±… ì„¤ì •
    if sys.platform == "win32":
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    
    try:
        asyncio.run(run_mock_interview())
    except ImportError as e:
        print(f"\nâŒ ImportError: {e}")
        print("ìŠ¤í¬ë¦½íŠ¸ê°€ í”„ë¡œì íŠ¸ì˜ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì°¸ì¡°í•˜ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        print("PYTHONPATH í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
