from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, BackgroundTasks, Request, Query
from fastapi.responses import StreamingResponse, HTMLResponse
from typing import Optional
import logging
from typing import List, Union
import boto3
from botocore.exceptions import ClientError
from backend.services.supabase_client import supabase_client
from backend.schemas.user import UserResponse
from schemas.interview import InterviewHistoryResponse, InterviewSettings, AnswerSubmission, AICompetitionAnswerSubmission, CompetitionTurnSubmission, InterviewResponse, TTSRequest, STTResponse, MemoUpdateRequest
from backend.schemas.gaze import GazeAnalysisResponse
from services.interview_service import InterviewService
from services.interview_service_temp import InterviewServiceTemp
from backend.services.auth_service import AuthService
from backend.services.voice_service import elevenlabs_tts_stream
from fastapi.responses import HTMLResponse
import io
import time
import os
import tempfile
import aiohttp
from dotenv import load_dotenv



# ì„œë¹„ìŠ¤ ê³„ì¸µ ì‚¬ìš©
interview_service = InterviewService()
interview_service_temp = InterviewServiceTemp()

# AuthService ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
auth_service = AuthService()

# ì˜ì¡´ì„± ì£¼ì…
def get_interview_service():
    return interview_service

def get_temp_interview_service():
    return interview_service_temp

# ë¡œê±° ì„¤ì •
interview_logger = logging.getLogger("interview_logger")

# APIRouter ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
interview_router = APIRouter(
    prefix="/interview",
    tags=["Interview"],
)

# @interview_router.post("/start")
# async def start_interview(
#     settings: InterviewSettings,
#     service: InterviewService = Depends(get_interview_service)
# ):
#     """ë©´ì ‘ ì‹œì‘ - ì„œë¹„ìŠ¤ ê³„ì¸µ ì‚¬ìš©"""
#     try:
#         settings_dict = {
#             "company": settings.company,
#             "position": settings.position,
#             "candidate_name": settings.candidate_name,
#             "documents": settings.documents
#         }
# =================================================================
# ğŸš€ TTS í…ŒìŠ¤íŠ¸ìš© ì„ì‹œ ì½”ë“œ START (ë‚˜ì¤‘ì— ì´ ë¶€ë¶„ì„ ì‚­ì œí•˜ì„¸ìš”)
# =================================================================


@interview_router.get("/tts-test", response_class=HTMLResponse, summary="[í…ŒìŠ¤íŠ¸ìš©] TTS ì›¹ í˜ì´ì§€")
async def get_tts_test_page():
    """
    TTS APIë¥¼ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•œ ê°„ë‹¨í•œ HTML í˜ì´ì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì´ ì—”ë“œí¬ì¸íŠ¸ëŠ” ê°œë°œ ë° ë””ë²„ê¹… ëª©ì ìœ¼ë¡œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    """
    try:
        with open("temp_test.html", "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: temp_test.html")
# =================================================================
# ğŸš€ TTS í…ŒìŠ¤íŠ¸ìš© ì„ì‹œ ì½”ë“œ END
# =================================================================
        
#         result = await service.start_interview(settings_dict)
#         return result
        
#     except Exception as e:
#         interview_logger.error(f"ë©´ì ‘ ì‹œì‘ ì˜¤ë¥˜: {str(e)}")
#         raise HTTPException(status_code=500, detail=str(e))
    
# @interview_router.post("/upload")
# async def upload_document(
#     file: UploadFile = File(...),
#     service: InterviewService = Depends(get_interview_service)
# ):
#     """ë¬¸ì„œ ì—…ë¡œë“œ ë° ë¶„ì„"""
#     try:
#         content = await file.read()
#         file_data = {
#             "filename": file.filename,
#             "content": content
#         }
        
#         result = await service.upload_document(file_data)
#         return result
        
#     except Exception as e:
#         interview_logger.error(f"ë¬¸ì„œ ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
#         raise HTTPException(status_code=500, detail=str(e))

# @interview_router.get("/question")
# async def get_next_question(
#     session_id: str,
#     service: InterviewService = Depends(get_interview_service)
# ):
#     """ë‹¤ìŒ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸° - ì„œë¹„ìŠ¤ ê³„ì¸µ ì‚¬ìš©"""
#     try:
#         result = await service.get_next_question(session_id)
#         return result
        
#     except Exception as e:
#         interview_logger.error(f"ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {str(e)}")
#         raise HTTPException(status_code=500, detail=str(e))

@interview_router.get("/question")
async def get_next_question_ai_competition(
    session_id: str,
    service: InterviewService = Depends(get_interview_service)
):
    """AI ê²½ìŸ ë©´ì ‘ì—ì„œ ë‹¤ìŒ ì§ˆë¬¸/ë‹µë³€ í„´ ì§„í–‰"""
    try:
        result = await service.advance_interview_turn(session_id)
        return result
        
    except Exception as e:
        interview_logger.error(f"ë©´ì ‘ í„´ ì§„í–‰ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# @interview_router.post("/answer")
# async def submit_answer(
#     answer_data: AnswerSubmission,
#     service: InterviewService = Depends(get_interview_service)
# ):
#     """ë‹µë³€ ì œì¶œ - ì„œë¹„ìŠ¤ ê³„ì¸µ ì‚¬ìš©"""
#     try:
#         answer_dict = {
#             "session_id": answer_data.session_id,
#             "answer": answer_data.answer,
#             "time_spent": answer_data.time_spent
#         }
        
#         result = await service.submit_answer(answer_dict)
#         return result
        
#     except Exception as e:
#         interview_logger.error(f"ë‹µë³€ ì œì¶œ ì˜¤ë¥˜: {str(e)}")
#         raise HTTPException(status_code=500, detail=str(e))

# @interview_router.post("/answer")
# async def submit_user_answer(
#     answer_data: AnswerSubmission,
#     service: InterviewService = Depends(get_interview_service)
# ):
#     """ì‚¬ìš©ì ë‹µë³€ ì œì¶œ - Orchestrator ê¸°ë°˜"""
#     try:
#         result = await service.submit_user_answer(
#             session_id=answer_data.session_id,
#             user_answer=answer_data.answer,
#             time_spent=answer_data.time_spent
#         )
#         return result
        
#     except Exception as e:
#         interview_logger.error(f"ì‚¬ìš©ì ë‹µë³€ ì œì¶œ ì˜¤ë¥˜: {str(e)}")
#         raise HTTPException(status_code=500, detail=str(e))

# AI ê²½ìŸ ëª¨ë“œ ì—”ë“œí¬ì¸íŠ¸

@interview_router.post("/ai/start")
async def start_ai_competition(
    settings: InterviewSettings,
    service: InterviewService = Depends(get_interview_service),
    current_user: UserResponse = Depends(auth_service.get_current_user)
):
    """AI ì§€ì›ìì™€ì˜ ê²½ìŸ ë©´ì ‘ ì‹œì‘"""
    start_time = time.perf_counter()
    try:
        interview_logger.info(f"ğŸ› FastAPI DEBUG: ë°›ì€ settings = {settings.dict()}")

        # 1. Pydantic ëª¨ë¸ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ì›ë³¸ ë°ì´í„°ë¥¼ ëª¨ë‘ ë³´ì¡´í•©ë‹ˆë‹¤.
        settings_dict = settings.dict()
        
        # 2. user_idë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
        settings_dict['user_id'] = current_user.user_id

        # 3. user_resume_idê°€ ì—†ìœ¼ë©´ DBì—ì„œ ì¡°íšŒí•˜ì—¬ ì¶”ê°€í•©ë‹ˆë‹¤.
        if not settings.user_resume_id:
            try:
                from backend.services.existing_tables_service import existing_tables_service
                user_resumes = await existing_tables_service.get_user_resumes(current_user.user_id)
                if user_resumes:
                    # settings_dictë¥¼ ì§ì ‘ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
                    settings_dict['user_resume_id'] = user_resumes[0].get('user_resume_id')
                    interview_logger.info(f"âœ… ìë™ ì¡°íšŒëœ user_resume_id: {settings_dict['user_resume_id']}")
            except Exception as e:
                interview_logger.error(f"âŒ user_resume_id ìë™ ì¡°íšŒ ì‹¤íŒ¨: {e}")

        # 4. posting_idê°€ ìˆìœ¼ë©´ DB ì •ë³´ë¥¼ ì´ìš©í•´ ì¼ë¶€ ê°’ì„ ë®ì–´ì”ë‹ˆë‹¤. (update ì‚¬ìš©)
        if settings.posting_id:
            from backend.services.existing_tables_service import existing_tables_service
            posting_info = await existing_tables_service.get_posting_by_id(settings.posting_id)
            if posting_info:
                interview_logger.info(f"ğŸ“‹ ì‹¤ì œ ì±„ìš©ê³µê³  ì‚¬ìš©: posting_id={settings.posting_id}")
                # ë®ì–´ì“¸ ë‚´ìš©ë§Œ update()ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì¡´ ë°ì´í„°ë¥¼ ë³´ì¡´í•©ë‹ˆë‹¤.
                settings_dict.update({
                    "company": posting_info.get('company', {}).get('name', settings.company),
                    "position": posting_info.get('position', {}).get('position_name', settings.position),
                    "company_id": posting_info.get('company_id'),
                    "position_id": posting_info.get('position_id'),
                })
            else:
                interview_logger.warning(f"âš ï¸ ì±„ìš©ê³µê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: posting_id={settings.posting_id}")
        
        interview_logger.info(f"ğŸ› FastAPI DEBUG: ì„œë¹„ìŠ¤ì— ì „ë‹¬í•  ìµœì¢… settings_dict = {settings_dict}")
        
        result = await service.start_ai_competition(settings_dict, start_time=start_time)
        
        end_time = time.perf_counter()
        elapsed_time = end_time - start_time
        interview_logger.info(f"âœ… AI ê²½ìŸ ë©´ì ‘ ì‹œì‘ ì„±ê³µ. ì´ ì²˜ë¦¬ ì‹œê°„: {elapsed_time:.4f}ì´ˆ")
        
        return result
        
    except Exception as e:
        end_time = time.perf_counter()
        elapsed_time = end_time - start_time
        interview_logger.error(f"AI ê²½ìŸ ë©´ì ‘ ì‹œì‘ ì˜¤ë¥˜: {str(e)}. ì²˜ë¦¬ ì‹œê°„: {elapsed_time:.4f}ì´ˆ", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@interview_router.post("/answer")
async def submit_user_answer(
    submission: AICompetitionAnswerSubmission,
    service: InterviewService = Depends(get_interview_service)
):
    """ì‚¬ìš©ì ë‹µë³€ ì œì¶œ - AI ê²½ìŸ ë©´ì ‘ìš©"""
    try:
        interview_logger.info(f"ğŸ‘¤ ì‚¬ìš©ì ë‹µë³€ ì œì¶œ ìš”ì²­: {submission.session_id}")
        
        result = await service.submit_user_answer(
            session_id=submission.session_id,
            user_answer=submission.answer,
            time_spent=submission.time_spent
        )
        
        interview_logger.info(f"âœ… ì‚¬ìš©ì ë‹µë³€ ì œì¶œ ì™„ë£Œ: {submission.session_id}")
        return result
        
    except Exception as e:
        interview_logger.error(f"ì‚¬ìš©ì ë‹µë³€ ì œì¶œ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@interview_router.get("/session/active")
async def get_active_sessions(
    service: InterviewService = Depends(get_interview_service)
):
    """í˜„ì¬ í™œì„± ì„¸ì…˜ë“¤ ì¡°íšŒ"""
    try:
        active_sessions = service.get_active_sessions()
        return {
            "active_sessions": active_sessions,
            "count": len(active_sessions)
        }
    except Exception as e:
        interview_logger.error(f"í™œì„± ì„¸ì…˜ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@interview_router.get("/session/{session_id}/state")
async def get_session_state(
    session_id: str,
    service: InterviewService = Depends(get_interview_service)
):
    """íŠ¹ì • ì„¸ì…˜ì˜ ìƒíƒœ ì¡°íšŒ"""
    try:
        state = service.get_session_state(session_id)
        if not state:
            raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return {
            "session_id": session_id,
            "state": state,
            "is_active": True
        }
    except HTTPException:
        raise
    except Exception as e:
        interview_logger.error(f"ì„¸ì…˜ ìƒíƒœ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@interview_router.get("/ai-answer/{session_id}/{question_id}")
async def get_ai_answer(
    session_id: str,
    question_id: str,
    service: InterviewService = Depends(get_interview_service)
):
    """AI ì§€ì›ìì˜ ë‹µë³€ ìƒì„±"""
    try:
        result = await service.get_ai_answer(session_id, question_id)
        return result
        
    except Exception as e:
        interview_logger.error(f"AI ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@interview_router.post("/comparison/turn")
async def process_competition_turn(
    submission: CompetitionTurnSubmission,
    service: InterviewService = Depends(get_interview_service)
):
    """ê²½ìŸ ë©´ì ‘ í†µí•© í„´ ì²˜ë¦¬"""
    try:
        result = await service.process_competition_turn(
            submission.comparison_session_id,
            submission.answer
        )
        return result
    except Exception as e:
        interview_logger.error(f"ê²½ìŸ ë©´ì ‘ í„´ ì²˜ë¦¬ API ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# ğŸš€ ìƒˆë¡œìš´ í„´ì œ ë©´ì ‘ ì—”ë“œí¬ì¸íŠ¸
@interview_router.post("/turn-based/start")
async def start_turn_based_interview(
    settings: InterviewSettings,
    service: InterviewService = Depends(get_interview_service)
):
    """í„´ì œ ë©´ì ‘ ì‹œì‘ - ìƒˆë¡œìš´ InterviewerService ì‚¬ìš©"""
    try:
        settings_dict = {
            "company": settings.company,
            "position": settings.position,
            "candidate_name": settings.candidate_name
        }
        
        result = await service.start_turn_based_interview(settings_dict)
        return result
        
    except Exception as e:
        interview_logger.error(f"í„´ì œ ë©´ì ‘ ì‹œì‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@interview_router.get("/turn-based/question/{session_id}")
async def get_turn_based_question(
    session_id: str,
    user_answer: Optional[str] = None,
    service: InterviewService = Depends(get_interview_service)
):
    """í„´ì œ ë©´ì ‘ ë‹¤ìŒ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°"""
    try:
        result = await service.get_turn_based_question(session_id, user_answer)
        return result
        
    except Exception as e:
        interview_logger.error(f"í„´ì œ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# ğŸŸ¢ GET /interview/history â€“ ë‚´ ë©´ì ‘ ê¸°ë¡ ì¡°íšŒ
@interview_router.get("/history", response_model=List[InterviewResponse])
async def get_interview_history(current_user: UserResponse = Depends(auth_service.get_current_user)):
    """í˜„ì¬ ì¸ì¦ëœ ì‚¬ìš©ìì˜ ë©´ì ‘ ê¸°ë¡ì„ Supabaseì—ì„œ ì¡°íšŒí•©ë‹ˆë‹¤."""
    print(f"ğŸ” DEBUG: ë©´ì ‘ íˆìŠ¤í† ë¦¬ ì¡°íšŒ - ì‚¬ìš©ì ID: {current_user.user_id} (íƒ€ì…: {type(current_user.user_id)}), ì´ë©”ì¼: {current_user.email}")
    
    # ì „ì²´ interview í…Œì´ë¸” ë°ì´í„° í™•ì¸
    all_interviews = supabase_client.client.from_("interview").select("interview_id, user_id").execute()
    print(f"ğŸ” DEBUG: ì „ì²´ interview í…Œì´ë¸” ë ˆì½”ë“œ ìˆ˜: {len(all_interviews.data) if all_interviews.data else 0}")
    if all_interviews.data:
        user_ids_with_types = [(item['user_id'], type(item['user_id'])) for item in all_interviews.data[:5]]
        print(f"ğŸ” DEBUG: ì „ì²´ interview ì‚¬ìš©ì IDë“¤ê³¼ íƒ€ì…: {user_ids_with_types}")
        
        # í˜„ì¬ ì‚¬ìš©ì IDì™€ ì¼ì¹˜í•˜ëŠ”ì§€ ì§ì ‘ í™•ì¸
        matching_interviews = [item for item in all_interviews.data if str(item['user_id']) == str(current_user.user_id)]
        print(f"ğŸ” DEBUG: ë¬¸ìì—´ ë³€í™˜ í›„ ì¼ì¹˜í•˜ëŠ” ë©´ì ‘ ìˆ˜: {len(matching_interviews)}")
    
    # ì²« ë²ˆì§¸ íŒŒì¼ì˜ ë” ìƒì„¸í•œ ì¿¼ë¦¬ ì‚¬ìš© (company, position join í¬í•¨)
    # íƒ€ì… ë¶ˆì¼ì¹˜ ë°©ì§€ë¥¼ ìœ„í•´ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì¡°íšŒ
    res = supabase_client.client.from_("interview").select(
        "*, company(name), position(position_name)"
    ).eq("user_id", str(current_user.user_id)).execute()
    
    print(f"ğŸ” DEBUG: ì‚¬ìš©ìë³„ ë©´ì ‘ ê¸°ë¡ ì¡°íšŒ ê²°ê³¼: {len(res.data) if res.data else 0}ê°œ")
    if res.data:
        print(f"ğŸ” DEBUG: ì²« ë²ˆì§¸ ë©´ì ‘ ê¸°ë¡: {res.data[0]}")
    
    if not res.data:
        return []  # ë¹ˆ ë°°ì—´ ë°˜í™˜ (404 ì—ëŸ¬ ëŒ€ì‹ )
    # ai_resume_id/user_resume_idê°€ Noneì¸ ê²½ìš°ì—ë„ ìŠ¤í‚¤ë§ˆ ê²€ì¦ì„ í†µê³¼í•˜ë„ë¡ ë³´ì •
    data = res.data
    for row in data:
        if 'ai_resume_id' in row and row['ai_resume_id'] is None:
            row['ai_resume_id'] = None
        if 'user_resume_id' in row and row['user_resume_id'] is None:
            row['user_resume_id'] = None
        # total_feedbackì´ Noneì¸ ê²½ìš° ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜
        if 'total_feedback' in row and row['total_feedback'] is None:
            row['total_feedback'] = ""
    return data


@interview_router.get("/history/{interview_id}")
async def get_interview_results(
    interview_id: int,
    current_user: UserResponse = Depends(auth_service.get_current_user)
):
    """í˜„ì¬ ë¡œê·¸ì¸í•œ ìœ ì €ì˜ íŠ¹ì • ë©´ì ‘ ê¸°ë¡ ì¡°íšŒ (ìƒì„¸ ë°ì´í„° + ì „ì²´ í”¼ë“œë°± + ì˜ìƒ URL)"""
    
    # 1. history_detail í…Œì´ë¸”ì—ì„œ ì§ˆë¬¸ë³„ ìƒì„¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    detail_res = supabase_client.client.from_("history_detail") \
        .select("*") \
        .eq("interview_id", interview_id) \
        .execute()
    
    # 2. interview í…Œì´ë¸”ì—ì„œ ì „ì²´ í”¼ë“œë°± ê°€ì ¸ì˜¤ê¸°
    interview_res = supabase_client.client.from_("interview") \
        .select("total_feedback") \
        .eq("interview_id", interview_id) \
        .execute()
    
    # 3. plans í…Œì´ë¸”ì—ì„œ ê°œì„  ê³„íš ê°€ì ¸ì˜¤ê¸°
    plans_res = supabase_client.client.from_("plans") \
        .select("shortly_plan, long_plan") \
        .eq("interview_id", interview_id) \
        .execute()
    
    # 4. media_files í…Œì´ë¸”ì—ì„œ ì˜ìƒ íŒŒì¼ ì •ë³´ í™•ì¸
    video_url = None
    video_metadata = None
    
    try:
        media_res = supabase_client.client.from_("media_files") \
            .select("s3_key, file_name, file_size, duration, created_at") \
            .eq("interview_id", interview_id) \
            .eq("file_type", "video") \
            .order("created_at", desc=True) \
            .limit(1) \
            .execute()
        
        if media_res.data and len(media_res.data) > 0:
            video_file = media_res.data[0]
            # ì˜ìƒì´ ìˆìœ¼ë©´ ìŠ¤íŠ¸ë¦¬ë° URL ì œê³µ
            video_url = f"/interview/video/{interview_id}/stream"
            video_metadata = {
                "file_name": video_file.get("file_name"),
                "file_size": video_file.get("file_size"),
                "duration": video_file.get("duration"),
                "created_at": video_file.get("created_at")
            }
            interview_logger.info(f"âœ… ë©´ì ‘ {interview_id}ì˜ ì˜ìƒ íŒŒì¼ ë°œê²¬: {video_file.get('file_name')}")
        else:
            interview_logger.info(f"â„¹ï¸ ë©´ì ‘ {interview_id}ì— ëŒ€í•œ ì˜ìƒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            
    except Exception as e:
        interview_logger.warning(f"âš ï¸ ì˜ìƒ íŒŒì¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")
        # ì˜ìƒ íŒŒì¼ ì¡°íšŒ ì‹¤íŒ¨ëŠ” ì „ì²´ APIë¥¼ ì‹¤íŒ¨ì‹œí‚¤ì§€ ì•ŠìŒ
    
    # ë‹¤ìš´ë¡œë“œ URL ìƒì„±
    download_url = None
    download_optimized_url = None
    if video_url:
        download_url = f"/interview/video/{interview_id}/download"
        download_optimized_url = f"/interview/video/{interview_id}/download?optimize=true"
    
    # ë°ì´í„° í†µí•©
    result = {
        "details": detail_res.data or [],
        "total_feedback": interview_res.data[0]["total_feedback"] if interview_res.data else None,
        "plans": plans_res.data[0] if plans_res.data else None,
        "video_url": video_url,
        "download_url": download_url,
        "download_optimized_url": download_optimized_url,
        "video_metadata": video_metadata
    }
    
    return result


@interview_router.get("/{interview_id}/gaze-analysis", response_model=GazeAnalysisResponse, summary="[ì‹ ê·œ] íŠ¹ì • ë©´ì ‘ì˜ ì‹œì„  ë¶„ì„ ê²°ê³¼ ì¡°íšŒ")
async def get_gaze_analysis_for_interview(
    interview_id: int,
    current_user: UserResponse = Depends(auth_service.get_current_user)
):
    """íŠ¹ì • ë©´ì ‘ì— ëŒ€í•œ ì‹œì„  ë¶„ì„(ë¹„ì–¸ì–´ì  í”¼ë“œë°±) ê²°ê³¼ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    try:
        interview_logger.info(f"ğŸ“ˆ ì‹œì„  ë¶„ì„ ê²°ê³¼ ìš”ì²­: interview_id={interview_id}")
        
        # 1. í•´ë‹¹ ë©´ì ‘ì´ í˜„ì¬ ì‚¬ìš©ìì˜ ê²ƒì¸ì§€ í™•ì¸ (ë³´ì•ˆ ê°•í™”)
        interview_res = supabase_client.client.from_("interview") \
            .select("user_id") \
            .eq("interview_id", interview_id) \
            .eq("user_id", current_user.user_id) \
            .single() \
            .execute()

        if not interview_res.data:
            raise HTTPException(status_code=403, detail="í•´ë‹¹ ë©´ì ‘ì— ì ‘ê·¼í•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")

        # 2. gaze_analysis í…Œì´ë¸”ì—ì„œ ê²°ê³¼ ì¡°íšŒ (í…Œì´ë¸”ëª…ì€ ê°€ì •)
        # TODO: 2ë‹¨ê³„ì—ì„œ ì‹¤ì œ DB ì¡°íšŒ ë¡œì§ìœ¼ë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.
        gaze_res = supabase_client.client.from_("gaze_analysis") \
            .select("*") \
            .eq("interview_id", interview_id) \
            .order("created_at", desc=True) \
            .limit(1) \
            .execute()

        if not gaze_res.data:
            # ğŸš¨ ì¤‘ìš”: í˜„ì¬ëŠ” ë°ì´í„°ê°€ ì—†ìœ¼ë©´ 404ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
            # 2ë‹¨ê³„ì—ì„œ gaze.pyê°€ DBì— ë°ì´í„°ë¥¼ ì €ì¥í•˜ë„ë¡ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.
            interview_logger.warning(f"âš ï¸ interview_id={interview_id}ì— ëŒ€í•œ ì‹œì„  ë¶„ì„ ë°ì´í„° ì—†ìŒ")
            raise HTTPException(status_code=404, detail="í•´ë‹¹ ë©´ì ‘ì˜ ì‹œì„  ë¶„ì„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        analysis_data = gaze_res.data[0]
        
        # í”„ë¡ íŠ¸ì—”ë“œê°€ ê¸°ëŒ€í•˜ëŠ” GazeAnalysisResponse ëª¨ë¸ë¡œ ë³€í™˜
        return GazeAnalysisResponse(
            gaze_id=analysis_data.get("gaze_id"),
            interview_id=analysis_data.get("interview_id"),
            user_id=analysis_data.get("user_id"),
            gaze_score=analysis_data.get("gaze_score", 0),
            jitter_score=analysis_data.get("jitter_score", 0),
            compliance_score=analysis_data.get("compliance_score", 0),
            stability_rating=analysis_data.get("stability_rating", "N/A"),
            created_at=analysis_data.get("created_at"),
            gaze_points=analysis_data.get("gaze_points"),
            calibration_points=analysis_data.get("calibration_points"),
            video_metadata=analysis_data.get("video_metadata"),
        )

    except HTTPException:
        raise
    except Exception as e:
        interview_logger.error(f"âŒ ì‹œì„  ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="ì‹œì„  ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì¤‘ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")


@interview_router.get("/video/{interview_id}/stream")
async def stream_interview_video(interview_id: int, request: Request):
    """
    ë©´ì ‘ ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë° ì—”ë“œí¬ì¸íŠ¸ (Range í—¤ë” ì§€ì› - ë¹„ë””ì˜¤ íƒìƒ‰ ê¸°ëŠ¥).
    ì´ ì—”ë“œí¬ì¸íŠ¸ëŠ” ì¸ì¦ëœ ì‚¬ìš©ìì—ê²Œë§Œ ë…¸ì¶œë˜ëŠ” ê²°ê³¼ í˜ì´ì§€ë¥¼ í†µí•´ ì ‘ê·¼ë˜ë¯€ë¡œ,
    ì—”ë“œí¬ì¸íŠ¸ ìì²´ì˜ ì¸ì¦ì€ ìƒëµí•˜ì—¬ ë¹„ë””ì˜¤ í”Œë ˆì´ì–´ í˜¸í™˜ì„±ì„ ë†’ì…ë‹ˆë‹¤.
    """
    try:
        # 1. DBì—ì„œ ì˜ìƒ ì •ë³´ ì¡°íšŒ
        interview_logger.info(f"ğŸ“¹ ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ ìˆ˜ì‹ : interview_id={interview_id}")
        media_res = supabase_client.client.from_("media_files") \
            .select("s3_key, file_name, file_size") \
            .eq("interview_id", interview_id) \
            .eq("file_type", "video") \
            .order("created_at", desc=True) \
            .limit(1) \
            .execute()

        if not media_res.data:
            interview_logger.warning(f"âš ï¸ ì˜ìƒ íŒŒì¼ì„ DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ: interview_id={interview_id}")
            raise HTTPException(status_code=404, detail="í•´ë‹¹ ë©´ì ‘ì˜ ì˜ìƒ íŒŒì¼ì„ DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        video_file = media_res.data[0]
        s3_key = video_file["s3_key"]
        file_size = video_file.get("file_size")
        interview_logger.info(f"âœ… DB ì¡°íšŒ ì„±ê³µ. S3 Key: {s3_key}, File Size: {file_size}")

        # 2. S3 í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        aws_access_key = os.getenv('AWS_ACCESS_KEY_ID')
        aws_secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')
        s3_client = boto3.client('s3', aws_access_key_id=aws_access_key, aws_secret_access_key=aws_secret_key, region_name='ap-northeast-2')
        bucket_name = 'betago-s3'

        # 3. Range í—¤ë” ì²˜ë¦¬
        range_header = request.headers.get('range')
        if range_header and file_size:
            interview_logger.info(f"ğŸ“Š Range ìš”ì²­: {range_header}, íŒŒì¼ í¬ê¸°: {file_size}")
            
            try:
                # Range í—¤ë” íŒŒì‹± ê°œì„  (ì˜ˆ: "bytes=0-1023", "bytes=1024-", "bytes=-1000")
                range_match = range_header.replace('bytes=', '').split('-')
                interview_logger.info(f"ğŸ“Š Range íŒŒì‹± ê²°ê³¼: {range_match}")
                
                # ë‹¤ì–‘í•œ Range íŒ¨í„´ ì²˜ë¦¬
                if len(range_match) == 2:
                    if range_match[0] == '' and range_match[1] != '':
                        # suffix-byte-range-spec: "bytes=-1000" (ë§ˆì§€ë§‰ 1000ë°”ì´íŠ¸)
                        suffix_length = int(range_match[1])
                        start = max(0, file_size - suffix_length)
                        end = file_size - 1
                    elif range_match[0] != '' and range_match[1] == '':
                        # range from start to end: "bytes=1024-"
                        start = int(range_match[0])
                        end = file_size - 1
                    elif range_match[0] != '' and range_match[1] != '':
                        # range with both start and end: "bytes=0-1023"
                        start = int(range_match[0])
                        end = int(range_match[1])
                    else:
                        # ì˜ëª»ëœ Range í—¤ë”
                        interview_logger.warning(f"âš ï¸ ì˜ëª»ëœ Range í—¤ë” í˜•ì‹: {range_header}")
                        start = 0
                        end = file_size - 1
                else:
                    interview_logger.warning(f"âš ï¸ Range í—¤ë” íŒŒì‹± ì‹¤íŒ¨: {range_header}")
                    start = 0
                    end = file_size - 1
                
                # ë²”ìœ„ ê²€ì¦ ë° ì¡°ì •
                start = max(0, min(start, file_size - 1))
                end = max(start, min(end, file_size - 1))
                content_length = end - start + 1
                
                interview_logger.info(f"ğŸ“Š Range ì²˜ë¦¬ ì™„ë£Œ: {start}-{end}/{file_size} (Length: {content_length})")
                
            except (ValueError, IndexError) as e:
                interview_logger.error(f"âŒ Range í—¤ë” íŒŒì‹± ì˜¤ë¥˜: {e}")
                # ì˜¤ë¥˜ ì‹œ ì „ì²´ íŒŒì¼ ë°˜í™˜
                start = 0
                end = file_size - 1
                content_length = file_size
            
            # S3ì—ì„œ Rangeë¡œ ê°ì²´ ê°€ì ¸ì˜¤ê¸°
            s3_object = s3_client.get_object(
                Bucket=bucket_name, 
                Key=s3_key,
                Range=f'bytes={start}-{end}'
            )
            streaming_content = s3_object['Body']
            
            # Range ì‘ë‹µ í—¤ë” ì„¤ì • (RFC 7233 ì¤€ìˆ˜)
            response_headers = {
                "Accept-Ranges": "bytes",
                "Content-Range": f"bytes {start}-{end}/{file_size}",
                "Content-Length": str(content_length),
                "Cache-Control": "no-cache, no-store, must-revalidate",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Expose-Headers": "Accept-Ranges, Content-Range, Content-Length",
                "Pragma": "no-cache",
                "Expires": "0"
            }
            
            interview_logger.info(f"âœ… Range ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘: {start}-{end}/{file_size} -> Content-Range: bytes {start}-{end}/{file_size}")
            return StreamingResponse(
                streaming_content, 
                status_code=206,  # Partial Content
                media_type=s3_object.get('ContentType', 'video/webm'), 
                headers=response_headers
            )
        else:
            # Range í—¤ë”ê°€ ì—†ëŠ” ê²½ìš° ì „ì²´ íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë°
            interview_logger.info("ğŸ“Š ì „ì²´ íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë°")
            s3_object = s3_client.get_object(Bucket=bucket_name, Key=s3_key)
            streaming_content = s3_object['Body']

            response_headers = {
                "Accept-Ranges": "bytes",
                "Cache-Control": "no-cache, no-store, must-revalidate",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Expose-Headers": "Accept-Ranges, Content-Length",
                "Pragma": "no-cache",
                "Expires": "0"
            }
            if file_size:
                response_headers["Content-Length"] = str(file_size)

            interview_logger.info(f"âœ… ì „ì²´ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘: {s3_key} (íŒŒì¼ í¬ê¸°: {file_size})")
            return StreamingResponse(
                streaming_content, 
                media_type=s3_object.get('ContentType', 'video/webm'), 
                headers=response_headers
            )

    except ClientError as e:
        error_code = e.response.get("Error", {}).get("Code")
        interview_logger.error(f"S3 ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜ (interview_id: {interview_id}): {error_code}")
        if error_code == 'NoSuchKey':
            raise HTTPException(status_code=404, detail=f"S3ì— í•´ë‹¹ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {s3_key}")
        else:
            raise HTTPException(status_code=500, detail=f"S3 ì²˜ë¦¬ ì˜¤ë¥˜: {error_code}")

    except HTTPException:
        # ì´ë¯¸ ì²˜ë¦¬ëœ HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì „ë‹¬
        raise
    except Exception as e:
        interview_logger.error(f"ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ (interview_id: {interview_id}): {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@interview_router.get("/video/{interview_id}/download")
async def download_interview_video(interview_id: int, optimize: bool = False):
    """
    ë©´ì ‘ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸.
    ìŠ¤íŠ¸ë¦¬ë°ê³¼ ë‹¬ë¦¬ Range í—¤ë”ë¥¼ ë¬´ì‹œí•˜ê³  ì „ì²´ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    optimize=true ì‹œ ì‹œê°„ íƒìƒ‰ì— ìµœì í™”ëœ íŒŒì¼ë¡œ ë³€í™˜í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤.
    """
    try:
        # 1. DBì—ì„œ ì˜ìƒ ì •ë³´ ì¡°íšŒ
        interview_logger.info(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ìš”ì²­ ìˆ˜ì‹ : interview_id={interview_id}, optimize={optimize}")
        media_res = supabase_client.client.from_("media_files") \
            .select("s3_key, file_name, file_size") \
            .eq("interview_id", interview_id) \
            .eq("file_type", "video") \
            .order("created_at", desc=True) \
            .limit(1) \
            .execute()

        if not media_res.data:
            interview_logger.warning(f"âš ï¸ ë‹¤ìš´ë¡œë“œí•  ì˜ìƒ íŒŒì¼ì„ DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ: interview_id={interview_id}")
            raise HTTPException(status_code=404, detail="í•´ë‹¹ ë©´ì ‘ì˜ ì˜ìƒ íŒŒì¼ì„ DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        video_file = media_res.data[0]
        s3_key = video_file["s3_key"]
        file_name = video_file.get("file_name", f"interview_{interview_id}_video.webm")
        file_size = video_file.get("file_size")
        interview_logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ DB ì¡°íšŒ ì„±ê³µ. S3 Key: {s3_key}, File Name: {file_name}")

        # 2. S3 í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        aws_access_key = os.getenv('AWS_ACCESS_KEY_ID')
        aws_secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')
        s3_client = boto3.client('s3', aws_access_key_id=aws_access_key, aws_secret_access_key=aws_secret_key, region_name='ap-northeast-2')
        bucket_name = 'betago-s3'

        # 3. S3ì—ì„œ ì „ì²´ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
        s3_object = s3_client.get_object(Bucket=bucket_name, Key=s3_key)
        
        if optimize:
            # FFmpeg ìµœì í™” ì ìš©
            interview_logger.info("ğŸ”§ FFmpeg ìµœì í™” ì ìš© ì¤‘...")
            from utils.video_optimizer import VideoOptimizer
            
            if not VideoOptimizer.is_ffmpeg_available():
                interview_logger.warning("FFmpegë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì›ë³¸ íŒŒì¼ë¡œ ì œê³µí•©ë‹ˆë‹¤")
                streaming_content = s3_object['Body']
                optimized_file_name = file_name
            else:
                import tempfile
                
                # ìµœì í™”ëœ íŒŒì¼ì„ ìœ„í•œ ì„ì‹œ íŒŒì¼ ìƒì„±
                file_extension = file_name.split('.')[-1] if '.' in file_name else 'webm'
                optimized_file_name = file_name.replace(f'.{file_extension}', f'_optimized.{file_extension}')
                
                with tempfile.NamedTemporaryFile(delete=False, suffix=f'.{file_extension}') as temp_output:
                    temp_output_path = temp_output.name
                
                try:
                    # FFmpegë¡œ ìµœì í™” ìˆ˜í–‰
                    optimization_success = VideoOptimizer.optimize_for_seeking(
                        s3_object['Body'], 
                        temp_output_path, 
                        file_extension
                    )
                    
                    if optimization_success and os.path.exists(temp_output_path):
                        interview_logger.info("âœ… FFmpeg ìµœì í™” ì™„ë£Œ")
                        
                        # ìµœì í™”ëœ íŒŒì¼ì„ ë©”ëª¨ë¦¬ë¡œ ì½ì–´ì„œ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë³€í™˜
                        import io
                        optimized_data = io.BytesIO()
                        with open(temp_output_path, 'rb') as f:
                            optimized_data.write(f.read())
                        optimized_data.seek(0)
                        
                        streaming_content = optimized_data
                        
                        # ìµœì í™”ëœ íŒŒì¼ í¬ê¸° ì—…ë°ì´íŠ¸
                        file_size = os.path.getsize(temp_output_path)
                    else:
                        interview_logger.warning("FFmpeg ìµœì í™” ì‹¤íŒ¨, ì›ë³¸ íŒŒì¼ë¡œ ì œê³µí•©ë‹ˆë‹¤")
                        # S3 ê°ì²´ë¥¼ ë‹¤ì‹œ ê°€ì ¸ì™€ì•¼ í•¨ (ìŠ¤íŠ¸ë¦¼ì´ ì´ë¯¸ ì½í˜”ìœ¼ë¯€ë¡œ)
                        s3_object = s3_client.get_object(Bucket=bucket_name, Key=s3_key)
                        streaming_content = s3_object['Body']
                        optimized_file_name = file_name
                        
                except Exception as e:
                    interview_logger.error(f"ìµœì í™” ì¤‘ ì˜¤ë¥˜: {e}")
                    # S3 ê°ì²´ë¥¼ ë‹¤ì‹œ ê°€ì ¸ì™€ì•¼ í•¨
                    s3_object = s3_client.get_object(Bucket=bucket_name, Key=s3_key)
                    streaming_content = s3_object['Body']
                    optimized_file_name = file_name
                finally:
                    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                    if os.path.exists(temp_output_path):
                        try:
                            os.unlink(temp_output_path)
                        except Exception as cleanup_error:
                            interview_logger.warning(f"ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {cleanup_error}")
        else:
            # ì›ë³¸ íŒŒì¼ ê·¸ëŒ€ë¡œ ì œê³µ
            streaming_content = s3_object['Body']
            optimized_file_name = file_name

        # 4. ë‹¤ìš´ë¡œë“œìš© ì‘ë‹µ í—¤ë” ì„¤ì •
        response_headers = {
            "Content-Disposition": f'attachment; filename="{optimized_file_name}"',
            "Cache-Control": "no-cache",
            "Content-Description": "File Transfer"
        }
        if file_size:
            response_headers["Content-Length"] = str(file_size)

        interview_logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ ì‹œì‘: {optimized_file_name}")
        return StreamingResponse(
            streaming_content, 
            media_type="application/octet-stream",  # ë‹¤ìš´ë¡œë“œ ê°•ì œ
            headers=response_headers
        )

    except ClientError as e:
        error_code = e.response.get("Error", {}).get("Code")
        interview_logger.error(f"S3 ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜ (interview_id: {interview_id}): {error_code}")
        if error_code == 'NoSuchKey':
            raise HTTPException(status_code=404, detail=f"S3ì— í•´ë‹¹ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {s3_key}")
        else:
            raise HTTPException(status_code=500, detail=f"S3 ì²˜ë¦¬ ì˜¤ë¥˜: {error_code}")

    except HTTPException:
        # ì´ë¯¸ ì²˜ë¦¬ëœ HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì „ë‹¬
        raise
    except Exception as e:
        interview_logger.error(f"ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ (interview_id: {interview_id}): {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì¤‘ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@interview_router.post("/memo")
async def update_memo(memo_update: MemoUpdateRequest):
    """
    Updates the memo field in the history_detail table.
    """
    try:
        response = supabase_client.client.from_("history_detail").update(
            {"memo": memo_update.memo}
        ).eq("interview_id", memo_update.interview_id).eq(
            "question_index", memo_update.question_index
        ).eq(
            "who", memo_update.who
        ).execute()

        if response.data:
            interview_logger.info(f"ë©”ëª¨ ì—…ë°ì´íŠ¸ ì„±ê³µ: interview_id={memo_update.interview_id}, question_index={memo_update.question_index}, who={memo_update.who}")
            return {"message": "ë©”ëª¨ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤."}
        else:
            interview_logger.warning(f"ë©”ëª¨ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: í•´ë‹¹ í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ. interview_id={memo_update.interview_id}, question_index={memo_update.question_index}, who={memo_update.who}")
            raise HTTPException(status_code=404, detail="í•´ë‹¹ ë©´ì ‘ ê¸°ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    except HTTPException:
        raise
    except Exception as e:
        interview_logger.error(f"ë©”ëª¨ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë©”ëª¨ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# ğŸŸ¢ POST /interview/tts
@interview_router.post("/tts")
async def text_to_speech_elevenlabs(req: TTSRequest):
    # ë¡œê·¸ ì¶”ê°€
    interview_logger.info(f"TTS ìš”ì²­ ìˆ˜ì‹ : voice_id='{req.voice_id}', text='{req.text[:50]}...'")

    # ë¹ˆ í…ìŠ¤íŠ¸ ìœ íš¨ì„± ê²€ì‚¬
    if not req.text or not req.text.strip():
        raise HTTPException(status_code=400, detail="TTSë¥¼ ìœ„í•œ í…ìŠ¤íŠ¸ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

    try:
        audio_bytes = await elevenlabs_tts_stream(req.text, req.voice_id)
        return StreamingResponse(io.BytesIO(audio_bytes), media_type="audio/mpeg")
    except HTTPException as e:
        # voice_serviceì—ì„œ ë°œìƒí•œ HTTPExceptionì„ ê·¸ëŒ€ë¡œ ì „ë‹¬
        interview_logger.error(f"TTS API ì˜¤ë¥˜ ë°œìƒ: {e.status_code} - {e.detail}")
        raise e
    except Exception as e:
        # ê·¸ ì™¸ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ì²˜ë¦¬
        interview_logger.error(f"TTS ì²˜ë¦¬ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail="TTS ì²˜ë¦¬ ì¤‘ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

# ğŸŸ¢ POST /interview/stt
@interview_router.post("/stt", response_model=STTResponse)
async def speech_to_text(file: UploadFile = File(...)):
    """ìŒì„± íŒŒì¼ì„ OpenAI Whisperë¡œ í…ìŠ¤íŠ¸ ë³€í™˜ í›„ íŒŒì¼ ì‚­ì œ"""
    # íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬
    if not file or not file.filename:
        raise HTTPException(status_code=400, detail="ìŒì„± íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    
    # ì§€ì›í•˜ëŠ” ì˜¤ë””ì˜¤ í˜•ì‹ í™•ì¸
    allowed_extensions = ['.wav', '.mp3', '.m4a', '.webm', '.ogg', '.flac']
    file_extension = os.path.splitext(file.filename)[1].lower()
    if file_extension not in allowed_extensions:
        raise HTTPException(
            status_code=400, 
            detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {', '.join(allowed_extensions)}"
        )
    
    # OpenAI API í‚¤ í™•ì¸
    load_dotenv()
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    if not OPENAI_API_KEY:
        raise HTTPException(status_code=500, detail="OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    temp_file_path = None
    try:
        # ì„ì‹œ íŒŒì¼ë¡œ ìŒì„± ë°ì´í„° ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as temp_file:
            temp_file_path = temp_file.name
            content = await file.read()
            temp_file.write(content)
        
        interview_logger.info(f"ğŸ™ï¸ STT ì²˜ë¦¬ ì‹œì‘: {file.filename} ({len(content)} bytes)")
        interview_logger.info(f"ğŸ“„ íŒŒì¼ ì •ë³´: content_type={file.content_type}, filename={file.filename}")
        
        # OpenAI Whisper API í˜¸ì¶œ
        headers = {
            "Authorization": f"Bearer {OPENAI_API_KEY}"
        }
        
        # íŒŒì¼ì„ í•œ ë²ˆì— ì½ì–´ì„œ ë©”ëª¨ë¦¬ì— ì €ì¥
        with open(temp_file_path, 'rb') as audio_file:
            audio_data = audio_file.read()
            
        interview_logger.info(f"ğŸ“Š ì˜¤ë””ì˜¤ ë°ì´í„° í¬ê¸°: {len(audio_data)} bytes")
        
        form_data = aiohttp.FormData()
        form_data.add_field('file', audio_data, filename=file.filename, content_type=file.content_type or 'audio/webm')
        form_data.add_field('model', 'whisper-1')
        form_data.add_field('response_format', 'json')
        # ì–¸ì–´ë¥¼ ìë™ ê°ì§€ë¡œ ë³€ê²½ (ë” ì •í™•í•  ìˆ˜ ìˆìŒ)
        # form_data.add_field('language', 'ko')  # í•œêµ­ì–´ ê°•ì œ ì„¤ì • ì œê±°
        form_data.add_field('temperature', '0')  # ì¼ê´€ì„± ìˆëŠ” ê²°ê³¼ë¥¼ ìœ„í•´ temperature 0 ì„¤ì •
        
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://api.openai.com/v1/audio/transcriptions",
                headers=headers,
                data=form_data
            ) as response:
                if response.status != 200:
                    error_text = await response.text()
                    interview_logger.error(f"âŒ Whisper API ì˜¤ë¥˜: {response.status} - {error_text}")
                    raise HTTPException(
                        status_code=response.status,
                        detail=f"STT API ì˜¤ë¥˜: {error_text}"
                    )
                
                result = await response.json()
                transcribed_text = result.get('text', '').strip()
                
                # ì „ì²´ Whisper API ì‘ë‹µ ë¡œê¹…
                interview_logger.info(f"ğŸ¤– Whisper API ì „ì²´ ì‘ë‹µ: {result}")
                interview_logger.info(f"ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸: '{transcribed_text}'")
        
        return STTResponse(
            text=transcribed_text,
            confidence=1.0,  # WhisperëŠ” confidence scoreë¥¼ ì œê³µí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ê¸°ë³¸ê°’
            success=True
        )
        
    except HTTPException:
        raise
    except Exception as e:
        interview_logger.error(f"âŒ STT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"STT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if temp_file_path and os.path.exists(temp_file_path):
            try:
                os.unlink(temp_file_path)
                interview_logger.info(f"ğŸ—‘ï¸ ì„ì‹œ ìŒì„± íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {temp_file_path}")
            except Exception as cleanup_error:
                interview_logger.warning(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {cleanup_error}")


# ============================================================================
# ğŸš€ í…ìŠ¤íŠ¸ ê¸°ë°˜ AI ê²½ìŸ ë©´ì ‘ ì—”ë“œí¬ì¸íŠ¸ë“¤ (InterviewServiceTemp ì‚¬ìš©)
# ============================================================================

@interview_router.post("/text-competition/start")
async def start_text_competition(
    settings: InterviewSettings,
    temp_service: InterviewServiceTemp = Depends(get_temp_interview_service)
):
    """í…ìŠ¤íŠ¸ ê¸°ë°˜ AI ê²½ìŸ ë©´ì ‘ ì‹œì‘"""
    try:
        interview_logger.info(f"ğŸ¯ í…ìŠ¤íŠ¸ ê²½ìŸ ë©´ì ‘ ì‹œì‘ ìš”ì²­: {settings.company} - {settings.position}")
        
        # ğŸ” ë””ë²„ê¹…: ë°›ì€ ì„¤ì • ë°ì´í„° í™•ì¸ (ì²« ë²ˆì§¸ íŒŒì¼ì—ì„œ)
        interview_logger.info(f"ğŸ“‹ ë°›ì€ ì„¤ì • ë°ì´í„°: company={settings.company}, position={settings.position}, candidate_name={settings.candidate_name}")
        interview_logger.info(f"ğŸ“„ ì´ë ¥ì„œ ë°ì´í„° í™•ì¸: {settings.resume is not None}")
        if settings.resume:
            interview_logger.info(f"ğŸ“ ì´ë ¥ì„œ ë‚´ìš©: name={settings.resume.get('name', 'N/A')}, tech={str(settings.resume.get('tech', 'N/A'))[:50]}...")
        
        settings_dict = {
            "company": settings.company,
            "position": settings.position,
            "candidate_name": settings.candidate_name,
            "documents": settings.documents or [],
            "resume": settings.resume,  # ğŸ†• ì´ë ¥ì„œ ë°ì´í„° ì¶”ê°€ (ì²« ë²ˆì§¸ íŒŒì¼ì—ì„œ)
            "difficulty": settings.difficulty  # ğŸ†• ë‚œì´ë„ ì¶”ê°€ (ì²« ë²ˆì§¸ íŒŒì¼ì—ì„œ)
        }
        
        result = await temp_service.start_text_interview(settings_dict)
        
        interview_logger.info(f"âœ… í…ìŠ¤íŠ¸ ê²½ìŸ ë©´ì ‘ ì‹œì‘ ì„±ê³µ: {result.get('session_id')}")
        return result
        
    except Exception as e:
        interview_logger.error(f"âŒ í…ìŠ¤íŠ¸ ê²½ìŸ ë©´ì ‘ ì‹œì‘ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@interview_router.post("/text-competition/submit-answer")
async def submit_text_answer(
    answer_data: dict,
    temp_service: InterviewServiceTemp = Depends(get_temp_interview_service)
):
    """í…ìŠ¤íŠ¸ ë‹µë³€ ì œì¶œ ë° AI ë‹µë³€ + ë‹¤ìŒ ì§ˆë¬¸ ë°›ê¸°"""
    try:
        session_id = answer_data.get("session_id")
        answer = answer_data.get("answer")
        
        if not session_id or not answer:
            raise HTTPException(status_code=400, detail="session_idì™€ answerê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        interview_logger.info(f"ğŸ“ í…ìŠ¤íŠ¸ ë‹µë³€ ì œì¶œ: {session_id}")
        
        result = await temp_service.submit_answer_and_get_next(session_id, answer)
        
        interview_logger.info(f"âœ… í…ìŠ¤íŠ¸ ë‹µë³€ ì²˜ë¦¬ ì™„ë£Œ: {session_id} - {result.get('status')}")
        return result
        
    except Exception as e:
        interview_logger.error(f"âŒ í…ìŠ¤íŠ¸ ë‹µë³€ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@interview_router.get("/text-competition/session/{session_id}")
async def get_text_session_info(
    session_id: str,
    temp_service: InterviewServiceTemp = Depends(get_temp_interview_service)
):
    """í…ìŠ¤íŠ¸ ê¸°ë°˜ ë©´ì ‘ ì„¸ì…˜ ì •ë³´ ì¡°íšŒ"""
    try:
        interview_logger.info(f"ğŸ” í…ìŠ¤íŠ¸ ì„¸ì…˜ ì •ë³´ ì¡°íšŒ: {session_id}")
        
        result = await temp_service.get_session_info(session_id)
        
        if "error" in result:
            raise HTTPException(status_code=404, detail=result["error"])
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        interview_logger.error(f"âŒ í…ìŠ¤íŠ¸ ì„¸ì…˜ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@interview_router.get("/text-competition/results/{session_id}")
async def get_text_interview_results(
    session_id: str,
    temp_service: InterviewServiceTemp = Depends(get_temp_interview_service)
):
    """í…ìŠ¤íŠ¸ ê¸°ë°˜ ë©´ì ‘ ê²°ê³¼ ì¡°íšŒ"""
    try:
        interview_logger.info(f"ğŸ“Š í…ìŠ¤íŠ¸ ë©´ì ‘ ê²°ê³¼ ì¡°íšŒ: {session_id}")
        
        result = await temp_service.get_interview_results(session_id)
        
        if "error" in result:
            raise HTTPException(status_code=404, detail=result["error"])
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        interview_logger.error(f"âŒ í…ìŠ¤íŠ¸ ë©´ì ‘ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@interview_router.delete("/text-competition/session/{session_id}")
async def cleanup_text_session(
    session_id: str,
    temp_service: InterviewServiceTemp = Depends(get_temp_interview_service)
):
    """í…ìŠ¤íŠ¸ ê¸°ë°˜ ë©´ì ‘ ì„¸ì…˜ ì •ë¦¬"""
    try:
        interview_logger.info(f"ğŸ§¹ í…ìŠ¤íŠ¸ ì„¸ì…˜ ì •ë¦¬ ìš”ì²­: {session_id}")
        
        success = temp_service.cleanup_session(session_id)
        
        if success:
            return {"message": "ì„¸ì…˜ì´ ì„±ê³µì ìœ¼ë¡œ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.", "session_id": session_id}
        else:
            raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
    except HTTPException:
        raise
    except Exception as e:
        interview_logger.error(f"âŒ í…ìŠ¤íŠ¸ ì„¸ì…˜ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@interview_router.get("/text-competition/stats")
async def get_text_interview_stats(
    temp_service: InterviewServiceTemp = Depends(get_temp_interview_service)
):
    """í…ìŠ¤íŠ¸ ê¸°ë°˜ ë©´ì ‘ ì‹œìŠ¤í…œ í†µê³„"""
    try:
        active_sessions = temp_service.get_active_sessions_count()
        
        return {
            "active_sessions": active_sessions,
            "service_type": "text_based_competition",
            "system_status": "operational"
        }
        
    except Exception as e:
        interview_logger.error(f"âŒ í…ìŠ¤íŠ¸ ë©´ì ‘ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# ========================================
# ğŸ¯ Feedback ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€ (ë‘ ë²ˆì§¸ íŒŒì¼ì—ì„œ)
# ========================================

# Feedback ëª¨ë¸ ì„í¬íŠ¸
try:
    from llm.feedback.api_models import QuestionRequest, QuestionResponse, PlansRequest, PlansResponse
    from llm.feedback.api_service import InterviewEvaluationService
    
    # ì „ì—­ í‰ê°€ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤)
    evaluation_service = InterviewEvaluationService()
    
    @interview_router.post("/feedback/evaluate")
    async def evaluate_interview(request: Union[QuestionRequest, List[QuestionRequest]]):
        """ë©´ì ‘ ì§ˆë¬¸-ë‹µë³€ í‰ê°€ (ë‹¨ì¼ ë˜ëŠ” ë°°ì¹˜)"""
        try:
            # ë‹¨ì¼ ìš”ì²­ì¸ì§€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ ì²´í¬
            if isinstance(request, list):
                # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° - ë°°ì¹˜ ì²˜ë¦¬
                results = []
                for i, req in enumerate(request):
                    interview_logger.info(f"ë°°ì¹˜ í‰ê°€ {i+1}/{len(request)}: user_id={req.user_id}, questions={len(req.qa_pairs)}")
                    
                    result = evaluation_service.evaluate_multiple_questions(
                        user_id=req.user_id,
                        qa_pairs=req.qa_pairs,
                        ai_resume_id=req.ai_resume_id,
                        user_resume_id=req.user_resume_id,
                        posting_id=req.posting_id,
                        company_id=req.company_id,
                        position_id=req.position_id
                    )
                    results.append(result)
                
                return {
                    "success": True,
                    "message": f"{len(results)}ê°œ í‰ê°€ ì™„ë£Œ",
                    "results": results
                }
            else:
                # ê¸°ì¡´ ë‹¨ì¼ ì²˜ë¦¬ ë¡œì§ ìœ ì§€
                interview_logger.info(f"ë©´ì ‘ í‰ê°€ ìš”ì²­: user_id={request.user_id}, questions={len(request.qa_pairs)}")
                
                result = evaluation_service.evaluate_multiple_questions(
                    user_id=request.user_id,
                    qa_pairs=request.qa_pairs,
                    ai_resume_id=request.ai_resume_id,
                    user_resume_id=request.user_resume_id,
                    posting_id=request.posting_id,
                    company_id=request.company_id,
                    position_id=request.position_id
                )
                
                return QuestionResponse(**result)
            
        except Exception as e:
            interview_logger.error(f"ë©´ì ‘ í‰ê°€ ì˜¤ë¥˜: {str(e)}")
            raise HTTPException(status_code=500, detail=f"ë©´ì ‘ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    @interview_router.post("/feedback/plans", response_model=PlansResponse)
    async def generate_interview_plans(request: PlansRequest):
        """ë©´ì ‘ ì¤€ë¹„ ê³„íš ìƒì„±"""
        try:
            interview_logger.info(f"ë©´ì ‘ ê³„íš ìƒì„± ìš”ì²­: interview_id={request.interview_id}")
            
            result = evaluation_service.generate_interview_plans(request.interview_id)
            
            return PlansResponse(**result)
            
        except Exception as e:
            interview_logger.error(f"ë©´ì ‘ ê³„íš ìƒì„± ì˜¤ë¥˜: {str(e)}")
            raise HTTPException(status_code=500, detail=f"ë©´ì ‘ ê³„íš ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

except ImportError as e:
    interview_logger.warning(f"Feedback ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    @interview_router.post("/feedback/evaluate")
    async def evaluate_interview_fallback():
        raise HTTPException(status_code=503, detail="ë©´ì ‘ í‰ê°€ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    @interview_router.post("/feedback/plans")
    async def generate_interview_plans_fallback():
        raise HTTPException(status_code=503, detail="ë©´ì ‘ ê³„íš ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ğŸŸ¢ POST /interview/complete â€“ ë©´ì ‘ ì™„ë£Œ ì²˜ë¦¬ (ë¹„ë™ê¸°)
@interview_router.post("/complete")
async def complete_interview_async(
    session_id: str,
    background_tasks: BackgroundTasks,
    current_user: UserResponse = Depends(auth_service.get_current_user)
):
    """ë©´ì ‘ ì™„ë£Œ ì‹œ ì¦‰ì‹œ ì‘ë‹µí•˜ê³  ë°±ê·¸ë¼ìš´ë“œì—ì„œ í”¼ë“œë°± ì²˜ë¦¬"""
    try:
        interview_logger.info(f"ğŸ ë©´ì ‘ ì™„ë£Œ ìš”ì²­: session_id={session_id}, user={current_user.user_id}")
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ í”¼ë“œë°± ì²˜ë¦¬ ìŠ¤ì¼€ì¤„ë§
        if FEEDBACK_ENABLED:
            background_tasks.add_task(process_feedback_async, session_id, current_user.user_id)
        
        # ì¦‰ì‹œ ì‘ë‹µ ë°˜í™˜
        return {
            "status": "completed",
            "message": "ë©´ì ‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. í”¼ë“œë°± ì²˜ë¦¬ê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì§„í–‰ë©ë‹ˆë‹¤.",
            "session_id": session_id,
            "feedback_processing": FEEDBACK_ENABLED
        }
        
    except Exception as e:
        interview_logger.error(f"âŒ ë©´ì ‘ ì™„ë£Œ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

async def process_feedback_async(session_id: str, user_id: int):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë˜ëŠ” í”¼ë“œë°± ì²˜ë¦¬"""
    try:
        interview_logger.info(f"ğŸ”„ ë°±ê·¸ë¼ìš´ë“œ í”¼ë“œë°± ì²˜ë¦¬ ì‹œì‘: session_id={session_id}")
        
        if FEEDBACK_ENABLED:
            # ê¸°ì¡´ í”¼ë“œë°± í‰ê°€ ë¡œì§ ì‹¤í–‰
            request = EvaluationRequest(session_id=session_id)
            evaluation_service.evaluate_interview(request)
            
            interview_logger.info(f"âœ… ë°±ê·¸ë¼ìš´ë“œ í”¼ë“œë°± ì²˜ë¦¬ ì™„ë£Œ: session_id={session_id}")
        else:
            interview_logger.warning(f"âš ï¸ í”¼ë“œë°± ì„œë¹„ìŠ¤ ë¹„í™œì„±í™”: session_id={session_id}")
            
    except Exception as e:
        interview_logger.error(f"âŒ ë°±ê·¸ë¼ìš´ë“œ í”¼ë“œë°± ì²˜ë¦¬ ì‹¤íŒ¨: session_id={session_id}, error={str(e)}")

# ğŸŸ¢ GET /interview/global-stats â€“ ì „ì²´ ì‚¬ìš©ì í†µê³„ ì¡°íšŒ
@interview_router.get("/global-stats")
async def get_global_interview_stats():
    """ì „ì²´ ì‚¬ìš©ìì˜ ë©´ì ‘ í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    try:
        # ì „ì²´ ë©´ì ‘ ìˆ˜ ì¡°íšŒ
        total_interviews_res = supabase_client.client.from_("interview").select("interview_id", count="exact").execute()
        total_interviews = total_interviews_res.count if total_interviews_res.count else 0
        
        # ì „ì²´ í‰ê·  ì ìˆ˜ ê³„ì‚° (total_feedbackì—ì„œ ì ìˆ˜ ì¶”ì¶œ)
        interviews_with_feedback = supabase_client.client.from_("interview").select("total_feedback").not_.is_("total_feedback", "null").execute()
        
        total_score = 0
        score_count = 0
        
        for interview in interviews_with_feedback.data:
            try:
                if interview.get('total_feedback'):
                    feedback_data = interview['total_feedback']
                    if isinstance(feedback_data, str):
                        import json
                        feedback_data = json.loads(feedback_data)
                    
                    # ì ìˆ˜ ì¶”ì¶œ ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼)
                    score = 0
                    if isinstance(feedback_data, dict):
                        if feedback_data.get('user', {}).get('overall_score') is not None:
                            score = feedback_data['user']['overall_score']
                        elif feedback_data.get('overall_score') is not None:
                            score = feedback_data['overall_score']
                        elif feedback_data.get('ai_interviewer', {}).get('overall_score') is not None:
                            score = feedback_data['ai_interviewer']['overall_score']
                    
                    if score > 0:
                        total_score += score
                        score_count += 1
            except:
                continue
        
        global_average_score = round(total_score / score_count) if score_count > 0 else 0
        
        return {
            "total_interviews": total_interviews,
            "global_average_score": global_average_score
        }
        
    except Exception as e:
        interview_logger.error(f"ì „ì²´ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        return {
            "total_interviews": 0,
            "global_average_score": 0
        }