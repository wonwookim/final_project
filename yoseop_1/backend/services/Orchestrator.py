import time
import json
import random
import asyncio
from dataclasses import dataclass, field
from typing import Optional, Dict, Any

@dataclass
class Metadata:
    interview_id: str
    step: int
    task: str
    from_agent: str 
    next_agent: str
    status_code: int

@dataclass
class Content:
    type: str
    content: str

@dataclass
class Metrics:
    total_time: Optional[float] = None
    duration: Optional[float] = None

@dataclass
class AgentMessage:
    metadata: Metadata
    content: Content
    metrics: Metrics = field(default_factory=Metrics)

class Orchestrator:
    def __init__(self, session_id: str, session_state: Dict[str, Any], 
                 question_generator=None, ai_candidate_model=None):
        """
        Orchestrator: ëª¨ë“  ë©´ì ‘ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë‹´ë‹¹
        - í”Œë¡œìš° ì œì–´
        - ì—ì´ì „íŠ¸ ì¡°ìœ¨
        - ë©”ì‹œì§€ ì²˜ë¦¬
        - ìƒíƒœ ì—…ë°ì´íŠ¸
        """
        self.session_id = session_id
        self.session_state = session_state  # InterviewServiceì˜ session_state ì°¸ì¡°
        self.question_generator = question_generator
        self.ai_candidate_model = ai_candidate_model

    def handle_message(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """ë©”ì‹œì§€ë¥¼ ë°›ì•„ì„œ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  ë‹¤ìŒ ì•¡ì…˜ì„ ê²°ì •"""
        from_agent = message.get("metadata", {}).get("from_agent", "unknown")
        print(f"[{from_agent}] -> [Orchestrator]")
        print(json.dumps(message, indent=2, ensure_ascii=False))

        task = message.get("metadata", {}).get("task")
        content = message.get("content", {}).get("content")

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        self._update_state_from_message(task, content, from_agent)

        # ë‹¤ìŒ ë©”ì‹œì§€ ê²°ì •
        next_message = self._decide_next_message()
        next_agent = next_message.get("metadata", {}).get("next_agent", "unknown")
        print(f"[Orchestrator] -> [{next_agent}]")
        print(json.dumps(next_message, indent=2, ensure_ascii=False))
        return next_message

    def _update_state_from_message(self, task: str, content: str, from_agent: str) -> None:
        """ë©”ì‹œì§€ë¡œë¶€í„° ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        if task == "intro_generated":
            # ì¸íŠ¸ë¡œ ë©”ì‹œì§€ ìƒì„± ì™„ë£Œ - ë‹µë³€ ì—†ì´ ë°”ë¡œ í„´ ì¦ê°€
            self.session_state['turn_count'] += 1  # í„´ 0 ì™„ë£Œ, í„´ 1ë¡œ ì´ë™
            # current_questionì€ ì„¤ì •í•˜ì§€ ì•ŠìŒ (ë‹µë³€ ìš”ì²­í•˜ì§€ ì•ŠìŒ)
            
        elif task == "question_generated":
            self.session_state['current_question'] = content
            
            # ğŸ†• ì§ˆë¬¸ íƒ€ì… ì¶”ì¶œ ë¡œì§ ì œê±° - QuestionGeneratorì—ì„œ ê²°ì •í•œ ë©´ì ‘ê´€ ì‚¬ìš©
            # current_interviewerëŠ” QuestionGeneratorì—ì„œ ì´ë¯¸ ì„¤ì •ë¨
            # ì—¬ê¸°ì„œëŠ” ì§ˆë¬¸ ë‚´ìš©ë§Œ ì €ì¥í•˜ê³  ë©´ì ‘ê´€ ì¶”ì¸¡í•˜ì§€ ì•ŠìŒ
            
        elif task == "individual_questions_generated":
            # ğŸ†• ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì™„ë£Œ - contentëŠ” dict í˜•íƒœ
            import json
            if isinstance(content, str):
                questions_data = json.loads(content)
            else:
                questions_data = content
                
            self.session_state['current_questions'] = {
                'user_question': questions_data.get('user_question', {}),
                'ai_question': questions_data.get('ai_question', {}),
                'is_individual': questions_data.get('is_individual_questions', True),
                'interviewer_type': questions_data.get('interviewer_type', 'HR')
            }
            
            print(f"[DEBUG] ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒíƒœ ì €ì¥ ì™„ë£Œ")
            print(f"[DEBUG] ì‚¬ìš©ì ì§ˆë¬¸: {questions_data.get('user_question', {}).get('question', 'N/A')[:30]}...")
            print(f"[DEBUG] AI ì§ˆë¬¸: {questions_data.get('ai_question', {}).get('question', 'N/A')[:30]}...")
            
        elif task == "individual_answer_generated":
            # ğŸ†• ê°œë³„ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ì²˜ë¦¬
            current_questions = self.session_state.get('current_questions', {})
            if current_questions.get('is_individual', False):
                # ê°œë³„ ì§ˆë¬¸ì˜ ê²½ìš° answererì— ë”°ë¼ í•´ë‹¹í•˜ëŠ” ì§ˆë¬¸ ë§¤í•‘
                if from_agent == 'user':
                    question_text = current_questions.get('user_question', {}).get('question', '')
                elif from_agent == 'ai':
                    question_text = current_questions.get('ai_question', {}).get('question', '')
                else:
                    question_text = self.session_state.get('current_question', '')
            else:
                question_text = self.session_state.get('current_question', '')
            
            # qa_historyì— ë‹µë³€ ì €ì¥
            self.session_state['qa_history'].append({
                "question": question_text,
                "answerer": from_agent,
                "answer": content
            })
            
            # ê°œë³„ ë‹µë³€ ì™„ë£Œ ì²´í¬ (ì‚¬ìš©ìì™€ AI ëª¨ë‘ ë‹µë³€í–ˆëŠ”ì§€)
            if current_questions.get('is_individual', False):
                # í˜„ì¬ í„´ì˜ ê°œë³„ ë‹µë³€ ìˆ˜ ê³„ì‚°
                individual_answers = len([qa for qa in self.session_state['qa_history'] 
                                        if qa['question'] in [
                                            current_questions.get('user_question', {}).get('question', ''),
                                            current_questions.get('ai_question', {}).get('question', '')
                                        ]])
                
                if individual_answers >= 2:
                    self._handle_turn_completion_for_individual_questions()
            else:
                # ê¸°ì¡´ ë¡œì§ ìœ ì§€ (ê³µí†µ ì§ˆë¬¸ì¸ ê²½ìš°)
                self._handle_turn_completion_for_common_question()
                
        elif task == "answer_generated":
            # ê¸°ì¡´ ë‹µë³€ ì²˜ë¦¬ (ë©”ì¸ ì§ˆë¬¸ ë˜ëŠ” ê³µí†µ ê¼¬ë¦¬ì§ˆë¬¸)
            self.session_state['qa_history'].append({
                "question": self.session_state['current_question'],
                "answerer": from_agent,
                "answer": content
            })

            # ë‘ ë‹µë³€ì´ ëª¨ë‘ ì™„ë£Œë˜ë©´ í„´ ì¦ê°€ ë° ê¼¬ë¦¬ ì§ˆë¬¸ ìƒíƒœ ì—…ë°ì´íŠ¸
            current_answers = len([qa for qa in self.session_state['qa_history']
                                  if qa['question'] == self.session_state['current_question']])

            if current_answers >= 2:
                self._handle_turn_completion_for_common_question()

    def _handle_turn_completion_for_common_question(self):
        """ê³µí†µ ì§ˆë¬¸ ì™„ë£Œ ì‹œ ì²˜ë¦¬"""
        # ğŸ†• ê¼¬ë¦¬ ì§ˆë¬¸ ì¹´ìš´íŠ¸ ì¦ê°€ (ìˆ˜ì •ëœ ë¡œì§)
        current_interviewer = self.session_state.get('current_interviewer')
        if current_interviewer and current_interviewer in ['HR', 'TECH', 'COLLABORATION']:
            turn_state = self.session_state.get('interviewer_turn_state', {})
            if current_interviewer in turn_state:
                # í˜„ì¬ ì§ˆë¬¸ì´ ë©”ì¸ ì§ˆë¬¸ì¸ì§€ ê¼¬ë¦¬ ì§ˆë¬¸ì¸ì§€ íŒë‹¨
                current_turn = self.session_state.get('turn_count', 0)
                
                # í„´ 1, 2ëŠ” ê³ ì • ì§ˆë¬¸ì´ë¯€ë¡œ ì¹´ìš´íŠ¸í•˜ì§€ ì•ŠìŒ
                if current_turn > 2:
                    # ë©”ì¸ ì§ˆë¬¸ ì™„ë£Œ í‘œì‹œ
                    if not turn_state[current_interviewer]['main_question_asked']:
                        turn_state[current_interviewer]['main_question_asked'] = True
                    else:
                        # ê¼¬ë¦¬ ì§ˆë¬¸ ì¹´ìš´íŠ¸ ì¦ê°€
                        turn_state[current_interviewer]['follow_up_count'] += 1
        
        self.session_state['turn_count'] += 1
        self.session_state['current_question'] = None
    
    def _handle_turn_completion_for_individual_questions(self):
        """ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ì™„ë£Œ ì‹œ ì²˜ë¦¬"""
        current_interviewer = self.session_state.get('current_interviewer')
        if current_interviewer and current_interviewer in ['HR', 'TECH', 'COLLABORATION']:
            turn_state = self.session_state.get('interviewer_turn_state', {})
            if current_interviewer in turn_state:
                # ê¼¬ë¦¬ ì§ˆë¬¸ ì¹´ìš´íŠ¸ ì¦ê°€
                turn_state[current_interviewer]['follow_up_count'] += 1
        
        self.session_state['turn_count'] += 1
        self.session_state['current_questions'] = None
        print(f"[DEBUG] ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ í„´ ì™„ë£Œ, ë‹¤ìŒ í„´ìœ¼ë¡œ ì´ë™")

    def _decide_next_message(self) -> Dict[str, Any]:
        """ë‹¤ìŒ ë©”ì‹œì§€ ê²°ì • - ì‹¤ì œ í”Œë¡œìš° ì œì–´ ë¡œì§"""
        current_turn = self.session_state.get('turn_count', 0)
        start_time = self.session_state.get('start_time')
        
        # í„´ 0: ì¸íŠ¸ë¡œ ì²˜ë¦¬
        if current_turn == 0:
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_intro",
                from_agent="orchestrator",
                content_text="ì¸íŠ¸ë¡œ ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
                turn_count=current_turn,
                content_type="INTRO",
                start_time=start_time
            )
            message["metadata"]["next_agent"] = "interviewer"
            return message
        
        # ì™„ë£Œ ì¡°ê±´ ì²´í¬
        if current_turn >= self.session_state.get('total_question_limit', 15):
            self.session_state['is_completed'] = True
            message = self.create_agent_message(
                session_id=self.session_id,
                task="end_interview",
                from_agent="orchestrator",
                content_text="ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.",
                turn_count=current_turn,
                content_type="OUTTRO",
                start_time=start_time
            )
            message["metadata"]["next_agent"] = "orchestrator"
            return message

        # ğŸ†• ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ì²˜ë¦¬ ë¡œì§
        current_questions = self.session_state.get('current_questions')
        if current_questions and current_questions.get('is_individual', False):
            return self._handle_individual_questions_flow(current_questions, current_turn, start_time)
        
        # í˜„ì¬ ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ ìƒˆ ì§ˆë¬¸ ìƒì„± (ë©”ì¸ ì§ˆë¬¸ ë˜ëŠ” ê¼¬ë¦¬ì§ˆë¬¸ ê²°ì •)
        if not self.session_state.get('current_question'):
            # ğŸ†• ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì¡°ê±´ ì²´í¬
            if self._should_generate_individual_follow_up():
                print(f"[DEBUG] ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì¡°ê±´ ë§Œì¡±")
                message = self.create_agent_message(
                    session_id=self.session_id,
                    task="generate_individual_follow_up",
                    from_agent="orchestrator",
                    content_text="ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.",
                    turn_count=current_turn,
                    start_time=start_time
                )
                message["metadata"]["next_agent"] = "interviewer_individual"
                return message
            else:
                # ì¼ë°˜ ë©”ì¸ ì§ˆë¬¸ ìƒì„±
                message = self.create_agent_message(
                    session_id=self.session_id,
                    task="generate_question",
                    from_agent="orchestrator",
                    content_text="ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.",
                    turn_count=current_turn,
                    start_time=start_time
                )
                message["metadata"]["next_agent"] = "interviewer"
                return message
        
        # í˜„ì¬ ë©”ì¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìˆ˜ í™•ì¸
        current_answers = len([qa for qa in self.session_state['qa_history'] 
                             if qa['question'] == self.session_state['current_question']])
        
        # ì²« ë²ˆì§¸ ë‹µë³€: ëœë¤ ì„ íƒ
        if current_answers == 0:
            selected_agent = 'user' if self._random_select() == -1 else 'ai'
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_answer",
                from_agent="orchestrator",
                content_text=self.session_state['current_question'],
                turn_count=current_turn,
                start_time=start_time
            )
            message["metadata"]["next_agent"] = selected_agent
            return message
        
        # ë‘ ë²ˆì§¸ ë‹µë³€: ë°˜ëŒ€ ì—ì´ì „íŠ¸
        elif current_answers == 1:
            # ì²« ë²ˆì§¸ ë‹µë³€ì í™•ì¸
            first_answerer = self.session_state['qa_history'][-1]['answerer']
            selected_agent = 'ai' if first_answerer == 'user' else 'user'
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_answer",
                from_agent="orchestrator",
                content_text=self.session_state['current_question'],
                turn_count=current_turn,
                start_time=start_time
            )
            message["metadata"]["next_agent"] = selected_agent
            return message
        
        # ëª¨ë“  ë‹µë³€ ì™„ë£Œ: ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ
        else:
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_question",
                from_agent="orchestrator",
                content_text="ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.",
                turn_count=current_turn,
                start_time=start_time
            )
            message["metadata"]["next_agent"] = "interviewer"
            return message

   

    def _random_select(self) -> int:
        """ì‚¬ìš©ìì™€ AI ì¤‘ ëœë¤ìœ¼ë¡œ ì„ íƒ"""
        return random.choice([-1, 1])

    def _should_generate_individual_follow_up(self) -> bool:
        """ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ì„ ìƒì„±í•  ì¡°ê±´ì¸ì§€ ì²´í¬"""
        current_turn = self.session_state.get('turn_count', 0)
        current_interviewer = self.session_state.get('current_interviewer')
        turn_state = self.session_state.get('interviewer_turn_state', {})
        
        # í„´ 3 ì´í›„ && í˜„ì¬ ë©´ì ‘ê´€ì´ ì„¤ì •ë˜ì–´ ìˆê³  && ë©”ì¸ ì§ˆë¬¸ì´ ì™„ë£Œëœ ìƒíƒœ
        if (current_turn > 2 and 
            current_interviewer and 
            current_interviewer in turn_state):
            
            interviewer_state = turn_state[current_interviewer]
            main_asked = interviewer_state.get('main_question_asked', False)
            follow_up_count = interviewer_state.get('follow_up_count', 0)
            
            # ë©”ì¸ ì§ˆë¬¸ì€ ì™„ë£Œí–ˆê³ , ê¼¬ë¦¬ì§ˆë¬¸ì´ 2ê°œ ë¯¸ë§Œì¸ ê²½ìš°
            if main_asked and follow_up_count < 2:
                # ìµœê·¼ì— ë‘ ë‹µë³€ì´ ëª¨ë‘ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
                qa_history = self.session_state.get('qa_history', [])
                if len(qa_history) >= 2:
                    # ë§ˆì§€ë§‰ 2ê°œê°€ ê°™ì€ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì¸ì§€ í™•ì¸
                    recent_questions = [qa['question'] for qa in qa_history[-2:]]
                    if len(set(recent_questions)) == 1:  # ê°™ì€ ì§ˆë¬¸
                        print(f"[DEBUG] ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ì¡°ê±´ ë§Œì¡±: {current_interviewer}, follow_up={follow_up_count}/2")
                        return True
        
        return False

    def _handle_individual_questions_flow(self, current_questions: Dict, current_turn: int, start_time: float) -> Dict[str, Any]:
        """ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ í”Œë¡œìš° ì²˜ë¦¬"""
        user_question = current_questions.get('user_question', {}).get('question', '')
        ai_question = current_questions.get('ai_question', {}).get('question', '')
        
        # ê°œë³„ ì§ˆë¬¸ë“¤ì— ëŒ€í•œ ë‹µë³€ ìˆ˜ í™•ì¸
        qa_history = self.session_state.get('qa_history', [])
        individual_answers = len([qa for qa in qa_history 
                                if qa['question'] in [user_question, ai_question]])
        
        print(f"[DEBUG] ê°œë³„ ì§ˆë¬¸ í”Œë¡œìš°: ë‹µë³€ ìˆ˜ {individual_answers}/2")
        
        # ì²« ë²ˆì§¸ ë‹µë³€: ëœë¤ ì„ íƒ
        if individual_answers == 0:
            selected_agent = 'user' if self._random_select() == -1 else 'ai'
            question_text = user_question if selected_agent == 'user' else ai_question
            
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_individual_answer",
                from_agent="orchestrator",
                content_text=question_text,
                turn_count=current_turn,
                start_time=start_time
            )
            message["metadata"]["next_agent"] = selected_agent
            return message
        
        # ë‘ ë²ˆì§¸ ë‹µë³€: ë°˜ëŒ€ ì—ì´ì „íŠ¸
        elif individual_answers == 1:
            # ì²« ë²ˆì§¸ ë‹µë³€ì í™•ì¸
            first_answerer = qa_history[-1]['answerer']
            selected_agent = 'ai' if first_answerer == 'user' else 'user'
            question_text = user_question if selected_agent == 'user' else ai_question
            
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_individual_answer",
                from_agent="orchestrator",
                content_text=question_text,
                turn_count=current_turn,
                start_time=start_time
            )
            message["metadata"]["next_agent"] = selected_agent
            return message
        
        # ë‘ ë‹µë³€ ëª¨ë‘ ì™„ë£Œ: ë‹¤ìŒ ë‹¨ê³„ë¡œ (ì´ ê²½ìš°ëŠ” ì´ë¯¸ _update_state_from_messageì—ì„œ ì²˜ë¦¬ë¨)
        else:
            return self._decide_next_message()  # ì¬ê·€ í˜¸ì¶œë¡œ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •

    # ì—ì´ì „íŠ¸ ì¡°ìœ¨ ë©”ì„œë“œë“¤ (ë‚´ë¶€ ì²˜ë¦¬ìš©)
    async def _request_question_from_interviewer(self) -> str:
        """ë©´ì ‘ê´€(QuestionGenerator)ì—ê²Œ ì§ˆë¬¸ ìƒì„±ì„ ìš”ì²­í•˜ê³ , í…ìŠ¤íŠ¸ ê²°ê³¼ë§Œ ë°˜í™˜"""
        try:
            from llm.shared.logging_config import interview_logger
            interview_logger.info(f"ğŸ“¤ ë©´ì ‘ê´€ì—ê²Œ ì§ˆë¬¸ ìƒì„± ìš”ì²­: {self.session_id}")
            
            # QuestionGeneratorì—ê²Œ ìƒíƒœ ê°ì²´(state)ë¥¼ ì „ë‹¬í•˜ì—¬ ì§ˆë¬¸ ìƒì„±
            question_data = await asyncio.to_thread(
                self.question_generator.generate_question_with_orchestrator_state,
                self.session_state
            )
            
            # ğŸ†• í„´ ì „í™˜ ì²˜ë¦¬
            if question_data.get('turn_switch'):
                # ğŸ†• í„´ ì „í™˜ ì‹œ ë°”ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì„ ìš”ì²­ (ì¬ê·€ í˜¸ì¶œ)
                print(f"[DEBUG] í„´ ì „í™˜ ê°ì§€: {question_data.get('message', '')}")
                # ìƒíƒœ ì—…ë°ì´íŠ¸ í›„ ë‹¤ì‹œ ì§ˆë¬¸ ìš”ì²­
                return await self._request_question_from_interviewer()
            
            # ğŸ†• ê°œë³„ ì§ˆë¬¸ ë°ì´í„° ì²´í¬ - ì§ì ‘ ë°˜í™˜
            if 'user_question' in question_data and 'ai_question' in question_data:
                print(f"[DEBUG] ê°œë³„ ì§ˆë¬¸ ê°ì§€ë¨ - ê°œë³„ ì§ˆë¬¸ ë°ì´í„° ë°˜í™˜")
                return question_data  # Dict í˜•íƒœë¡œ ë°˜í™˜
            
            # ì¼ë°˜ ì§ˆë¬¸ ë°˜í™˜
            return question_data.get('question', 'ë‹¤ìŒ ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ê°€ìš”?')
            
        except Exception as e:
            from llm.shared.logging_config import interview_logger
            interview_logger.error(f"ë©´ì ‘ê´€ ì§ˆë¬¸ ìš”ì²­ ì˜¤ë¥˜: {e}", exc_info=True)
            return "ì£„ì†¡í•©ë‹ˆë‹¤, ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    async def _request_individual_follow_up_questions(self) -> Dict[str, Any]:
        """ë©´ì ‘ê´€ì—ê²Œ ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ 2ê°œ ìƒì„± ìš”ì²­"""
        try:
            from llm.shared.logging_config import interview_logger
            interview_logger.info(f"ğŸ“¤ ë©´ì ‘ê´€ì—ê²Œ ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ìš”ì²­: {self.session_id}")
            
            # qa_historyì—ì„œ ìµœì‹  ë‹µë³€ë“¤ ì¶”ì¶œ
            qa_history = self.session_state.get('qa_history', [])
            if len(qa_history) < 2:
                raise ValueError("ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ì„ ìƒì„±í•˜ë ¤ë©´ ìµœì†Œ 2ê°œì˜ ë‹µë³€ì´ í•„ìš”í•©ë‹ˆë‹¤")
            
            # ê°€ì¥ ìµœê·¼ ì§ˆë¬¸ê³¼ ë‹µë³€ë“¤ ì¶”ì¶œ 
            latest_qa_pairs = qa_history[-2:]  # ë§ˆì§€ë§‰ 2ê°œ (ì‚¬ìš©ì + AI ë‹µë³€)
            previous_question = latest_qa_pairs[0]['question'] if latest_qa_pairs else ''
            
            # ì‚¬ìš©ìì™€ AI ë‹µë³€ ë¶„ë¦¬
            user_answer = ""
            ai_answer = ""
            for qa in latest_qa_pairs:
                if qa['answerer'] == 'user':
                    user_answer = qa['answer']
                elif qa['answerer'] == 'ai':
                    ai_answer = qa['answer']
            
            if not user_answer or not ai_answer:
                raise ValueError("ì‚¬ìš©ìì™€ AI ë‹µë³€ì´ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤")
            
            # íšŒì‚¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            company_info = self.question_generator.companies_data.get(
                self.session_state.get('company_id'), {}
            )
            
            # í˜„ì¬ ë©´ì ‘ê´€ ì •ë³´
            current_interviewer = self.session_state.get('current_interviewer', 'HR')
            
            # ì‚¬ìš©ì ì´ë ¥ì„œ ì •ë³´
            user_resume = {
                'name': self.session_state.get('user_name', 'ì§€ì›ì'),
                'position': self.session_state.get('position', 'ê°œë°œì')
            }
            
            print(f"[DEBUG] ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± - ë©´ì ‘ê´€: {current_interviewer}")
            print(f"[DEBUG] ì´ì „ ì§ˆë¬¸: {previous_question[:50]}...")
            print(f"[DEBUG] ì‚¬ìš©ì ë‹µë³€: {user_answer[:50]}...")
            print(f"[DEBUG] AI ë‹µë³€: {ai_answer[:50]}...")
            
            # ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ìš”ì²­
            follow_up_data = await asyncio.to_thread(
                self.question_generator.generate_follow_up_questions_for_both,
                previous_question=previous_question,
                user_answer=user_answer,
                ai_answer=ai_answer,
                company_info=company_info,
                interviewer_role=current_interviewer,
                user_resume=user_resume
            )
            
            return follow_up_data
            
        except Exception as e:
            from llm.shared.logging_config import interview_logger
            interview_logger.error(f"ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìš”ì²­ ì˜¤ë¥˜: {e}", exc_info=True)
            
            # í´ë°±: ê³µí†µ ê¼¬ë¦¬ì§ˆë¬¸ ì‚¬ìš©
            try:
                common_question = await self._request_question_from_interviewer()
                return {
                    'user_question': {'question': common_question},
                    'ai_question': {'question': common_question},
                    'interviewer_type': self.session_state.get('current_interviewer', 'HR'),
                    'question_type': 'follow_up',
                    'is_individual_questions': False,
                    'fallback_reason': 'individual_request_failed'
                }
            except Exception as fallback_error:
                interview_logger.error(f"í´ë°± ì§ˆë¬¸ ìƒì„±ë„ ì‹¤íŒ¨: {fallback_error}")
                return {
                    'user_question': {'question': 'ì¶”ê°€ë¡œ ì„¤ëª…í•´ ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?'},
                    'ai_question': {'question': 'ë” ìì„¸í•œ ë‚´ìš©ì„ ë§ì”€í•´ ì£¼ì„¸ìš”.'},
                    'interviewer_type': 'HR',
                    'question_type': 'follow_up',
                    'is_individual_questions': False,
                    'fallback_reason': 'complete_fallback'
                }

    async def _request_answer_from_ai_candidate(self, question: str) -> str:
        """AI ì§€ì›ìì—ê²Œ ë‹µë³€ ìƒì„±ì„ ìš”ì²­í•˜ê³ , í…ìŠ¤íŠ¸ ê²°ê³¼ë§Œ ë°˜í™˜"""
        try:
            from llm.shared.logging_config import interview_logger
            interview_logger.info(f"ğŸ“¤ AI ì§€ì›ìì—ê²Œ ë‹µë³€ ìš”ì²­: {self.session_id}")
            
            ai_persona = self.session_state.get('ai_persona')
            
            # ë‹µë³€ ìƒì„± ìš”ì²­ êµ¬ì„±
            from llm.shared.models import AnswerRequest, QuestionType, LLMProvider
            from llm.candidate.quality_controller import QualityLevel
            
            answer_request = AnswerRequest(
                question_content=question,
                question_type=QuestionType.HR, # TODO: ì§ˆë¬¸ ìœ í˜•ì„ stateì—ì„œ ê°€ì ¸ì˜¤ë„ë¡ ê°œì„ 
                question_intent="ë©´ì ‘ê´€ì˜ ì§ˆë¬¸",
                company_id=self.session_state.get('company_id'),
                position=self.session_state.get('position'),
                quality_level=QualityLevel.AVERAGE,
                llm_provider=LLMProvider.OPENAI_GPT4O
            )
            
            response = await asyncio.to_thread(
                self.ai_candidate_model.generate_answer,
                request=answer_request,
                persona=ai_persona
            )
            return response.answer_content
            
        except Exception as e:
            from llm.shared.logging_config import interview_logger
            interview_logger.error(f"AI ì§€ì›ì ë‹µë³€ ìš”ì²­ ì˜¤ë¥˜: {e}", exc_info=True)
            return "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    @staticmethod
    def create_agent_message(session_id: str, task: str, from_agent: str, content_text: str, 
                             turn_count: int, duration: float = 0, content_type: str = "text", 
                             start_time: float = None) -> Dict[str, Any]:
        """ì™¸ë¶€(Agent)ì—ì„œ Orchestratorë¡œ ë³´ë‚¼ ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ëŠ” ì •ì  ë©”ì„œë“œ"""
        # ğŸ†• total_time ê³„ì‚°
        total_time = None
        if start_time:
            total_time = time.time() - start_time
        
        return {
            "metadata": {
                "interview_id": session_id,
                "step": turn_count,
                "task": task,
                "from_agent": from_agent,
                "next_agent": "orchestrator",
                "status_code": 200
            },
            "content": {
                "type": content_type,
                "content": content_text
            },
            "metrics": {
                "duration": duration,
                "total_time": total_time
            }
        }

    async def process_user_answer(self, user_answer: str, time_spent: float = None) -> Dict[str, Any]:
        """ì‚¬ìš©ì ë‹µë³€ì„ ì²˜ë¦¬í•˜ê³  ì „ì²´ í”Œë¡œìš°ë¥¼ ì™„ë£Œí•˜ì—¬ ìµœì¢… ê²°ê³¼ ë°˜í™˜"""
        print(f"[Orchestrator] ğŸ”„ ì‚¬ìš©ì ë‹µë³€ ì²˜ë¦¬ ì‹œì‘: {self.session_id}")
        
        # ğŸ†• ê°œë³„ ì§ˆë¬¸ ìƒíƒœ ì²´í¬
        current_questions = self.session_state.get('current_questions')
        is_individual_question = current_questions and current_questions.get('is_individual', False)
        
        # 1. ì‚¬ìš©ì ë‹µë³€ ë©”ì‹œì§€ ìƒì„± ë° ì²˜ë¦¬
        task = "individual_answer_generated" if is_individual_question else "answer_generated"
        
        user_message = self.create_agent_message(
            session_id=self.session_id,
            task=task,
            from_agent="user",
            content_text=user_answer,
            turn_count=self.session_state.get('turn_count', 0),
            duration=time_spent,
            start_time=self.session_state.get('start_time')
        )
        
        # 2. ì‚¬ìš©ì ë‹µë³€ìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ (handle_messageì—ì„œ JSON ì¶œë ¥ë¨)
        self.handle_message(user_message)
        
        # 3. ë‹¤ìŒ ì•¡ì…˜ ê²°ì • ë° ì „ì²´ í”Œë¡œìš° ì²˜ë¦¬
        return await self._process_complete_flow()
    
    async def _process_complete_flow(self) -> Dict[str, Any]:
        """ì™„ì „í•œ í”Œë¡œìš°ë¥¼ ì²˜ë¦¬í•˜ì—¬ ìµœì¢… ê²°ê³¼ ë°˜í™˜"""
        print(f"[Orchestrator] ï¿½ï¿½ _process_complete_flow ì‹œì‘: {self.session_id}")
        
        while True:
            print(f"[Orchestrator] ğŸ”„ while ë£¨í”„ ì‹œì‘ - turn_count: {self.session_state.get('turn_count', 0)}")
            
            # ë‹¤ìŒ ë©”ì‹œì§€ ê²°ì •
            next_message = self._decide_next_message()
            next_agent = next_message.get("metadata", {}).get("next_agent")
            task = next_message.get("metadata", {}).get("task")
            
            print(f"[Orchestrator] ğŸ”„ ë‹¤ìŒ ì•¡ì…˜ ê²°ì •: {next_agent} - {task}")
            
            # ì™„ë£Œ ì¡°ê±´ ì²´í¬
            if task == "end_interview":
                print(f"[Orchestrator] âœ… ë©´ì ‘ ì™„ë£Œ")
                result = {
                    "status": "completed",
                    "message": "ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.",
                    "qa_history": self.session_state.get('qa_history', []),
                    "session_id": self.session_id
                }
                print(f"[Orchestrator] -> [Client]")
                print(json.dumps(result, indent=2, ensure_ascii=False))
                return result
            
            # ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸° ìƒíƒœì¸ ê²½ìš°
            if next_agent == "user":
                print(f"[Orchestrator] ğŸ‘¤ ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸°")
                result = self.create_user_waiting_message()
                print(f"[Orchestrator] -> [Client]")
                print(json.dumps(result, indent=2, ensure_ascii=False))
                return result
            
            # ì—ì´ì „íŠ¸ ì‘ì—… ìˆ˜í–‰ (handle_messageì—ì„œ JSON ì¶œë ¥ë¨)
            if next_agent == "interviewer":
                print(f"[Orchestrator] ğŸ¤ ë©´ì ‘ê´€ ì‘ì—… ì‹œì‘")
                await self._process_interviewer_task()
            elif next_agent == "interviewer_individual":
                print(f"[Orchestrator] ğŸ¤ğŸ¤ ë©´ì ‘ê´€ ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ì‘ì—… ì‹œì‘")
                await self._process_individual_interviewer_task()
            elif next_agent == "ai":
                print(f"[Orchestrator] ğŸ¤– AI ì§€ì›ì ì‘ì—… ì‹œì‘")
                await self._process_ai_task(next_message.get("content", {}).get("content"))
            
            print(f"[Orchestrator] ğŸ”„ while ë£¨í”„ ë")
    
    async def _process_interviewer_task(self):
        """ë©´ì ‘ê´€ ì‘ì—… ì²˜ë¦¬"""
        print(f"[Orchestrator] -> [Interviewer] (ì§ˆë¬¸ ìƒì„± ìš”ì²­)")
        
        # ğŸ†• í˜„ì¬ ìƒíƒœ ë””ë²„ê¹… (ê°œì„ )
        current_interviewer = self.session_state.get('current_interviewer')
        turn_state = self.session_state.get('interviewer_turn_state', {})
        current_turn = self.session_state.get('turn_count', 0)
        
        print(f"[DEBUG] í„´ {current_turn}: í˜„ì¬ ë©´ì ‘ê´€ = {current_interviewer}")
        for role, state in turn_state.items():
            main_done = "âœ“" if state['main_question_asked'] else "âœ—"
            follow_count = state['follow_up_count']
            print(f"[DEBUG]   {role}: ë©”ì¸ {main_done}, ê¼¬ë¦¬ {follow_count}ê°œ")
        
        question_result = await self._request_question_from_interviewer()
        
        # ğŸ†• ë°˜í™˜ê°’ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬
        if isinstance(question_result, dict) and 'user_question' in question_result and 'ai_question' in question_result:
            print(f"[DEBUG] ê°œë³„ ì§ˆë¬¸ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")
            
            # ê°œë³„ ì§ˆë¬¸ ë©”ì‹œì§€ ìƒì„±
            questions_message = self.create_agent_message(
                session_id=self.session_id,
                task="individual_questions_generated",
                from_agent="interviewer",
                content_text=json.dumps(question_result),
                turn_count=current_turn,
                content_type=current_interviewer or "HR",
                start_time=self.session_state.get('start_time')
            )
            
            # handle_messageì—ì„œ JSON ì¶œë ¥ë¨
            self.handle_message(questions_message)
            
        else:
            # ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§)
            question_content = question_result if isinstance(question_result, str) else str(question_result)
            
            # ğŸ†• content_type ê²°ì •
            content_type = "INTRO" if current_turn == 0 else current_interviewer or "HR"
            
            # í˜„ì¬ í„´ì— ë”°ë¼ task ê²°ì •
            task = "intro_generated" if current_turn == 0 else "question_generated"
            
            question_message = self.create_agent_message(
                session_id=self.session_id,
                task=task,
                from_agent="interviewer",
                content_text=question_content,
                turn_count=current_turn,
                content_type=content_type,
                start_time=self.session_state.get('start_time')
            )
            
            # handle_messageì—ì„œ JSON ì¶œë ¥ë¨
            self.handle_message(question_message)
    
    async def _process_individual_interviewer_task(self):
        """ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì‘ì—… ì²˜ë¦¬"""
        print(f"[Orchestrator] -> [Interviewer] (ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ìš”ì²­)")
        
        # í˜„ì¬ ìƒíƒœ ë””ë²„ê¹…
        current_interviewer = self.session_state.get('current_interviewer')
        turn_state = self.session_state.get('interviewer_turn_state', {})
        current_turn = self.session_state.get('turn_count', 0)
        
        print(f"[DEBUG] ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± - í„´ {current_turn}, ë©´ì ‘ê´€: {current_interviewer}")
        
        try:
            # ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ìš”ì²­
            individual_questions = await self._request_individual_follow_up_questions()
            
            # ê°œë³„ ì§ˆë¬¸ ë©”ì‹œì§€ ìƒì„± ë° ì²˜ë¦¬
            questions_message = self.create_agent_message(
                session_id=self.session_id,
                task="individual_questions_generated",
                from_agent="interviewer",
                content_text=json.dumps(individual_questions),  # Dictë¥¼ JSONìœ¼ë¡œ ë³€í™˜
                turn_count=current_turn,
                content_type=current_interviewer or "HR",
                start_time=self.session_state.get('start_time')
            )
            
            # handle_messageì—ì„œ JSON ì¶œë ¥ë¨
            self.handle_message(questions_message)
            
        except Exception as e:
            print(f"[ERROR] ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ì¼ë°˜ ì§ˆë¬¸ìœ¼ë¡œ ëŒ€ì²´
            await self._process_interviewer_task()
    
    async def _process_ai_task(self, question: str):
        """AI ì§€ì›ì ì‘ì—… ì²˜ë¦¬"""
        print(f"[Orchestrator] -> [AI Candidate] (ì§ˆë¬¸: {question[:50]}...)")
        
        # ì˜ˆì „ ë¡œì§ìœ¼ë¡œ ë³µì›: ì›ë³¸ ì§ˆë¬¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        ai_answer = await self._request_answer_from_ai_candidate(question)
        
        # ğŸ†• ê°œë³„ ì§ˆë¬¸ ìƒíƒœ ì²´í¬
        current_questions = self.session_state.get('current_questions')
        is_individual_question = current_questions and current_questions.get('is_individual', False)
        
        # ğŸ†• content_type ê²°ì • (í˜„ì¬ ë©´ì ‘ê´€ ê¸°ë°˜)
        current_interviewer = self.session_state.get('current_interviewer', 'HR')
        content_type = current_interviewer if current_interviewer in ['HR', 'TECH', 'COLLABORATION'] else 'HR'
        
        # ê°œë³„ ì§ˆë¬¸ ì—¬ë¶€ì— ë”°ë¼ task ê²°ì •
        task = "individual_answer_generated" if is_individual_question else "answer_generated"
        
        ai_message = self.create_agent_message(
            session_id=self.session_id,
            task=task,
            from_agent="ai",
            content_text=ai_answer,
            turn_count=self.session_state.get('turn_count', 0),
            content_type=content_type,
            start_time=self.session_state.get('start_time')
        )
        
        # handle_messageì—ì„œ JSON ì¶œë ¥ë¨
        self.handle_message(ai_message)
    
    def create_user_waiting_message(self) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸° ë©”ì‹œì§€ ìƒì„±"""
        # ğŸ†• ê°œë³„ ì§ˆë¬¸ ìƒíƒœ ì²´í¬
        current_questions = self.session_state.get('current_questions')
        is_individual_question = current_questions and current_questions.get('is_individual', False)
        
        # ğŸ†• ì§ˆë¬¸ í…ìŠ¤íŠ¸ ê²°ì •
        if is_individual_question:
            question_text = current_questions.get('user_question', {}).get('question', '')
            print(f"[DEBUG] ì‚¬ìš©ì ê°œë³„ ì§ˆë¬¸: {question_text[:50]}...")
        else:
            question_text = self.session_state.get('current_question', '')
        
        # ğŸ†• content_type ê²°ì • (í˜„ì¬ ë©´ì ‘ê´€ ê¸°ë°˜)
        current_interviewer = self.session_state.get('current_interviewer', 'HR')
        content_type = current_interviewer if current_interviewer in ['HR', 'TECH', 'COLLABORATION'] else 'HR'
        
        response = self.create_agent_message(
            session_id=self.session_id,
            task="wait_for_user_input",
            from_agent="orchestrator",
            content_text=question_text,
            turn_count=self.session_state.get('turn_count', 0),
            content_type=content_type,
            start_time=self.session_state.get('start_time')
        )
        # next_agentë¥¼ 'user'ë¡œ ìˆ˜ì •í•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œê°€ ì˜¬ë°”ë¥´ê²Œ ì¸ì‹í•˜ë„ë¡ í•¨
        response['metadata']['next_agent'] = 'user'
        response['status'] = 'waiting_for_user'
        response['message'] = 'ë‹µë³€ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'
        response['session_id'] = self.session_id
        
        # ğŸ†• í„´ ì •ë³´ ì¶”ê°€ (ê°œë³„ ì§ˆë¬¸ ì •ë³´ í¬í•¨)
        response['turn_info'] = {
            'current_turn': self.session_state.get('turn_count', 0),
            'is_user_turn': True,
            'is_individual_question': is_individual_question,
            'question_type': 'individual_follow_up' if is_individual_question else 'main_question'
        }
        
        return response

    
