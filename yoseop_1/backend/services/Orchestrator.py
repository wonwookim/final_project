import time
import json
import random
import asyncio
from dataclasses import dataclass, field
from typing import Optional, Dict, Any

@dataclass
class Metadata:
    interview_id: str
    step: int
    task: str
    from_agent: str 
    next_agent: str
    status_code: int

@dataclass
class Content:
    type: str
    content: str

@dataclass
class Metrics:
    total_time: Optional[float] = None
    duration: Optional[float] = None

@dataclass
class AgentMessage:
    metadata: Metadata
    content: Content
    metrics: Metrics = field(default_factory=Metrics)

class Orchestrator:
    def __init__(self, session_id: str, session_state: Dict[str, Any], 
                 question_generator=None, ai_candidate_model=None):
        """
        Orchestrator: ëª¨ë“  ë©´ì ‘ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë‹´ë‹¹
        - í”Œë¡œìš° ì œì–´
        - ì—ì´ì „íŠ¸ ì¡°ìœ¨
        - ë©”ì‹œì§€ ì²˜ë¦¬
        - ìƒíƒœ ì—…ë°ì´íŠ¸
        """
        self.session_id = session_id
        self.session_state = session_state  # InterviewServiceì˜ session_state ì°¸ì¡°
        self.question_generator = question_generator
        self.ai_candidate_model = ai_candidate_model

    def handle_message(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """ë©”ì‹œì§€ë¥¼ ë°›ì•„ì„œ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  ë‹¤ìŒ ì•¡ì…˜ì„ ê²°ì •"""
        from_agent = message.get("metadata", {}).get("from_agent", "unknown")
        print(f"[{from_agent}] -> [Orchestrator]")
        print(json.dumps(message, indent=2, ensure_ascii=False))

        task = message.get("metadata", {}).get("task")
        content = message.get("content", {}).get("content")

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        self._update_state_from_message(task, content, from_agent)

        # ë‹¤ìŒ ë©”ì‹œì§€ ê²°ì •
        next_message = self._decide_next_message()
        next_agent = next_message.get("metadata", {}).get("next_agent", "unknown")
        print(f"[Orchestrator] -> [{next_agent}]")
        print(json.dumps(next_message, indent=2, ensure_ascii=False))
        return next_message

    def _update_state_from_message(self, task: str, content: str, from_agent: str) -> None:
        """ë©”ì‹œì§€ë¡œë¶€í„° ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        if task == "intro_generated":
            # ì¸íŠ¸ë¡œ ë©”ì‹œì§€ ìƒì„± ì™„ë£Œ - ë‹µë³€ ì—†ì´ ë°”ë¡œ í„´ ì¦ê°€
            self.session_state['turn_count'] += 1  # í„´ 0 ì™„ë£Œ, í„´ 1ë¡œ ì´ë™
            # current_questionì€ ì„¤ì •í•˜ì§€ ì•ŠìŒ (ë‹µë³€ ìš”ì²­í•˜ì§€ ì•ŠìŒ)
            
        elif task == "question_generated":
            self.session_state['current_question'] = content
            
            # ğŸ†• ì§ˆë¬¸ íƒ€ì… ì¶”ì¶œ ë¡œì§ ì œê±° - QuestionGeneratorì—ì„œ ê²°ì •í•œ ë©´ì ‘ê´€ ì‚¬ìš©
            # current_interviewerëŠ” QuestionGeneratorì—ì„œ ì´ë¯¸ ì„¤ì •ë¨
            # ì—¬ê¸°ì„œëŠ” ì§ˆë¬¸ ë‚´ìš©ë§Œ ì €ì¥í•˜ê³  ë©´ì ‘ê´€ ì¶”ì¸¡í•˜ì§€ ì•ŠìŒ
            
        elif task == "answer_generated":
            # ğŸ†• ë‹µë³€ ì •ë³´ë¥¼ qa_historyì—ë§Œ ì €ì¥
            self.session_state['qa_history'].append({
                "question": self.session_state['current_question'],
                "answerer": from_agent,
                "answer": content
            })
            
            # ë‘ ë‹µë³€ì´ ëª¨ë‘ ì™„ë£Œë˜ë©´ í„´ ì¦ê°€ ë° ê¼¬ë¦¬ ì§ˆë¬¸ ìƒíƒœ ì—…ë°ì´íŠ¸
            current_answers = len([qa for qa in self.session_state['qa_history'] 
                                 if qa['question'] == self.session_state['current_question']])
            
            if current_answers >= 2:
                # ğŸ†• ê¼¬ë¦¬ ì§ˆë¬¸ ì¹´ìš´íŠ¸ ì¦ê°€ (ìˆ˜ì •ëœ ë¡œì§)
                current_interviewer = self.session_state.get('current_interviewer')
                if current_interviewer and current_interviewer in ['HR', 'TECH', 'COLLABORATION']:
                    turn_state = self.session_state.get('interviewer_turn_state', {})
                    if current_interviewer in turn_state:
                        # í˜„ì¬ ì§ˆë¬¸ì´ ë©”ì¸ ì§ˆë¬¸ì¸ì§€ ê¼¬ë¦¬ ì§ˆë¬¸ì¸ì§€ íŒë‹¨
                        current_turn = self.session_state.get('turn_count', 0)
                        
                        # í„´ 1, 2ëŠ” ê³ ì • ì§ˆë¬¸ì´ë¯€ë¡œ ì¹´ìš´íŠ¸í•˜ì§€ ì•ŠìŒ
                        if current_turn > 2:
                            # ë©”ì¸ ì§ˆë¬¸ ì™„ë£Œ í‘œì‹œ
                            if not turn_state[current_interviewer]['main_question_asked']:
                                turn_state[current_interviewer]['main_question_asked'] = True
                            else:
                                # ê¼¬ë¦¬ ì§ˆë¬¸ ì¹´ìš´íŠ¸ ì¦ê°€
                                turn_state[current_interviewer]['follow_up_count'] += 1
                
                self.session_state['turn_count'] += 1
                self.session_state['current_question'] = None

    def _decide_next_message(self) -> Dict[str, Any]:
        """ë‹¤ìŒ ë©”ì‹œì§€ ê²°ì • - ì‹¤ì œ í”Œë¡œìš° ì œì–´ ë¡œì§"""
        current_turn = self.session_state.get('turn_count', 0)
        
        # í„´ 0: ì¸íŠ¸ë¡œ ì²˜ë¦¬
        if current_turn == 0:
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_intro",
                from_agent="orchestrator",
                content_text="ì¸íŠ¸ë¡œ ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
                turn_count=current_turn
            )
            message["metadata"]["next_agent"] = "interviewer"
            return message
        
        # ì™„ë£Œ ì¡°ê±´ ì²´í¬
        if current_turn >= self.session_state.get('total_question_limit', 15):
            self.session_state['is_completed'] = True
            message = self.create_agent_message(
                session_id=self.session_id,
                task="end_interview",
                from_agent="orchestrator",
                content_text="ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.",
                turn_count=current_turn
            )
            message["metadata"]["next_agent"] = "orchestrator"
            return message

        # í˜„ì¬ ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ ìƒˆ ì§ˆë¬¸ ìƒì„±
        if not self.session_state['current_question']:
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_question",
                from_agent="orchestrator",
                content_text="ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.",
                turn_count=current_turn
            )
            message["metadata"]["next_agent"] = "interviewer"
            return message
        
        # í˜„ì¬ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìˆ˜ í™•ì¸
        current_answers = len([qa for qa in self.session_state['qa_history'] 
                             if qa['question'] == self.session_state['current_question']])
        
        # ì²« ë²ˆì§¸ ë‹µë³€: ëœë¤ ì„ íƒ
        if current_answers == 0:
            selected_agent = 'user' if self._random_select() == -1 else 'ai'
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_answer",
                from_agent="orchestrator",
                content_text=self.session_state['current_question'],
                turn_count=current_turn
            )
            message["metadata"]["next_agent"] = selected_agent
            return message
        
        # ë‘ ë²ˆì§¸ ë‹µë³€: ë°˜ëŒ€ ì—ì´ì „íŠ¸
        elif current_answers == 1:
            # ì²« ë²ˆì§¸ ë‹µë³€ì í™•ì¸
            first_answerer = self.session_state['qa_history'][-1]['answerer']
            selected_agent = 'ai' if first_answerer == 'user' else 'user'
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_answer",
                from_agent="orchestrator",
                content_text=self.session_state['current_question'],
                turn_count=current_turn
            )
            message["metadata"]["next_agent"] = selected_agent
            return message
        
        # ëª¨ë“  ë‹µë³€ ì™„ë£Œ: ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ
        else:
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_question",
                from_agent="orchestrator",
                content_text="ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.",
                turn_count=current_turn
            )
            message["metadata"]["next_agent"] = "interviewer"
            return message

   

    def _random_select(self) -> int:
        """ì‚¬ìš©ìì™€ AI ì¤‘ ëœë¤ìœ¼ë¡œ ì„ íƒ"""
        return random.choice([-1, 1])

    # ì—ì´ì „íŠ¸ ì¡°ìœ¨ ë©”ì„œë“œë“¤ (ë‚´ë¶€ ì²˜ë¦¬ìš©)
    async def _request_question_from_interviewer(self) -> str:
        """ë©´ì ‘ê´€(QuestionGenerator)ì—ê²Œ ì§ˆë¬¸ ìƒì„±ì„ ìš”ì²­í•˜ê³ , í…ìŠ¤íŠ¸ ê²°ê³¼ë§Œ ë°˜í™˜"""
        try:
            from llm.shared.logging_config import interview_logger
            interview_logger.info(f"ğŸ“¤ ë©´ì ‘ê´€ì—ê²Œ ì§ˆë¬¸ ìƒì„± ìš”ì²­: {self.session_id}")
            
            # QuestionGeneratorì—ê²Œ ìƒíƒœ ê°ì²´(state)ë¥¼ ì „ë‹¬í•˜ì—¬ ì§ˆë¬¸ ìƒì„±
            question_data = await asyncio.to_thread(
                self.question_generator.generate_question_with_orchestrator_state,
                self.session_state
            )
            
            # ğŸ†• í„´ ì „í™˜ ì²˜ë¦¬
            if question_data.get('turn_switch'):
                # ğŸ†• í„´ ì „í™˜ ì‹œ ë°”ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì„ ìš”ì²­ (ì¬ê·€ í˜¸ì¶œ)
                print(f"[DEBUG] í„´ ì „í™˜ ê°ì§€: {question_data.get('message', '')}")
                # ìƒíƒœ ì—…ë°ì´íŠ¸ í›„ ë‹¤ì‹œ ì§ˆë¬¸ ìš”ì²­
                return await self._request_question_from_interviewer()
            
            # ì¼ë°˜ ì§ˆë¬¸ ë°˜í™˜
            return question_data.get('question', 'ë‹¤ìŒ ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ê°€ìš”?')
            
        except Exception as e:
            from llm.shared.logging_config import interview_logger
            interview_logger.error(f"ë©´ì ‘ê´€ ì§ˆë¬¸ ìš”ì²­ ì˜¤ë¥˜: {e}", exc_info=True)
            return "ì£„ì†¡í•©ë‹ˆë‹¤, ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    async def _request_answer_from_ai_candidate(self, question: str) -> str:
        """AI ì§€ì›ìì—ê²Œ ë‹µë³€ ìƒì„±ì„ ìš”ì²­í•˜ê³ , í…ìŠ¤íŠ¸ ê²°ê³¼ë§Œ ë°˜í™˜"""
        try:
            from llm.shared.logging_config import interview_logger
            interview_logger.info(f"ğŸ“¤ AI ì§€ì›ìì—ê²Œ ë‹µë³€ ìš”ì²­: {self.session_id}")
            
            ai_persona = self.session_state.get('ai_persona')
            
            # ë‹µë³€ ìƒì„± ìš”ì²­ êµ¬ì„±
            from llm.shared.models import AnswerRequest, QuestionType, LLMProvider
            from llm.candidate.quality_controller import QualityLevel
            
            answer_request = AnswerRequest(
                question_content=question,
                question_type=QuestionType.HR, # TODO: ì§ˆë¬¸ ìœ í˜•ì„ stateì—ì„œ ê°€ì ¸ì˜¤ë„ë¡ ê°œì„ 
                question_intent="ë©´ì ‘ê´€ì˜ ì§ˆë¬¸",
                company_id=self.session_state.get('company_id'),
                position=self.session_state.get('position'),
                quality_level=QualityLevel.AVERAGE,
                llm_provider=LLMProvider.OPENAI_GPT4O
            )
            
            response = await asyncio.to_thread(
                self.ai_candidate_model.generate_answer,
                request=answer_request,
                persona=ai_persona
            )
            return response.answer_content
            
        except Exception as e:
            from llm.shared.logging_config import interview_logger
            interview_logger.error(f"AI ì§€ì›ì ë‹µë³€ ìš”ì²­ ì˜¤ë¥˜: {e}", exc_info=True)
            return "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    @staticmethod
    def create_agent_message(session_id: str, task: str, from_agent: str, content_text: str, 
                             turn_count: int, duration: float = 0, content_type: str = "text") -> Dict[str, Any]:
        """ì™¸ë¶€(Agent)ì—ì„œ Orchestratorë¡œ ë³´ë‚¼ ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ëŠ” ì •ì  ë©”ì„œë“œ"""
        return {
            "metadata": {
                "interview_id": session_id,
                "step": turn_count,
                "task": task,
                "from_agent": from_agent,
                "next_agent": "orchestrator",
                "status_code": 200
            },
            "content": {
                "type": content_type,
                "content": content_text
            },
            "metrics": {
                "duration": duration
            }
        }

    async def process_user_answer(self, user_answer: str, time_spent: float = None) -> Dict[str, Any]:
        """ì‚¬ìš©ì ë‹µë³€ì„ ì²˜ë¦¬í•˜ê³  ì „ì²´ í”Œë¡œìš°ë¥¼ ì™„ë£Œí•˜ì—¬ ìµœì¢… ê²°ê³¼ ë°˜í™˜"""
        print(f"[Orchestrator] ğŸ”„ ì‚¬ìš©ì ë‹µë³€ ì²˜ë¦¬ ì‹œì‘: {self.session_id}")
        
        # 1. ì‚¬ìš©ì ë‹µë³€ ë©”ì‹œì§€ ìƒì„± ë° ì²˜ë¦¬
        user_message = self.create_agent_message(
            session_id=self.session_id,
            task="answer_generated",
            from_agent="user",
            content_text=user_answer,
            turn_count=self.session_state.get('turn_count', 0),
            duration=time_spent
        )
        
        # 2. ì‚¬ìš©ì ë‹µë³€ìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ (handle_messageì—ì„œ JSON ì¶œë ¥ë¨)
        self.handle_message(user_message)
        
        # 3. ë‹¤ìŒ ì•¡ì…˜ ê²°ì • ë° ì „ì²´ í”Œë¡œìš° ì²˜ë¦¬
        return await self._process_complete_flow()
    
    async def _process_complete_flow(self) -> Dict[str, Any]:
        """ì™„ì „í•œ í”Œë¡œìš°ë¥¼ ì²˜ë¦¬í•˜ì—¬ ìµœì¢… ê²°ê³¼ ë°˜í™˜"""
        print(f"[Orchestrator] ï¿½ï¿½ _process_complete_flow ì‹œì‘: {self.session_id}")
        
        while True:
            print(f"[Orchestrator] ğŸ”„ while ë£¨í”„ ì‹œì‘ - turn_count: {self.session_state.get('turn_count', 0)}")
            
            # ë‹¤ìŒ ë©”ì‹œì§€ ê²°ì •
            next_message = self._decide_next_message()
            next_agent = next_message.get("metadata", {}).get("next_agent")
            task = next_message.get("metadata", {}).get("task")
            
            print(f"[Orchestrator] ğŸ”„ ë‹¤ìŒ ì•¡ì…˜ ê²°ì •: {next_agent} - {task}")
            
            # ì™„ë£Œ ì¡°ê±´ ì²´í¬
            if task == "end_interview":
                print(f"[Orchestrator] âœ… ë©´ì ‘ ì™„ë£Œ")
                result = {
                    "status": "completed",
                    "message": "ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.",
                    "qa_history": self.session_state.get('qa_history', []),
                    "session_id": self.session_id
                }
                print(f"[Orchestrator] -> [Client]")
                print(json.dumps(result, indent=2, ensure_ascii=False))
                return result
            
            # ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸° ìƒíƒœì¸ ê²½ìš°
            if next_agent == "user":
                print(f"[Orchestrator] ğŸ‘¤ ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸°")
                result = self.create_user_waiting_message()
                print(f"[Orchestrator] -> [Client]")
                print(json.dumps(result, indent=2, ensure_ascii=False))
                return result
            
            # ì—ì´ì „íŠ¸ ì‘ì—… ìˆ˜í–‰ (handle_messageì—ì„œ JSON ì¶œë ¥ë¨)
            if next_agent == "interviewer":
                print(f"[Orchestrator] ğŸ¤ ë©´ì ‘ê´€ ì‘ì—… ì‹œì‘")
                await self._process_interviewer_task()
            elif next_agent == "ai":
                print(f"[Orchestrator] ğŸ¤– AI ì§€ì›ì ì‘ì—… ì‹œì‘")
                await self._process_ai_task(next_message.get("content", {}).get("content"))
            
            print(f"[Orchestrator] ğŸ”„ while ë£¨í”„ ë")
    
    async def _process_interviewer_task(self):
        """ë©´ì ‘ê´€ ì‘ì—… ì²˜ë¦¬"""
        print(f"[Orchestrator] -> [Interviewer] (ì§ˆë¬¸ ìƒì„± ìš”ì²­)")
        
        # ğŸ†• í˜„ì¬ ìƒíƒœ ë””ë²„ê¹… (ê°œì„ )
        current_interviewer = self.session_state.get('current_interviewer')
        turn_state = self.session_state.get('interviewer_turn_state', {})
        current_turn = self.session_state.get('turn_count', 0)
        
        print(f"[DEBUG] í„´ {current_turn}: í˜„ì¬ ë©´ì ‘ê´€ = {current_interviewer}")
        for role, state in turn_state.items():
            main_done = "âœ“" if state['main_question_asked'] else "âœ—"
            follow_count = state['follow_up_count']
            print(f"[DEBUG]   {role}: ë©”ì¸ {main_done}, ê¼¬ë¦¬ {follow_count}ê°œ")
        
        question_content = await self._request_question_from_interviewer()
        
        # í˜„ì¬ í„´ì— ë”°ë¼ task ê²°ì •
        task = "intro_generated" if current_turn == 0 else "question_generated"
        
        question_message = self.create_agent_message(
            session_id=self.session_id,
            task=task,
            from_agent="interviewer",
            content_text=question_content,
            turn_count=current_turn
        )
        
        # handle_messageì—ì„œ JSON ì¶œë ¥ë¨
        self.handle_message(question_message)
    
    async def _process_ai_task(self, question: str):
        """AI ì§€ì›ì ì‘ì—… ì²˜ë¦¬"""
        print(f"[Orchestrator] -> [AI Candidate] (ì§ˆë¬¸: {question[:50]}...)")
        
        ai_answer = await self._request_answer_from_ai_candidate(question)
        
        ai_message = self.create_agent_message(
            session_id=self.session_id,
            task="answer_generated",
            from_agent="ai",
            content_text=ai_answer,
            turn_count=self.session_state.get('turn_count', 0)
        )
        
        # handle_messageì—ì„œ JSON ì¶œë ¥ë¨
        self.handle_message(ai_message)
    
    def create_user_waiting_message(self) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸° ë©”ì‹œì§€ ìƒì„±"""
        response = self.create_agent_message(
            session_id=self.session_id,
            task="wait_for_user_input",
            from_agent="orchestrator",
            content_text=self.session_state.get('current_question'),
            turn_count=self.session_state.get('turn_count', 0)
        )
        # next_agentë¥¼ 'user'ë¡œ ìˆ˜ì •í•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œê°€ ì˜¬ë°”ë¥´ê²Œ ì¸ì‹í•˜ë„ë¡ í•¨
        response['metadata']['next_agent'] = 'user'
        response['status'] = 'waiting_for_user'
        response['message'] = 'ë‹µë³€ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'
        response['session_id'] = self.session_id
        
        # í„´ ì •ë³´ ì¶”ê°€
        response['turn_info'] = {
            'current_turn': self.session_state.get('turn_count', 0),
            'is_user_turn': True
        }
        
        return response
