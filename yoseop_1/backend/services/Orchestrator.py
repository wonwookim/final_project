import time
import json
import random
import asyncio
import re
import base64
from dataclasses import dataclass, field
from typing import Optional, Dict, Any, List, Tuple

# TTS ë™ì‹œ ìš”ì²­ ì œí•œì„ ìœ„í•œ ì„¸ë§ˆí¬ì–´ ì¶”ê°€
_tts_semaphore = asyncio.Semaphore(1)  # í•œ ë²ˆì— í•˜ë‚˜ì˜ TTS ìš”ì²­ë§Œ í—ˆìš©

@dataclass
class Metadata:
    interview_id: str
    step: int
    task: str
    from_agent: str 
    next_agent: str
    status_code: int

@dataclass
class Content:
    type: str
    content: str

@dataclass
class Metrics:
    total_time: Optional[float] = None
    duration: Optional[float] = None

@dataclass
class AgentMessage:
    metadata: Metadata
    content: Content
    metrics: Metrics = field(default_factory=Metrics)

class Orchestrator:
    def __init__(self, session_id: str, session_state: Dict[str, Any], 
                 question_generator=None, ai_candidate_model=None):
        """
        Orchestrator: ëª¨ë“  ë©´ì ‘ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë‹´ë‹¹
        - í”Œë¡œìš° ì œì–´
        - ì—ì´ì „íŠ¸ ì¡°ìœ¨
        - ë©”ì‹œì§€ ì²˜ë¦¬
        - ìƒíƒœ ì—…ë°ì´íŠ¸
        """
        self.session_id = session_id
        self.session_state = session_state  # InterviewServiceì˜ session_state ì°¸ì¡°
        self.question_generator = question_generator
        self.ai_candidate_model = ai_candidate_model

    def handle_message(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """ë©”ì‹œì§€ë¥¼ ë°›ì•„ì„œ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  ë‹¤ìŒ ì•¡ì…˜ì„ ê²°ì •"""
        from_agent = message.get("metadata", {}).get("from_agent", "unknown")
        print(f"[TRACE] {from_agent} -> Orchestrator")
        print(json.dumps(message, indent=2, ensure_ascii=False))

        task = message.get("metadata", {}).get("task")
        content = message.get("content", {}).get("content")

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        self._update_state_from_message(task, content, from_agent)

        # ë‹¤ìŒ ë©”ì‹œì§€ ê²°ì •
        next_message = self._decide_next_message()
        next_agent = next_message.get("metadata", {}).get("next_agent", "unknown")
        print(f"[TRACE] Orchestrator -> {next_agent}")
        print(json.dumps(next_message, indent=2, ensure_ascii=False))
        return next_message

    def _update_state_from_message(self, task: str, content: str, from_agent: str) -> None:
        """ë©”ì‹œì§€ë¡œë¶€í„° ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        if task == "intro_generated":
            # ì¸íŠ¸ë¡œ ë©”ì‹œì§€ ìƒì„± ì™„ë£Œ - ì„¸ì…˜ì— ì €ì¥
            self.session_state['intro_message'] = content
            # ë‹µë³€ ì—†ì´ ë°”ë¡œ í„´ ì¦ê°€
            self.session_state['turn_count'] += 1  # í„´ 0 ì™„ë£Œ, í„´ 1ë¡œ ì´ë™
            # current_questionì€ ì„¤ì •í•˜ì§€ ì•ŠìŒ (ë‹µë³€ ìš”ì²­í•˜ì§€ ì•ŠìŒ)
            
        elif task == "question_generated":
            # í„´ 0ì—ì„œ ë°›ì€ ë©”ì‹œì§€ëŠ” ì¸íŠ¸ë¡œ ë©”ì‹œì§€ë¡œ ì²˜ë¦¬
            current_turn = self.session_state.get('turn_count', 0)
            if current_turn == 0:
                self.session_state['intro_message'] = content
                self.session_state['turn_count'] += 1  # í„´ 0 ì™„ë£Œ, í„´ 1ë¡œ ì´ë™
                print(f"[DEBUG] ì¸íŠ¸ë¡œ ë©”ì‹œì§€ ì²˜ë¦¬ ì™„ë£Œ: í„´ {current_turn} -> {self.session_state['turn_count']}")
            else:
                # ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬
                self.session_state['current_question'] = content
                print(f"[DEBUG] ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬: í„´ {current_turn}")
            
            # ğŸ†• ì§ˆë¬¸ íƒ€ì… ì¶”ì¶œ ë¡œì§ ì œê±° - QuestionGeneratorì—ì„œ ê²°ì •í•œ ë©´ì ‘ê´€ ì‚¬ìš©
            # current_interviewerëŠ” QuestionGeneratorì—ì„œ ì´ë¯¸ ì„¤ì •ë¨
            # ì—¬ê¸°ì„œëŠ” ì§ˆë¬¸ ë‚´ìš©ë§Œ ì €ì¥í•˜ê³  ë©´ì ‘ê´€ ì¶”ì¸¡í•˜ì§€ ì•ŠìŒ
            
        elif task == "individual_questions_generated":
            # ğŸ†• ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì™„ë£Œ - contentëŠ” dict í˜•íƒœ
            import json
            if isinstance(content, str):
                questions_data = json.loads(content)
            else:
                questions_data = content
                
            self.session_state['current_questions'] = {
                'user_question': questions_data.get('user_question', {}),
                'ai_question': questions_data.get('ai_question', {}),
                'is_individual': questions_data.get('is_individual_questions', True),
                'interviewer_type': questions_data.get('interviewer_type', 'HR')
            }
            
            print(f"[DEBUG] ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒíƒœ ì €ì¥ ì™„ë£Œ")
            print(f"[DEBUG] ì‚¬ìš©ì ì§ˆë¬¸: {questions_data.get('user_question', {}).get('question', 'N/A')[:30]}...")
            print(f"[DEBUG] AI ì§ˆë¬¸: {questions_data.get('ai_question', {}).get('question', 'N/A')[:30]}...")
            
        elif task == "individual_answer_generated":
            # ğŸ†• ê°œë³„ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ì²˜ë¦¬
            current_questions = self.session_state.get('current_questions', {})
            if current_questions.get('is_individual', False):
                # ê°œë³„ ì§ˆë¬¸ì˜ ê²½ìš° answererì— ë”°ë¼ í•´ë‹¹í•˜ëŠ” ì§ˆë¬¸ ë§¤í•‘
                if from_agent == 'user':
                    question_text = current_questions.get('user_question', {}).get('question', '')
                elif from_agent == 'ai':
                    question_text = current_questions.get('ai_question', {}).get('question', '')
                else:
                    question_text = self.session_state.get('current_question', '')
            else:
                question_text = self.session_state.get('current_question', '')
            
            # qa_historyì— ë‹µë³€ ì €ì¥
            qa_entry = {
                "question": question_text,
                "answerer": from_agent,
                "answer": content
            }
            self.session_state['qa_history'].append(qa_entry)
            print(f"[DEBUG] QA ì €ì¥: answerer={from_agent}, question='{question_text[:50]}...', answer='{content[:30]}...'")
            
            # ê°œë³„ ë‹µë³€ ì™„ë£Œ ì²´í¬ (ì‚¬ìš©ìì™€ AI ëª¨ë‘ ë‹µë³€í–ˆëŠ”ì§€)
            if current_questions.get('is_individual', False):
                # í˜„ì¬ í„´ì˜ ê°œë³„ ë‹µë³€ ìˆ˜ ê³„ì‚°
                individual_answers = len([qa for qa in self.session_state['qa_history'] 
                                        if qa['question'] in [
                                            current_questions.get('user_question', {}).get('question', ''),
                                            current_questions.get('ai_question', {}).get('question', '')
                                        ]])
                
                if individual_answers >= 2:
                    self._handle_turn_completion_for_individual_questions()
            else:
                # ê¸°ì¡´ ë¡œì§ ìœ ì§€ (ê³µí†µ ì§ˆë¬¸ì¸ ê²½ìš°)
                self._handle_turn_completion_for_common_question()
                
        elif task == "answer_generated":
            # ê¸°ì¡´ ë‹µë³€ ì²˜ë¦¬ (ë©”ì¸ ì§ˆë¬¸ ë˜ëŠ” ê³µí†µ ê¼¬ë¦¬ì§ˆë¬¸)
            # AIê°€ ì‹¤ì œë¡œ ë°›ì€ ì§ˆë¬¸ì´ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë³´ì •
            if from_agent == 'ai' and '_ai_actual_question' in self.session_state:
                question_text = self.session_state.pop('_ai_actual_question')
            else:
                question_text = self.session_state['current_question']

            qa_entry = {
                "question": question_text,
                "answerer": from_agent,
                "answer": content
            }
            self.session_state['qa_history'].append(qa_entry)
            print(f"[DEBUG] QA ì €ì¥ (async): answerer={from_agent}, question='{question_text[:50]}...', answer='{content[:30]}...'")

            # ë‘ ë‹µë³€ì´ ëª¨ë‘ ì™„ë£Œë˜ë©´ í„´ ì¦ê°€ ë° ê¼¬ë¦¬ ì§ˆë¬¸ ìƒíƒœ ì—…ë°ì´íŠ¸
            # í˜„ì¬ ì§ˆë¬¸(ì‚¬ìš©ììš©)ê³¼ AIìš© ë³€í™˜ í…ìŠ¤íŠ¸ ë‘˜ ë‹¤ì— ëŒ€í•´ ë‹µë³€ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            try:
                user_question = self.session_state['current_question']
                ai_question_variant = self._format_question_for_ai(user_question)
                answers_for_pair = [qa for qa in self.session_state['qa_history']
                                    if qa['question'] in (user_question, ai_question_variant)]
                answerers = {qa['answerer'] for qa in answers_for_pair}
                if {'user', 'ai'}.issubset(answerers):
                    self._handle_turn_completion_for_common_question()
            except Exception:
                # í´ë°±: ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í˜„ì¬ ì§ˆë¬¸ í…ìŠ¤íŠ¸ ê¸°ì¤€ ì¹´ìš´íŠ¸
                current_answers = len([qa for qa in self.session_state['qa_history']
                                      if qa['question'] == self.session_state['current_question']])
                if current_answers >= 2:
                    self._handle_turn_completion_for_common_question()

    def _handle_turn_completion_for_common_question(self):
        """ê³µí†µ ì§ˆë¬¸ ì™„ë£Œ ì‹œ ì²˜ë¦¬"""
        # ğŸ†• ê¼¬ë¦¬ ì§ˆë¬¸ ì¹´ìš´íŠ¸ ì¦ê°€ (ìˆ˜ì •ëœ ë¡œì§)
        current_interviewer = self.session_state.get('current_interviewer')
        if current_interviewer and current_interviewer in ['HR', 'TECH', 'COLLABORATION']:
            turn_state = self.session_state.get('interviewer_turn_state', {})
            if current_interviewer in turn_state:
                # í˜„ì¬ ì§ˆë¬¸ì´ ë©”ì¸ ì§ˆë¬¸ì¸ì§€ ê¼¬ë¦¬ ì§ˆë¬¸ì¸ì§€ íŒë‹¨
                current_turn = self.session_state.get('turn_count', 0)
                
                # í„´ 1, 2ëŠ” ê³ ì • ì§ˆë¬¸ì´ë¯€ë¡œ ì¹´ìš´íŠ¸í•˜ì§€ ì•ŠìŒ
                if current_turn > 2:
                    # ë©”ì¸ ì§ˆë¬¸ ì™„ë£Œ í‘œì‹œ
                    if not turn_state[current_interviewer]['main_question_asked']:
                        turn_state[current_interviewer]['main_question_asked'] = True
                    else:
                        # ê¼¬ë¦¬ ì§ˆë¬¸ ì¹´ìš´íŠ¸ ì¦ê°€
                        turn_state[current_interviewer]['follow_up_count'] += 1
        
        self.session_state['turn_count'] += 1
        self.session_state['current_question'] = None
    
    def _handle_turn_completion_for_individual_questions(self):
        """ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ì™„ë£Œ ì‹œ ì²˜ë¦¬"""
        current_interviewer = self.session_state.get('current_interviewer')
        if current_interviewer and current_interviewer in ['HR', 'TECH', 'COLLABORATION']:
            turn_state = self.session_state.get('interviewer_turn_state', {})
            if current_interviewer in turn_state:
                # ê¼¬ë¦¬ ì§ˆë¬¸ ì¹´ìš´íŠ¸ ì¦ê°€
                turn_state[current_interviewer]['follow_up_count'] += 1
        
        self.session_state['turn_count'] += 1
        self.session_state['current_questions'] = None
        print(f"[DEBUG] ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ í„´ ì™„ë£Œ, ë‹¤ìŒ í„´ìœ¼ë¡œ ì´ë™")

    def _decide_next_message(self) -> Dict[str, Any]:
        """ë‹¤ìŒ ë©”ì‹œì§€ ê²°ì • - ì‹¤ì œ í”Œë¡œìš° ì œì–´ ë¡œì§"""
        current_turn = self.session_state.get('turn_count', 0)
        start_time = self.session_state.get('start_time')
        
        # í„´ 0: ì¸íŠ¸ë¡œ ì²˜ë¦¬
        if current_turn == 0:
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_intro",
                from_agent="orchestrator",
                content_text="ì¸íŠ¸ë¡œ ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
                turn_count=current_turn,
                content_type="INTRO",
                start_time=start_time
            )
            message["metadata"]["next_agent"] = "interviewer"
            return message
        
        # ì™„ë£Œ ì¡°ê±´ ì²´í¬ (í„´ 0: ì¸íŠ¸ë¡œ ì œì™¸)
        if current_turn > self.session_state.get('total_question_limit', 15):
            self.session_state['is_completed'] = True
            message = self.create_agent_message(
                session_id=self.session_id,
                task="end_interview",
                from_agent="orchestrator",
                content_text="ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.",
                turn_count=current_turn,
                content_type="OUTTRO",
                start_time=start_time
            )
            message["metadata"]["next_agent"] = "orchestrator"
            return message

        # ğŸ†• ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ì²˜ë¦¬ ë¡œì§
        current_questions = self.session_state.get('current_questions')
        if current_questions and current_questions.get('is_individual', False):
            return self._handle_individual_questions_flow(current_questions, current_turn, start_time)
        
        # í˜„ì¬ ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ ìƒˆ ì§ˆë¬¸ ìƒì„± (ë©”ì¸ ì§ˆë¬¸ ë˜ëŠ” ê¼¬ë¦¬ì§ˆë¬¸ ê²°ì •)
        if not self.session_state.get('current_question'):
            # ğŸ†• ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì¡°ê±´ ì²´í¬
            if self._should_generate_individual_follow_up():
                print(f"[DEBUG] ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì¡°ê±´ ë§Œì¡±")
                message = self.create_agent_message(
                    session_id=self.session_id,
                    task="generate_individual_follow_up",
                    from_agent="orchestrator",
                    content_text="ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.",
                    turn_count=current_turn,
                    start_time=start_time
                )
                message["metadata"]["next_agent"] = "interviewer_individual"
                return message
            else:
                # ì¼ë°˜ ë©”ì¸ ì§ˆë¬¸ ìƒì„±
                message = self.create_agent_message(
                    session_id=self.session_id,
                    task="generate_question",
                    from_agent="orchestrator",
                    content_text="ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.",
                    turn_count=current_turn,
                    start_time=start_time
                )
                message["metadata"]["next_agent"] = "interviewer"
                return message
        
        # í˜„ì¬ ë©”ì¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìˆ˜ í™•ì¸ (AIìš© ë³€í˜• í¬í•¨)
        user_question = self.session_state['current_question']
        ai_question_variant = self._format_question_for_ai(user_question) if user_question else None
        current_answers = len([qa for qa in self.session_state['qa_history']
                             if qa['question'] == user_question or (ai_question_variant and qa['question'] == ai_question_variant)])
        
        # ì²« ë²ˆì§¸ ë‹µë³€: ëœë¤ ì„ íƒ
        if current_answers == 0:
            selected_agent = 'user' if self._random_select() == -1 else 'ai'
            # ì—ì´ì „íŠ¸ë³„ë¡œ ì „ë‹¬í•  ì§ˆë¬¸ í…ìŠ¤íŠ¸ ê²°ì •
            if selected_agent == 'ai':
                question_text = self._format_question_for_ai(self.session_state['current_question'])
                # QA ê¸°ë¡ì„ ìœ„í•´ ì„ì‹œ ì €ì¥
                self.session_state['_ai_actual_question'] = question_text
            else:
                question_text = self.session_state['current_question']
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_answer",
                from_agent="orchestrator",
                content_text=question_text,
                turn_count=current_turn,
                start_time=start_time
            )
            message["metadata"]["next_agent"] = selected_agent
            return message
        
        # ë‘ ë²ˆì§¸ ë‹µë³€: ë°˜ëŒ€ ì—ì´ì „íŠ¸
        elif current_answers == 1:
            # ì²« ë²ˆì§¸ ë‹µë³€ì í™•ì¸
            first_answerer = self.session_state['qa_history'][-1]['answerer']
            selected_agent = 'ai' if first_answerer == 'user' else 'user'
            # ì—ì´ì „íŠ¸ë³„ë¡œ ì „ë‹¬í•  ì§ˆë¬¸ í…ìŠ¤íŠ¸ ê²°ì •
            if selected_agent == 'ai':
                question_text = self._format_question_for_ai(self.session_state['current_question'])
                self.session_state['_ai_actual_question'] = question_text
            else:
                question_text = self.session_state['current_question']
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_answer",
                from_agent="orchestrator",
                content_text=question_text,
                turn_count=current_turn,
                start_time=start_time
            )
            message["metadata"]["next_agent"] = selected_agent
            return message
        
        # ëª¨ë“  ë‹µë³€ ì™„ë£Œ: ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ
        else:
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_question",
                from_agent="orchestrator",
                content_text="ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.",
                turn_count=current_turn,
                start_time=start_time
            )
            message["metadata"]["next_agent"] = "interviewer"
            return message

   

    def _random_select(self) -> int:
        """ì‚¬ìš©ìì™€ AI ì¤‘ ëœë¤ìœ¼ë¡œ ì„ íƒ"""
        return random.choice([-1, 1])

    def _should_generate_individual_follow_up(self) -> bool:
        """ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ì„ ìƒì„±í•  ì¡°ê±´ì¸ì§€ ì²´í¬"""
        current_turn = self.session_state.get('turn_count', 0)
        current_interviewer = self.session_state.get('current_interviewer')
        turn_state = self.session_state.get('interviewer_turn_state', {})
        
        # í„´ 3 ì´í›„ && í˜„ì¬ ë©´ì ‘ê´€ì´ ì„¤ì •ë˜ì–´ ìˆê³  && ë©”ì¸ ì§ˆë¬¸ì´ ì™„ë£Œëœ ìƒíƒœ
        if (current_turn > 2 and 
            current_interviewer and 
            current_interviewer in turn_state):
            
            interviewer_state = turn_state[current_interviewer]
            main_asked = interviewer_state.get('main_question_asked', False)
            follow_up_count = interviewer_state.get('follow_up_count', 0)
            
            # ë©”ì¸ ì§ˆë¬¸ì€ ì™„ë£Œí–ˆê³ , ê¼¬ë¦¬ì§ˆë¬¸ì´ 2ê°œ ë¯¸ë§Œì¸ ê²½ìš°
            if main_asked and follow_up_count < 2:
                # ìµœê·¼ì— ë‘ ë‹µë³€ì´ ëª¨ë‘ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
                qa_history = self.session_state.get('qa_history', [])
                if len(qa_history) >= 2:
                    # ë§ˆì§€ë§‰ 2ê°œê°€ ê°™ì€ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì¸ì§€ í™•ì¸
                    recent_questions = [qa['question'] for qa in qa_history[-2:]]
                    if len(set(recent_questions)) == 1:  # ê°™ì€ ì§ˆë¬¸
                        print(f"[DEBUG] ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ì¡°ê±´ ë§Œì¡±: {current_interviewer}, follow_up={follow_up_count}/2")
                        return True
        
        return False

    def _handle_individual_questions_flow(self, current_questions: Dict, current_turn: int, start_time: float) -> Dict[str, Any]:
        """ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ í”Œë¡œìš° ì²˜ë¦¬"""
        user_question = current_questions.get('user_question', {}).get('question', '')
        ai_question = current_questions.get('ai_question', {}).get('question', '')
        
        # ê°œë³„ ì§ˆë¬¸ë“¤ì— ëŒ€í•œ ë‹µë³€ ìˆ˜ í™•ì¸
        qa_history = self.session_state.get('qa_history', [])
        individual_answers = len([qa for qa in qa_history 
                                if qa['question'] in [user_question, ai_question]])
        
        print(f"[DEBUG] ê°œë³„ ì§ˆë¬¸ í”Œë¡œìš°: ë‹µë³€ ìˆ˜ {individual_answers}/2")
        
        # ì²« ë²ˆì§¸ ë‹µë³€: ëœë¤ ì„ íƒ
        if individual_answers == 0:
            selected_agent = 'user' if self._random_select() == -1 else 'ai'
            question_text = user_question if selected_agent == 'user' else ai_question
            
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_individual_answer",
                from_agent="orchestrator",
                content_text=question_text,
                turn_count=current_turn,
                start_time=start_time
            )
            message["metadata"]["next_agent"] = selected_agent
            return message
        
        # ë‘ ë²ˆì§¸ ë‹µë³€: ë°˜ëŒ€ ì—ì´ì „íŠ¸
        elif individual_answers == 1:
            # ì²« ë²ˆì§¸ ë‹µë³€ì í™•ì¸
            first_answerer = qa_history[-1]['answerer']
            selected_agent = 'ai' if first_answerer == 'user' else 'user'
            question_text = user_question if selected_agent == 'user' else ai_question
            
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_individual_answer",
                from_agent="orchestrator",
                content_text=question_text,
                turn_count=current_turn,
                start_time=start_time
            )
            message["metadata"]["next_agent"] = selected_agent
            return message
        
        # ë‘ ë‹µë³€ ëª¨ë‘ ì™„ë£Œ: ë‹¤ìŒ ë‹¨ê³„ë¡œ (ì´ ê²½ìš°ëŠ” ì´ë¯¸ _update_state_from_messageì—ì„œ ì²˜ë¦¬ë¨)
        else:
            return self._decide_next_message()  # ì¬ê·€ í˜¸ì¶œë¡œ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •

    # ì—ì´ì „íŠ¸ ì¡°ìœ¨ ë©”ì„œë“œë“¤ (ë‚´ë¶€ ì²˜ë¦¬ìš©)
    async def _request_question_from_interviewer(self) -> str:
        """ë©´ì ‘ê´€(QuestionGenerator)ì—ê²Œ ì§ˆë¬¸ ìƒì„±ì„ ìš”ì²­í•˜ê³ , í…ìŠ¤íŠ¸ ê²°ê³¼ë§Œ ë°˜í™˜"""
        try:
            from llm.shared.logging_config import interview_logger
            interview_logger.info(f"ğŸ“¤ ë©´ì ‘ê´€ì—ê²Œ ì§ˆë¬¸ ìƒì„± ìš”ì²­: {self.session_id}")
            
            # QuestionGeneratorì—ê²Œ ìƒíƒœ ê°ì²´(state)ë¥¼ ì „ë‹¬í•˜ì—¬ ì§ˆë¬¸ ìƒì„±
            question_data = await asyncio.to_thread(
                self.question_generator.generate_question_with_orchestrator_state,
                self.session_state
            )
            
            # ğŸ†• í„´ ì „í™˜ ì²˜ë¦¬
            if question_data.get('turn_switch'):
                # ğŸ†• í„´ ì „í™˜ ì‹œ ë°”ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì„ ìš”ì²­ (ì¬ê·€ í˜¸ì¶œ)
                print(f"[DEBUG] í„´ ì „í™˜ ê°ì§€: {question_data.get('message', '')}")
                # ìƒíƒœ ì—…ë°ì´íŠ¸ í›„ ë‹¤ì‹œ ì§ˆë¬¸ ìš”ì²­
                return await self._request_question_from_interviewer()
            
            # ğŸ†• ê°œë³„ ì§ˆë¬¸ ë°ì´í„° ì²´í¬ - ì§ì ‘ ë°˜í™˜
            if 'user_question' in question_data and 'ai_question' in question_data:
                print(f"[DEBUG] ê°œë³„ ì§ˆë¬¸ ê°ì§€ë¨ - ê°œë³„ ì§ˆë¬¸ ë°ì´í„° ë°˜í™˜")
                return question_data  # Dict í˜•íƒœë¡œ ë°˜í™˜
            
            # ì¼ë°˜ ì§ˆë¬¸ ë°˜í™˜
            return question_data.get('question', 'ë‹¤ìŒ ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ê°€ìš”?')
            
        except Exception as e:
            from llm.shared.logging_config import interview_logger
            interview_logger.error(f"ë©´ì ‘ê´€ ì§ˆë¬¸ ìš”ì²­ ì˜¤ë¥˜: {e}", exc_info=True)
            return "ì£„ì†¡í•©ë‹ˆë‹¤, ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    async def _request_individual_follow_up_questions(self) -> Dict[str, Any]:
        """ë©´ì ‘ê´€ì—ê²Œ ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ 2ê°œ ìƒì„± ìš”ì²­"""
        try:
            from llm.shared.logging_config import interview_logger
            interview_logger.info(f"ğŸ“¤ ë©´ì ‘ê´€ì—ê²Œ ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ìš”ì²­: {self.session_id}")
            
            # qa_historyì—ì„œ ìµœì‹  ë‹µë³€ë“¤ ì¶”ì¶œ
            qa_history = self.session_state.get('qa_history', [])
            if len(qa_history) < 2:
                raise ValueError("ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ì„ ìƒì„±í•˜ë ¤ë©´ ìµœì†Œ 2ê°œì˜ ë‹µë³€ì´ í•„ìš”í•©ë‹ˆë‹¤")
            
            # ê°€ì¥ ìµœê·¼ ì§ˆë¬¸ê³¼ ë‹µë³€ë“¤ ì¶”ì¶œ 
            latest_qa_pairs = qa_history[-2:]  # ë§ˆì§€ë§‰ 2ê°œ (ì‚¬ìš©ì + AI ë‹µë³€)
            previous_question = latest_qa_pairs[0]['question'] if latest_qa_pairs else ''
            
            # ì‚¬ìš©ìì™€ AI ë‹µë³€ ë¶„ë¦¬
            user_answer = ""
            ai_answer = ""
            for qa in latest_qa_pairs:
                if qa['answerer'] == 'user':
                    user_answer = qa['answer']
                elif qa['answerer'] == 'ai':
                    ai_answer = qa['answer']
            
            if not user_answer or not ai_answer:
                raise ValueError("ì‚¬ìš©ìì™€ AI ë‹µë³€ì´ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤")
            
            # íšŒì‚¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            company_info = self.question_generator.companies_data.get(
                self.session_state.get('company_id'), {}
            )
            
            # í˜„ì¬ ë©´ì ‘ê´€ ì •ë³´
            current_interviewer = self.session_state.get('current_interviewer', 'HR')
            
            # ì‚¬ìš©ì ì´ë ¥ì„œ ì •ë³´
            user_resume = {
                'name': self.session_state.get('user_name', 'ì§€ì›ì'),
                'position': self.session_state.get('position', 'ê°œë°œì')
            }
            
            print(f"[DEBUG] ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± - ë©´ì ‘ê´€: {current_interviewer}")
            print(f"[DEBUG] ì´ì „ ì§ˆë¬¸: {previous_question[:50]}...")
            print(f"[DEBUG] ì‚¬ìš©ì ë‹µë³€: {user_answer[:50]}...")
            print(f"[DEBUG] AI ë‹µë³€: {ai_answer[:50]}...")
            
            # ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ìš”ì²­
            follow_up_data = await asyncio.to_thread(
                self.question_generator.generate_follow_up_questions_for_both,
                previous_question=previous_question,
                user_answer=user_answer,
                ai_answer=ai_answer,
                company_info=company_info,
                interviewer_role=current_interviewer,
                user_resume=user_resume
            )
            
            return follow_up_data
            
        except Exception as e:
            from llm.shared.logging_config import interview_logger
            interview_logger.error(f"ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìš”ì²­ ì˜¤ë¥˜: {e}", exc_info=True)
            
            # í´ë°±: ê³µí†µ ê¼¬ë¦¬ì§ˆë¬¸ ì‚¬ìš©
            try:
                common_question = await self._request_question_from_interviewer()
                return {
                    'user_question': {'question': common_question},
                    'ai_question': {'question': common_question},
                    'interviewer_type': self.session_state.get('current_interviewer', 'HR'),
                    'question_type': 'follow_up',
                    'is_individual_questions': False,
                    'fallback_reason': 'individual_request_failed'
                }
            except Exception as fallback_error:
                interview_logger.error(f"í´ë°± ì§ˆë¬¸ ìƒì„±ë„ ì‹¤íŒ¨: {fallback_error}")
                return {
                    'user_question': {'question': 'ì¶”ê°€ë¡œ ì„¤ëª…í•´ ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?'},
                    'ai_question': {'question': 'ë” ìì„¸í•œ ë‚´ìš©ì„ ë§ì”€í•´ ì£¼ì„¸ìš”.'},
                    'interviewer_type': 'HR',
                    'question_type': 'follow_up',
                    'is_individual_questions': False,
                    'fallback_reason': 'complete_fallback'
                }

    async def _request_answer_from_ai_candidate(self, question: str) -> str:
        """AI ì§€ì›ìì—ê²Œ ë‹µë³€ ìƒì„±ì„ ìš”ì²­í•˜ê³ , í…ìŠ¤íŠ¸ ê²°ê³¼ë§Œ ë°˜í™˜"""
        try:
            from llm.shared.logging_config import interview_logger
            interview_logger.info(f"ğŸ“¤ AI ì§€ì›ìì—ê²Œ ë‹µë³€ ìš”ì²­: {self.session_id}")
            
            ai_persona = self.session_state.get('ai_persona')
            
            # ë‹µë³€ ìƒì„± ìš”ì²­ êµ¬ì„±
            from llm.shared.models import AnswerRequest, QuestionType, LLMProvider
            from llm.candidate.quality_controller import QualityLevel
            
            answer_request = AnswerRequest(
                question_content=question,
                question_type=QuestionType.HR, # TODO: ì§ˆë¬¸ ìœ í˜•ì„ stateì—ì„œ ê°€ì ¸ì˜¤ë„ë¡ ê°œì„ 
                question_intent="ë©´ì ‘ê´€ì˜ ì§ˆë¬¸",
                company_id=self.session_state.get('company_id'),
                position=self.session_state.get('position'),
                quality_level=QualityLevel.AVERAGE,
                llm_provider=LLMProvider.OPENAI_GPT4O
            )
            
            response = await asyncio.to_thread(
                self.ai_candidate_model.generate_answer,
                request=answer_request,
                persona=ai_persona
            )
            return response.answer_content
            
        except Exception as e:
            from llm.shared.logging_config import interview_logger
            interview_logger.error(f"AI ì§€ì›ì ë‹µë³€ ìš”ì²­ ì˜¤ë¥˜: {e}", exc_info=True)
            return "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    async def _generate_tts(self, text: str) -> Optional[str]:
        """í…ìŠ¤íŠ¸ë¥¼ TTSë¡œ ë³€í™˜í•˜ì—¬ base64 ì¸ì½”ë”©ëœ MP3 ë°ì´í„° ë°˜í™˜"""
        async with _tts_semaphore:  # TTS ë™ì‹œ ìš”ì²­ ì œí•œ
            try:
                print(f"[ğŸ” TTS_DEBUG] _generate_tts í•¨ìˆ˜ ì‹œì‘ (ì„¸ë§ˆí¬ì–´ íšë“)")
                print(f"[ğŸ” TTS_DEBUG] ì…ë ¥ text: '{text[:100] if text else 'None'}'")
                print(f"[ğŸ” TTS_DEBUG] text íƒ€ì…: {type(text)}")
                print(f"[ğŸ” TTS_DEBUG] text ê¸¸ì´: {len(text) if text else 0}")
                
                if not text or not text.strip():
                    print(f"[ğŸ” TTS_DEBUG] âŒ textê°€ ë¹„ì–´ìˆìŒ - ë°˜í™˜ None")
                    return None
                    
                from backend.services.voice_service import elevenlabs_tts_stream
                print(f"[ğŸ” TTS_DEBUG] voice_service import ì„±ê³µ")
                print(f"[ğŸ” TTS_DEBUG] TTS ìƒì„± ì‹œì‘: {text[:50]}...")
                print(f"[ğŸ” TTS_DEBUG] ì •ì œëœ text: '{text.strip()[:50]}...'")
                
                # ElevenLabs API í˜¸ì¶œ
                print(f"[ğŸ” TTS_DEBUG] elevenlabs_tts_stream í˜¸ì¶œ ì‹œì‘")
                audio_bytes = await elevenlabs_tts_stream(
                    text=text.strip(), 
                    voice_id="21m00Tcm4TlvDq8ikWAM"  # Rachel ìŒì„±
                )
                print(f"[ğŸ” TTS_DEBUG] elevenlabs_tts_stream í˜¸ì¶œ ì™„ë£Œ")
                print(f"[ğŸ” TTS_DEBUG] audio_bytes íƒ€ì…: {type(audio_bytes)}")
                print(f"[ğŸ” TTS_DEBUG] audio_bytes ê¸¸ì´: {len(audio_bytes) if audio_bytes else 0}")
                
                if not audio_bytes:
                    print(f"[ğŸ” TTS_DEBUG] âŒ audio_bytesê°€ ë¹„ì–´ìˆìŒ")
                    return None
                
                # base64 ì¸ì½”ë”©
                print(f"[ğŸ” TTS_DEBUG] base64 ì¸ì½”ë”© ì‹œì‘")
                audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
                print(f"[ğŸ” TTS_DEBUG] base64 ì¸ì½”ë”© ì™„ë£Œ")
                print(f"[ğŸ” TTS_DEBUG] âœ… TTS ìƒì„± ì™„ë£Œ: {len(audio_base64)} chars (ì„¸ë§ˆí¬ì–´ í•´ì œ)")
                
                return audio_base64
                
            except Exception as e:
                print(f"[ğŸ” TTS_DEBUG] âŒ TTS ìƒì„± ì‹¤íŒ¨: {e}")
                import traceback
                print(f"[ğŸ” TTS_DEBUG] ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
                return None

    async def _handle_missing_tts_for_first_response(self, result: Dict[str, Any]) -> None:
        """ì²« ë²ˆì§¸ ì‘ë‹µì—ì„œ ëˆ„ë½ëœ TTSë¥¼ ì¶”ê°€ë¡œ ìƒì„±"""
        try:
            current_turn = self.session_state.get('turn_count', 0)
            
            print(f"[ğŸ” TTS_DEBUG] _handle_missing_tts_for_first_response í•¨ìˆ˜ í˜¸ì¶œë¨")
            print(f"[ğŸ” TTS_DEBUG] current_turn: {current_turn}")
            print(f"[ğŸ” TTS_DEBUG] result í‚¤ë“¤: {list(result.keys())}")
            
            # ì²« ë²ˆì§¸ í„´(INTRO + ì²« ì§ˆë¬¸)ì—ì„œë§Œ ì²˜ë¦¬
            if current_turn <= 1:
                print(f"[ğŸ” TTS_DEBUG] ì¡°ê±´ ë§Œì¡±: current_turn({current_turn}) <= 1")
                print(f"[ğŸ” TTS_DEBUG] ì²« ë²ˆì§¸ ì‘ë‹µ TTS ë³´ì™„ ì²˜ë¦¬ ì‹œì‘ (í„´ {current_turn})")
                
                # INTRO ë©”ì‹œì§€ TTS ì¶”ê°€ (create_user_waiting_messageì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆì„ ìˆ˜ ìˆìŒ)
                intro_message_exists = 'intro_message' in result
                intro_audio_exists = 'intro_audio' in result
                print(f"[ğŸ” TTS_DEBUG] intro_message ì¡´ì¬: {intro_message_exists}")
                print(f"[ğŸ” TTS_DEBUG] intro_audio ì¡´ì¬: {intro_audio_exists}")
                
                if intro_message_exists:
                    intro_text = result['intro_message']
                    print(f"[ğŸ” TTS_DEBUG] intro_text: '{intro_text[:100] if intro_text else 'None'}'")
                    print(f"[ğŸ” TTS_DEBUG] intro_text.strip() ê²°ê³¼: {bool(intro_text and intro_text.strip())}")
                    
                    if not intro_audio_exists and intro_text and intro_text.strip():
                        print(f"[ğŸ” TTS_DEBUG] ëˆ„ë½ëœ INTRO TTS ìƒì„± ì‹œì‘: {intro_text[:50]}...")
                        intro_audio = await self._generate_tts(intro_text)
                        print(f"[ğŸ” TTS_DEBUG] _generate_tts ê²°ê³¼: {bool(intro_audio)} (ê¸¸ì´: {len(intro_audio) if intro_audio else 0})")
                        if intro_audio:
                            result['intro_audio'] = intro_audio
                            print(f"[ğŸ” TTS_DEBUG] âœ… INTRO TTS ë³´ì™„ ì™„ë£Œ")
                        else:
                            print(f"[ğŸ” TTS_DEBUG] âŒ INTRO TTS ìƒì„± ì‹¤íŒ¨")
                    else:
                        if intro_audio_exists:
                            print(f"[ğŸ” TTS_DEBUG] â­ï¸ INTRO audio ì´ë¯¸ ì¡´ì¬í•¨")
                        if not intro_text or not intro_text.strip():
                            print(f"[ğŸ” TTS_DEBUG] â­ï¸ INTRO textê°€ ë¹„ì–´ìˆìŒ")
                
                # ì²« ì§ˆë¬¸ TTS ì¶”ê°€ (create_user_waiting_messageì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆì„ ìˆ˜ ìˆìŒ)
                question_text = result.get('content', {}).get('content', '')
                question_audio_exists = 'question_audio' in result
                print(f"[ğŸ” TTS_DEBUG] question_text: '{question_text[:100] if question_text else 'None'}'")
                print(f"[ğŸ” TTS_DEBUG] question_audio ì¡´ì¬: {question_audio_exists}")
                print(f"[ğŸ” TTS_DEBUG] question_text.strip() ê²°ê³¼: {bool(question_text and question_text.strip())}")
                
                if question_text and question_text.strip() and not question_audio_exists:
                    print(f"[ğŸ” TTS_DEBUG] ëˆ„ë½ëœ ì²« ì§ˆë¬¸ TTS ìƒì„± ì‹œì‘: {question_text[:50]}...")
                    question_audio = await self._generate_tts(question_text)
                    print(f"[ğŸ” TTS_DEBUG] _generate_tts ê²°ê³¼: {bool(question_audio)} (ê¸¸ì´: {len(question_audio) if question_audio else 0})")
                    if question_audio:
                        result['question_audio'] = question_audio
                        print(f"[ğŸ” TTS_DEBUG] âœ… ì²« ì§ˆë¬¸ TTS ë³´ì™„ ì™„ë£Œ")
                    else:
                        print(f"[ğŸ” TTS_DEBUG] âŒ ì²« ì§ˆë¬¸ TTS ìƒì„± ì‹¤íŒ¨")
                else:
                    if question_audio_exists:
                        print(f"[ğŸ” TTS_DEBUG] â­ï¸ ì§ˆë¬¸ audio ì´ë¯¸ ì¡´ì¬í•¨")
                    if not question_text or not question_text.strip():
                        print(f"[ğŸ” TTS_DEBUG] â­ï¸ ì§ˆë¬¸ textê°€ ë¹„ì–´ìˆìŒ")
                        
                print(f"[ğŸ” TTS_DEBUG] ì²« ë²ˆì§¸ ì‘ë‹µ TTS ë³´ì™„ ì²˜ë¦¬ ì™„ë£Œ")
                print(f"[ğŸ” TTS_DEBUG] ìµœì¢… result í‚¤ë“¤: {list(result.keys())}")
            else:
                print(f"[ğŸ” TTS_DEBUG] ì¡°ê±´ ë¶ˆë§Œì¡±: current_turn({current_turn}) > 1, TTS ë³´ì™„ ê±´ë„ˆëœ€")
            
        except Exception as e:
            print(f"[ğŸ” TTS_DEBUG] âŒ ì²« ë²ˆì§¸ ì‘ë‹µ TTS ë³´ì™„ ì‹¤íŒ¨: {e}")
            import traceback
            print(f"[ğŸ” TTS_DEBUG] ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")

    async def _generate_and_play_tts(self, text: str, agent_type: str = "interviewer") -> None:
        """í…ìŠ¤íŠ¸ë¥¼ TTSë¡œ ë³€í™˜í•˜ê³  ì¬ìƒí•œ í›„ ë‹¤ìŒ ì‘ì—…ìœ¼ë¡œ ë„˜ì–´ê°"""
        try:
            if not text or not text.strip():
                print(f"[ğŸ”Š TTS_PLAY] {agent_type} í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŒ - TTS ê±´ë„ˆëœ€")
                return
            
            print(f"[ğŸ”Š TTS_PLAY] {agent_type} TTS ìƒì„± ë° ì¬ìƒ ì‹œì‘: {text[:50]}...")
            
            # TTS ìƒì„±
            audio_base64 = await self._generate_tts(text)
            if not audio_base64:
                print(f"[ğŸ”Š TTS_PLAY] âŒ {agent_type} TTS ìƒì„± ì‹¤íŒ¨")
                return
            
            # TTS ì¬ìƒ ì‹œì‘
            print(f"[ğŸ”Š TTS_PLAY] âœ… {agent_type} TTS ìƒì„± ì™„ë£Œ, ì¬ìƒ ì‹œì‘")
            
            # ì¬ìƒ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
            # ë°©ë²• 1: í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ë°˜ ëŒ€ëµì  ì¬ìƒ ì‹œê°„ ê³„ì‚° (ì´ˆë‹¹ ì•½ 3-4ìŒì ˆ)
            estimated_duration = len(text) / 3.5  # ì´ˆë‹¹ ì•½ 3.5ìŒì ˆë¡œ ê³„ì‚°
            min_duration = 1.0  # ìµœì†Œ 1ì´ˆ
            max_duration = 10.0  # ìµœëŒ€ 10ì´ˆ
            wait_time = max(min_duration, min(estimated_duration, max_duration))
            
            print(f"[ğŸ”Š TTS_PLAY] ğŸ“Š ì˜ˆìƒ ì¬ìƒ ì‹œê°„: {wait_time:.1f}ì´ˆ (í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}ì)")
            await asyncio.sleep(wait_time)
            
            print(f"[ğŸ”Š TTS_PLAY] âœ… {agent_type} TTS ì¬ìƒ ì™„ë£Œ, ë‹¤ìŒ ì‘ì—… ì§„í–‰")
            
        except Exception as e:
            print(f"[ğŸ”Š TTS_PLAY] âŒ {agent_type} TTS ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            print(f"[ğŸ”Š TTS_PLAY] ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")

    async def _generate_and_play_tts_with_callback(self, text: str, agent_type: str = "interviewer", 
                                                 on_complete: callable = None) -> None:
        """í…ìŠ¤íŠ¸ë¥¼ TTSë¡œ ë³€í™˜í•˜ê³  ì¬ìƒí•œ í›„ ì½œë°± í•¨ìˆ˜ ì‹¤í–‰"""
        try:
            if not text or not text.strip():
                print(f"[ğŸ”Š TTS_PLAY] {agent_type} í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŒ - TTS ê±´ë„ˆëœ€")
                if on_complete:
                    await on_complete()
                return
            
            print(f"[ğŸ”Š TTS_PLAY] {agent_type} TTS ìƒì„± ë° ì¬ìƒ ì‹œì‘: {text[:50]}...")
            
            # TTS ìƒì„±
            audio_base64 = await self._generate_tts(text)
            if not audio_base64:
                print(f"[ğŸ”Š TTS_PLAY] âŒ {agent_type} TTS ìƒì„± ì‹¤íŒ¨")
                if on_complete:
                    await on_complete()
                return
            
            # TTS ì¬ìƒ ì‹œì‘
            print(f"[ğŸ”Š TTS_PLAY] âœ… {agent_type} TTS ìƒì„± ì™„ë£Œ, ì¬ìƒ ì‹œì‘")
            
            # ì¬ìƒ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
            estimated_duration = len(text) / 3.5
            min_duration = 1.0
            max_duration = 10.0
            wait_time = max(min_duration, min(estimated_duration, max_duration))
            
            print(f"[ğŸ”Š TTS_PLAY] ğŸ“Š ì˜ˆìƒ ì¬ìƒ ì‹œê°„: {wait_time:.1f}ì´ˆ (í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}ì)")
            await asyncio.sleep(wait_time)
            
            print(f"[ğŸ”Š TTS_PLAY] âœ… {agent_type} TTS ì¬ìƒ ì™„ë£Œ")
            
            # ì½œë°± í•¨ìˆ˜ ì‹¤í–‰
            if on_complete:
                await on_complete()
            
        except Exception as e:
            print(f"[ğŸ”Š TTS_PLAY] âŒ {agent_type} TTS ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            print(f"[ğŸ”Š TTS_PLAY] ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
            if on_complete:
                await on_complete()

    @staticmethod
    def create_agent_message(session_id: str, task: str, from_agent: str, content_text: str, 
                             turn_count: int, duration: float = 0, content_type: str = "text", 
                             start_time: float = None) -> Dict[str, Any]:
        """ì™¸ë¶€(Agent)ì—ì„œ Orchestratorë¡œ ë³´ë‚¼ ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ëŠ” ì •ì  ë©”ì„œë“œ"""
        # ğŸ†• total_time ê³„ì‚°
        total_time = None
        if start_time:
            total_time = time.time() - start_time
        
        return {
            "metadata": {
                "interview_id": session_id,
                "step": turn_count,
                "task": task,
                "from_agent": from_agent,
                "next_agent": "orchestrator",
                "status_code": 200
            },
            "content": {
                "type": content_type,
                "content": content_text
            },
            "metrics": {
                "duration": duration,
                "total_time": total_time
            }
        }

    async def process_user_answer(self, user_answer: str, time_spent: float = None) -> Dict[str, Any]:
        """ì‚¬ìš©ì ë‹µë³€ì„ ì²˜ë¦¬í•˜ê³  ì „ì²´ í”Œë¡œìš°ë¥¼ ì™„ë£Œí•˜ì—¬ ìµœì¢… ê²°ê³¼ ë°˜í™˜"""
        print(f"[TRACE] Orchestrator.process_user_answer start: session={self.session_id}")
        
        # ğŸ†• ê°œë³„ ì§ˆë¬¸ ìƒíƒœ ì²´í¬
        current_questions = self.session_state.get('current_questions')
        is_individual_question = current_questions and current_questions.get('is_individual', False)
        
        # 1. ì‚¬ìš©ì ë‹µë³€ ë©”ì‹œì§€ ìƒì„± ë° ì²˜ë¦¬
        task = "individual_answer_generated" if is_individual_question else "answer_generated"
        
        user_message = self.create_agent_message(
            session_id=self.session_id,
            task=task,
            from_agent="user",
            content_text=user_answer,
            turn_count=self.session_state.get('turn_count', 0),
            duration=time_spent,
            start_time=self.session_state.get('start_time')
        )
        
        # 2. ì‚¬ìš©ì ë‹µë³€ìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ (handle_messageì—ì„œ JSON ì¶œë ¥ë¨)
        self.handle_message(user_message)
        
        # 3. ë‹¤ìŒ ì•¡ì…˜ ê²°ì • ë° ì „ì²´ í”Œë¡œìš° ì²˜ë¦¬
        return await self._process_complete_flow()
    
    async def _process_complete_flow(self) -> Dict[str, Any]:
        """ì™„ì „í•œ í”Œë¡œìš°ë¥¼ ì²˜ë¦¬í•˜ì—¬ ìµœì¢… ê²°ê³¼ ë°˜í™˜"""
        print(f"[TRACE] Orchestrator._process_complete_flow start: session={self.session_id}")
        
        while True:
            print(f"[TRACE] turn={self.session_state.get('turn_count', 0)}")
            
            # ë‹¤ìŒ ë©”ì‹œì§€ ê²°ì •
            next_message = self._decide_next_message()
            next_agent = next_message.get("metadata", {}).get("next_agent")
            task = next_message.get("metadata", {}).get("task")
            
            print(f"[TRACE] decide_next -> next_agent={next_agent}, task={task}")
            
            # ì™„ë£Œ ì¡°ê±´ ì²´í¬
            if task == "end_interview":
                print(f"[TRACE] interview complete")
                result = {
                    "status": "completed",
                    "message": "ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.",
                    "qa_history": self.session_state.get('qa_history', []),
                    "session_id": self.session_id
                }
                # ğŸ†• í”„ë¡ íŠ¸ ì¶”ì¶œìš© AI ë©”íƒ€ë°ì´í„° í¬í•¨ (resume_id ì „ë‹¬)
                try:
                    ai_resume_id = self.session_state.get('ai_resume_id') or (
                        (self.session_state.get('ai_persona') or {}).get('resume_id') if isinstance(self.session_state.get('ai_persona'), dict) else None
                    )
                except Exception:
                    ai_resume_id = None
                result['turn_info'] = {
                    'ai_metadata': {
                        'resume_id': ai_resume_id
                    }
                }
                print(f"[TRACE] Orchestrator -> Client (complete)")
                print(json.dumps(result, indent=2, ensure_ascii=False))
                return result
            
            # ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸° ìƒíƒœì¸ ê²½ìš°
            if next_agent == "user":
                print(f"[TRACE] wait for user input")
                result = await self.create_user_waiting_message()
                
                # ğŸ†• ì²« ë²ˆì§¸ ì‘ë‹µì—ì„œ ëˆ„ë½ëœ TTS ì²˜ë¦¬
                await self._handle_missing_tts_for_first_response(result)
                
                print(f"[TRACE] Orchestrator -> Client (wait)")
                # JSON ì¶œë ¥ì€ create_user_waiting_messageì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨
                return result
            
            # ì—ì´ì „íŠ¸ ì‘ì—… ìˆ˜í–‰ (handle_messageì—ì„œ JSON ì¶œë ¥ë¨)
            if next_agent == "interviewer":
                print(f"[TRACE] interviewer task start")
                await self._process_interviewer_task_parallel()
            elif next_agent == "interviewer_individual":
                print(f"[TRACE] interviewer individual follow-up task start")
                await self._process_individual_interviewer_task_parallel()
            elif next_agent == "ai":
                print(f"[TRACE] ai task start")
                await self._process_ai_task_parallel(next_message.get("content", {}).get("content"))
            
            print(f"[TRACE] loop end")
    
    async def _process_interviewer_task(self):
        """ë©´ì ‘ê´€ ì‘ì—… ì²˜ë¦¬"""
        print(f"[TRACE] Orchestrator -> Interviewer (generate_question)")
        
        # ğŸ†• í˜„ì¬ ìƒíƒœ ë””ë²„ê¹… (ê°œì„ )
        current_interviewer = self.session_state.get('current_interviewer')
        turn_state = self.session_state.get('interviewer_turn_state', {})
        current_turn = self.session_state.get('turn_count', 0)
        
        print(f"[TRACE] interviewer_state turn={current_turn}, current_interviewer={current_interviewer}")
        for role, state in turn_state.items():
            main_done = "âœ“" if state['main_question_asked'] else "âœ—"
            follow_count = state['follow_up_count']
            print(f"[DEBUG]   {role}: ë©”ì¸ {main_done}, ê¼¬ë¦¬ {follow_count}ê°œ")
        
        question_result = await self._request_question_from_interviewer()
        
        # ğŸ†• ë°˜í™˜ê°’ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬
        if isinstance(question_result, dict) and 'user_question' in question_result and 'ai_question' in question_result:
            print(f"[TRACE] individual questions generated (dict)")
            
            # ê°œë³„ ì§ˆë¬¸ ë©”ì‹œì§€ ìƒì„±
            questions_message = self.create_agent_message(
                session_id=self.session_id,
                task="individual_questions_generated",
                from_agent="interviewer",
                content_text=json.dumps(question_result),
                turn_count=current_turn,
                content_type=current_interviewer or "HR",
                start_time=self.session_state.get('start_time')
            )
            
            # TRACE ì¶œë ¥: interviewer -> orchestrator (individual_questions_generated)
            self.handle_message(questions_message)
            
            # ğŸ†• ê°œë³„ ì§ˆë¬¸ TTS ìƒì„± ë° ì¬ìƒ
            user_question = question_result.get('user_question', {}).get('question', '')
            ai_question = question_result.get('ai_question', {}).get('question', '')
            
            if user_question:
                await self._generate_and_play_tts(user_question, "ë©´ì ‘ê´€(ì‚¬ìš©ììš©)")
            if ai_question:
                await self._generate_and_play_tts(ai_question, "ë©´ì ‘ê´€(AIìš©)")
            
        else:
            # ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬
            question_content = question_result if isinstance(question_result, str) else str(question_result)
            
            # ğŸ†• content_type ê²°ì •
            content_type = "INTRO" if current_turn == 0 else current_interviewer or "HR"
            
            # í˜„ì¬ í„´ì— ë”°ë¼ task ê²°ì •
            task = "intro_generated" if current_turn == 0 else "question_generated"
            
            question_message = self.create_agent_message(
                session_id=self.session_id,
                task=task,
                from_agent="interviewer",
                content_text=question_content,
                turn_count=current_turn,
                content_type=content_type,
                start_time=self.session_state.get('start_time')
            )
            
            # TRACE ì¶œë ¥: interviewer -> orchestrator (question_generated)
            self.handle_message(question_message)
            
            # ğŸ†• ë©´ì ‘ê´€ ì§ˆë¬¸ TTS ìƒì„± ë° ì¬ìƒ
            if question_content:
                await self._generate_and_play_tts(question_content, "ë©´ì ‘ê´€")
    
    async def _process_individual_interviewer_task(self):
        """ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì‘ì—… ì²˜ë¦¬"""
        print(f"[TRACE] Orchestrator -> Interviewer (generate_individual_follow_up)")
        
        # í˜„ì¬ ìƒíƒœ ë””ë²„ê¹…
        current_interviewer = self.session_state.get('current_interviewer')
        turn_state = self.session_state.get('interviewer_turn_state', {})
        current_turn = self.session_state.get('turn_count', 0)
        
        print(f"[TRACE] individual follow-up start turn={current_turn}, interviewer={current_interviewer}")
        
        try:
            # ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ìš”ì²­
            individual_questions = await self._request_individual_follow_up_questions()
            
            # ê°œë³„ ì§ˆë¬¸ ë©”ì‹œì§€ ìƒì„± ë° ì²˜ë¦¬
            questions_message = self.create_agent_message(
                session_id=self.session_id,
                task="individual_questions_generated",
                from_agent="interviewer",
                content_text=json.dumps(individual_questions),  # Dictë¥¼ JSONìœ¼ë¡œ ë³€í™˜
                turn_count=current_turn,
                content_type=current_interviewer or "HR",
                start_time=self.session_state.get('start_time')
            )
            
            # TRACE ì¶œë ¥: interviewer -> orchestrator (individual_questions_generated)
            self.handle_message(questions_message)
            
            # ğŸ†• ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ TTS ìƒì„± ë° ì¬ìƒ
            user_question = individual_questions.get('user_question', {}).get('question', '')
            ai_question = individual_questions.get('ai_question', {}).get('question', '')
            
            if user_question:
                await self._generate_and_play_tts(user_question, "ë©´ì ‘ê´€(ê°œë³„-ì‚¬ìš©ììš©)")
            if ai_question:
                await self._generate_and_play_tts(ai_question, "ë©´ì ‘ê´€(ê°œë³„-AIìš©)")
            
        except Exception as e:
            print(f"[TRACE][ERROR] individual follow-up generation failed: {e}")
            # í´ë°±: ì¼ë°˜ ì§ˆë¬¸ìœ¼ë¡œ ëŒ€ì²´
            await self._process_interviewer_task()

    async def _process_individual_interviewer_task_parallel(self) -> Dict[str, Any]:
        """
        ğŸ†• ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì ìš©í•œ ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì‘ì—… ì²˜ë¦¬
        """
        print(f"[TRACE] Orchestrator -> Interviewer (generate_individual_follow_up)")
        
        # í˜„ì¬ ìƒíƒœ ë””ë²„ê¹…
        current_interviewer = self.session_state.get('current_interviewer')
        turn_state = self.session_state.get('interviewer_turn_state', {})
        current_turn = self.session_state.get('turn_count', 0)
        
        print(f"[TRACE] individual follow-up start turn={current_turn}, interviewer={current_interviewer}")
        
        try:
            # ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ìš”ì²­
            individual_questions = await self._request_individual_follow_up_questions()
            
            # ê°œë³„ ì§ˆë¬¸ ë©”ì‹œì§€ ìƒì„± ë° ì²˜ë¦¬
            questions_message = self.create_agent_message(
                session_id=self.session_id,
                task="individual_questions_generated",
                from_agent="interviewer",
                content_text=json.dumps(individual_questions),  # Dictë¥¼ JSONìœ¼ë¡œ ë³€í™˜
                turn_count=current_turn,
                content_type=current_interviewer or "HR",
                start_time=self.session_state.get('start_time')
            )
            
            # TRACE ì¶œë ¥: interviewer -> orchestrator (individual_questions_generated)
            self.handle_message(questions_message)
            
            # ğŸ†• ë³‘ë ¬ TTS ì²˜ë¦¬ - ì¬ìƒì„ ê¸°ë‹¤ë¦¬ì§€ ì•Šê³  ì¦‰ì‹œ ë‹¤ìŒ ì‘ì—… ì¤€ë¹„
            user_question = individual_questions.get('user_question', {}).get('question', '')
            ai_question = individual_questions.get('ai_question', {}).get('question', '')
            
            print(f"[DEBUG] ê°œë³„ ì§ˆë¬¸ TTS ì²˜ë¦¬: ì‚¬ìš©ììš©='{user_question[:30]}...', AIìš©='{ai_question[:30]}...'")
            
            if user_question:
                print(f"[DEBUG] ì‚¬ìš©ììš© ì§ˆë¬¸ TTS íƒœìŠ¤í¬ ìƒì„±")
                asyncio.create_task(self._generate_and_play_tts_parallel(user_question, "ë©´ì ‘ê´€(ê°œë³„-ì‚¬ìš©ììš©)"))
            if ai_question:
                print(f"[DEBUG] AIìš© ì§ˆë¬¸ TTS íƒœìŠ¤í¬ ìƒì„±")
                asyncio.create_task(self._generate_and_play_tts_parallel(ai_question, "ë©´ì ‘ê´€(ê°œë³„-AIìš©)"))
            
            return questions_message
            
        except Exception as e:
            print(f"[TRACE][ERROR] individual follow-up generation failed: {e}")
            # í´ë°±: ì¼ë°˜ ì§ˆë¬¸ìœ¼ë¡œ ëŒ€ì²´
            return await self._process_interviewer_task_parallel()
    
    async def _process_ai_task(self, question: str):
        """AI ì§€ì›ì ì‘ì—… ì²˜ë¦¬"""
        print(f"[TRACE] Orchestrator -> AI (question) : {question[:50]}...")
        
        # AIì—ê²Œ ì „ë‹¬í•  ì§ˆë¬¸ì—ì„œ ì‚¬ìš©ì ì´ë¦„ í˜¸ì¹­ì„ AIìš©ìœ¼ë¡œ ìµœì†Œ ì¹˜í™˜
        ai_question = self._format_question_for_ai(question)
        
        # ğŸ†• AI ì§ˆë¬¸ì„ í´ë¼ì´ì–¸íŠ¸ ì „ë‹¬ìš©ìœ¼ë¡œ ì„ì‹œ ì €ì¥
        self.session_state['latest_ai_question'] = ai_question
        print(f"[DEBUG] AI ì§ˆë¬¸ ì„ì‹œ ì €ì¥: {ai_question[:50]}...")
        
        ai_answer = await self._request_answer_from_ai_candidate(ai_question)
        
        # ğŸ†• AI ë‹µë³€ì„ í´ë¼ì´ì–¸íŠ¸ ì „ë‹¬ìš©ìœ¼ë¡œ ì„ì‹œ ì €ì¥  
        self.session_state['latest_ai_answer'] = ai_answer
        print(f"[DEBUG] AI ë‹µë³€ ì„ì‹œ ì €ì¥: {ai_answer[:50]}...")
        
        # ğŸ†• ê°œë³„ ì§ˆë¬¸ ìƒíƒœ ì²´í¬
        current_questions = self.session_state.get('current_questions')
        is_individual_question = current_questions and current_questions.get('is_individual', False)
        
        # ğŸ†• content_type ê²°ì • (í˜„ì¬ ë©´ì ‘ê´€ ê¸°ë°˜)
        current_interviewer = self.session_state.get('current_interviewer', 'HR')
        content_type = current_interviewer if current_interviewer in ['HR', 'TECH', 'COLLABORATION'] else 'HR'
        
        # ê°œë³„ ì§ˆë¬¸ ì—¬ë¶€ì— ë”°ë¼ task ê²°ì •
        task = "individual_answer_generated" if is_individual_question else "answer_generated"
        
        # AIê°€ ì‹¤ì œë¡œ ë°›ì€ ì§ˆë¬¸ì„ ìƒíƒœì— ì„ì‹œ ì €ì¥ (qa ê¸°ë¡ìš©)
        self.session_state['_ai_actual_question'] = ai_question

        ai_message = self.create_agent_message(
            session_id=self.session_id,
            task=task,
            from_agent="ai",
            content_text=ai_answer,
            turn_count=self.session_state.get('turn_count', 0),
            content_type=content_type,
            start_time=self.session_state.get('start_time')
        )
        
        # handle_messageì—ì„œ JSON ì¶œë ¥ë¨
        self.handle_message(ai_message)
        
        # ğŸ†• AI ë‹µë³€ TTS ìƒì„± ë° ì¬ìƒ
        if ai_answer:
            await self._generate_and_play_tts(ai_answer, "AIì§€ì›ì")

    async def create_user_waiting_message(self) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸° ë©”ì‹œì§€ ìƒì„±"""
        # ğŸ†• ê°œë³„ ì§ˆë¬¸ ìƒíƒœ ì²´í¬
        current_questions = self.session_state.get('current_questions')
        is_individual_question = current_questions and current_questions.get('is_individual', False)
        
        # ğŸ†• ì§ˆë¬¸ í…ìŠ¤íŠ¸ ê²°ì •
        if is_individual_question:
            question_text = current_questions.get('user_question', {}).get('question', '')
            print(f"[DEBUG] ì‚¬ìš©ì ê°œë³„ ì§ˆë¬¸: {question_text[:50]}...")
        else:
            question_text = self.session_state.get('current_question', '')
        
        # ğŸ†• content_type ê²°ì • (í˜„ì¬ ë©´ì ‘ê´€ ê¸°ë°˜)
        current_interviewer = self.session_state.get('current_interviewer', 'HR')
        content_type = current_interviewer if current_interviewer in ['HR', 'TECH', 'COLLABORATION'] else 'HR'
        
        response = self.create_agent_message(
            session_id=self.session_id,
            task="wait_for_user_input",
            from_agent="orchestrator",
            content_text=question_text,
            turn_count=self.session_state.get('turn_count', 0),
            content_type=content_type,
            start_time=self.session_state.get('start_time')
        )
        # next_agentë¥¼ 'user'ë¡œ ìˆ˜ì •í•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œê°€ ì˜¬ë°”ë¥´ê²Œ ì¸ì‹í•˜ë„ë¡ í•¨
        response['metadata']['next_agent'] = 'user'
        response['status'] = 'waiting_for_user'
        response['message'] = 'ë‹µë³€ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'
        response['session_id'] = self.session_id
        
        # ğŸ†• INTRO ë©”ì‹œì§€ í¬í•¨ (ìˆëŠ” ê²½ìš°) - í•œ ë²ˆë§Œ ì „ë‹¬ + TTS ë³€í™˜
        intro_message = self.session_state.get('intro_message')
        print(f"[ğŸ” TTS_DEBUG] create_user_waiting_message - intro_message ì¡´ì¬: {bool(intro_message)}")
        if intro_message:
            print(f"[ğŸ” TTS_DEBUG] intro_message ë‚´ìš©: '{intro_message[:100] if intro_message else 'None'}'")
            response['intro_message'] = intro_message
            print(f"[ğŸ” TTS_DEBUG] INTRO ë©”ì‹œì§€ í´ë¼ì´ì–¸íŠ¸ ì „ë‹¬: {intro_message[:50]}...")
            
            # TTS ë³€í™˜
            print(f"[ğŸ” TTS_DEBUG] INTRO TTS ìƒì„± ì‹œì‘...")
            intro_audio = await self._generate_tts(intro_message)
            print(f"[ğŸ” TTS_DEBUG] INTRO TTS ìƒì„± ê²°ê³¼: {bool(intro_audio)} (ê¸¸ì´: {len(intro_audio) if intro_audio else 0})")
            if intro_audio:
                response['intro_audio'] = intro_audio
                print(f"[ğŸ” TTS_DEBUG] âœ… INTRO TTS ìƒì„± ì™„ë£Œ")
            else:
                print(f"[ğŸ” TTS_DEBUG] âŒ INTRO TTS ìƒì„± ì‹¤íŒ¨")
            
            # í•œ ë²ˆ ì „ë‹¬ í›„ ì‚­ì œ
            del self.session_state['intro_message']
            print(f"[ğŸ” TTS_DEBUG] intro_message ì„¸ì…˜ì—ì„œ ì‚­ì œë¨")
        else:
            print(f"[ğŸ” TTS_DEBUG] intro_messageê°€ ì„¸ì…˜ì— ì—†ìŒ")
        
        # ğŸ†• í„´ ì •ë³´ ì¶”ê°€ (ê°œë³„ ì§ˆë¬¸ ì •ë³´ í¬í•¨)
        try:
            ai_resume_id = self.session_state.get('ai_resume_id') or (
                (self.session_state.get('ai_persona') or {}).get('resume_id') if isinstance(self.session_state.get('ai_persona'), dict) else None
            )
        except Exception:
            ai_resume_id = None
        response['turn_info'] = {
            'current_turn': self.session_state.get('turn_count', 0),
            'is_user_turn': True,
            'is_individual_question': is_individual_question,
            'question_type': 'individual_follow_up' if is_individual_question else 'main_question',
            'ai_metadata': {
                'resume_id': ai_resume_id
            }
        }
        
        # ğŸ†• AI ì§ˆë¬¸ê³¼ ë‹µë³€ì„ í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ë‹¬ (TTSìš©) + TTS ë³€í™˜
        latest_ai_question = self.session_state.get('latest_ai_question')
        latest_ai_answer = self.session_state.get('latest_ai_answer')
        
        print(f"[DEBUG] AI ë°ì´í„° ì „ë‹¬ ì²´í¬:")
        print(f"  - latest_ai_question ì¡´ì¬: {bool(latest_ai_question)}")
        print(f"  - latest_ai_answer ì¡´ì¬: {bool(latest_ai_answer)}")
        
        if latest_ai_question:
            response['ai_question'] = {
                'content': latest_ai_question
            }
            print(f"[DEBUG] AI ì§ˆë¬¸ í´ë¼ì´ì–¸íŠ¸ ì „ë‹¬: {latest_ai_question[:50]}...")
            
            # TTS ë³€í™˜
            ai_question_audio = await self._generate_tts(latest_ai_question)
            if ai_question_audio:
                response['ai_question_audio'] = ai_question_audio
                print(f"[DEBUG] AI ì§ˆë¬¸ TTS ìƒì„± ì™„ë£Œ")
            
            # í•œë²ˆ ì „ë‹¬ í›„ ì‚­ì œ
            del self.session_state['latest_ai_question']
            
        if latest_ai_answer:
            response['ai_answer'] = {
                'content': latest_ai_answer
            }
            print(f"[DEBUG] AI ë‹µë³€ í´ë¼ì´ì–¸íŠ¸ ì „ë‹¬: {latest_ai_answer[:50]}...")
            
            # TTS ë³€í™˜
            ai_answer_audio = await self._generate_tts(latest_ai_answer)
            if ai_answer_audio:
                response['ai_answer_audio'] = ai_answer_audio
                print(f"[DEBUG] AI ë‹µë³€ TTS ìƒì„± ì™„ë£Œ")
            
            # í•œë²ˆ ì „ë‹¬ í›„ ì‚­ì œ
            del self.session_state['latest_ai_answer']
        
        # ğŸ†• ì‚¬ìš©ì ì§ˆë¬¸ TTS ë³€í™˜
        print(f"[ğŸ” TTS_DEBUG] ì‚¬ìš©ì ì§ˆë¬¸ TTS ë³€í™˜ ì²´í¬:")
        print(f"[ğŸ” TTS_DEBUG] question_text: '{question_text[:100] if question_text else 'None'}'")
        print(f"[ğŸ” TTS_DEBUG] question_text.strip() ê²°ê³¼: {bool(question_text and question_text.strip())}")
        if question_text and question_text.strip():
            print(f"[ğŸ” TTS_DEBUG] ì‚¬ìš©ì ì§ˆë¬¸ TTS ìƒì„± ì‹œì‘...")
            question_audio = await self._generate_tts(question_text)
            print(f"[ğŸ” TTS_DEBUG] ì‚¬ìš©ì ì§ˆë¬¸ TTS ìƒì„± ê²°ê³¼: {bool(question_audio)} (ê¸¸ì´: {len(question_audio) if question_audio else 0})")
            if question_audio:
                response['question_audio'] = question_audio
                print(f"[ğŸ” TTS_DEBUG] âœ… ì‚¬ìš©ì ì§ˆë¬¸ TTS ìƒì„± ì™„ë£Œ: {question_text[:50]}...")
            else:
                print(f"[ğŸ” TTS_DEBUG] âŒ ì‚¬ìš©ì ì§ˆë¬¸ TTS ìƒì„± ì‹¤íŒ¨")
        else:
            print(f"[ğŸ” TTS_DEBUG] ì‚¬ìš©ì ì§ˆë¬¸ textê°€ ë¹„ì–´ìˆìŒ, TTS ê±´ë„ˆëœ€")
        
        # ğŸ†• ìµœì¢… ì‘ë‹µ JSON ë¡œê·¸ (ë””ë²„ê¹…ìš©) - ì˜¤ë””ì˜¤ ë°ì´í„° ì¶•ì•½
        print(f"[DEBUG] ìµœì¢… í´ë¼ì´ì–¸íŠ¸ ì‘ë‹µ JSON:")
        response_for_log = response.copy()
        
        # ì˜¤ë””ì˜¤ í•„ë“œë“¤ì„ ê¸¸ì´ ì •ë³´ë¡œ ëŒ€ì²´
        audio_fields = ['intro_audio', 'ai_question_audio', 'ai_answer_audio', 'question_audio']
        for field in audio_fields:
            if field in response_for_log:
                audio_data = response_for_log[field]
                if audio_data:
                    response_for_log[field] = f"[AUDIO_DATA:{len(audio_data)} chars]"
                else:
                    response_for_log[field] = "[AUDIO_DATA:EMPTY]"
        
        print(json.dumps(response_for_log, indent=2, ensure_ascii=False))
        
        # ğŸ†• TTS ìƒì„± ìƒíƒœ ìš”ì•½
        print(f"[ğŸ” TTS_SUMMARY] === TTS ìƒì„± ê²°ê³¼ ìš”ì•½ ===")
        for field in audio_fields:
            if field in response:
                status = "âœ… ì„±ê³µ" if response[field] else "âŒ ì‹¤íŒ¨"
                length = len(response[field]) if response[field] else 0
                print(f"[ğŸ” TTS_SUMMARY] {field}: {status} ({length} chars)")
            else:
                print(f"[ğŸ” TTS_SUMMARY] {field}: â­ï¸ ì—†ìŒ")
        print(f"[ğŸ” TTS_SUMMARY] ========================")
        
        return response

    def _format_question_for_ai(self, question: str) -> str:
        """AIì—ê²Œ ë³´ë‚¼ ë•Œ ì‚¬ìš©ì ì´ë¦„ í˜¸ì¹­ì„ 'AI ì§€ì›ìë‹˜'ìœ¼ë¡œ ìµœì†Œ ì¹˜í™˜"""
        try:
            if not isinstance(question, str):
                return question

            user_name_raw = self.session_state.get('user_name', 'ì§€ì›ì') or 'ì§€ì›ì'
            # ê³µë°± ì œê±° ë° 'ë‹˜' ì œê±°í•œ ë‘ ê°€ì§€ ë²„ì „ ì¤€ë¹„
            user_name_compact = re.sub(r"\s+", "", user_name_raw)
            name_wo_suffix = user_name_compact[:-1] if user_name_compact.endswith('ë‹˜') else user_name_compact

            # íŒ¨í„´ë“¤: ë§¨ ì•ì— ë“±ì¥í•˜ëŠ” ì´ë¦„ í˜¸ì¹­ + ì„ íƒì  ê³µë°±/ì½¤ë§ˆë¥¼ AIìš©ìœ¼ë¡œ ì¹˜í™˜
            patterns = [
                rf"^\s*{re.escape(name_wo_suffix)}\s*ë‹˜\s*[,ï¼Œ ]*",
                rf"^\s*{re.escape(user_name_compact)}\s*[,ï¼Œ ]*",
                rf"{re.escape(name_wo_suffix)}\s*ë‹˜\s*[,ï¼Œ ]*",
                rf"{re.escape(user_name_compact)}\s*[,ï¼Œ ]*",
            ]

            for pat in patterns:
                if re.search(pat, question):
                    question = re.sub(pat, "AI ì§€ì›ìë‹˜, ", question, count=1)
                    break

            # ì¼ë°˜ì ì¸ 'ì§€ì›ìë‹˜' í˜¸ì¹­ ì¹˜í™˜ (í•œ ë²ˆë§Œ)
            if re.search(r"ì§€ì›ìë‹˜\s*[,ï¼Œ ]*", question):
                question = re.sub(r"ì§€ì›ìë‹˜\s*[,ï¼Œ ]*", "AI ì§€ì›ìë‹˜, ", question, count=1)

            # ì„ ë‘ì— ì¤‘ë³µëœ 'AI ' í† í° ì •ë¦¬: 'AI AI ì§€ì›ìë‹˜' -> 'AI ì§€ì›ìë‹˜'
            question = re.sub(r"^\s*(AI\s+)+ì§€ì›ìë‹˜\s*[,ï¼Œ ]*", "AI ì§€ì›ìë‹˜, ", question)

            # í˜¸ì¹­ì´ ì—†ìœ¼ë©´ ì•ì—ë§Œ ë¶™ì„ (ì¤‘ë³µ ë°©ì§€)
            if not question.strip().startswith("AI ì§€ì›ìë‹˜"):
                question = f"AI ì§€ì›ìë‹˜, {question}"
            return question
        except Exception:
            return question

    async def _generate_and_play_tts_parallel(self, text: str, agent_type: str = "interviewer") -> None:
        """
        ğŸ†• ë³‘ë ¬ ì²˜ë¦¬ë¥¼ í†µí•œ íš¨ìœ¨ì ì¸ TTS ìƒì„± ë° ì¬ìƒ
        TTS ìƒì„±ê³¼ ì¬ìƒì„ ë³„ë„ íƒœìŠ¤í¬ë¡œ ë¶„ë¦¬í•˜ì—¬ ë™ì‹œì— ì²˜ë¦¬
        """
        try:
            print(f"ğŸµ [{agent_type}] TTS ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘: {text[:50]}...")
            print(f"[DEBUG] TTS í•¨ìˆ˜ í˜¸ì¶œë¨ - agent_type: {agent_type}, text_length: {len(text)}")
            
            # TTS ìƒì„± íƒœìŠ¤í¬ (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰)
            print(f"ğŸµ [{agent_type}] TTS ìƒì„± íƒœìŠ¤í¬ ì‹œì‘ (ì„¸ë§ˆí¬ì–´ ëŒ€ê¸° ì¤‘...)")
            tts_task = asyncio.create_task(self._generate_tts_async(text))
            
            # TTS ìƒì„±ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
            audio_data = await tts_task
            
            if audio_data:
                # ì¬ìƒ íƒœìŠ¤í¬ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰)
                playback_task = asyncio.create_task(self._play_audio_async(audio_data, text))
                
                # ì¬ìƒ íƒœìŠ¤í¬ë¥¼ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰í•˜ê³  ì¦‰ì‹œ ë°˜í™˜
                # ì´ë ‡ê²Œ í•˜ë©´ ì¬ìƒ ì¤‘ì—ë„ ë‹¤ìŒ ì‘ì—…ì„ ì¤€ë¹„í•  ìˆ˜ ìˆìŒ
                print(f"ğŸµ [{agent_type}] TTS ì¬ìƒ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)")
                
                # ì¬ìƒ ì™„ë£Œë¥¼ ê¸°ë‹¤ë¦¬ì§€ ì•Šê³  ì¦‰ì‹œ ë°˜í™˜
                # í•„ìš”ì‹œ ë‚˜ì¤‘ì— playback_taskë¥¼ awaití•  ìˆ˜ ìˆìŒ
                
            else:
                print(f"âŒ [{agent_type}] TTS ìƒì„± ì‹¤íŒ¨")
                
        except Exception as e:
            print(f"âŒ [{agent_type}] TTS ë³‘ë ¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    async def _generate_tts_async(self, text: str) -> Optional[str]:
        """
        ğŸ†• ë¹„ë™ê¸° TTS ìƒì„±
        """
        try:
            print(f"[DEBUG] _generate_tts_async í˜¸ì¶œë¨ - text_length: {len(text)}")
            # ì‹¤ì œ TTS ì„œë¹„ìŠ¤ í˜¸ì¶œì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬
            audio_data = await self._generate_tts(text)
            print(f"[DEBUG] _generate_tts_async ì™„ë£Œ - audio_data: {'ìˆìŒ' if audio_data else 'ì—†ìŒ'}")
            return audio_data
        except Exception as e:
            print(f"TTS ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    async def _play_audio_async(self, audio_data: str, text: str) -> None:
        """
        ğŸ†• ë¹„ë™ê¸° ì˜¤ë””ì˜¤ ì¬ìƒ (ì‹œë®¬ë ˆì´ì…˜)
        """
        try:
            # ì¬ìƒ ì‹œê°„ ê³„ì‚°
            estimated_duration = len(text) * 0.06  # ì´ˆ ë‹¨ìœ„
            
            print(f"ğŸ”Š ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘ (ì˜ˆìƒ ì‹œê°„: {estimated_duration:.1f}ì´ˆ)")
            
            # ì¬ìƒ ì‹œê°„ë§Œí¼ ëŒ€ê¸° (ì‹¤ì œë¡œëŠ” ì˜¤ë””ì˜¤ ì¬ìƒ API í˜¸ì¶œ)
            await asyncio.sleep(estimated_duration)
            
            print(f"âœ… ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ")
            
        except Exception as e:
            print(f"ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ ì˜¤ë¥˜: {e}")

    async def _process_interviewer_task_parallel(self) -> Dict[str, Any]:
        """
        ğŸ†• ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì ìš©í•œ ë©´ì ‘ê´€ íƒœìŠ¤í¬ ì²˜ë¦¬
        """
        try:
            # ì§ˆë¬¸ ìš”ì²­
            question_content = await self._request_question_from_interviewer()
            
            if question_content:
                # ì§ˆë¬¸ ë©”ì‹œì§€ ìƒì„± ë° ì²˜ë¦¬
                question_message = self.create_agent_message(
                        session_id=self.session_id,
                        task="question_generated",
                        content_text=question_content,
                        from_agent="interviewer",
                        turn_count=self.session_state.get('turn_count', 0)
                    )
                
                self.handle_message(question_message)
                
                # ğŸ†• ë³‘ë ¬ TTS ì²˜ë¦¬ - ì¬ìƒì„ ê¸°ë‹¤ë¦¬ì§€ ì•Šê³  ì¦‰ì‹œ ë‹¤ìŒ ì‘ì—… ì¤€ë¹„
                if question_content:
                    asyncio.create_task(self._generate_and_play_tts_parallel(question_content, "ë©´ì ‘ê´€"))
                
                return question_message
            else:
                return self.create_agent_message(
                    session_id=self.session_id,
                    task="error",
                    content_text="ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨",
                    from_agent="orchestrator",
                    turn_count=self.session_state.get('turn_count', 0)
                )
                
        except Exception as e:
            print(f"ë©´ì ‘ê´€ íƒœìŠ¤í¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return self.create_agent_message(
                session_id=self.session_id,
                task="error",
                content_text=f"ë©´ì ‘ê´€ íƒœìŠ¤í¬ ì˜¤ë¥˜: {str(e)}",
                from_agent="orchestrator",
                turn_count=self.session_state.get('turn_count', 0)
            )

    async def _process_ai_task_parallel(self, question: str) -> Dict[str, Any]:
        """
        ğŸ†• ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì ìš©í•œ AI íƒœìŠ¤í¬ ì²˜ë¦¬
        """
        try:
            print(f"[DEBUG] AI íƒœìŠ¤í¬ ì‹œì‘: {question[:50]}...")
            
            # AI ë‹µë³€ ìš”ì²­
            ai_answer = await self._request_answer_from_ai_candidate(question)
            
            if ai_answer:
                print(f"[DEBUG] AI ë‹µë³€ ìƒì„± ì™„ë£Œ: {ai_answer[:50]}...")
                
                # AI ë‹µë³€ ë©”ì‹œì§€ ìƒì„± ë° ì²˜ë¦¬
                ai_message = self.create_agent_message(
                        session_id=self.session_id,
                        task="answer_generated",
                        content_text=ai_answer,
                        from_agent="ai",
                        turn_count=self.session_state.get('turn_count', 0)
                    )
                
                self.handle_message(ai_message)
                
                # ğŸ†• ë³‘ë ¬ TTS ì²˜ë¦¬ - ì¬ìƒì„ ê¸°ë‹¤ë¦¬ì§€ ì•Šê³  ì¦‰ì‹œ ë‹¤ìŒ ì‘ì—… ì¤€ë¹„
                if ai_answer:
                    print(f"[DEBUG] AI TTS íƒœìŠ¤í¬ ìƒì„± ì‹œì‘")
                    asyncio.create_task(self._generate_and_play_tts_parallel(ai_answer, "AIì§€ì›ì"))
                    print(f"[DEBUG] AI TTS íƒœìŠ¤í¬ ìƒì„± ì™„ë£Œ")
                else:
                    print(f"[DEBUG] AI ë‹µë³€ì´ ë¹„ì–´ìˆì–´ TTS ê±´ë„ˆëœ€")
                
                return ai_message
            else:
                return self.create_agent_message(
                    session_id=self.session_id,
                    task="error",
                    content_text="AI ë‹µë³€ ìƒì„± ì‹¤íŒ¨",
                    from_agent="orchestrator",
                    turn_count=self.session_state.get('turn_count', 0)
                )
                
        except Exception as e:
            print(f"AI íƒœìŠ¤í¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return self.create_agent_message(
                session_id=self.session_id,
                task="error",
                content_text=f"AI íƒœìŠ¤í¬ ì˜¤ë¥˜: {str(e)}",
                from_agent="orchestrator",
                turn_count=self.session_state.get('turn_count', 0)
            )

    
