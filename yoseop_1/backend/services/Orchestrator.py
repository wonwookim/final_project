import time
import json
import random
import asyncio
from dataclasses import dataclass, field
from typing import Optional, Dict, Any

@dataclass
class Metadata:
    interview_id: str
    step: int
    task: str
    from_agent: str 
    next_agent: str
    status_code: int

@dataclass
class Content:
    type: str
    content: str

@dataclass
class Metrics:
    total_time: Optional[float] = None
    duration: Optional[float] = None
    answer_seq: Optional[int] = None

@dataclass
class AgentMessage:
    metadata: Metadata
    content: Content
    metrics: Metrics = field(default_factory=Metrics)

class Orchestrator:
    def __init__(self, session_id: str, session_state: Dict[str, Any], 
                 question_generator=None, ai_candidate_model=None):
        """
        Orchestrator: ëª¨ë“  ë©´ì ‘ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë‹´ë‹¹
        - í”Œë¡œìš° ì œì–´
        - ì—ì´ì „íŠ¸ ì¡°ìœ¨
        - ë©”ì‹œì§€ ì²˜ë¦¬
        - ìƒíƒœ ì—…ë°ì´íŠ¸
        """
        self.session_id = session_id
        self.session_state = session_state  # InterviewServiceì˜ session_state ì°¸ì¡°
        self.question_generator = question_generator
        self.ai_candidate_model = ai_candidate_model

    def handle_message(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """ë©”ì‹œì§€ë¥¼ ë°›ì•„ì„œ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  ë‹¤ìŒ ì•¡ì…˜ì„ ê²°ì •"""
        from_agent = message.get("metadata", {}).get("from_agent", "unknown")
        print(f"[{from_agent}] -> [Orchestrator]")
        print(json.dumps(message, indent=2, ensure_ascii=False))

        task = message.get("metadata", {}).get("task")
        content = message.get("content", {}).get("content")

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        self._update_state_from_message(task, content, from_agent)

        # ë‹¤ìŒ ë©”ì‹œì§€ ê²°ì •
        next_message = self._decide_next_message()
        next_agent = next_message.get("metadata", {}).get("next_agent", "unknown")
        print(f"[Orchestrator] -> [{next_agent}]")
        print(json.dumps(next_message, indent=2, ensure_ascii=False))
        return next_message

    def _update_state_from_message(self, task: str, content: str, from_agent: str) -> None:
        """ë©”ì‹œì§€ë¡œë¶€í„° ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        if task == "question_generated":
            self.session_state['current_question'] = content
            self.session_state['answer_seq'] = 1
            self.session_state['who_answers_first'] = 'user' if self.session_state['turn_count'] % 2 == 0 else 'ai'
            
        elif task == "answer_generated":
            self.session_state['qa_history'].append({
                "question": self.session_state['current_question'],
                "answerer": from_agent,
                "answer": content
            })
            
            if self.session_state['answer_seq'] == 1:
                self.session_state['answer_seq'] = 2
            else:
                self.session_state['answer_seq'] = 0
                self.session_state['turn_count'] += 1
                self.session_state['current_question'] = None

    def _decide_next_message(self) -> Dict[str, Any]:
        """ë‹¤ìŒ ë©”ì‹œì§€ ê²°ì • - ì‹¤ì œ í”Œë¡œìš° ì œì–´ ë¡œì§"""
        next_agent_options = ['user', 'ai']

        # ì™„ë£Œ ì¡°ê±´ ì²´í¬
        if self.session_state['turn_count'] >= self.session_state.get('total_question_limit', 15):
            self.session_state['is_completed'] = True
            return self.create_message("ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.", "end_interview", "system")

        # answer_seqì— ë”°ë¥¸ ë‹¤ìŒ ì•¡ì…˜ ê²°ì •
        if self.session_state['answer_seq'] == 0:
            # ì²« ë²ˆì§¸: ë©´ì ‘ê´€ì´ ì§ˆë¬¸ ìƒì„±
            self.session_state['random_choice'] = self._random_select()
            return self.create_message("ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.", "generate_question", "interviewer")
        
        elif self.session_state['answer_seq'] == 1:
            # ë‘ ë²ˆì§¸: ëœë¤ ì„ íƒëœ ì—ì´ì „íŠ¸ê°€ ë‹µë³€
            selected_agent = next_agent_options[0] if self.session_state['random_choice'] == -1 else next_agent_options[1]
            self.session_state['who_answers_first'] = selected_agent
            return self.create_message(self.session_state['current_question'], "generate_answer", selected_agent)
            
        elif self.session_state['answer_seq'] == 2:
            # ì„¸ ë²ˆì§¸: ë°˜ëŒ€ ì—ì´ì „íŠ¸ê°€ ë‹µë³€
            selected_agent = next_agent_options[1] if self.session_state['random_choice'] == -1 else next_agent_options[0]
            return self.create_message(self.session_state['current_question'], "generate_answer", selected_agent)

    def create_message(self, content_text: str, task: str, next_agent: str, content_type: str = "text") -> Dict[str, Any]:
        """ë©”ì‹œì§€ ìƒì„±"""
        current_time = time.perf_counter()
        return {
            "metadata": {
                "interview_id": self.session_id,
                "step": self.session_state['turn_count'],
                "task": task,
                "from_agent": "orchestrator",
                "next_agent": next_agent,
                "status_code": 200
            },
            "content": {
                "type": content_type,
                "content": content_text
            },
            "metrics": {
                "total_time": current_time - self.session_state.get('start_time', current_time),
                "duration": 0,
                "answer_seq": self.session_state['answer_seq']
            }
        }

    def _random_select(self) -> int:
        """ì‚¬ìš©ìì™€ AI ì¤‘ ëœë¤ìœ¼ë¡œ ì„ íƒ"""
        return random.choice([-1, 1])

    # ì—ì´ì „íŠ¸ ì¡°ìœ¨ ë©”ì„œë“œë“¤ (ë‚´ë¶€ ì²˜ë¦¬ìš©)
    async def _request_question_from_interviewer(self) -> str:
        """ë©´ì ‘ê´€(QuestionGenerator)ì—ê²Œ ì§ˆë¬¸ ìƒì„±ì„ ìš”ì²­í•˜ê³ , í…ìŠ¤íŠ¸ ê²°ê³¼ë§Œ ë°˜í™˜"""
        try:
            from llm.shared.logging_config import interview_logger
            interview_logger.info(f"ğŸ“¤ ë©´ì ‘ê´€ì—ê²Œ ì§ˆë¬¸ ìƒì„± ìš”ì²­: {self.session_id}")
            
            # QuestionGeneratorì—ê²Œ ìƒíƒœ ê°ì²´(state)ë¥¼ ì „ë‹¬í•˜ì—¬ ì§ˆë¬¸ ìƒì„±
            question_data = await asyncio.to_thread(
                self.question_generator.generate_question_with_orchestrator_state,
                self.session_state
            )
            return question_data.get('question', 'ë‹¤ìŒ ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ê°€ìš”?')
            
        except Exception as e:
            from llm.shared.logging_config import interview_logger
            interview_logger.error(f"ë©´ì ‘ê´€ ì§ˆë¬¸ ìš”ì²­ ì˜¤ë¥˜: {e}", exc_info=True)
            return "ì£„ì†¡í•©ë‹ˆë‹¤, ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    async def _request_answer_from_ai_candidate(self, question: str) -> str:
        """AI ì§€ì›ìì—ê²Œ ë‹µë³€ ìƒì„±ì„ ìš”ì²­í•˜ê³ , í…ìŠ¤íŠ¸ ê²°ê³¼ë§Œ ë°˜í™˜"""
        try:
            from llm.shared.logging_config import interview_logger
            interview_logger.info(f"ğŸ“¤ AI ì§€ì›ìì—ê²Œ ë‹µë³€ ìš”ì²­: {self.session_id}")
            
            ai_persona = self.session_state.get('ai_persona')
            
            # ë‹µë³€ ìƒì„± ìš”ì²­ êµ¬ì„±
            from llm.shared.models import AnswerRequest, QuestionType, LLMProvider
            from llm.candidate.quality_controller import QualityLevel
            
            answer_request = AnswerRequest(
                question_content=question,
                question_type=QuestionType.HR, # TODO: ì§ˆë¬¸ ìœ í˜•ì„ stateì—ì„œ ê°€ì ¸ì˜¤ë„ë¡ ê°œì„ 
                question_intent="ë©´ì ‘ê´€ì˜ ì§ˆë¬¸",
                company_id=self.session_state.get('company_id'),
                position=self.session_state.get('position'),
                quality_level=QualityLevel.AVERAGE,
                llm_provider=LLMProvider.OPENAI_GPT4O
            )
            
            response = await asyncio.to_thread(
                self.ai_candidate_model.generate_answer,
                request=answer_request,
                persona=ai_persona
            )
            return response.answer_content
            
        except Exception as e:
            from llm.shared.logging_config import interview_logger
            interview_logger.error(f"AI ì§€ì›ì ë‹µë³€ ìš”ì²­ ì˜¤ë¥˜: {e}", exc_info=True)
            return "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    @staticmethod
    def create_agent_message(session_id: str, task: str, from_agent: str, content_text: str, 
                             turn_count: int, duration: float = 0, content_type: str = "text") -> Dict[str, Any]:
        """ì™¸ë¶€(Agent)ì—ì„œ Orchestratorë¡œ ë³´ë‚¼ ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ëŠ” ì •ì  ë©”ì„œë“œ"""
        return {
            "metadata": {
                "interview_id": session_id,
                "step": turn_count,
                "task": task,
                "from_agent": from_agent,
                "next_agent": "orchestrator",
                "status_code": 200
            },
            "content": {
                "type": content_type,
                "content": content_text
            },
            "metrics": {
                "duration": duration
            }
        }

    async def process_user_answer(self, user_answer: str, time_spent: float = None) -> Dict[str, Any]:
        """ì‚¬ìš©ì ë‹µë³€ì„ ì²˜ë¦¬í•˜ê³  ì „ì²´ í”Œë¡œìš°ë¥¼ ì™„ë£Œí•˜ì—¬ ìµœì¢… ê²°ê³¼ ë°˜í™˜"""
        print(f"[Orchestrator] ğŸ”„ ì‚¬ìš©ì ë‹µë³€ ì²˜ë¦¬ ì‹œì‘: {self.session_id}")
        
        # 1. ì‚¬ìš©ì ë‹µë³€ ë©”ì‹œì§€ ìƒì„± ë° ì²˜ë¦¬
        user_message = self.create_agent_message(
            session_id=self.session_id,
            task="answer_generated",
            from_agent="user",
            content_text=user_answer,
            turn_count=self.session_state.get('turn_count', 0),
            duration=time_spent
        )
        
        # 2. ì‚¬ìš©ì ë‹µë³€ìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ (handle_messageì—ì„œ JSON ì¶œë ¥ë¨)
        self.handle_message(user_message)
        
        # 3. ë‹¤ìŒ ì•¡ì…˜ ê²°ì • ë° ì „ì²´ í”Œë¡œìš° ì²˜ë¦¬
        return await self._process_complete_flow()
    
    async def _process_complete_flow(self) -> Dict[str, Any]:
        """ì™„ì „í•œ í”Œë¡œìš°ë¥¼ ì²˜ë¦¬í•˜ì—¬ ìµœì¢… ê²°ê³¼ ë°˜í™˜"""
        while True:
            # ë‹¤ìŒ ë©”ì‹œì§€ ê²°ì •
            next_message = self._decide_next_message()
            next_agent = next_message.get("metadata", {}).get("next_agent")
            task = next_message.get("metadata", {}).get("task")
            
            # ì™„ë£Œ ì¡°ê±´ ì²´í¬
            if task == "end_interview":
                result = {
                    "status": "completed",
                    "message": "ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                    "qa_history": self.session_state.get('qa_history', []),
                    "session_id": self.session_id
                }
                print(f"[Orchestrator] -> [Client]")
                print(json.dumps(result, indent=2, ensure_ascii=False))
                return result
            
            # ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸° ìƒíƒœì¸ ê²½ìš°
            if next_agent == "user":
                result = self.create_user_waiting_message()
                print(f"[Orchestrator] -> [Client]")
                print(json.dumps(result, indent=2, ensure_ascii=False))
                return result
            
            # ì—ì´ì „íŠ¸ ì‘ì—… ìˆ˜í–‰ (handle_messageì—ì„œ JSON ì¶œë ¥ë¨)
            if next_agent == "interviewer":
                await self._process_interviewer_task()
            elif next_agent == "ai":
                await self._process_ai_task(next_message.get("content", {}).get("content"))
    
    async def _process_interviewer_task(self):
        """ë©´ì ‘ê´€ ì‘ì—… ì²˜ë¦¬"""
        print(f"[Orchestrator] -> [Interviewer] (ì§ˆë¬¸ ìƒì„± ìš”ì²­)")
        
        question_content = await self._request_question_from_interviewer()
        
        question_message = self.create_agent_message(
            session_id=self.session_id,
            task="question_generated",
            from_agent="interviewer",
            content_text=question_content,
            turn_count=self.session_state.get('turn_count', 0)
        )
        
        # handle_messageì—ì„œ JSON ì¶œë ¥ë¨
        self.handle_message(question_message)
    
    async def _process_ai_task(self, question: str):
        """AI ì§€ì›ì ì‘ì—… ì²˜ë¦¬"""
        print(f"[Orchestrator] -> [AI Candidate] (ì§ˆë¬¸: {question[:50]}...)")
        
        ai_answer = await self._request_answer_from_ai_candidate(question)
        
        ai_message = self.create_agent_message(
            session_id=self.session_id,
            task="answer_generated",
            from_agent="ai",
            content_text=ai_answer,
            turn_count=self.session_state.get('turn_count', 0)
        )
        
        # handle_messageì—ì„œ JSON ì¶œë ¥ë¨
        self.handle_message(ai_message)
    
    def create_user_waiting_message(self) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸° ë©”ì‹œì§€ ìƒì„±"""
        response = self.create_agent_message(
            session_id=self.session_id,
            task="wait_for_user_input",
            from_agent="orchestrator",
            content_text=self.session_state.get('current_question'),
            turn_count=self.session_state.get('turn_count', 0)
        )
        # next_agentë¥¼ 'user'ë¡œ ìˆ˜ì •í•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œê°€ ì˜¬ë°”ë¥´ê²Œ ì¸ì‹í•˜ë„ë¡ í•¨
        response['metadata']['next_agent'] = 'user'
        response['status'] = 'waiting_for_user'
        response['message'] = 'ë‹µë³€ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'
        response['session_id'] = self.session_id
        
        # í„´ ì •ë³´ ì¶”ê°€
        response['turn_info'] = {
            'current_turn': self.session_state.get('turn_count', 0),
            'answer_seq': self.session_state.get('answer_seq', 0),
            'who_answers_first': self.session_state.get('who_answers_first', 'user'),
            'is_user_turn': True
        }
        
        return response
