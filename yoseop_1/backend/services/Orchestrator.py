import time
import json
import random
import asyncio
import re
import base64
from dataclasses import dataclass, field
from typing import Optional, Dict, Any, List, Tuple

# TTSëŠ” ì´ì œ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì²˜ë¦¬í•˜ë¯€ë¡œ ì„¸ë§ˆí¬ì–´ ì œê±°

@dataclass
class Metadata:
    interview_id: str
    step: int
    task: str
    from_agent: str 
    next_agent: str
    status_code: int

@dataclass
class Content:
    type: str
    content: str

@dataclass
class Metrics:
    total_time: Optional[float] = None
    duration: Optional[float] = None

@dataclass
class AgentMessage:
    metadata: Metadata
    content: Content
    metrics: Metrics = field(default_factory=Metrics)

class Orchestrator:
    def __init__(self, session_id: str, session_state: Dict[str, Any], 
                 question_generator=None, ai_candidate_model=None):
        """
        Orchestrator: ëª¨ë“  ë©´ì ‘ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë‹´ë‹¹
        - í”Œë¡œìš° ì œì–´
        - ì—ì´ì „íŠ¸ ì¡°ìœ¨
        - ë©”ì‹œì§€ ì²˜ë¦¬
        - ìƒíƒœ ì—…ë°ì´íŠ¸
        """
        self.session_id = session_id
        self.session_state = session_state  # InterviewServiceì˜ session_state ì°¸ì¡°
        self.question_generator = question_generator
        self.ai_candidate_model = ai_candidate_model
        
        # TTSëŠ” í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì²˜ë¦¬í•˜ë¯€ë¡œ ì´ë ¥ ì¶”ì  ë¶ˆí•„ìš”

    async def handle_message(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """ë©”ì‹œì§€ë¥¼ ë°›ì•„ì„œ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  ë‹¤ìŒ ì•¡ì…˜ì„ ê²°ì • (ğŸ†• ì¦‰ì‹œ TTS ì²˜ë¦¬ í¬í•¨)"""
        from_agent = message.get("metadata", {}).get("from_agent", "unknown")
        print(f"[TRACE] {from_agent} -> Orchestrator")
        # ì˜¤ë””ì˜¤ ë°ì´í„° ì œì™¸í•˜ê³  ë¡œê·¸ ì¶œë ¥
        message_log = {k: v for k, v in message.items() if not k.endswith('_audio')}
        print(json.dumps(message_log, indent=2, ensure_ascii=False))

        task = message.get("metadata", {}).get("task")
        content = message.get("content", {}).get("content")

        # TTS ìƒì„± ë¡œì§ ì œê±° - í…ìŠ¤íŠ¸ë§Œ ì²˜ë¦¬í•˜ê³  í”„ë¡ íŠ¸ì—”ë“œì—ì„œ TTS ì²˜ë¦¬

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        self._update_state_from_message(task, content, from_agent)

        # ë‹¤ìŒ ë©”ì‹œì§€ ê²°ì •
        next_message = self._decide_next_message()
        next_agent = next_message.get("metadata", {}).get("next_agent", "unknown")
        print(f"[TRACE] Orchestrator -> {next_agent}")
        # ì˜¤ë””ì˜¤ ë°ì´í„° ì œì™¸í•˜ê³  ë¡œê·¸ ì¶œë ¥
        next_message_log = {k: v for k, v in next_message.items() if not k.endswith('_audio')}
        print(json.dumps(next_message_log, indent=2, ensure_ascii=False))
        return next_message

    def _update_state_from_message(self, task: str, content: str, from_agent: str) -> None:
        """ë©”ì‹œì§€ë¡œë¶€í„° ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        if task == "intro_generated":
            # ì¸íŠ¸ë¡œ ë©”ì‹œì§€ ìƒì„± ì™„ë£Œ - ì„¸ì…˜ì— ì €ì¥
            self.session_state['intro_message'] = content
            # ë‹µë³€ ì—†ì´ ë°”ë¡œ í„´ ì¦ê°€
            self.session_state['turn_count'] += 1  # í„´ 0 ì™„ë£Œ, í„´ 1ë¡œ ì´ë™
            # current_questionì€ ì„¤ì •í•˜ì§€ ì•ŠìŒ (ë‹µë³€ ìš”ì²­í•˜ì§€ ì•ŠìŒ)
            
        elif task == "question_generated":
            # í„´ 0ì—ì„œ ë°›ì€ ë©”ì‹œì§€ëŠ” ì¸íŠ¸ë¡œ ë©”ì‹œì§€ë¡œ ì²˜ë¦¬
            current_turn = self.session_state.get('turn_count', 0)
            if current_turn == 0:
                self.session_state['intro_message'] = content
                self.session_state['turn_count'] += 1  # í„´ 0 ì™„ë£Œ, í„´ 1ë¡œ ì´ë™
                print(f"[DEBUG] ì¸íŠ¸ë¡œ ë©”ì‹œì§€ ì²˜ë¦¬ ì™„ë£Œ: í„´ {current_turn} -> {self.session_state['turn_count']}")
            else:
                # ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬
                self.session_state['current_question'] = content
                print(f"[DEBUG] ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬: í„´ {current_turn}")
            
            # ğŸ†• ì§ˆë¬¸ íƒ€ì… ì¶”ì¶œ ë¡œì§ ì œê±° - QuestionGeneratorì—ì„œ ê²°ì •í•œ ë©´ì ‘ê´€ ì‚¬ìš©
            # current_interviewerëŠ” QuestionGeneratorì—ì„œ ì´ë¯¸ ì„¤ì •ë¨
            # ì—¬ê¸°ì„œëŠ” ì§ˆë¬¸ ë‚´ìš©ë§Œ ì €ì¥í•˜ê³  ë©´ì ‘ê´€ ì¶”ì¸¡í•˜ì§€ ì•ŠìŒ
            
        elif task == "individual_questions_generated":
            # ğŸ†• ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì™„ë£Œ - contentëŠ” dict í˜•íƒœ
            import json
            if isinstance(content, str):
                questions_data = json.loads(content)
            else:
                questions_data = content
                
            self.session_state['current_questions'] = {
                'user_question': questions_data.get('user_question', {}),
                'ai_question': questions_data.get('ai_question', {}),
                'is_individual': questions_data.get('is_individual_questions', True),
                'interviewer_type': questions_data.get('interviewer_type', 'HR')
            }
            
            print(f"[DEBUG] ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒíƒœ ì €ì¥ ì™„ë£Œ")
            print(f"[DEBUG] ì‚¬ìš©ì ì§ˆë¬¸: {questions_data.get('user_question', {}).get('question', 'N/A')[:30]}...")
            print(f"[DEBUG] AI ì§ˆë¬¸: {questions_data.get('ai_question', {}).get('question', 'N/A')[:30]}...")
            
        elif task == "individual_answer_generated":
            # ğŸ†• ê°œë³„ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ì²˜ë¦¬
            current_questions = self.session_state.get('current_questions', {})
            if current_questions.get('is_individual', False):
                # ê°œë³„ ì§ˆë¬¸ì˜ ê²½ìš° answererì— ë”°ë¼ í•´ë‹¹í•˜ëŠ” ì§ˆë¬¸ ë§¤í•‘
                if from_agent == 'user':
                    question_text = current_questions.get('user_question', {}).get('question', '')
                elif from_agent == 'ai':
                    question_text = current_questions.get('ai_question', {}).get('question', '')
                else:
                    question_text = self.session_state.get('current_question', '')
            else:
                question_text = self.session_state.get('current_question', '')
            
            # qa_historyì— ë‹µë³€ ì €ì¥
            qa_entry = {
                "question": question_text,
                "answerer": from_agent,
                "answer": content
            }
            self.session_state['qa_history'].append(qa_entry)
            print(f"[DEBUG] QA ì €ì¥: answerer={from_agent}, question='{question_text[:50]}...', answer='{content[:30]}...'")
            
            # ê°œë³„ ë‹µë³€ ì™„ë£Œ ì²´í¬ (ì‚¬ìš©ìì™€ AI ëª¨ë‘ ë‹µë³€í–ˆëŠ”ì§€)
            if current_questions.get('is_individual', False):
                # í˜„ì¬ í„´ì˜ ê°œë³„ ë‹µë³€ ìˆ˜ ê³„ì‚°
                individual_answers = len([qa for qa in self.session_state['qa_history'] 
                                        if qa['question'] in [
                                            current_questions.get('user_question', {}).get('question', ''),
                                            current_questions.get('ai_question', {}).get('question', '')
                                        ]])
                
                if individual_answers >= 2:
                    self._handle_turn_completion_for_individual_questions()
            else:
                # ê¸°ì¡´ ë¡œì§ ìœ ì§€ (ê³µí†µ ì§ˆë¬¸ì¸ ê²½ìš°)
                self._handle_turn_completion_for_common_question()
                
        elif task == "answer_generated":
            # ê¸°ì¡´ ë‹µë³€ ì²˜ë¦¬ (ë©”ì¸ ì§ˆë¬¸ ë˜ëŠ” ê³µí†µ ê¼¬ë¦¬ì§ˆë¬¸)
            # AIê°€ ì‹¤ì œë¡œ ë°›ì€ ì§ˆë¬¸ì´ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë³´ì •
            if from_agent == 'ai' and '_ai_actual_question' in self.session_state:
                question_text = self.session_state.pop('_ai_actual_question')
            else:
                question_text = self.session_state['current_question']

            qa_entry = {
                "question": question_text,
                "answerer": from_agent,
                "answer": content
            }
            self.session_state['qa_history'].append(qa_entry)
            print(f"[DEBUG] QA ì €ì¥ (async): answerer={from_agent}, question='{question_text[:50]}...', answer='{content[:30]}...'")

            # ë‘ ë‹µë³€ì´ ëª¨ë‘ ì™„ë£Œë˜ë©´ í„´ ì¦ê°€ ë° ê¼¬ë¦¬ ì§ˆë¬¸ ìƒíƒœ ì—…ë°ì´íŠ¸
            # í˜„ì¬ ì§ˆë¬¸(ì‚¬ìš©ììš©)ê³¼ AIìš© ë³€í™˜ í…ìŠ¤íŠ¸ ë‘˜ ë‹¤ì— ëŒ€í•´ ë‹µë³€ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            try:
                user_question = self.session_state['current_question']
                ai_question_variant = self._format_question_for_ai(user_question)
                answers_for_pair = [qa for qa in self.session_state['qa_history']
                                    if qa['question'] in (user_question, ai_question_variant)]
                answerers = {qa['answerer'] for qa in answers_for_pair}
                if {'user', 'ai'}.issubset(answerers):
                    self._handle_turn_completion_for_common_question()
            except Exception:
                # í´ë°±: ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í˜„ì¬ ì§ˆë¬¸ í…ìŠ¤íŠ¸ ê¸°ì¤€ ì¹´ìš´íŠ¸
                current_answers = len([qa for qa in self.session_state['qa_history']
                                      if qa['question'] == self.session_state['current_question']])
                if current_answers >= 2:
                    self._handle_turn_completion_for_common_question()

    def _handle_turn_completion_for_common_question(self):
        """ê³µí†µ ì§ˆë¬¸ ì™„ë£Œ ì‹œ ì²˜ë¦¬"""
        # ğŸ†• ê¼¬ë¦¬ ì§ˆë¬¸ ì¹´ìš´íŠ¸ ì¦ê°€ (ìˆ˜ì •ëœ ë¡œì§)
        current_interviewer = self.session_state.get('current_interviewer')
        if current_interviewer and current_interviewer in ['HR', 'TECH', 'COLLABORATION']:
            turn_state = self.session_state.get('interviewer_turn_state', {})
            if current_interviewer in turn_state:
                # í˜„ì¬ ì§ˆë¬¸ì´ ë©”ì¸ ì§ˆë¬¸ì¸ì§€ ê¼¬ë¦¬ ì§ˆë¬¸ì¸ì§€ íŒë‹¨
                current_turn = self.session_state.get('turn_count', 0)
                
                # í„´ 1, 2ëŠ” ê³ ì • ì§ˆë¬¸ì´ë¯€ë¡œ ì¹´ìš´íŠ¸í•˜ì§€ ì•ŠìŒ
                if current_turn > 2:
                    # ë©”ì¸ ì§ˆë¬¸ ì™„ë£Œ í‘œì‹œ
                    if not turn_state[current_interviewer]['main_question_asked']:
                        turn_state[current_interviewer]['main_question_asked'] = True
                    else:
                        # ê¼¬ë¦¬ ì§ˆë¬¸ ì¹´ìš´íŠ¸ ì¦ê°€
                        turn_state[current_interviewer]['follow_up_count'] += 1
        
        self.session_state['turn_count'] += 1
        self.session_state['current_question'] = None
    
    def _handle_turn_completion_for_individual_questions(self):
        """ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ì™„ë£Œ ì‹œ ì²˜ë¦¬"""
        current_interviewer = self.session_state.get('current_interviewer')
        if current_interviewer and current_interviewer in ['HR', 'TECH', 'COLLABORATION']:
            turn_state = self.session_state.get('interviewer_turn_state', {})
            if current_interviewer in turn_state:
                # ê¼¬ë¦¬ ì§ˆë¬¸ ì¹´ìš´íŠ¸ ì¦ê°€
                turn_state[current_interviewer]['follow_up_count'] += 1
        
        self.session_state['turn_count'] += 1
        self.session_state['current_questions'] = None
        print(f"[DEBUG] ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ í„´ ì™„ë£Œ, ë‹¤ìŒ í„´ìœ¼ë¡œ ì´ë™")

    def _decide_next_message(self) -> Dict[str, Any]:
        """ë‹¤ìŒ ë©”ì‹œì§€ ê²°ì • - ì‹¤ì œ í”Œë¡œìš° ì œì–´ ë¡œì§"""
        current_turn = self.session_state.get('turn_count', 0)
        start_time = self.session_state.get('start_time')
        
        # í„´ 0: ì¸íŠ¸ë¡œ ì²˜ë¦¬
        if current_turn == 0:
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_intro",
                from_agent="orchestrator",
                content_text="ì¸íŠ¸ë¡œ ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
                turn_count=current_turn,
                content_type="INTRO",
                start_time=start_time
            )
            message["metadata"]["next_agent"] = "interviewer"
            return message
        
        # ì™„ë£Œ ì¡°ê±´ ì²´í¬ (í„´ 0: ì¸íŠ¸ë¡œ ì œì™¸)
        if current_turn > self.session_state.get('total_question_limit', 15):
            self.session_state['is_completed'] = True
            message = self.create_agent_message(
                session_id=self.session_id,
                task="end_interview",
                from_agent="orchestrator",
                content_text="ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.",
                turn_count=current_turn,
                content_type="OUTTRO",
                start_time=start_time
            )
            message["metadata"]["next_agent"] = "orchestrator"
            return message

        # ğŸ†• ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ì²˜ë¦¬ ë¡œì§
        current_questions = self.session_state.get('current_questions')
        if current_questions and current_questions.get('is_individual', False):
            return self._handle_individual_questions_flow(current_questions, current_turn, start_time)
        
        # í˜„ì¬ ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ ìƒˆ ì§ˆë¬¸ ìƒì„± (ë©”ì¸ ì§ˆë¬¸ ë˜ëŠ” ê¼¬ë¦¬ì§ˆë¬¸ ê²°ì •)
        if not self.session_state.get('current_question'):
            # ğŸ†• ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì¡°ê±´ ì²´í¬
            if self._should_generate_individual_follow_up():
                print(f"[DEBUG] ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì¡°ê±´ ë§Œì¡±")
                message = self.create_agent_message(
                    session_id=self.session_id,
                    task="generate_individual_follow_up",
                    from_agent="orchestrator",
                    content_text="ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.",
                    turn_count=current_turn,
                    start_time=start_time
                )
                message["metadata"]["next_agent"] = "interviewer_individual"
                return message
            else:
                # ì¼ë°˜ ë©”ì¸ ì§ˆë¬¸ ìƒì„±
                message = self.create_agent_message(
                    session_id=self.session_id,
                    task="generate_question",
                    from_agent="orchestrator",
                    content_text="ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.",
                    turn_count=current_turn,
                    start_time=start_time
                )
                message["metadata"]["next_agent"] = "interviewer"
                return message
        
        # í˜„ì¬ ë©”ì¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìˆ˜ í™•ì¸ (AIìš© ë³€í˜• í¬í•¨)
        user_question = self.session_state['current_question']
        ai_question_variant = self._format_question_for_ai(user_question) if user_question else None
        current_answers = len([qa for qa in self.session_state['qa_history']
                             if qa['question'] == user_question or (ai_question_variant and qa['question'] == ai_question_variant)])
        
        # ì²« ë²ˆì§¸ ë‹µë³€: ëœë¤ ì„ íƒ
        if current_answers == 0:
            selected_agent = 'user' if self._random_select() == -1 else 'ai'
            # ì—ì´ì „íŠ¸ë³„ë¡œ ì „ë‹¬í•  ì§ˆë¬¸ í…ìŠ¤íŠ¸ ê²°ì •
            if selected_agent == 'ai':
                question_text = self._format_question_for_ai(self.session_state['current_question'])
                # QA ê¸°ë¡ì„ ìœ„í•´ ì„ì‹œ ì €ì¥
                self.session_state['_ai_actual_question'] = question_text
            else:
                question_text = self.session_state['current_question']
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_answer",
                from_agent="orchestrator",
                content_text=question_text,
                turn_count=current_turn,
                start_time=start_time
            )
            message["metadata"]["next_agent"] = selected_agent
            return message
        
        # ë‘ ë²ˆì§¸ ë‹µë³€: ë°˜ëŒ€ ì—ì´ì „íŠ¸
        elif current_answers == 1:
            # ì²« ë²ˆì§¸ ë‹µë³€ì í™•ì¸
            first_answerer = self.session_state['qa_history'][-1]['answerer']
            selected_agent = 'ai' if first_answerer == 'user' else 'user'
            # ì—ì´ì „íŠ¸ë³„ë¡œ ì „ë‹¬í•  ì§ˆë¬¸ í…ìŠ¤íŠ¸ ê²°ì •
            if selected_agent == 'ai':
                question_text = self._format_question_for_ai(self.session_state['current_question'])
                self.session_state['_ai_actual_question'] = question_text
            else:
                question_text = self.session_state['current_question']
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_answer",
                from_agent="orchestrator",
                content_text=question_text,
                turn_count=current_turn,
                start_time=start_time
            )
            message["metadata"]["next_agent"] = selected_agent
            return message
        
        # ëª¨ë“  ë‹µë³€ ì™„ë£Œ: ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ
        else:
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_question",
                from_agent="orchestrator",
                content_text="ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.",
                turn_count=current_turn,
                start_time=start_time
            )
            message["metadata"]["next_agent"] = "interviewer"
            return message

   

    def _random_select(self) -> int:
        """ì‚¬ìš©ìì™€ AI ì¤‘ ëœë¤ìœ¼ë¡œ ì„ íƒ"""
        return random.choice([-1, 1])

    def _should_generate_individual_follow_up(self) -> bool:
        """ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ì„ ìƒì„±í•  ì¡°ê±´ì¸ì§€ ì²´í¬"""
        current_turn = self.session_state.get('turn_count', 0)
        current_interviewer = self.session_state.get('current_interviewer')
        turn_state = self.session_state.get('interviewer_turn_state', {})
        
        # í„´ 3 ì´í›„ && í˜„ì¬ ë©´ì ‘ê´€ì´ ì„¤ì •ë˜ì–´ ìˆê³  && ë©”ì¸ ì§ˆë¬¸ì´ ì™„ë£Œëœ ìƒíƒœ
        if (current_turn > 2 and 
            current_interviewer and 
            current_interviewer in turn_state):
            
            interviewer_state = turn_state[current_interviewer]
            main_asked = interviewer_state.get('main_question_asked', False)
            follow_up_count = interviewer_state.get('follow_up_count', 0)
            
            # ë©”ì¸ ì§ˆë¬¸ì€ ì™„ë£Œí–ˆê³ , ê¼¬ë¦¬ì§ˆë¬¸ì´ 2ê°œ ë¯¸ë§Œì¸ ê²½ìš°
            if main_asked and follow_up_count < 2:
                # ìµœê·¼ì— ë‘ ë‹µë³€ì´ ëª¨ë‘ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
                qa_history = self.session_state.get('qa_history', [])
                if len(qa_history) >= 2:
                    # ë§ˆì§€ë§‰ 2ê°œê°€ ê°™ì€ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì¸ì§€ í™•ì¸
                    recent_questions = [qa['question'] for qa in qa_history[-2:]]
                    if len(set(recent_questions)) == 1:  # ê°™ì€ ì§ˆë¬¸
                        print(f"[DEBUG] ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ì¡°ê±´ ë§Œì¡±: {current_interviewer}, follow_up={follow_up_count}/2")
                        return True
        
        return False

    def _handle_individual_questions_flow(self, current_questions: Dict, current_turn: int, start_time: float) -> Dict[str, Any]:
        """ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ í”Œë¡œìš° ì²˜ë¦¬"""
        user_question = current_questions.get('user_question', {}).get('question', '')
        ai_question = current_questions.get('ai_question', {}).get('question', '')
        
        # ê°œë³„ ì§ˆë¬¸ë“¤ì— ëŒ€í•œ ë‹µë³€ ìˆ˜ í™•ì¸
        qa_history = self.session_state.get('qa_history', [])
        individual_answers = len([qa for qa in qa_history 
                                if qa['question'] in [user_question, ai_question]])
        
        print(f"[DEBUG] ê°œë³„ ì§ˆë¬¸ í”Œë¡œìš°: ë‹µë³€ ìˆ˜ {individual_answers}/2")
        
        # ì²« ë²ˆì§¸ ë‹µë³€: ëœë¤ ì„ íƒ
        if individual_answers == 0:
            selected_agent = 'user' if self._random_select() == -1 else 'ai'
            question_text = user_question if selected_agent == 'user' else ai_question
            
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_individual_answer",
                from_agent="orchestrator",
                content_text=question_text,
                turn_count=current_turn,
                start_time=start_time
            )
            message["metadata"]["next_agent"] = selected_agent
            return message
        
        # ë‘ ë²ˆì§¸ ë‹µë³€: ë°˜ëŒ€ ì—ì´ì „íŠ¸
        elif individual_answers == 1:
            # ì²« ë²ˆì§¸ ë‹µë³€ì í™•ì¸
            first_answerer = qa_history[-1]['answerer']
            selected_agent = 'ai' if first_answerer == 'user' else 'user'
            question_text = user_question if selected_agent == 'user' else ai_question
            
            message = self.create_agent_message(
                session_id=self.session_id,
                task="generate_individual_answer",
                from_agent="orchestrator",
                content_text=question_text,
                turn_count=current_turn,
                start_time=start_time
            )
            message["metadata"]["next_agent"] = selected_agent
            return message
        
        # ë‘ ë‹µë³€ ëª¨ë‘ ì™„ë£Œ: ë‹¤ìŒ ë‹¨ê³„ë¡œ (ì´ ê²½ìš°ëŠ” ì´ë¯¸ _update_state_from_messageì—ì„œ ì²˜ë¦¬ë¨)
        else:
            return self._decide_next_message()  # ì¬ê·€ í˜¸ì¶œë¡œ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •

    # ì—ì´ì „íŠ¸ ì¡°ìœ¨ ë©”ì„œë“œë“¤ (ë‚´ë¶€ ì²˜ë¦¬ìš©)
    async def _request_question_from_interviewer(self) -> str:
        """ë©´ì ‘ê´€(QuestionGenerator)ì—ê²Œ ì§ˆë¬¸ ìƒì„±ì„ ìš”ì²­í•˜ê³ , í…ìŠ¤íŠ¸ ê²°ê³¼ë§Œ ë°˜í™˜"""
        try:
            from llm.shared.logging_config import interview_logger
            interview_logger.info(f"ğŸ“¤ ë©´ì ‘ê´€ì—ê²Œ ì§ˆë¬¸ ìƒì„± ìš”ì²­: {self.session_id}")
            
            # QuestionGeneratorì—ê²Œ ìƒíƒœ ê°ì²´(state)ë¥¼ ì „ë‹¬í•˜ì—¬ ì§ˆë¬¸ ìƒì„±
            question_data = await asyncio.to_thread(
                self.question_generator.generate_question_with_orchestrator_state,
                self.session_state
            )
            
            # ğŸ†• í„´ ì „í™˜ ì²˜ë¦¬
            if question_data.get('turn_switch'):
                # ğŸ†• í„´ ì „í™˜ ì‹œ ë°”ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì„ ìš”ì²­ (ì¬ê·€ í˜¸ì¶œ)
                print(f"[DEBUG] í„´ ì „í™˜ ê°ì§€: {question_data.get('message', '')}")
                # ìƒíƒœ ì—…ë°ì´íŠ¸ í›„ ë‹¤ì‹œ ì§ˆë¬¸ ìš”ì²­
                return await self._request_question_from_interviewer()
            
            # ğŸ†• ê°œë³„ ì§ˆë¬¸ ë°ì´í„° ì²´í¬ - ì§ì ‘ ë°˜í™˜
            if 'user_question' in question_data and 'ai_question' in question_data:
                print(f"[DEBUG] ê°œë³„ ì§ˆë¬¸ ê°ì§€ë¨ - ê°œë³„ ì§ˆë¬¸ ë°ì´í„° ë°˜í™˜")
                return question_data  # Dict í˜•íƒœë¡œ ë°˜í™˜
            
            # ì¼ë°˜ ì§ˆë¬¸ ë°˜í™˜
            return question_data.get('question', 'ë‹¤ìŒ ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ê°€ìš”?')
            
        except Exception as e:
            from llm.shared.logging_config import interview_logger
            interview_logger.error(f"ë©´ì ‘ê´€ ì§ˆë¬¸ ìš”ì²­ ì˜¤ë¥˜: {e}", exc_info=True)
            return "ì£„ì†¡í•©ë‹ˆë‹¤, ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    async def _request_individual_follow_up_questions(self) -> Dict[str, Any]:
        """ë©´ì ‘ê´€ì—ê²Œ ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ 2ê°œ ìƒì„± ìš”ì²­"""
        try:
            from llm.shared.logging_config import interview_logger
            interview_logger.info(f"ğŸ“¤ ë©´ì ‘ê´€ì—ê²Œ ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ìš”ì²­: {self.session_id}")
            
            # qa_historyì—ì„œ ìµœì‹  ë‹µë³€ë“¤ ì¶”ì¶œ
            qa_history = self.session_state.get('qa_history', [])
            if len(qa_history) < 2:
                raise ValueError("ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ì„ ìƒì„±í•˜ë ¤ë©´ ìµœì†Œ 2ê°œì˜ ë‹µë³€ì´ í•„ìš”í•©ë‹ˆë‹¤")
            
            # ê°€ì¥ ìµœê·¼ ì§ˆë¬¸ê³¼ ë‹µë³€ë“¤ ì¶”ì¶œ 
            latest_qa_pairs = qa_history[-2:]  # ë§ˆì§€ë§‰ 2ê°œ (ì‚¬ìš©ì + AI ë‹µë³€)
            previous_question = latest_qa_pairs[0]['question'] if latest_qa_pairs else ''
            
            # ì‚¬ìš©ìì™€ AI ë‹µë³€ ë¶„ë¦¬
            user_answer = ""
            ai_answer = ""
            for qa in latest_qa_pairs:
                if qa['answerer'] == 'user':
                    user_answer = qa['answer']
                elif qa['answerer'] == 'ai':
                    ai_answer = qa['answer']
            
            if not user_answer or not ai_answer:
                raise ValueError("ì‚¬ìš©ìì™€ AI ë‹µë³€ì´ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤")
            
            # íšŒì‚¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            company_info = self.question_generator.companies_data.get(
                self.session_state.get('company_id'), {}
            )
            
            # í˜„ì¬ ë©´ì ‘ê´€ ì •ë³´
            current_interviewer = self.session_state.get('current_interviewer', 'HR')
            
            # ì‚¬ìš©ì ì´ë ¥ì„œ ì •ë³´
            user_resume = {
                'name': self.session_state.get('user_name', 'ì§€ì›ì'),
                'position': self.session_state.get('position', 'ê°œë°œì')
            }
            
            print(f"[DEBUG] ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± - ë©´ì ‘ê´€: {current_interviewer}")
            print(f"[DEBUG] ì´ì „ ì§ˆë¬¸: {previous_question[:50]}...")
            print(f"[DEBUG] ì‚¬ìš©ì ë‹µë³€: {user_answer[:50]}...")
            print(f"[DEBUG] AI ë‹µë³€: {ai_answer[:50]}...")
            
            # ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ìš”ì²­
            follow_up_data = await asyncio.to_thread(
                self.question_generator.generate_follow_up_questions_for_both,
                previous_question=previous_question,
                user_answer=user_answer,
                ai_answer=ai_answer,
                company_info=company_info,
                interviewer_role=current_interviewer,
                user_resume=user_resume
            )
            
            return follow_up_data
            
        except Exception as e:
            from llm.shared.logging_config import interview_logger
            interview_logger.error(f"ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìš”ì²­ ì˜¤ë¥˜: {e}", exc_info=True)
            
            # í´ë°±: ê³µí†µ ê¼¬ë¦¬ì§ˆë¬¸ ì‚¬ìš©
            try:
                common_question = await self._request_question_from_interviewer()
                return {
                    'user_question': {'question': common_question},
                    'ai_question': {'question': common_question},
                    'interviewer_type': self.session_state.get('current_interviewer', 'HR'),
                    'question_type': 'follow_up',
                    'is_individual_questions': False,
                    'fallback_reason': 'individual_request_failed'
                }
            except Exception as fallback_error:
                interview_logger.error(f"í´ë°± ì§ˆë¬¸ ìƒì„±ë„ ì‹¤íŒ¨: {fallback_error}")
                return {
                    'user_question': {'question': 'ì¶”ê°€ë¡œ ì„¤ëª…í•´ ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?'},
                    'ai_question': {'question': 'ë” ìì„¸í•œ ë‚´ìš©ì„ ë§ì”€í•´ ì£¼ì„¸ìš”.'},
                    'interviewer_type': 'HR',
                    'question_type': 'follow_up',
                    'is_individual_questions': False,
                    'fallback_reason': 'complete_fallback'
                }

    async def _request_answer_from_ai_candidate(self, question: str) -> str:
        """AI ì§€ì›ìì—ê²Œ ë‹µë³€ ìƒì„±ì„ ìš”ì²­í•˜ê³ , í…ìŠ¤íŠ¸ ê²°ê³¼ë§Œ ë°˜í™˜"""
        try:
            from llm.shared.logging_config import interview_logger
            interview_logger.info(f"ğŸ“¤ AI ì§€ì›ìì—ê²Œ ë‹µë³€ ìš”ì²­: {self.session_id}")
            
            ai_persona = self.session_state.get('ai_persona')
            
            # ë‹µë³€ ìƒì„± ìš”ì²­ êµ¬ì„±
            from llm.shared.models import AnswerRequest, QuestionType, LLMProvider
            from llm.candidate.quality_controller import QualityLevel
            
            answer_request = AnswerRequest(
                question_content=question,
                question_type=QuestionType.HR, # TODO: ì§ˆë¬¸ ìœ í˜•ì„ stateì—ì„œ ê°€ì ¸ì˜¤ë„ë¡ ê°œì„ 
                question_intent="ë©´ì ‘ê´€ì˜ ì§ˆë¬¸",
                company_id=self.session_state.get('company_id'),
                position=self.session_state.get('position'),
                quality_level=QualityLevel.AVERAGE,
                llm_provider=LLMProvider.OPENAI_GPT4O
            )
            
            response = await asyncio.to_thread(
                self.ai_candidate_model.generate_answer,
                request=answer_request,
                persona=ai_persona
            )
            return response.answer_content
            
        except Exception as e:
            from llm.shared.logging_config import interview_logger
            interview_logger.error(f"AI ì§€ì›ì ë‹µë³€ ìš”ì²­ ì˜¤ë¥˜: {e}", exc_info=True)
            return "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    # TTS ìƒì„± ë©”ì„œë“œ ì œê±° - í”„ë¡ íŠ¸ì—”ë“œì—ì„œ TTS ì²˜ë¦¬

    # TTS ì²˜ë¦¬ ë©”ì„œë“œë“¤ ì œê±° - í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì²˜ë¦¬

    # TTS ì¬ìƒ ë©”ì„œë“œë“¤ ì œê±° - í”„ë¡ íŠ¸ì—”ë“œì—ì„œ TTS ì²˜ë¦¬

    # ì‹¤ì‹œê°„ TTS ë©”ì„œë“œ ì œê±° - í”„ë¡ íŠ¸ì—”ë“œì—ì„œ TTS ì²˜ë¦¬
    
    # TTS ì €ì¥ ë©”ì„œë“œ ì œê±° - í”„ë¡ íŠ¸ì—”ë“œì—ì„œ TTS ì²˜ë¦¬

    # TTS íŒë‹¨ ë©”ì„œë“œ ì œê±° - í”„ë¡ íŠ¸ì—”ë“œì—ì„œ TTS ì²˜ë¦¬

    # TTS ì—ì´ì „íŠ¸ íƒ€ì… ê²°ì • ë©”ì„œë“œ ì œê±° - í”„ë¡ íŠ¸ì—”ë“œì—ì„œ TTS ì²˜ë¦¬

    # ê°œë³„ ì§ˆë¬¸ TTS ìƒì„± ë©”ì„œë“œ ì œê±° - í”„ë¡ íŠ¸ì—”ë“œì—ì„œ TTS ì²˜ë¦¬

    @staticmethod
    def create_agent_message(session_id: str, task: str, from_agent: str, content_text: str, 
                             turn_count: int, duration: float = 0, content_type: str = "text", 
                             start_time: float = None) -> Dict[str, Any]:
        """ì™¸ë¶€(Agent)ì—ì„œ Orchestratorë¡œ ë³´ë‚¼ ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ëŠ” ì •ì  ë©”ì„œë“œ"""
        # ğŸ†• total_time ê³„ì‚°
        total_time = None
        if start_time:
            total_time = time.time() - start_time
        
        return {
            "metadata": {
                "interview_id": session_id,
                "step": turn_count,
                "task": task,
                "from_agent": from_agent,
                "next_agent": "orchestrator",
                "status_code": 200
            },
            "content": {
                "type": content_type,
                "content": content_text
            },
            "metrics": {
                "duration": duration,
                "total_time": total_time
            }
        }

    async def process_user_answer(self, user_answer: str, time_spent: float = None) -> Dict[str, Any]:
        """ì‚¬ìš©ì ë‹µë³€ì„ ì²˜ë¦¬í•˜ê³  ì „ì²´ í”Œë¡œìš°ë¥¼ ì™„ë£Œí•˜ì—¬ ìµœì¢… ê²°ê³¼ ë°˜í™˜"""
        print(f"[TRACE] Orchestrator.process_user_answer start: session={self.session_id}")
        
        # ğŸ†• ê°œë³„ ì§ˆë¬¸ ìƒíƒœ ì²´í¬
        current_questions = self.session_state.get('current_questions')
        is_individual_question = current_questions and current_questions.get('is_individual', False)
        
        # 1. ì‚¬ìš©ì ë‹µë³€ ë©”ì‹œì§€ ìƒì„± ë° ì²˜ë¦¬
        task = "individual_answer_generated" if is_individual_question else "answer_generated"
        
        user_message = self.create_agent_message(
            session_id=self.session_id,
            task=task,
            from_agent="user",
            content_text=user_answer,
            turn_count=self.session_state.get('turn_count', 0),
            duration=time_spent,
            start_time=self.session_state.get('start_time')
        )
        
        # 2. ì‚¬ìš©ì ë‹µë³€ìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸ (handle_messageì—ì„œ JSON ì¶œë ¥ë¨)
        await self.handle_message(user_message)
        
        # 3. ë‹¤ìŒ ì•¡ì…˜ ê²°ì • ë° ì „ì²´ í”Œë¡œìš° ì²˜ë¦¬
        return await self._process_complete_flow()
    
    async def _process_complete_flow(self) -> Dict[str, Any]:
        """ì™„ì „í•œ í”Œë¡œìš°ë¥¼ ì²˜ë¦¬í•˜ì—¬ ìµœì¢… ê²°ê³¼ ë°˜í™˜"""
        print(f"[TRACE] Orchestrator._process_complete_flow start: session={self.session_id}")
        
        while True:
            print(f"[TRACE] turn={self.session_state.get('turn_count', 0)}")
            
            # ë‹¤ìŒ ë©”ì‹œì§€ ê²°ì •
            next_message = self._decide_next_message()
            next_agent = next_message.get("metadata", {}).get("next_agent")
            task = next_message.get("metadata", {}).get("task")
            
            print(f"[TRACE] decide_next -> next_agent={next_agent}, task={task}")
            
            # ì™„ë£Œ ì¡°ê±´ ì²´í¬
            if task == "end_interview":
                print(f"[TRACE] interview complete")
                result = {
                    "status": "completed",
                    "message": "ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.",
                    "qa_history": self.session_state.get('qa_history', []),
                    "session_id": self.session_id
                }
                # ğŸ†• í”„ë¡ íŠ¸ ì¶”ì¶œìš© AI ë©”íƒ€ë°ì´í„° í¬í•¨ (resume_id ì „ë‹¬)
                try:
                    ai_resume_id = self.session_state.get('ai_resume_id') or (
                        (self.session_state.get('ai_persona') or {}).get('resume_id') if isinstance(self.session_state.get('ai_persona'), dict) else None
                    )
                except Exception:
                    ai_resume_id = None
                result['turn_info'] = {
                    'ai_metadata': {
                        'resume_id': ai_resume_id
                    }
                }
                print(f"[TRACE] Orchestrator -> Client (complete)")
                # ì˜¤ë””ì˜¤ ë°ì´í„° ì œì™¸í•˜ê³  ë¡œê·¸ ì¶œë ¥
                result_log = {k: v for k, v in result.items() if not k.endswith('_audio')}
                print(json.dumps(result_log, indent=2, ensure_ascii=False))
                return result
            
            # ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸° ìƒíƒœì¸ ê²½ìš°
            if next_agent == "user":
                print(f"[TRACE] wait for user input")
                result = await self.create_user_waiting_message()
                
                print(f"[TRACE] Orchestrator -> Client (wait)")
                # JSON ì¶œë ¥ì€ create_user_waiting_messageì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨
                return result
            
            # ì—ì´ì „íŠ¸ ì‘ì—… ìˆ˜í–‰ (handle_messageì—ì„œ TTS ìˆœì°¨ ì²˜ë¦¬ í¬í•¨)
            if next_agent == "interviewer":
                print(f"[TRACE] interviewer task start")
                await self._process_interviewer_task()
            elif next_agent == "interviewer_individual":
                print(f"[TRACE] interviewer individual follow-up task start")
                await self._process_individual_interviewer_task()
            elif next_agent == "ai":
                print(f"[TRACE] ai task start")
                await self._process_ai_task(next_message.get("content", {}).get("content"))
            
            print(f"[TRACE] loop end")

    async def _process_initial_flow(self) -> Dict[str, Any]:
        """
        âš¡ ë©´ì ‘ ì‹œì‘ìš© ì´ˆê¸° í”Œë¡œìš°: INTRO + ì²« ë²ˆì§¸ ì§ˆë¬¸ ì²˜ë¦¬í•˜ê³  ì¦‰ì‹œ ì‘ë‹µ
        - ì „ì²´ ë©´ì ‘ í”Œë¡œìš° ëŒ€ì‹  INTRO + ì²« ì§ˆë¬¸ë§Œ ìƒì„±í•˜ì—¬ API ì‘ë‹µ ì†ë„ ìµœì í™”
        """
        print(f"[âš¡ INITIAL_FLOW] ë©´ì ‘ ì‹œì‘ ì´ˆê¸° í”Œë¡œìš° ì‹œì‘: session={self.session_id}")
        print(f"[âš¡ DEBUG] ì‹œì‘ ì‹œ session_state: {self.session_state}")
        
        try:
            # 1. INTRO ìƒì„± ë° TTS ì²˜ë¦¬
            current_turn = self.session_state.get('turn_count', 0)
            print(f"[âš¡ DEBUG] INTRO ë‹¨ê³„ - current_turn: {current_turn}")
            
            if current_turn == 0:
                print(f"[âš¡ INITIAL_FLOW] INTRO ìƒì„± ì‹œì‘ (turn={current_turn})")
                
                # ë©´ì ‘ê´€ì—ê²Œ INTRO ìš”ì²­
                intro_content = await self._request_question_from_interviewer()
                print(f"[âš¡ DEBUG] INTRO content ìƒì„±ë¨: {intro_content[:100]}...")
                
                # INTRO ë©”ì‹œì§€ ìƒì„± ë° ì²˜ë¦¬
                intro_response = self.create_agent_message(
                    session_id=self.session_id,
                    task="intro_generated",
                    from_agent="interviewer", 
                    content_text=intro_content,
                    turn_count=current_turn,
                    content_type="INTRO",
                    start_time=self.session_state.get('start_time')
                )
                
                # handle_messageë¡œ TTS ìƒì„± ë° ìƒíƒœ ì—…ë°ì´íŠ¸
                await self.handle_message(intro_response)
                print(f"[âš¡ INITIAL_FLOW] âœ… INTRO ì²˜ë¦¬ ì™„ë£Œ")
                print(f"[âš¡ DEBUG] INTRO ì²˜ë¦¬ í›„ session_state: {self.session_state}")
            else:
                print(f"[âš¡ WARNING] INTRO ë‹¨ê³„ ê±´ë„ˆëœ€ - current_turnì´ 0ì´ ì•„ë‹˜: {current_turn}")
            
            # 2. ì²« ë²ˆì§¸ ì§ˆë¬¸ ìƒì„± ë° TTS ì²˜ë¦¬
            current_turn = self.session_state.get('turn_count', 0)
            print(f"[âš¡ DEBUG] ì²« ë²ˆì§¸ ì§ˆë¬¸ ë‹¨ê³„ - current_turn: {current_turn}")
            
            if current_turn == 1:  # INTRO ì²˜ë¦¬ í›„ í„´ì´ 1ì´ ë¨
                print(f"[âš¡ INITIAL_FLOW] ì²« ë²ˆì§¸ ì§ˆë¬¸ ìƒì„± ì‹œì‘ (turn={current_turn})")
                
                # ë©´ì ‘ê´€ì—ê²Œ ì²« ë²ˆì§¸ ì§ˆë¬¸ ìš”ì²­
                first_question = await self._request_question_from_interviewer()
                print(f"[âš¡ DEBUG] ì²« ë²ˆì§¸ ì§ˆë¬¸ content ìƒì„±ë¨: {first_question[:100]}...")
                
                # ì²« ë²ˆì§¸ ì§ˆë¬¸ ë©”ì‹œì§€ ìƒì„± ë° ì²˜ë¦¬
                question_response = self.create_agent_message(
                    session_id=self.session_id,
                    task="question_generated",
                    from_agent="interviewer", 
                    content_text=first_question,
                    turn_count=current_turn,
                    content_type="QUESTION",
                    start_time=self.session_state.get('start_time')
                )
                
                # handle_messageë¡œ TTS ìƒì„± ë° ìƒíƒœ ì—…ë°ì´íŠ¸
                await self.handle_message(question_response)
                print(f"[âš¡ INITIAL_FLOW] âœ… ì²« ë²ˆì§¸ ì§ˆë¬¸ ì²˜ë¦¬ ì™„ë£Œ")
                print(f"[âš¡ DEBUG] ì²« ë²ˆì§¸ ì§ˆë¬¸ ì²˜ë¦¬ í›„ session_state: {self.session_state}")
            else:
                print(f"[âš¡ WARNING] ì²« ë²ˆì§¸ ì§ˆë¬¸ ë‹¨ê³„ ê±´ë„ˆëœ€ - current_turnì´ 1ì´ ì•„ë‹˜: {current_turn}")
                
            # 3. session_state ìƒì„¸ ë¶„ì„
            print(f"[âš¡ DEBUG] === ìµœì¢… session_state ë¶„ì„ ===")
            print(f"[âš¡ DEBUG] turn_count: {self.session_state.get('turn_count')}")
            print(f"[âš¡ DEBUG] intro_message: {bool(self.session_state.get('intro_message'))}")
            print(f"[âš¡ DEBUG] intro_audio: {bool(self.session_state.get('intro_audio'))}")
            print(f"[âš¡ DEBUG] current_question: {bool(self.session_state.get('current_question'))}")
            print(f"[âš¡ DEBUG] question_audio: {bool(self.session_state.get('question_audio'))}")
            if self.session_state.get('current_question'):
                print(f"[âš¡ DEBUG] current_question ë‚´ìš©: {self.session_state.get('current_question')[:50]}...")
                
            # 4. INTRO + ì²« ë²ˆì§¸ ì§ˆë¬¸ ì‘ë‹µ ì¦‰ì‹œ ë°˜í™˜ (í´ë¼ì´ì–¸íŠ¸ í˜¸í™˜ì„± ë³´ì¥)
            first_question = self.session_state.get('current_question')
            ai_resume_id = self.session_state.get('ai_resume_id')
            
            result = {
                "status": "interview_started",
                "message": "ë©´ì ‘ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. INTROì™€ ì²« ë²ˆì§¸ ì§ˆë¬¸ì„ í™•ì¸í•´ì£¼ì„¸ìš”.",
                "session_id": self.session_id,
                "intro_message": self.session_state.get('intro_message'),
                "first_question": first_question,
                # ì˜¤ë””ì˜¤ í•„ë“œë“¤ ì œê±°
                # ğŸ†• í´ë¼ì´ì–¸íŠ¸ê°€ ê¸°ëŒ€í•˜ëŠ” content êµ¬ì¡° ì¶”ê°€
                "content": {
                    "question": first_question,
                    "content": first_question,  # í˜¸í™˜ì„±ì„ ìœ„í•œ ì¤‘ë³µ
                    "metadata": {
                        "ai_resume_id": ai_resume_id,
                        "interviewer_type": "HR",
                        "question_type": "main",
                        "turn_count": self.session_state.get('turn_count', 0)
                    }
                },
                # ğŸ†• ìµœìƒìœ„ ë ˆë²¨ì—ë„ ai_resume_id í¬í•¨ (ë‹¤ì¤‘ ì ‘ê·¼ ê²½ë¡œ)
                "ai_resume_id": ai_resume_id,
                "metadata": {
                    "ai_resume_id": ai_resume_id,
                    "session_id": self.session_id,
                    "interviewer_type": "HR"
                },
                # ğŸ†• ai_answer êµ¬ì¡°ë„ ì¶”ê°€ (í´ë¼ì´ì–¸íŠ¸ í˜¸í™˜ì„±)
                "ai_answer": {
                    "metadata": {
                        "ai_resume_id": ai_resume_id
                    }
                },
                "turn_info": {
                    "current_turn": self.session_state.get('turn_count', 0),
                    "is_user_turn": True,
                    "next_action": "wait_user_answer",
                    "ai_metadata": {
                        "ai_resume_id": ai_resume_id
                    }
                }
            }
            
            print(f"[âš¡ INITIAL_FLOW] === ë©´ì ‘ ì‹œì‘ ì‘ë‹µ ì¤€ë¹„ ì™„ë£Œ ===")
            print(f"[âš¡ INITIAL_FLOW] INTRO ë©”ì‹œì§€: {bool(result.get('intro_message'))}")
            print(f"[âš¡ INITIAL_FLOW] ì²« ë²ˆì§¸ ì§ˆë¬¸: {bool(result.get('first_question'))}")
            print(f"[âš¡ INITIAL_FLOW] ğŸ†• content í•„ë“œ: {bool(result.get('content'))}")
            print(f"[âš¡ INITIAL_FLOW] ğŸ†• ai_resume_id (ìµœìƒìœ„): {result.get('ai_resume_id')}")
            print(f"[âš¡ INITIAL_FLOW] ğŸ†• ai_answer.metadata: {bool(result.get('ai_answer', {}).get('metadata'))}")
            print(f"[âš¡ INITIAL_FLOW] ğŸ†• content.metadata.ai_resume_id: {result.get('content', {}).get('metadata', {}).get('ai_resume_id')}")
            if result.get('first_question'):
                print(f"[âš¡ INITIAL_FLOW] ì²« ë²ˆì§¸ ì§ˆë¬¸ ë‚´ìš©: {result.get('first_question')[:50]}...")
            print(f"[âš¡ INITIAL_FLOW] âœ… API ì¦‰ì‹œ ì‘ë‹µ (í…ìŠ¤íŠ¸ ì „ìš©)!")
            
            return result
            
        except Exception as e:
            print(f"[âš¡ INITIAL_FLOW] âŒ ì´ˆê¸° í”Œë¡œìš° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            print(f"[âš¡ INITIAL_FLOW] ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
            
            return {
                "status": "error",
                "message": f"ë©´ì ‘ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "session_id": self.session_id
            }
    
    async def _process_interviewer_task(self):
        """ë©´ì ‘ê´€ ì‘ì—… ì²˜ë¦¬"""
        print(f"[TRACE] Orchestrator -> Interviewer (generate_question)")
        
        # ğŸ†• í˜„ì¬ ìƒíƒœ ë””ë²„ê¹… (ê°œì„ )
        current_interviewer = self.session_state.get('current_interviewer')
        turn_state = self.session_state.get('interviewer_turn_state', {})
        current_turn = self.session_state.get('turn_count', 0)
        
        print(f"[TRACE] interviewer_state turn={current_turn}, current_interviewer={current_interviewer}")
        for role, state in turn_state.items():
            main_done = "âœ“" if state['main_question_asked'] else "âœ—"
            follow_count = state['follow_up_count']
            print(f"[DEBUG]   {role}: ë©”ì¸ {main_done}, ê¼¬ë¦¬ {follow_count}ê°œ")
        
        question_result = await self._request_question_from_interviewer()
        
        # ğŸ†• ë°˜í™˜ê°’ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬
        if isinstance(question_result, dict) and 'user_question' in question_result and 'ai_question' in question_result:
            print(f"[TRACE] individual questions generated (dict)")
            
            # ê°œë³„ ì§ˆë¬¸ ë©”ì‹œì§€ ìƒì„±
            questions_message = self.create_agent_message(
                session_id=self.session_id,
                task="individual_questions_generated",
                from_agent="interviewer",
                content_text=json.dumps(question_result),
                turn_count=current_turn,
                content_type=current_interviewer or "HR",
                start_time=self.session_state.get('start_time')
            )
            
            # TRACE ì¶œë ¥: interviewer -> orchestrator (individual_questions_generated)
            # ğŸ†• handle_messageì—ì„œ TTSê°€ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬ë¨
            await self.handle_message(questions_message)
            
        else:
            # ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬
            question_content = question_result if isinstance(question_result, str) else str(question_result)
            
            # ğŸ†• content_type ê²°ì •
            content_type = "INTRO" if current_turn == 0 else current_interviewer or "HR"
            
            # í˜„ì¬ í„´ì— ë”°ë¼ task ê²°ì •
            task = "intro_generated" if current_turn == 0 else "question_generated"
            
            question_message = self.create_agent_message(
                session_id=self.session_id,
                task=task,
                from_agent="interviewer",
                content_text=question_content,
                turn_count=current_turn,
                content_type=content_type,
                start_time=self.session_state.get('start_time')
            )
            
            # TRACE ì¶œë ¥: interviewer -> orchestrator (question_generated)  
            # ğŸ†• handle_messageì—ì„œ TTSê°€ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬ë¨
            await self.handle_message(question_message)
    
    async def _process_individual_interviewer_task(self):
        """ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì‘ì—… ì²˜ë¦¬"""
        print(f"[TRACE] Orchestrator -> Interviewer (generate_individual_follow_up)")
        
        # í˜„ì¬ ìƒíƒœ ë””ë²„ê¹…
        current_interviewer = self.session_state.get('current_interviewer')
        turn_state = self.session_state.get('interviewer_turn_state', {})
        current_turn = self.session_state.get('turn_count', 0)
        
        print(f"[TRACE] individual follow-up start turn={current_turn}, interviewer={current_interviewer}")
        
        try:
            # ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ìš”ì²­
            individual_questions = await self._request_individual_follow_up_questions()
            
            # ê°œë³„ ì§ˆë¬¸ ë©”ì‹œì§€ ìƒì„± ë° ì²˜ë¦¬
            questions_message = self.create_agent_message(
                session_id=self.session_id,
                task="individual_questions_generated",
                from_agent="interviewer",
                content_text=json.dumps(individual_questions),  # Dictë¥¼ JSONìœ¼ë¡œ ë³€í™˜
                turn_count=current_turn,
                content_type=current_interviewer or "HR",
                start_time=self.session_state.get('start_time')
            )
            
            # TRACE ì¶œë ¥: interviewer -> orchestrator (individual_questions_generated)
            # ğŸ†• handle_messageì—ì„œ TTSê°€ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬ë¨  
            await self.handle_message(questions_message)
            
        except Exception as e:
            print(f"[TRACE][ERROR] individual follow-up generation failed: {e}")
            # í´ë°±: ì¼ë°˜ ì§ˆë¬¸ìœ¼ë¡œ ëŒ€ì²´
            await self._process_interviewer_task()

    async def _process_individual_interviewer_task_parallel(self) -> Dict[str, Any]:
        """
        ğŸ†• ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì ìš©í•œ ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì‘ì—… ì²˜ë¦¬
        """
        print(f"[TRACE] Orchestrator -> Interviewer (generate_individual_follow_up)")
        
        # í˜„ì¬ ìƒíƒœ ë””ë²„ê¹…
        current_interviewer = self.session_state.get('current_interviewer')
        turn_state = self.session_state.get('interviewer_turn_state', {})
        current_turn = self.session_state.get('turn_count', 0)
        
        print(f"[TRACE] individual follow-up start turn={current_turn}, interviewer={current_interviewer}")
        
        try:
            # ê°œë³„ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ìš”ì²­
            individual_questions = await self._request_individual_follow_up_questions()
            
            # ê°œë³„ ì§ˆë¬¸ ë©”ì‹œì§€ ìƒì„± ë° ì²˜ë¦¬
            questions_message = self.create_agent_message(
                session_id=self.session_id,
                task="individual_questions_generated",
                from_agent="interviewer",
                content_text=json.dumps(individual_questions),  # Dictë¥¼ JSONìœ¼ë¡œ ë³€í™˜
                turn_count=current_turn,
                content_type=current_interviewer or "HR",
                start_time=self.session_state.get('start_time')
            )
            
            # TRACE ì¶œë ¥: interviewer -> orchestrator (individual_questions_generated)
            # ğŸ†• handle_messageì—ì„œ TTSê°€ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬ë¨
            await self.handle_message(questions_message)
            
            return questions_message
            
        except Exception as e:
            print(f"[TRACE][ERROR] individual follow-up generation failed: {e}")
            # í´ë°±: ì¼ë°˜ ì§ˆë¬¸ìœ¼ë¡œ ëŒ€ì²´
            return await self._process_interviewer_task_parallel()
    
    async def _process_ai_task(self, question: str):
        """AI ì§€ì›ì ì‘ì—… ì²˜ë¦¬"""
        print(f"[TRACE] Orchestrator -> AI (question) : {question[:50]}...")
        
        # AIì—ê²Œ ì „ë‹¬í•  ì§ˆë¬¸ì—ì„œ ì‚¬ìš©ì ì´ë¦„ í˜¸ì¹­ì„ AIìš©ìœ¼ë¡œ ìµœì†Œ ì¹˜í™˜
        ai_question = self._format_question_for_ai(question)
        
        # ğŸ†• AI ì§ˆë¬¸ì„ í´ë¼ì´ì–¸íŠ¸ ì „ë‹¬ìš©ìœ¼ë¡œ ì„ì‹œ ì €ì¥
        self.session_state['latest_ai_question'] = ai_question
        print(f"[DEBUG] AI ì§ˆë¬¸ ì„ì‹œ ì €ì¥: {ai_question[:50]}...")
        
        ai_answer = await self._request_answer_from_ai_candidate(ai_question)
        
        # ğŸ†• AI ë‹µë³€ì„ í´ë¼ì´ì–¸íŠ¸ ì „ë‹¬ìš©ìœ¼ë¡œ ì„ì‹œ ì €ì¥  
        self.session_state['latest_ai_answer'] = ai_answer
        print(f"[DEBUG] AI ë‹µë³€ ì„ì‹œ ì €ì¥: {ai_answer[:50]}...")
        
        # ğŸ†• ê°œë³„ ì§ˆë¬¸ ìƒíƒœ ì²´í¬
        current_questions = self.session_state.get('current_questions')
        is_individual_question = current_questions and current_questions.get('is_individual', False)
        
        # ğŸ†• content_type ê²°ì • (í˜„ì¬ ë©´ì ‘ê´€ ê¸°ë°˜)
        current_interviewer = self.session_state.get('current_interviewer', 'HR')
        content_type = current_interviewer if current_interviewer in ['HR', 'TECH', 'COLLABORATION'] else 'HR'
        
        # ê°œë³„ ì§ˆë¬¸ ì—¬ë¶€ì— ë”°ë¼ task ê²°ì •
        task = "individual_answer_generated" if is_individual_question else "answer_generated"
        
        # AIê°€ ì‹¤ì œë¡œ ë°›ì€ ì§ˆë¬¸ì„ ìƒíƒœì— ì„ì‹œ ì €ì¥ (qa ê¸°ë¡ìš©)
        self.session_state['_ai_actual_question'] = ai_question

        ai_message = self.create_agent_message(
            session_id=self.session_id,
            task=task,
            from_agent="ai",
            content_text=ai_answer,
            turn_count=self.session_state.get('turn_count', 0),
            content_type=content_type,
            start_time=self.session_state.get('start_time')
        )
        
        # handle_messageì—ì„œ JSON ì¶œë ¥ë˜ê³  TTSë„ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬ë¨
        await self.handle_message(ai_message)

    async def create_user_waiting_message(self) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸° ë©”ì‹œì§€ ìƒì„±"""
        # ğŸ†• ê°œë³„ ì§ˆë¬¸ ìƒíƒœ ì²´í¬
        current_questions = self.session_state.get('current_questions')
        is_individual_question = current_questions and current_questions.get('is_individual', False)
        
        # ğŸ†• ì§ˆë¬¸ í…ìŠ¤íŠ¸ ê²°ì •
        if is_individual_question:
            question_text = current_questions.get('user_question', {}).get('question', '')
            print(f"[DEBUG] ì‚¬ìš©ì ê°œë³„ ì§ˆë¬¸: {question_text[:50]}...")
        else:
            question_text = self.session_state.get('current_question', '')
        
        # ğŸ†• content_type ê²°ì • (í˜„ì¬ ë©´ì ‘ê´€ ê¸°ë°˜)
        current_interviewer = self.session_state.get('current_interviewer', 'HR')
        content_type = current_interviewer if current_interviewer in ['HR', 'TECH', 'COLLABORATION'] else 'HR'
        
        response = self.create_agent_message(
            session_id=self.session_id,
            task="wait_for_user_input",
            from_agent="orchestrator",
            content_text=question_text,
            turn_count=self.session_state.get('turn_count', 0),
            content_type=content_type,
            start_time=self.session_state.get('start_time')
        )
        # next_agentë¥¼ 'user'ë¡œ ìˆ˜ì •í•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œê°€ ì˜¬ë°”ë¥´ê²Œ ì¸ì‹í•˜ë„ë¡ í•¨
        response['metadata']['next_agent'] = 'user'
        response['status'] = 'waiting_for_user'
        response['message'] = 'ë‹µë³€ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'
        response['session_id'] = self.session_id
        
        # ğŸ†• INTRO ë©”ì‹œì§€ í¬í•¨ (ì²« ë²ˆì§¸ ì‘ë‹µì—ì„œë§Œ) - ì˜¤ë””ì˜¤ ì œê±°
        current_turn = self.session_state.get('turn_count', 0)
        intro_message = self.session_state.get('intro_message')
        
        # INTROëŠ” í„´ 1ì—ì„œë§Œ ì „ë‹¬ (í„´ 2 ì´í›„ì—ëŠ” ë¶ˆí•„ìš”)
        if current_turn <= 1 and intro_message:
            response['intro_message'] = intro_message
            print(f"[ğŸ“ TEXT] INTRO ë©”ì‹œì§€ ì „ë‹¬ (í„´ {current_turn}): {intro_message[:50]}...")
            
            # í•œ ë²ˆ ì „ë‹¬ í›„ ì‚­ì œ
            if 'intro_message' in self.session_state:
                del self.session_state['intro_message']
                
            print(f"[ğŸ“ TEXT] ğŸ—‘ï¸ INTRO ë°ì´í„° ì‚­ì œ ì™„ë£Œ - ë‹¤ìŒ í„´ë¶€í„°ëŠ” ì „ì†¡ ì•ˆí•¨")
        else:
            print(f"[ğŸ“ TEXT] INTRO ì „ì†¡ ê±´ë„ˆëœ€ (í„´ {current_turn}, intro_message ì¡´ì¬: {bool(intro_message)})")
        
        # AI ì§ˆë¬¸ í…ìŠ¤íŠ¸ë§Œ ì²˜ë¦¬ - ì˜¤ë””ì˜¤ ì œê±°
        current_question = question_text
        ai_resume_id = self.session_state.get('ai_resume_id')
        
        print(f"[ğŸ“ TEXT] AI ì§ˆë¬¸ í…ìŠ¤íŠ¸ ì „ë‹¬: {current_question[:50] if current_question else 'N/A'}...")
        
        # í‘œì¤€í™”ëœ ì‘ë‹µ êµ¬ì¡° ì¶”ê°€ - ì˜¤ë””ì˜¤ ì œê±°
        response['content'] = {
            'question': current_question,
            'content': current_question,
            'metadata': {
                'ai_resume_id': ai_resume_id,
                'interviewer_type': content_type,
                'question_type': 'main' if not is_individual_question else 'individual',
                'turn_count': self.session_state.get('turn_count', 0)
            }
        }
        
        # ai_answer êµ¬ì¡° ì¶”ê°€ - ì˜¤ë””ì˜¤ ì œê±°, í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„ ìœ„í•´ resume_idë„ ì¶”ê°€
        response['ai_answer'] = {
            'metadata': {
                'ai_resume_id': ai_resume_id,
                'resume_id': ai_resume_id  # í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•œ í•„ë“œ
            }
        }
        
        # ğŸ†• ìµœìƒìœ„ ai_resume_id
        response['ai_resume_id'] = ai_resume_id
        response['metadata'] = {
            'ai_resume_id': ai_resume_id,
            'resume_id': ai_resume_id,  # í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•œ í•„ë“œ
            'session_id': self.session_id,
            'interviewer_type': content_type
        }
        
        # ğŸ†• í„´ ì •ë³´ ì¶”ê°€ (ê°œë³„ ì§ˆë¬¸ ì •ë³´ í¬í•¨) - ai_resume_id ì¤‘ë³µ ì •ì˜ ì œê±°
        response['turn_info'] = {
            'current_turn': self.session_state.get('turn_count', 0),
            'is_user_turn': True,
            'is_individual_question': is_individual_question,
            'question_type': 'individual_follow_up' if is_individual_question else 'main_question',
            'ai_metadata': {
                'resume_id': ai_resume_id
            }
        }
        
        # ğŸ†• AI ì§ˆë¬¸ê³¼ ë‹µë³€ì„ í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ë‹¬ (í…ìŠ¤íŠ¸ + ì˜¤ë””ì˜¤)
        latest_ai_question = self.session_state.get('latest_ai_question')
        latest_ai_answer = self.session_state.get('latest_ai_answer')
        latest_ai_answer_audio = self.session_state.get('latest_ai_answer_audio')
        
        print(f"[ğŸ“ TEXT] AI ë°ì´í„° ì „ë‹¬ ì²´í¬:")
        print(f"  - latest_ai_question ì¡´ì¬: {bool(latest_ai_question)}")
        print(f"  - latest_ai_answer ì¡´ì¬: {bool(latest_ai_answer)}")
        
        if latest_ai_question:
            response['ai_question'] = {
                'content': latest_ai_question
            }
            print(f"[ğŸ“ TEXT] AI ì§ˆë¬¸ ì „ë‹¬: {latest_ai_question[:50]}...")
            
            # TTS ìƒì„± ì œê±° - í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì²˜ë¦¬
            
            # í•œë²ˆ ì „ë‹¬ í›„ ì‚­ì œ
            del self.session_state['latest_ai_question']
            
        if latest_ai_answer:
            response['ai_answer'] = {
                'content': latest_ai_answer
            }
            print(f"[ğŸ“ TEXT] AI ë‹µë³€ ì „ë‹¬: {latest_ai_answer[:50]}...")
            
            # í•œë²ˆ ì „ë‹¬ í›„ ì‚­ì œ
            del self.session_state['latest_ai_answer']
        
        # ì‚¬ìš©ì ì§ˆë¬¸ í…ìŠ¤íŠ¸ í™•ì¸ - ì˜¤ë””ì˜¤ ì œê±°
        if question_text and question_text.strip():
            print(f"[ğŸ“ TEXT] ì‚¬ìš©ì ì§ˆë¬¸ í™•ì¸: {question_text[:50]}...")
        else:
            print(f"[ğŸ“ TEXT] ì‚¬ìš©ì ì§ˆë¬¸ì´ ë¹„ì–´ìˆìŒ")
        
        # ìµœì¢… ì‘ë‹µ ìƒíƒœ ë¡œê·¸ - ì˜¤ë””ì˜¤ ì œê±°
        print(f"[ğŸ“ REALTIME] === í…ìŠ¤íŠ¸ ì „ìš© ì²˜ë¦¬ ì™„ë£Œ ===")
        print(f"[ğŸ“ REALTIME] TTS ìƒì„±: í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì²˜ë¦¬")
        print(f"[ğŸ“ REALTIME] âœ… API ì¦‰ì‹œ ì‘ë‹µ ì¤€ë¹„ ì™„ë£Œ!")
        
        # ì‘ë‹µ JSON ì¶œë ¥
        print(json.dumps(response, indent=2, ensure_ascii=False))
        
        return response

    def _format_question_for_ai(self, question: str) -> str:
        """AIì—ê²Œ ë³´ë‚¼ ë•Œ ì‚¬ìš©ì ì´ë¦„ í˜¸ì¹­ì„ 'AI ì§€ì›ìë‹˜'ìœ¼ë¡œ ìµœì†Œ ì¹˜í™˜"""
        try:
            if not isinstance(question, str):
                return question

            user_name_raw = self.session_state.get('user_name', 'ì§€ì›ì') or 'ì§€ì›ì'
            # ê³µë°± ì œê±° ë° 'ë‹˜' ì œê±°í•œ ë‘ ê°€ì§€ ë²„ì „ ì¤€ë¹„
            user_name_compact = re.sub(r"\s+", "", user_name_raw)
            name_wo_suffix = user_name_compact[:-1] if user_name_compact.endswith('ë‹˜') else user_name_compact

            # íŒ¨í„´ë“¤: ë§¨ ì•ì— ë“±ì¥í•˜ëŠ” ì´ë¦„ í˜¸ì¹­ + ì„ íƒì  ê³µë°±/ì½¤ë§ˆë¥¼ AIìš©ìœ¼ë¡œ ì¹˜í™˜
            patterns = [
                rf"^\s*{re.escape(name_wo_suffix)}\s*ë‹˜\s*[,ï¼Œ ]*",
                rf"^\s*{re.escape(user_name_compact)}\s*[,ï¼Œ ]*",
                rf"{re.escape(name_wo_suffix)}\s*ë‹˜\s*[,ï¼Œ ]*",
                rf"{re.escape(user_name_compact)}\s*[,ï¼Œ ]*",
            ]

            for pat in patterns:
                if re.search(pat, question):
                    question = re.sub(pat, "AI ì§€ì›ìë‹˜, ", question, count=1)
                    break

            # ì¼ë°˜ì ì¸ 'ì§€ì›ìë‹˜' í˜¸ì¹­ ì¹˜í™˜ (í•œ ë²ˆë§Œ)
            if re.search(r"ì§€ì›ìë‹˜\s*[,ï¼Œ ]*", question):
                question = re.sub(r"ì§€ì›ìë‹˜\s*[,ï¼Œ ]*", "AI ì§€ì›ìë‹˜, ", question, count=1)

            # ì„ ë‘ì— ì¤‘ë³µëœ 'AI ' í† í° ì •ë¦¬: 'AI AI ì§€ì›ìë‹˜' -> 'AI ì§€ì›ìë‹˜'
            question = re.sub(r"^\s*(AI\s+)+ì§€ì›ìë‹˜\s*[,ï¼Œ ]*", "AI ì§€ì›ìë‹˜, ", question)

            # í˜¸ì¹­ì´ ì—†ìœ¼ë©´ ì•ì—ë§Œ ë¶™ì„ (ì¤‘ë³µ ë°©ì§€)
            if not question.strip().startswith("AI ì§€ì›ìë‹˜"):
                question = f"AI ì§€ì›ìë‹˜, {question}"
            return question
        except Exception:
            return question

    # ğŸ—‘ï¸ ê¸°ì¡´ ë³‘ë ¬ ì²˜ë¦¬ ë©”ì„œë“œë“¤ ì œê±°ë¨ - ìˆœì°¨ ì²˜ë¦¬ ë°©ì‹ìœ¼ë¡œ ë³€ê²½
    # _generate_and_play_tts_parallel, _generate_tts_async, _play_audio_async 
    # ì´ì œ _generate_and_play_tts_sequential ë©”ì„œë“œ ì‚¬ìš©

    async def _process_interviewer_task_parallel(self) -> Dict[str, Any]:
        """ğŸ†• ìˆœì°¨ ì²˜ë¦¬ ë°©ì‹ìœ¼ë¡œ ë³€ê²½ëœ ë©´ì ‘ê´€ íƒœìŠ¤í¬ ì²˜ë¦¬"""
        # ê¸°ì¡´ _process_interviewer_taskì™€ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
        return await self._process_interviewer_task()

    async def _process_ai_task_parallel(self, question: str) -> Dict[str, Any]:
        """ğŸ†• ìˆœì°¨ ì²˜ë¦¬ ë°©ì‹ìœ¼ë¡œ ë³€ê²½ëœ AI íƒœìŠ¤í¬ ì²˜ë¦¬"""  
        # ê¸°ì¡´ _process_ai_taskì™€ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
        await self._process_ai_task(question)
        # AI íƒœìŠ¤í¬ëŠ” ë°˜í™˜ê°’ì´ ì—†ëŠ” void ë©”ì„œë“œì´ë¯€ë¡œ ì„±ê³µ ë©”ì‹œì§€ ë°˜í™˜
        return self.create_agent_message(
            session_id=self.session_id,
            task="ai_task_completed",
            content_text="AI ë‹µë³€ ì²˜ë¦¬ ì™„ë£Œ",
            from_agent="orchestrator", 
            turn_count=self.session_state.get('turn_count', 0)
        )

    
