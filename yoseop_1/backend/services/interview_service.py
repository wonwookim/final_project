#!/usr/bin/env python3
"""
Î©¥Ï†ë ÏÑúÎπÑÏä§
Î™®Îì† Î©¥Ï†ë Í¥ÄÎ†® ÎπÑÏ¶àÎãàÏä§ Î°úÏßÅÏùÑ Îã¥ÎãπÌïòÎäî ÏÑúÎπÑÏä§ Í≥ÑÏ∏µ
"""

import asyncio
import os
import json
from typing import Dict, List, Any, Optional
from pathlib import Path
import uuid
import time

# ÌÜµÌï© ÏÑ∏ÏÖò Í¥ÄÎ¶¨ Î™®Îìà (FinalInterviewSystem ÎåÄÏ≤¥)
from llm.session import SessionManager, InterviewSession, ComparisonSession
# ÏÉàÎ°úÏö¥ ÌÑ¥Ï†ú Î©¥Ï†ëÍ¥Ä ÏãúÏä§ÌÖú
from llm.interviewer.service import InterviewerService

# Î¨∏ÏÑú Ï≤òÎ¶¨ Î∞è AI Î™®Îç∏
from llm.interviewer.document_processor import DocumentProcessor, UserProfile
from llm.candidate.model import AICandidateModel
from llm.feedback.service import FeedbackService
from llm.shared.models import QuestionAnswer, QuestionType
from llm.shared.constants import ALLOWED_FILE_EXTENSIONS, MAX_FILE_SIZE
from llm.shared.logging_config import interview_logger, performance_logger

class InterviewService:
    """Î©¥Ï†ë ÏÑúÎπÑÏä§ - Î™®Îì† Î©¥Ï†ë Í¥ÄÎ†® Î°úÏßÅÏùÑ Îã¥Îãπ"""
    
    def __init__(self):
        """ÏÑúÎπÑÏä§ Ï¥àÍ∏∞Ìôî"""
        # üÜï ÌÜµÌï© ÏÑ∏ÏÖò Í¥ÄÎ¶¨Ïûê (FinalInterviewSystem + PersonalizedInterviewSystem ÌÜµÌï©)
        self.session_manager = SessionManager()
        
        # üöÄ ÏÉàÎ°úÏö¥ ÌÑ¥Ï†ú Î©¥Ï†ëÍ¥Ä ÏãúÏä§ÌÖú
        self.interviewer_service = InterviewerService()
        
        # Î≥¥Ï°∞ ÏÑúÎπÑÏä§Îì§
        self.document_processor = DocumentProcessor()
        self.ai_candidate_model = AICandidateModel()
        self.feedback_service = FeedbackService()
        
        # üîÑ Îçî Ïù¥ÏÉÅ ÌïÑÏöî ÏóÜÏùå - SessionManagerÍ∞Ä Î™®Îì† ÏÑ∏ÏÖòÏùÑ Í¥ÄÎ¶¨
        # self.comparison_sessions = {}
        
        # ÌöåÏÇ¨ Ïù¥Î¶Ñ Îß§Ìïë
        self.company_name_map = {
            "ÎÑ§Ïù¥Î≤Ñ": "naver",
            "Ïπ¥Ïπ¥Ïò§": "kakao", 
            "ÎùºÏù∏": "line",
            "Ïø†Ìå°": "coupang",
            "Î∞∞Îã¨ÏùòÎØºÏ°±": "baemin",
            "ÎãπÍ∑ºÎßàÏºì": "daangn", 
            "ÌÜ†Ïä§": "toss"
        }
    
    def get_company_id(self, company_name: str) -> str:
        """ÌöåÏÇ¨ Ïù¥Î¶ÑÏùÑ IDÎ°ú Î≥ÄÌôò"""
        return self.company_name_map.get(company_name, company_name.lower())
    
    async def start_interview(self, settings: Dict[str, Any]) -> Dict[str, Any]:
        """ÏùºÎ∞ò Î©¥Ï†ë ÏãúÏûë (SessionManager ÏÇ¨Ïö©)"""
        try:
            company_id = self.get_company_id(settings['company'])
            
            # üÜï SessionManagerÎ•º ÌÜµÌïú ÌëúÏ§Ä Î©¥Ï†ë ÏãúÏûë (FinalInterviewSystem Í∏∞Îä• ÌÜµÌï©)
            session_id = self.session_manager.start_interview(
                company_id=company_id,
                position=settings['position'],
                candidate_name=settings['candidate_name']
            )
            
            interview_logger.info(f"Î©¥Ï†ë ÏãúÏûë - ÏÑ∏ÏÖò ID: {session_id}")
            
            return {
                "session_id": session_id,
                "message": "Î©¥Ï†ëÏù¥ ÏãúÏûëÎêòÏóàÏäµÎãàÎã§."
            }
            
        except Exception as e:
            interview_logger.error(f"Î©¥Ï†ë ÏãúÏûë Ïò§Î•ò: {str(e)}")
            raise Exception(f"Î©¥Ï†ë ÏãúÏûë Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}")
    
    async def upload_document(self, file_data: Dict[str, Any]) -> Dict[str, Any]:
        """Î¨∏ÏÑú ÏóÖÎ°úÎìú Î∞è Î∂ÑÏÑù"""
        try:
            # ÌååÏùº Í≤ÄÏ¶ù
            filename = file_data['filename']
            content = file_data['content']
            
            if not filename.lower().endswith(tuple(ALLOWED_FILE_EXTENSIONS)):
                raise ValueError("ÏßÄÏõêÌïòÏßÄ ÏïäÎäî ÌååÏùº ÌòïÏãùÏûÖÎãàÎã§.")
            
            # ÌååÏùº Ï†ÄÏû•
            upload_dir = Path("uploads")
            upload_dir.mkdir(exist_ok=True)
            
            file_path = upload_dir / f"{uuid.uuid4()}_{filename}"
            
            with open(file_path, "wb") as buffer:
                buffer.write(content)
            
            # Î¨∏ÏÑú Î∂ÑÏÑù
            analyzed_content = await self._analyze_document_async(file_path)
            
            return {
                "file_id": str(file_path),
                "analyzed_content": analyzed_content,
                "message": "Î¨∏ÏÑú ÏóÖÎ°úÎìú Î∞è Î∂ÑÏÑùÏù¥ ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§."
            }
            
        except Exception as e:
            interview_logger.error(f"Î¨∏ÏÑú ÏóÖÎ°úÎìú Ïò§Î•ò: {str(e)}")
            raise Exception(f"Î¨∏ÏÑú ÏóÖÎ°úÎìú Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}")
    
    async def get_next_question(self, session_id: str) -> Dict[str, Any]:
        """Îã§Ïùå ÏßàÎ¨∏ Í∞ÄÏ†∏Ïò§Í∏∞ (SessionManager ÏÇ¨Ïö©)"""
        try:
            # üÜï SessionManagerÎ•º ÌÜµÌïú ÏßàÎ¨∏ Í∞ÄÏ†∏Ïò§Í∏∞
            question_data = self.session_manager.get_next_question(session_id)
            
            if not question_data:
                return {"completed": True, "message": "Î™®Îì† ÏßàÎ¨∏Ïù¥ ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§."}
            
            # ÏßÑÌñâÎ•† Ï†ïÎ≥¥ Í≥ÑÏÇ∞
            session = self.session_manager.get_session(session_id)
            if session:
                current_index = session.current_question_count
                total_questions = len(session.question_plan)
                progress = (current_index / total_questions) * 100 if total_questions > 0 else 0
            else:
                current_index = 0
                total_questions = 20
                progress = 0
            
            return {
                "question": {
                    "id": question_data["question_id"],
                    "question": question_data["question_content"],
                    "category": question_data["question_type"],
                    "time_limit": question_data.get("time_limit", 120),
                    "keywords": question_data.get("keywords", [])
                },
                "question_index": current_index,
                "total_questions": total_questions,
                "progress": progress
            }
            
        except Exception as e:
            interview_logger.error(f"ÏßàÎ¨∏ Í∞ÄÏ†∏Ïò§Í∏∞ Ïò§Î•ò: {str(e)}")
            raise Exception(f"ÏßàÎ¨∏ÏùÑ Í∞ÄÏ†∏Ïò§Îäî Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}")
    
    async def submit_answer(self, answer_data: Dict[str, Any]) -> Dict[str, Any]:
        """ÎãµÎ≥Ä Ï†úÏ∂ú (SessionManager ÏÇ¨Ïö©)"""
        try:
            session_id = answer_data['session_id']
            answer = answer_data['answer']
            
            # üÜï SessionManagerÎ•º ÌÜµÌïú ÎãµÎ≥Ä Ï†úÏ∂ú
            result = self.session_manager.submit_answer(session_id, answer)
            
            if "error" in result:
                raise Exception(result["error"])
            
            return {
                "status": result.get("status", "success"),
                "message": result.get("message", "ÎãµÎ≥ÄÏù¥ ÏÑ±Í≥µÏ†ÅÏúºÎ°ú Ï†úÏ∂úÎêòÏóàÏäµÎãàÎã§."),
                "question": result.get("question"),
                "answered_count": result.get("answered_count", 0),
                "total_questions": result.get("total_questions", 0)
            }
            
        except Exception as e:
            interview_logger.error(f"ÎãµÎ≥Ä Ï†úÏ∂ú Ïò§Î•ò: {str(e)}")
            raise Exception(f"ÎãµÎ≥Ä Ï†úÏ∂ú Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}")
    
    async def get_interview_results(self, session_id: str) -> Dict[str, Any]:
        """Î©¥Ï†ë Í≤∞Í≥º Ï°∞Ìöå (SessionManager ÏÇ¨Ïö©)"""
        try:
            # üÜï SessionManagerÎ•º ÌÜµÌïú Î©¥Ï†ë ÌèâÍ∞Ä
            results = self.session_manager.evaluate_interview(session_id)
            
            if "error" in results:
                raise ValueError(results["error"])
            
            # üßπ Î©¥Ï†ë ÏôÑÎ£å Ïãú ÌéòÎ•¥ÏÜåÎÇò Ï∫êÏãú Ï†ïÎ¶¨ (ÎπÑÍµê Î©¥Ï†ëÏù∏ Í≤ΩÏö∞)
            if session_id.startswith("comp_"):
                try:
                    self.session_manager.comparison_session_manager.clear_session_persona(session_id)
                    interview_logger.info(f"üßπ [CLEANUP] Î©¥Ï†ë ÏôÑÎ£å - ÌéòÎ•¥ÏÜåÎÇò Ï∫êÏãú Ï†ïÎ¶¨: {session_id}")
                except Exception as cleanup_error:
                    interview_logger.warning(f"‚ö†Ô∏è [CLEANUP] ÌéòÎ•¥ÏÜåÎÇò Ï∫êÏãú Ï†ïÎ¶¨ Ïã§Ìå®: {cleanup_error}")
            
            # Í≤∞Í≥ºÍ∞Ä Ïù¥ÎØ∏ ÏôÑÏ†ÑÌïú ÌòïÌÉúÎ°ú Î∞òÌôòÎê®
            return results
            
        except Exception as e:
            interview_logger.error(f"Í≤∞Í≥º Ï°∞Ìöå Ïò§Î•ò: {str(e)}")
            raise Exception(f"Í≤∞Í≥ºÎ•º Ï°∞ÌöåÌïòÎäî Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}")
    
    async def start_ai_competition(self, settings: Dict[str, Any]) -> Dict[str, Any]:
        """AI ÏßÄÏõêÏûêÏôÄÏùò Í≤ΩÏüÅ Î©¥Ï†ë ÏãúÏûë (SessionManager ÏÇ¨Ïö©)"""
        try:
            interview_logger.info("AI ÎπÑÍµê Î©¥Ï†ë ÏãúÏûë")
            
            # üÜï DB Í∏∞Î∞ò Ï†ïÎ≥¥Í∞Ä ÏûàÏúºÎ©¥ ÏÇ¨Ïö©, ÏóÜÏúºÎ©¥ Í∏∞Ï°¥ Î∞©Ïãù
            if settings.get('company_id') and settings.get('position_id'):
                company_id = settings['company_id']
                interview_logger.info(f"üìã DB Í∏∞Î∞ò Ï†ïÎ≥¥ ÏÇ¨Ïö©: company_id={company_id}, position_id={settings.get('position_id')}")
            else:
                # Í∏∞Ï°¥ Î∞©Ïãù: ÌöåÏÇ¨Î™ÖÏúºÎ°ú company_id Ï∞æÍ∏∞
                company_id = self.get_company_id(settings['company'])
            
            # üÜï SessionManagerÎ•º ÌÜµÌïú ÎπÑÍµê Î©¥Ï†ë ÏãúÏûë (ÏÉàÎ°úÏö¥ 20Í∞ú ÏßàÎ¨∏ ÏãúÏä§ÌÖú)
            comparison_session_id = await self.session_manager.start_comparison_interview(
                company_id=company_id,
                position=settings['position'],
                user_name=settings['candidate_name'],
                ai_name="Ï∂òÏãùÏù¥",
                posting_id=settings.get('posting_id'),  # üÜï posting_id Ï†ÑÎã¨
                position_id=settings.get('position_id')  # üÜï position_id Ï†ÑÎã¨
            )
            
            # AI Ïù¥Î¶Ñ Í∞ÄÏ†∏Ïò§Í∏∞
            from llm.core.llm_manager import LLMProvider
            ai_name = self.ai_candidate_model.get_ai_name(LLMProvider.OPENAI_GPT4O_MINI)
            
            # ÎûúÎç§ÏúºÎ°ú ÏãúÏûëÏûê Í≤∞Ï†ï
            import random
            starts_with_user = random.choice([True, False])
            
            if starts_with_user:
                # ÏÇ¨Ïö©ÏûêÎ∂ÄÌÑ∞ ÏãúÏûë - Ï≤´ ÏßàÎ¨∏ Í∞ÄÏ†∏Ïò§Í∏∞
                first_question = self.session_manager.get_comparison_next_question(comparison_session_id)
                
                return {
                    "session_id": comparison_session_id,
                    "comparison_session_id": comparison_session_id,
                    "user_session_id": comparison_session_id + "_user",
                    "ai_session_id": comparison_session_id + "_ai",
                    "question": first_question,
                    "current_phase": "user_turn",
                    "current_respondent": settings['candidate_name'],
                    "question_index": 1,
                    "total_questions": 20,
                    "ai_name": ai_name,
                    "starts_with_user": True,
                    "message": f"{settings['candidate_name']}ÎãòÎ∂ÄÌÑ∞ ÏãúÏûëÌï©ÎãàÎã§"
                }
            else:
                # AIÎ∂ÄÌÑ∞ ÏãúÏûë - Ï≤´ ÏßàÎ¨∏ÎèÑ Ìï®Íªò Ï†úÍ≥µ
                first_question = self.session_manager.get_comparison_next_question(comparison_session_id)
                
                return {
                    "session_id": comparison_session_id,
                    "comparison_session_id": comparison_session_id,
                    "user_session_id": comparison_session_id + "_user",
                    "ai_session_id": comparison_session_id + "_ai",
                    "question": first_question,
                    "current_phase": "ai_turn",
                    "current_respondent": ai_name,
                    "question_index": 1,
                    "total_questions": 20,
                    "ai_name": ai_name,
                    "user_name": settings['candidate_name'],
                    "starts_with_user": False,
                    "message": f"{ai_name}Î∂ÄÌÑ∞ ÏãúÏûëÌï©ÎãàÎã§"
                }
            
        except Exception as e:
            interview_logger.error(f"AI Í≤ΩÏüÅ Î©¥Ï†ë ÏãúÏûë Ïò§Î•ò: {str(e)}")
            raise Exception(f"AI Í≤ΩÏüÅ Î©¥Ï†ë ÏãúÏûë Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}")
    
    async def get_ai_answer(self, session_id: str, question_id: str) -> Dict[str, Any]:
        """AI ÏßÄÏõêÏûêÏùò ÎãµÎ≥Ä ÏÉùÏÑ±"""
        try:
            # URL ÎîîÏΩîÎî©
            import urllib.parse
            decoded_session_id = urllib.parse.unquote(session_id)
            
            # ÏÑ∏ÏÖò IDÏóêÏÑú ÌöåÏÇ¨ÏôÄ Ìè¨ÏßÄÏÖò ÌååÏã±
            session_parts = decoded_session_id.split('_')
            company_id = session_parts[0] if len(session_parts) > 0 else "naver"
            position = "_".join(session_parts[1:-1]) if len(session_parts) > 2 else "Î∞±ÏóîÎìú Í∞úÎ∞ú"
            
            # AI ÏÑ∏ÏÖò ÏãúÏûëÌïòÍ≥† ÏßàÎ¨∏ Í∞ÄÏ†∏Ïò§Í∏∞
            ai_session_id = self.ai_candidate_model.start_ai_interview(company_id, position)
            ai_question_data = self.ai_candidate_model.get_ai_next_question(ai_session_id)
            
            if ai_question_data:
                question_content = ai_question_data["question_content"]
                question_intent = ai_question_data["question_intent"]
                question_type = ai_question_data["question_type"]
            else:
                # Ìè¥Î∞± ÏßàÎ¨∏
                if question_id == "q_1":
                    question_content = "Ï∂òÏãùÏù¥, ÏûêÍ∏∞ÏÜåÍ∞úÎ•º Î∂ÄÌÉÅÎìúÎ¶ΩÎãàÎã§."
                    question_intent = "ÏßÄÏõêÏûêÏùò Í∏∞Î≥∏ Ï†ïÎ≥¥ÏôÄ ÏÑ±Í≤©, Ïó≠ÎüâÏùÑ ÌååÏïÖ"
                    question_type = "INTRO"
                elif question_id == "q_2":
                    question_content = f"Ï∂òÏãùÏù¥ÍªòÏÑú ÎÑ§Ïù¥Î≤ÑÏóê ÏßÄÏõêÌïòÍ≤å Îêú ÎèôÍ∏∞Îäî Î¨¥ÏóáÏù∏Í∞ÄÏöî?"
                    question_intent = "ÌöåÏÇ¨Ïóê ÎåÄÌïú Í¥ÄÏã¨ÎèÑÏôÄ ÏßÄÏõê ÎèôÍ∏∞ ÌååÏïÖ"
                    question_type = "MOTIVATION"
                else:
                    question_content = "Ï∂òÏãùÏù¥Ïóê ÎåÄÌï¥ Îçî ÏïåÎ†§Ï£ºÏÑ∏Ïöî."
                    question_intent = "ÏùºÎ∞òÏ†ÅÏù∏ ÌèâÍ∞Ä"
                    question_type = "HR"
            
            # AI ÎãµÎ≥Ä ÏÉùÏÑ±
            from llm.candidate.model import AnswerRequest
            from llm.shared.models import QuestionType
            from llm.candidate.quality_controller import QualityLevel
            from llm.core.llm_manager import LLMProvider
            
            # QuestionType Îß§Ìïë
            question_type_map = {
                "INTRO": QuestionType.INTRO,
                "MOTIVATION": QuestionType.MOTIVATION,
                "HR": QuestionType.HR,
                "TECH": QuestionType.TECH,
                "COLLABORATION": QuestionType.COLLABORATION
            }
            
            answer_request = AnswerRequest(
                question_content=question_content,
                question_type=question_type_map.get(question_type, QuestionType.HR),
                question_intent=question_intent,
                company_id=company_id,
                position=position,
                quality_level=QualityLevel.GOOD,
                llm_provider=LLMProvider.OPENAI_GPT4O_MINI
            )
            
            # üîÑ Îã®ÎèÖ AI ÎãµÎ≥Ä ÏÉùÏÑ± (ÏÑ∏ÏÖò ÏóÜÏùå - Îß§Î≤à ÏÉàÎ°úÏö¥ ÌéòÎ•¥ÏÜåÎÇò)
            interview_logger.info(f"üé≠ [STANDALONE AI] Îã®ÎèÖ AI ÎãµÎ≥Ä ÏÉùÏÑ± (ÏÑ∏ÏÖò Î¨¥Í¥Ä): {company_id} - {position}")
            ai_answer = self.ai_candidate_model.generate_answer(answer_request, persona=None)
            
            if not ai_answer:
                raise Exception("AI ÎãµÎ≥Ä ÏÉùÏÑ±Ïóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.")
            
            return {
                "question": question_content,
                "questionType": question_type,
                "questionIntent": question_intent,
                "answer": ai_answer.answer_content,
                "time_spent": 60,
                "score": 85,
                "quality_level": ai_answer.quality_level.value,
                "persona_name": ai_answer.persona_name
            }
            
        except Exception as e:
            interview_logger.error(f"AI ÎãµÎ≥Ä ÏÉùÏÑ± Ïò§Î•ò: {str(e)}")
            raise Exception(f"AI ÎãµÎ≥Ä ÏÉùÏÑ± Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}")
    
    async def submit_comparison_user_turn(self, answer_data: Dict[str, Any]) -> Dict[str, Any]:
        """ÎπÑÍµê Î©¥Ï†ë ÏÇ¨Ïö©Ïûê ÌÑ¥ ÎãµÎ≥Ä Ï†úÏ∂ú (SessionManager ÏÇ¨Ïö©)"""
        try:
            comparison_session_id = answer_data['comparison_session_id']
            answer = answer_data['answer']
            
            # üÜï SessionManagerÎ•º ÌÜµÌïú ÎπÑÍµê ÏÑ∏ÏÖò ÎãµÎ≥Ä Ï†úÏ∂ú (ÌÑ¥ Í¥ÄÎ¶¨Îäî ÎÇ¥Î∂ÄÏóêÏÑú Ï≤òÎ¶¨Îê®)
            result = self.session_manager.submit_comparison_answer(
                comparison_session_id, answer, "human"
            )
            
            # ÏÑ∏ÏÖò ÏÉÅÌÉú ÌôïÏù∏
            session = self.session_manager.get_comparison_session(comparison_session_id)
            interview_logger.info(f"üîç ÏÇ¨Ïö©Ïûê ÎãµÎ≥Ä Ï†úÏ∂ú ÌõÑ ÏÑ∏ÏÖò ÏÉÅÌÉú: current_question_index={session.current_question_index}, total_questions={session.total_questions}, is_complete={session.is_complete()}")
            
            # üÜï Î©¥Ï†ë ÏôÑÎ£å ÌôïÏù∏ (ÏÑ∏ÏÖòÏùò is_complete Î©îÏÑúÎìú ÏÇ¨Ïö©)
            if session and session.is_complete():
                interview_logger.info(f"‚úÖ ÏÇ¨Ïö©Ïûê ÌÑ¥ÏóêÏÑú Î©¥Ï†ë ÏôÑÎ£å ÌôïÏù∏: {session.current_question_index}/{session.total_questions}")
                return {
                    "status": "success",
                    "message": "ÎπÑÍµê Î©¥Ï†ëÏù¥ ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§",
                    "next_phase": "completed",
                    "interview_status": "completed",
                    "progress": {
                        "current": session.current_question_index,
                        "total": session.total_questions,
                        "percentage": 100
                    }
                }
            
            return {
                "status": "success", 
                "message": "ÏÇ¨Ïö©Ïûê ÎãµÎ≥ÄÏù¥ Ï†úÏ∂úÎêòÏóàÏäµÎãàÎã§",
                "next_phase": session.current_phase,  # ÏÑ∏ÏÖòÏóêÏÑú Í¥ÄÎ¶¨ÎêòÎäî ÌòÑÏû¨ ÌéòÏù¥Ï¶à
                "submission_result": result,
                "next_question": result.get("next_question"),  # Îëò Îã§ ÎãµÎ≥ÄÌñàÏùÑ ÎïåÏùò Îã§Ïùå ÏßàÎ¨∏
                "progress": {
                    "current": session.current_question_index + 1,  # ÌòÑÏû¨ ÏßÑÌñâ Ï§ëÏù∏ ÏßàÎ¨∏ Î≤àÌò∏
                    "total": session.total_questions,
                    "percentage": ((session.current_question_index + 1) / session.total_questions) * 100
                }
            }
            
        except Exception as e:
            interview_logger.error(f"ÏÇ¨Ïö©Ïûê ÌÑ¥ Ï†úÏ∂ú Ïò§Î•ò: {str(e)}")
            raise Exception(f"ÎãµÎ≥Ä Ï†úÏ∂ú Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}")
    
    async def process_comparison_ai_turn(self, ai_turn_data: Dict[str, Any]) -> Dict[str, Any]:
        """ÎπÑÍµê Î©¥Ï†ë AI ÌÑ¥ Ï≤òÎ¶¨ (SessionManager ÏÇ¨Ïö©)"""
        try:
            comparison_session_id = ai_turn_data['comparison_session_id']
            step = ai_turn_data.get('step', 'question')
            
            if step == 'question':
                # üÜï SessionManagerÎ•º ÌÜµÌïú AI ÏßàÎ¨∏ ÏÉùÏÑ±
                ai_question = self.session_manager.get_comparison_next_question(comparison_session_id)
                
                if not ai_question:
                    raise Exception("AI ÏßàÎ¨∏ÏùÑ ÏÉùÏÑ±Ìï† Ïàò ÏóÜÏäµÎãàÎã§")
                
                return {
                    "status": "success",
                    "step": "question_generated",
                    "ai_question": ai_question,
                    "message": "AI ÏßàÎ¨∏Ïù¥ ÏÉùÏÑ±ÎêòÏóàÏäµÎãàÎã§. 2-3Ï¥à ÌõÑ ÎãµÎ≥ÄÏù¥ ÏÉùÏÑ±Îê©ÎãàÎã§."
                }
                
            elif step == 'answer':
                # AI ÎãµÎ≥Ä ÏÉùÏÑ± Î∞è Ï†úÏ∂ú
                session = self.session_manager.get_comparison_session(comparison_session_id)
                if not session:
                    raise ValueError("ÎπÑÍµê ÏÑ∏ÏÖòÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§")
                
                # AI ÎãµÎ≥Ä ÏÉùÏÑ± Î°úÏßÅ (Í∏∞Ï°¥Í≥º ÎèôÏùº)
                from llm.candidate.model import AnswerRequest
                from llm.shared.models import QuestionType
                from llm.candidate.quality_controller import QualityLevel
                from llm.core.llm_manager import LLMProvider
                
                # ÌòÑÏû¨ ÏßàÎ¨∏ Í∞ÄÏ†∏Ïò§Í∏∞ (SessionManagerÏóêÏÑú Îã§Ïùå ÏßàÎ¨∏ Ï°∞ÌöåÎ•º ÌÜµÌï¥ ÌòÑÏû¨ ÏßàÎ¨∏ ÌôïÏù∏)
                current_question = self.session_manager.get_comparison_next_question(comparison_session_id)
                ai_question_content = current_question.get("question_content", "ÏûêÍ∏∞ÏÜåÍ∞úÎ•º Ìï¥Ï£ºÏÑ∏Ïöî.") if current_question else "ÏûêÍ∏∞ÏÜåÍ∞úÎ•º Ìï¥Ï£ºÏÑ∏Ïöî."
                
                answer_request = AnswerRequest(
                    question_content=ai_question_content,
                    question_type=QuestionType.HR,
                    question_intent="AI ÏßÄÏõêÏûê Ïó≠Îüâ ÌèâÍ∞Ä",
                    company_id=session.company_id,
                    position=getattr(session, 'position', 'Î∞±ÏóîÎìú Í∞úÎ∞úÏûê'),  # ÏÑ∏ÏÖòÏóêÏÑú position Í∞ÄÏ†∏Ïò§Í∏∞
                    quality_level=QualityLevel.GOOD,
                    llm_provider=LLMProvider.OPENAI_GPT4O_MINI
                )
                
                # ÎîîÎ≤ÑÍπÖÏùÑ ÏúÑÌïú Î°úÍπÖ
                interview_logger.info(f"üéØ AI ÎãµÎ≥Ä ÏÉùÏÑ± ÏöîÏ≤≠: {session.company_id} - {getattr(session, 'position', 'Î∞±ÏóîÎìú Í∞úÎ∞úÏûê')}")
                interview_logger.info(f"üìù ÏßàÎ¨∏ ÎÇ¥Ïö©: {ai_question_content}")
                
                # üÜï ÏÑ∏ÏÖòÎ≥Ñ ÌéòÎ•¥ÏÜåÎÇò Ï°∞Ìöå Î∞è ÏÉùÏÑ±
                session_persona = self.session_manager.comparison_session_manager.get_session_persona(comparison_session_id)
                
                if not session_persona:
                    # ÌéòÎ•¥ÏÜåÎÇòÍ∞Ä ÏóÜÏúºÎ©¥ ÏÉùÏÑ±ÌïòÍ≥† Ï∫êÏãúÏóê Ï†ÄÏû•
                    interview_logger.info(f"üé≠ [PERSONA] ÏÑ∏ÏÖò ÌéòÎ•¥ÏÜåÎÇò ÏÉùÏÑ± Ï§ë: {comparison_session_id}")
                    session_persona = self.ai_candidate_model.create_persona_for_interview(
                        session.company_id, 
                        getattr(session, 'position', 'Î∞±ÏóîÎìú Í∞úÎ∞úÏûê')
                    )
                    
                    if session_persona:
                        # ÏÉùÏÑ±Îêú ÌéòÎ•¥ÏÜåÎÇòÎ•º ÏÑ∏ÏÖòÏóê Ï†ÄÏû•
                        self.session_manager.comparison_session_manager.set_session_persona(comparison_session_id, session_persona)
                        interview_logger.info(f"‚úÖ [PERSONA] ÌéòÎ•¥ÏÜåÎÇò ÏÉùÏÑ± Î∞è Ï†ÄÏû• ÏôÑÎ£å: {session_persona.name}")
                    else:
                        interview_logger.error(f"‚ùå [PERSONA] ÌéòÎ•¥ÏÜåÎÇò ÏÉùÏÑ± Ïã§Ìå®: {comparison_session_id}")
                else:
                    interview_logger.info(f"‚úÖ [PERSONA] Í∏∞Ï°¥ ÏÑ∏ÏÖò ÌéòÎ•¥ÏÜåÎÇò Ïû¨ÏÇ¨Ïö©: {session_persona.name}")
                
                # ÌéòÎ•¥ÏÜåÎÇòÏôÄ Ìï®Íªò ÎãµÎ≥Ä ÏÉùÏÑ±
                ai_answer_response = self.ai_candidate_model.generate_answer(answer_request, persona=session_persona)
                
                interview_logger.info(f"‚úÖ AI ÎãµÎ≥Ä ÏÉùÏÑ± ÏôÑÎ£å: ÌéòÎ•¥ÏÜåÎÇò={ai_answer_response.persona_name}")
                
                if ai_answer_response.error:
                    interview_logger.error(f"‚ùå AI ÎãµÎ≥Ä ÏÉùÏÑ± Ïã§Ìå®: {ai_answer_response.error}")
                    raise Exception(f"AI ÎãµÎ≥Ä ÏÉùÏÑ± Ïã§Ìå®: {ai_answer_response.error}")
                
                # üÜï SessionManagerÎ•º ÌÜµÌïú AI ÎãµÎ≥Ä Ï†úÏ∂ú (ÌÑ¥ Í¥ÄÎ¶¨Îäî ÎÇ¥Î∂ÄÏóêÏÑú Ï≤òÎ¶¨Îê®)
                ai_submit_result = self.session_manager.submit_comparison_answer(
                    comparison_session_id, ai_answer_response.answer_content, "ai"
                )
                
                # üÜï ÏÑ∏ÏÖò ÏôÑÎ£å ÌôïÏù∏ (ÏÑ∏ÏÖòÏùò is_complete Î©îÏÑúÎìú ÏÇ¨Ïö©)
                updated_session = self.session_manager.get_comparison_session(comparison_session_id)
                interview_logger.info(f"üîç AI ÎãµÎ≥Ä Ï†úÏ∂ú ÌõÑ ÏÑ∏ÏÖò ÏÉÅÌÉú: current_question_index={updated_session.current_question_index}, total_questions={updated_session.total_questions}, is_complete={updated_session.is_complete()}")
                
                # ÏÑ∏ÏÖò ÏôÑÎ£å Ïó¨Î∂Ä ÌôïÏù∏
                if updated_session and updated_session.is_complete():
                    interview_logger.info(f"‚úÖ ÎπÑÍµê Î©¥Ï†ë ÏôÑÎ£å: {updated_session.current_question_index}/{updated_session.total_questions}")
                    return {
                        "status": "success",
                        "step": "answer_generated",
                        "interview_status": "completed",
                        "ai_answer": {
                            "content": ai_answer_response.answer_content,
                            "persona_name": ai_answer_response.persona_name,
                            "confidence": ai_answer_response.confidence_score
                        },
                        "message": f"ÎπÑÍµê Î©¥Ï†ëÏù¥ ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§ ({updated_session.current_question_index}/{updated_session.total_questions} ÏßàÎ¨∏ ÏôÑÎ£å)"
                    }
                else:
                    interview_logger.info(f"üîÑ Î©¥Ï†ë Í≥ÑÏÜç: {updated_session.current_question_index + 1}/{updated_session.total_questions} ÏßàÎ¨∏ ÏßÑÌñâ Ï§ë")
                    return {
                        "status": "success",
                        "step": "answer_generated", 
                        "interview_status": "continue",
                        "ai_answer": {
                            "content": ai_answer_response.answer_content,
                            "persona_name": ai_answer_response.persona_name,
                            "confidence": ai_answer_response.confidence_score
                        },
                        "next_question": ai_submit_result.get("next_question"),  # ÏÑ∏ÏÖòÏóêÏÑú Î∞òÌôòÎêú Îã§Ïùå ÏßàÎ¨∏
                        "next_user_question": ai_submit_result.get("next_question"),  # ÌîÑÎ°†Ìä∏ÏóîÎìú Ìò∏ÌôòÏÑ±ÏùÑ ÏúÑÌïú Ï§ëÎ≥µ ÌïÑÎìú
                        "next_phase": updated_session.current_phase,  # ÏÑ∏ÏÖòÏóêÏÑú Í¥ÄÎ¶¨ÎêòÎäî ÌòÑÏû¨ ÌéòÏù¥Ï¶à
                        "progress": {
                            "current": updated_session.current_question_index + 1,  # ÌòÑÏû¨ ÏßÑÌñâ Ï§ëÏù∏ ÏßàÎ¨∏ Î≤àÌò∏
                            "total": updated_session.total_questions,
                            "percentage": ((updated_session.current_question_index + 1) / updated_session.total_questions) * 100
                        }
                    }
            else:
                raise ValueError("Ïú†Ìö®ÌïòÏßÄ ÏïäÏùÄ step Í∞íÏûÖÎãàÎã§")
                
        except Exception as e:
            interview_logger.error(f"AI ÌÑ¥ Ï≤òÎ¶¨ Ïò§Î•ò: {str(e)}")
            raise Exception(f"AI ÌÑ¥ Ï≤òÎ¶¨ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}")
    
    async def get_interview_history(self, user_id: str = None) -> Dict[str, Any]:
        """Î©¥Ï†ë Í∏∞Î°ù Ï°∞Ìöå (SessionManager ÏÇ¨Ïö©)"""
        try:
            completed_sessions = []
            
            # üÜï SessionManagerÏùò Î™®Îì† ÏÑ∏ÏÖò Í∞ÄÏ†∏Ïò§Í∏∞
            all_sessions = self.session_manager.get_all_sessions()
            
            for session_info in all_sessions:
                if session_info.get("state") == "completed":
                    completed_sessions.append({
                        "session_id": session_info["session_id"],
                        "settings": {
                            "company": session_info.get("company_id", "unknown"),
                            "position": session_info.get("position", "unknown"),
                            "user_name": session_info.get("candidate_name", session_info.get("user_name", "unknown"))
                        },
                        "completed_at": session_info.get("created_at", ""),
                        "total_score": 85,  # Í∏∞Î≥∏Í∞í
                        "type": session_info.get("type", "standard")
                    })
            
            return {
                "total_interviews": len(completed_sessions),
                "interviews": completed_sessions
            }
            
        except Exception as e:
            interview_logger.error(f"Í∏∞Î°ù Ï°∞Ìöå Ïò§Î•ò: {str(e)}")
            raise Exception(f"Í∏∞Î°ùÏùÑ Ï°∞ÌöåÌïòÎäî Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}")
    
    # üöÄ ÏÉàÎ°úÏö¥ ÌÑ¥Ï†ú Î©¥Ï†ë ÏãúÏä§ÌÖú Î©îÏÑúÎìúÎì§
    
    async def start_turn_based_interview(self, settings: Dict[str, Any]) -> Dict[str, Any]:
        """ÌÑ¥Ï†ú Î©¥Ï†ë ÏãúÏûë - ÏÉàÎ°úÏö¥ InterviewerService ÏÇ¨Ïö©"""
        try:
            company_id = self.get_company_id(settings['company'])
            
            # ÏÑ∏ÏÖò ID ÏÉùÏÑ±
            session_id = f"turn_{company_id}_{settings['position']}_{uuid.uuid4().hex[:8]}"
            
            # ÏÇ¨Ïö©Ïûê Ïù¥Î†•ÏÑú Ï†ïÎ≥¥ (ÏûÑÏãú)
            user_resume = {
                'name': settings['candidate_name'],
                'career_years': '3',
                'technical_skills': ['Python', 'Django', 'PostgreSQL', 'AWS']
            }
            
            # AI ÏßÄÏõêÏûê ÌéòÎ•¥ÏÜåÎÇò ÏÉùÏÑ±
            from llm.candidate.model import CandidatePersona
            ai_persona = CandidatePersona(
                name='Ï∂òÏãùÏù¥', summary='3ÎÖÑÏ∞® Python Î∞±ÏóîÎìú Í∞úÎ∞úÏûê',
                background={'career_years': '3', 'current_position': 'Î∞±ÏóîÎìú Í∞úÎ∞úÏûê'},
                technical_skills=['Python', 'Django', 'PostgreSQL', 'AWS'],
                projects=[{'name': 'Ïù¥Ïª§Î®∏Ïä§ ÌîåÎû´Ìèº', 'description': 'ÎåÄÏö©Îüâ Ìä∏ÎûòÌîΩ Ï≤òÎ¶¨'}],
                experiences=[{'company': 'Ïä§ÌÉÄÌä∏ÏóÖ', 'position': 'Í∞úÎ∞úÏûê', 'period': '3ÎÖÑ'}],
                strengths=['Î¨∏Ï†ú Ìï¥Í≤∞', 'ÌïôÏäµ Îä•Î†•'], weaknesses=['ÏôÑÎ≤ΩÏ£ºÏùò'],
                motivation='Ï¢ãÏùÄ ÏÑúÎπÑÏä§Î•º ÎßåÎì§Í≥† Ïã∂Ïñ¥ÏÑú',
                inferred_personal_experiences=[{'experience': 'ÏÑ±Ïû•', 'lesson': 'ÎÅäÏûÑÏóÜÎäî ÌïôÏäµ'}],
                career_goal='ÏãúÎãàÏñ¥ Í∞úÎ∞úÏûêÎ°ú ÏÑ±Ïû•', personality_traits=['ÏπúÍ∑ºÌï®', 'Ï†ÑÎ¨∏ÏÑ±'],
                interview_style='ÏÉÅÌò∏ÏûëÏö©Ï†Å', resume_id=1
            )
            
            # ÏÑ∏ÏÖò ÏÉÅÌÉú Ï†ÄÏû• (Í∞ÑÎã®Ìïú Î©îÎ™®Î¶¨ Ï†ÄÏû•)
            if not hasattr(self, 'turn_based_sessions'):
                self.turn_based_sessions = {}
            
            self.turn_based_sessions[session_id] = {
                'user_resume': user_resume,
                'ai_persona': ai_persona,
                'company_id': company_id,
                'qa_history': [],
                'user_answers': [],
                'ai_answers': [],
                'created_at': time.time()
            }
            
            # Ï≤´ ÏßàÎ¨∏ ÏÉùÏÑ±
            first_question = self.interviewer_service.generate_next_question(
                user_resume, ai_persona, company_id
            )
            
            interview_logger.info(f"ÌÑ¥Ï†ú Î©¥Ï†ë ÏãúÏûë - ÏÑ∏ÏÖò ID: {session_id}")
            
            return {
                "session_id": session_id,
                "question": first_question,
                "total_question_limit": self.interviewer_service.total_question_limit,
                "current_interviewer": self.interviewer_service._get_current_interviewer(),
                "questions_asked": self.interviewer_service.questions_asked_count,
                "message": "ÌÑ¥Ï†ú Î©¥Ï†ëÏù¥ ÏãúÏûëÎêòÏóàÏäµÎãàÎã§."
            }
            
        except Exception as e:
            interview_logger.error(f"ÌÑ¥Ï†ú Î©¥Ï†ë ÏãúÏûë Ïò§Î•ò: {str(e)}")
            raise Exception(f"ÌÑ¥Ï†ú Î©¥Ï†ë ÏãúÏûë Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}")
    
    async def get_turn_based_question(self, session_id: str, user_answer: str = None) -> Dict[str, Any]:
        """ÌÑ¥Ï†ú Î©¥Ï†ë Îã§Ïùå ÏßàÎ¨∏ Í∞ÄÏ†∏Ïò§Í∏∞"""
        try:
            if not hasattr(self, 'turn_based_sessions') or session_id not in self.turn_based_sessions:
                raise ValueError("ÏÑ∏ÏÖòÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§")
            
            session_data = self.turn_based_sessions[session_id]
            
            # ÏÇ¨Ïö©Ïûê ÎãµÎ≥Ä Ï†ÄÏû•
            if user_answer:
                session_data['user_answers'].append(user_answer)
                
                # AI ÎãµÎ≥Ä ÏÉùÏÑ± (Í∞ÑÎã®Ìïú Íµ¨ÌòÑ)
                ai_answer = "Ï†ÄÎäî Í∏∞Ïà†Ï†Å ÏôÑÏÑ±ÎèÑÎ•º Ï§ëÏãúÌïòÎ©∞, ÏΩîÎìú Î¶¨Î∑∞ÏôÄ ÌÖåÏä§Ìä∏Î•º ÌÜµÌï¥ ÏïàÏ†ïÏ†ÅÏù∏ ÏÑúÎπÑÏä§Î•º ÎßåÎì§Î†§Í≥† ÎÖ∏Î†•Ìï©ÎãàÎã§."
                session_data['ai_answers'].append(ai_answer)
            
            # Îã§Ïùå ÏßàÎ¨∏ ÏÉùÏÑ±
            next_question = self.interviewer_service.generate_next_question(
                session_data['user_resume'],
                session_data['ai_persona'], 
                session_data['company_id'],
                session_data['qa_history'],
                user_answer,
                session_data['ai_answers'][-1] if session_data['ai_answers'] else None
            )
            
            # Î©¥Ï†ë Ï¢ÖÎ£å ÌôïÏù∏
            if next_question.get('is_final'):
                return {
                    "completed": True,
                    "message": next_question['question'],
                    "final_stats": {
                        "total_questions": self.interviewer_service.questions_asked_count,
                        "interviewer_stats": self.interviewer_service.interviewer_turn_state
                    }
                }
            
            # ÌÑ¥ Ï†ÑÌôò ÌôïÏù∏
            if next_question.get('force_turn_switch'):
                # Îã§Ïãú ÏßàÎ¨∏ ÏÉùÏÑ± ÏãúÎèÑ
                next_question = self.interviewer_service.generate_next_question(
                    session_data['user_resume'],
                    session_data['ai_persona'], 
                    session_data['company_id'],
                    session_data['qa_history']
                )
            
            # QA ÌûàÏä§ÌÜ†Î¶¨ ÏóÖÎç∞Ïù¥Ìä∏
            session_data['qa_history'].append({
                'question': next_question['question'],
                'interviewer_type': next_question['interviewer_type']
            })
            
            return {
                "question": next_question,
                "session_stats": {
                    "questions_asked": self.interviewer_service.questions_asked_count,
                    "remaining_questions": self.interviewer_service.total_question_limit - self.interviewer_service.questions_asked_count,
                    "current_interviewer": self.interviewer_service._get_current_interviewer(),
                    "turn_states": self.interviewer_service.interviewer_turn_state
                }
            }
            
        except Exception as e:
            interview_logger.error(f"ÌÑ¥Ï†ú ÏßàÎ¨∏ Í∞ÄÏ†∏Ïò§Í∏∞ Ïò§Î•ò: {str(e)}")
            raise Exception(f"ÏßàÎ¨∏ÏùÑ Í∞ÄÏ†∏Ïò§Îäî Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}")
    
    # Ìó¨Ìçº Î©îÏÜåÎìúÎì§
    
    async def _generate_personalized_profile(self, documents: List[str]) -> UserProfile:
        """Î¨∏ÏÑú Í∏∞Î∞ò ÏÇ¨Ïö©Ïûê ÌîÑÎ°úÌïÑ ÏÉùÏÑ± (ÌïÑÏöîÏãú ÏÇ¨Ïö©)"""
        try:
            profile = None
            
            for doc_path in documents:
                if os.path.exists(doc_path):
                    profile = await asyncio.to_thread(
                        self.document_processor.process_document, 
                        doc_path
                    )
                    break
            
            if not profile:
                # Í∏∞Î≥∏ ÌîÑÎ°úÌïÑ ÏÉùÏÑ±
                profile = UserProfile(
                    name="ÏßÄÏõêÏûê",
                    background={"career_years": "3", "education": "ÎåÄÌïôÍµê Ï°∏ÏóÖ"},
                    technical_skills=["Java", "Spring", "MySQL"],
                    projects=[{"name": "Ïõπ ÏÑúÎπÑÏä§ Í∞úÎ∞ú", "description": "Î∞±ÏóîÎìú API Í∞úÎ∞ú"}],
                    experiences=[{"company": "Ïù¥Ï†Ñ ÌöåÏÇ¨", "role": "Î∞±ÏóîÎìú Í∞úÎ∞úÏûê", "duration": "2ÎÖÑ"}],
                    strengths=["Î¨∏Ï†úÌï¥Í≤∞Îä•Î†•", "Ïª§ÎÆ§ÎãàÏºÄÏù¥ÏÖò"],
                    keywords=["Í∞úÎ∞ú", "ÌòëÏóÖ", "ÏÑ±Ïû•"],
                    career_goal="ÏãúÎãàÏñ¥ Í∞úÎ∞úÏûêÎ°ú ÏÑ±Ïû•",
                    unique_points=["Îπ†Î•∏ ÌïôÏäµ Îä•Î†•"]
                )
            
            return profile
            
        except Exception as e:
            interview_logger.error(f"ÌîÑÎ°úÌïÑ ÏÉùÏÑ± Ïò§Î•ò: {str(e)}")
            return None
    
    async def _analyze_document_async(self, file_path: Path) -> Dict:
        """Î¨∏ÏÑú Î∂ÑÏÑù (ÎπÑÎèôÍ∏∞)"""
        try:
            result = await asyncio.get_event_loop().run_in_executor(
                None,
                self.document_processor.process_document,
                str(file_path)
            )
            return result
        except Exception as e:
            interview_logger.error(f"Î¨∏ÏÑú Î∂ÑÏÑù Ïò§Î•ò: {str(e)}")
            return {}