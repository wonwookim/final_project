import json
import json
from typing import Dict, Any, List, Optional
import asyncio
import uuid
import time
from llm.interviewer.question_generator import QuestionGenerator
from llm.candidate.model import AICandidateModel, CandidatePersona
from llm.shared.models import AnswerRequest, QuestionType, LLMProvider
from llm.candidate.quality_controller import QualityLevel
from llm.shared.logging_config import interview_logger

from backend.services.Orchestrator import Orchestrator

class InterviewService:
    def __init__(self):
        self.active_orchestrators: Dict[str, Orchestrator] = {}
        self.question_generator = QuestionGenerator()
        self.ai_candidate_model = AICandidateModel()
        
        # ì—ì´ì „íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡
        self.agent_handlers = {
            "interviewer": self._handle_interviewer_message,
            "ai": self._handle_ai_candidate_message,
            "user": self._handle_user_message
        }
        
        self.company_name_map = {
            "ë„¤ì´ë²„": "naver", "ì¹´ì¹´ì˜¤": "kakao", "ë¼ì¸": "line",
            "ë¼ì¸í”ŒëŸ¬ìŠ¤": "ë¼ì¸í”ŒëŸ¬ìŠ¤", "ì¿ íŒ¡": "coupang", "ë°°ë‹¬ì˜ë¯¼ì¡±": "baemin",
            "ë‹¹ê·¼ë§ˆì¼“": "daangn", "í† ìŠ¤": "toss"
        }

    def get_company_id(self, company_name: str) -> str:
        return self.company_name_map.get(company_name, company_name.lower())

    def get_active_sessions(self) -> List[str]:
        """í˜„ì¬ í™œì„± ì„¸ì…˜ IDë“¤ì„ ë°˜í™˜"""
        return list(self.active_orchestrators.keys())
    
    def get_session_state(self, session_id: str) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • ì„¸ì…˜ì˜ ìƒíƒœë¥¼ ë°˜í™˜"""
        orchestrator = self.active_orchestrators.get(session_id)
        return orchestrator.get_current_state() if orchestrator else None
    
    def has_active_session(self, session_id: str) -> bool:
        """ì„¸ì…˜ì´ í™œì„± ìƒíƒœì¸ì§€ í™•ì¸"""
        return session_id in self.active_orchestrators

    async def _create_ai_persona(self, ai_candidate_model: AICandidateModel, company_id: str, position: str):
        persona = await asyncio.to_thread(
            ai_candidate_model.create_persona_for_interview, company_id, position
        )
        return persona if persona else ai_candidate_model._create_default_persona(company_id, position)

    def _get_orchestrator_or_error(self, session_id: str) -> tuple[Optional[Orchestrator], Optional[Dict]]:
        orchestrator = self.active_orchestrators.get(session_id)
        if not orchestrator:
            return None, {"error": "ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜ IDì…ë‹ˆë‹¤."}
        if orchestrator.state.get('is_completed', False):
            return None, {"error": "ì´ë¯¸ ì™„ë£Œëœ ë©´ì ‘ì…ë‹ˆë‹¤."}
        return orchestrator, None

    async def start_ai_competition(self, settings: Dict[str, Any], start_time: float = None) -> Dict[str, Any]:
        try:
            session_id = f"comp_{uuid.uuid4().hex[:12]}"
            company_id = self.get_company_id(settings['company'])
            ai_persona = await self._create_ai_persona(self.ai_candidate_model, company_id, settings['position'])
            
            orchestrator_settings = {
                'total_question_limit': 15,
                'company_id': company_id,
                'position': settings['position'],
                'user_name': settings['candidate_name'],
                'ai_persona': ai_persona
            }
            
            orchestrator = Orchestrator(session_id, orchestrator_settings)
            self.active_orchestrators[session_id] = orchestrator
            
            interview_logger.info(f"AI ê²½ìŸ ë©´ì ‘ ì‹œì‘: {session_id}")
            
            # Orchestratorì—ê²Œ ì²« í–‰ë™ì„ ìš”ì²­í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ë°›ìŒ
            initial_message = orchestrator._decide_next_message()
            print(f"[InterviewService] â¡ï¸ [Orchestrator]")
            print(json.dumps(initial_message, indent=2, ensure_ascii=False))
            
            # í•´ë‹¹ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ì—¬ ë©´ì ‘ì˜ ì²« ë‹¨ê³„ë¥¼ ì‹œì‘
            result = await self._process_orchestrator_message(session_id, initial_message)

            # ìµœì¢… ê²°ê³¼ì— session_id ì¶”ê°€
            if isinstance(result, dict) and 'session_id' not in result:
                result['session_id'] = session_id

            print(f"[InterviewService] â¡ï¸ [Client]")
            print(json.dumps(result, indent=2, ensure_ascii=False))
            return result

        except Exception as e:
            interview_logger.error(f"AI ê²½ìŸ ë©´ì ‘ ì‹œì‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return {"error": f"ë©´ì ‘ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

    async def submit_user_answer(self, session_id: str, user_answer: str, time_spent: float = None) -> Dict[str, Any]:
        try:
            orchestrator, error = self._get_orchestrator_or_error(session_id)
            if error: 
                return error

            interview_logger.info(f"ğŸ‘¤ ì‚¬ìš©ì ë‹µë³€ ì œì¶œ: {session_id}")
            
            # ì‚¬ìš©ì ë‹µë³€ì„ Orchestratorê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í‘œì¤€ ë©”ì‹œì§€ë¡œ ë³€í™˜
            user_message_to_orchestrator = Orchestrator.create_agent_message(
                session_id=session_id,
                task="answer_generated",
                from_agent="user",
                content_text=user_answer,
                turn_count=orchestrator.state.get('turn_count', 0),
                duration=time_spent
            )
            print(f"[InterviewService] â¡ï¸ [Orchestrator]")
            print(json.dumps(user_message_to_orchestrator, indent=2, ensure_ascii=False))
            
            # OrchestratorëŠ” ì´ ë©”ì‹œì§€ë¥¼ ë°›ì•„ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ê³ , ë‹¤ìŒ í–‰ë™ ë©”ì‹œì§€ë¥¼ ë°˜í™˜
            next_message_from_orchestrator = orchestrator.handle_message(user_message_to_orchestrator)
            
            # Orchestratorê°€ ê²°ì •í•œ ë‹¤ìŒ í–‰ë™ì„ ì²˜ë¦¬
            result = await self._process_orchestrator_message(session_id, next_message_from_orchestrator)
            
            # ìµœì¢… ê²°ê³¼ì— session_id ì¶”ê°€
            if isinstance(result, dict) and 'session_id' not in result:
                result['session_id'] = session_id

            print(f"[InterviewService] â¡ï¸ [Client]")
            print(json.dumps(result, indent=2, ensure_ascii=False))
            return result

        except Exception as e:
            interview_logger.error(f"ì‚¬ìš©ì ë‹µë³€ ì œì¶œ ì˜¤ë¥˜: {e}", exc_info=True)
            return {"error": f"ë‹µë³€ ì œì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

    async def _process_orchestrator_message(self, session_id: str, message: Dict[str, Any]) -> Dict[str, Any]:
        """Orchestratorì˜ ë©”ì‹œì§€ë¥¼ ë°›ì•„ ì‹¤ì œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ë‹¤ì‹œ Orchestratorì—ê²Œ ì „ë‹¬"""
        
        orchestrator, error = self._get_orchestrator_or_error(session_id)
        if error:
            return error

        task = message.get("metadata", {}).get("task")
        next_agent = message.get("metadata", {}).get("next_agent")

        print(f"[InterviewService] â¬…ï¸ [Orchestrator]")
        print(json.dumps(message, indent=2, ensure_ascii=False))
        interview_logger.info(f"ğŸ”„ Processing task: {task} for agent: {next_agent}")

        if task == "end_interview":
            return {
                "status": "completed",
                "message": "ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "qa_history": orchestrator.state.get('qa_history', [])
            }

        # ì—ì´ì „íŠ¸ í•¸ë“¤ëŸ¬ë¥¼ í†µí•´ ë‹¤ìŒ ì‘ì—… ì²˜ë¦¬
        handler = self.agent_handlers.get(next_agent)
        if not handler:
            return {"error": f"ì•Œ ìˆ˜ ì—†ëŠ” next_agent: {next_agent}"}
        
        # í•¸ë“¤ëŸ¬ëŠ” í•­ìƒ Orchestratorì—ê²Œ ë³´ë‚¼ ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•´ì•¼ í•¨
        response_message_to_orchestrator = await handler(orchestrator, message)
        
        print(f"[InterviewService] â¡ï¸ [Orchestrator]")
        print(json.dumps(response_message_to_orchestrator, indent=2, ensure_ascii=False))

        # ì‚¬ìš©ìì—ê²Œ ì‘ë‹µì„ ê¸°ë‹¤ë¦¬ë¼ëŠ” ë©”ì‹œì§€ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ Orchestratorì˜ handle_messageë¥¼ í˜¸ì¶œ
        if response_message_to_orchestrator.get("metadata", {}).get("task") == "wait_for_user_input":
            return response_message_to_orchestrator

        next_message_from_orchestrator = orchestrator.handle_message(response_message_to_orchestrator)
        
        # Orchestratorê°€ ê²°ì •í•œ ë‹¤ìŒ í–‰ë™ì„ ì¬ê·€ì ìœ¼ë¡œ ì²˜ë¦¬
        return await self._process_orchestrator_message(session_id, next_message_from_orchestrator)

    async def _handle_interviewer_message(self, orchestrator: Orchestrator, message: Dict[str, Any]) -> Dict[str, Any]:
        """ë©´ì ‘ê´€ ì—ì´ì „íŠ¸ì˜ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬"""
        question_content = await self._request_question_from_interviewer(orchestrator)
        
        return Orchestrator.create_agent_message(
            session_id=orchestrator.state['session_id'],
            task="question_generated",
            from_agent="interviewer",
            content_text=question_content,
            turn_count=orchestrator.state.get('turn_count', 0)
        )

    async def _handle_ai_candidate_message(self, orchestrator: Orchestrator, message: Dict[str, Any]) -> Dict[str, Any]:
        """AI ì§€ì›ì ì—ì´ì „íŠ¸ì˜ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬"""
        question = message.get("content", {}).get("content")
        ai_answer = await self._request_answer_from_ai_candidate(orchestrator, question)
        
        return Orchestrator.create_agent_message(
            session_id=orchestrator.state['session_id'],
            task="answer_generated",
            from_agent="ai",
            content_text=ai_answer,
            turn_count=orchestrator.state.get('turn_count', 0)
        )

    async def _handle_user_message(self, orchestrator: Orchestrator, message: Dict[str, Any]) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë‹¤ë¦¬ëŠ” ìƒíƒœë¥¼ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ë°˜í™˜"""
        # ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•  ë©”ì‹œì§€ëŠ” Orchestratorì˜ í‘œì¤€ ë©”ì‹œì§€ í˜•ì‹ì„ ë”°ë¥´ë˜,
        # ì¬ê·€ í˜¸ì¶œì„ ë©ˆì¶”ê¸° ìœ„í•´ íŠ¹ë³„í•œ taskëª…ì„ ì‚¬ìš©í•˜ê³ , ë°”ë¡œ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ë°˜í™˜ë©ë‹ˆë‹¤.
        response_to_client = orchestrator.create_message(
            content_text=orchestrator.state.get('current_question'),
            task="wait_for_user_input", # í´ë¼ì´ì–¸íŠ¸ê°€ ì´ taskë¥¼ ë³´ê³  ì‚¬ìš©ì ì…ë ¥ì„ í™œì„±í™”
            next_agent="user"
        )
        # ì¶”ê°€ì ìœ¼ë¡œ í´ë¼ì´ì–¸íŠ¸ê°€ UIë¥¼ êµ¬ì„±í•˜ëŠ” ë° í•„ìš”í•œ ì •ë³´ë¥¼ ë§ë¶™ì—¬ì¤ë‹ˆë‹¤.
        response_to_client['status'] = 'waiting_for_user'
        response_to_client['message'] = 'ë‹µë³€ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'
        return response_to_client
                

    async def _request_question_from_interviewer(self, orchestrator: Orchestrator) -> str:
        """ë©´ì ‘ê´€(QuestionGenerator)ì—ê²Œ ì§ˆë¬¸ ìƒì„±ì„ ìš”ì²­í•˜ê³ , í…ìŠ¤íŠ¸ ê²°ê³¼ë§Œ ë°˜í™˜"""
        try:
            interview_logger.info(f"ğŸ“¤ ë©´ì ‘ê´€ì—ê²Œ ì§ˆë¬¸ ìƒì„± ìš”ì²­: {orchestrator.state['session_id']}")
            
            # QuestionGeneratorì—ê²Œ ìƒíƒœ ê°ì²´(state)ë¥¼ ì „ë‹¬í•˜ì—¬ ì§ˆë¬¸ ìƒì„±
            question_data = await asyncio.to_thread(
                self.question_generator.generate_question_with_orchestrator_state,
                orchestrator.get_current_state()
            )
            return question_data.get('question', 'ë‹¤ìŒ ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ê°€ìš”?')
            
        except Exception as e:
            interview_logger.error(f"ë©´ì ‘ê´€ ì§ˆë¬¸ ìš”ì²­ ì˜¤ë¥˜: {e}", exc_info=True)
            return "ì£„ì†¡í•©ë‹ˆë‹¤, ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    async def _request_answer_from_ai_candidate(self, orchestrator: Orchestrator, question: str) -> str:
        """AI ì§€ì›ìì—ê²Œ ë‹µë³€ ìƒì„±ì„ ìš”ì²­í•˜ê³ , í…ìŠ¤íŠ¸ ê²°ê³¼ë§Œ ë°˜í™˜"""
        try:
            interview_logger.info(f"ğŸ“¤ AI ì§€ì›ìì—ê²Œ ë‹µë³€ ìš”ì²­: {orchestrator.state['session_id']}")
            
            state = orchestrator.get_current_state()
            ai_persona = state.get('ai_persona')
            
            # ë‹µë³€ ìƒì„± ìš”ì²­ êµ¬ì„±
            answer_request = AnswerRequest(
                question_content=question,
                question_type=QuestionType.HR, # TODO: ì§ˆë¬¸ ìœ í˜•ì„ stateì—ì„œ ê°€ì ¸ì˜¤ë„ë¡ ê°œì„ 
                question_intent="ë©´ì ‘ê´€ì˜ ì§ˆë¬¸",
                company_id=state.get('company_id'),
                position=state.get('position'),
                quality_level=QualityLevel.AVERAGE,
                llm_provider=LLMProvider.OPENAI_GPT4O
            )
            
            response = await asyncio.to_thread(
                self.ai_candidate_model.generate_answer,
                request=answer_request,
                persona=ai_persona
            )
            return response.answer_content
            
        except Exception as e:
            interview_logger.error(f"AI ì§€ì›ì ë‹µë³€ ìš”ì²­ ì˜¤ë¥˜: {e}", exc_info=True)
            return "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    def get_interview_flow_status(self, session_id: str) -> Dict[str, Any]:
        """í˜„ì¬ ë©´ì ‘ ì§„í–‰ ìƒíƒœì™€ ë‹¤ìŒ ì•¡ì…˜ì„ ë°˜í™˜"""
        orchestrator, error = self._get_orchestrator_or_error(session_id)
        if error:
            return error
        
        return orchestrator.get_current_state()

