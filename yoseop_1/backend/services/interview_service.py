import json
import json
from typing import Dict, Any, List, Optional
import asyncio
import uuid
import time
import boto3
import os
from llm.interviewer.question_generator import QuestionGenerator
from llm.candidate.model import AICandidateModel, CandidatePersona
from llm.shared.models import AnswerRequest, QuestionType, LLMProvider
from llm.candidate.quality_controller import QualityLevel
from llm.shared.logging_config import interview_logger

from backend.services.Orchestrator import Orchestrator
from backend.services.supabase_client import get_supabase_client
from backend.services.existing_tables_service import existing_tables_service
from backend.services.gaze_service import gaze_analyzer
class InterviewService:
    def __init__(self):
        # ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ (Orchestratorì˜ stateë¥¼ ì—¬ê¸°ë¡œ ì´ê´€)
        self.session_states: Dict[str, Dict[str, Any]] = {}
        self.active_orchestrators: Dict[str, Orchestrator] = {}
        self.question_generator = QuestionGenerator()
        self.ai_candidate_model = AICandidateModel()
        
        # ì—ì´ì „íŠ¸ í•¸ë“¤ëŸ¬ëŠ” Orchestratorë¡œ ì´ê´€ë¨
        
        self.company_name_map = {
            "ë„¤ì´ë²„": "naver", "ì¹´ì¹´ì˜¤": "kakao", "ë¼ì¸": "line",
            "ë¼ì¸í”ŒëŸ¬ìŠ¤": "ë¼ì¸í”ŒëŸ¬ìŠ¤", "ì¿ íŒ¡": "coupang", "ë°°ë‹¬ì˜ë¯¼ì¡±": "baemin",
            "ë‹¹ê·¼ë§ˆì¼“": "daangn", "í† ìŠ¤": "toss"
        }

    def get_company_id(self, company_name: str) -> str:
        return self.company_name_map.get(company_name, company_name.lower())

    # ì„¸ì…˜ ê´€ë¦¬ ë©”ì„œë“œë“¤
    def get_active_sessions(self) -> List[str]:
        """í˜„ì¬ í™œì„± ì„¸ì…˜ IDë“¤ì„ ë°˜í™˜"""
        return list(self.session_states.keys())
    
    def get_session_state(self, session_id: str) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • ì„¸ì…˜ì˜ ìƒíƒœë¥¼ ë°˜í™˜"""
        return self.session_states.get(session_id)
    
    def has_active_session(self, session_id: str) -> bool:
        """ì„¸ì…˜ì´ í™œì„± ìƒíƒœì¸ì§€ í™•ì¸"""
        return session_id in self.session_states
    
    def create_session_state(self, session_id: str, initial_settings: Dict[str, Any]) -> Dict[str, Any]:
        """ìƒˆë¡œìš´ ì„¸ì…˜ ìƒíƒœ ìƒì„±"""
        session_state = {
            "turn_count": 0,
            "current_question": None,
            "qa_history": [],
            "is_completed": False,
            "start_time": time.perf_counter(),
            # ğŸ†• ê¼¬ë¦¬ ì§ˆë¬¸ ê´€ë¦¬ë¥¼ ìœ„í•œ í•„ë“œë“¤ ì¶”ê°€
            "interviewer_turn_state": {
                'HR': {'main_question_asked': False, 'follow_up_count': 0},
                'TECH': {'main_question_asked': False, 'follow_up_count': 0},
                'COLLABORATION': {'main_question_asked': False, 'follow_up_count': 0}
            },
            "current_interviewer": None,
            # ğŸ†• TTS í†µí•© í: {'type': 'ìœ í˜•', 'content': 'TTSí•  í…ìŠ¤íŠ¸'} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ ì €ì¥
            "tts_queue": [],
            # ğŸ†• ì¤‘ë³µ ì œê±°: qa_historyì—ì„œ ìµœì‹  ë°ì´í„° ì¶”ì¶œ
            **initial_settings
        }
        self.session_states[session_id] = session_state
        interview_logger.info(f"DEBUG: create_session_state - ì„¸ì…˜ {session_id}ì´(ê°€) self.session_statesì— ì¶”ê°€ë¨. í˜„ì¬ self.session_states í‚¤: {self.session_states.keys()}")
        return session_state
    
    def update_session_state(self, session_id: str, updates: Dict[str, Any]) -> bool:
        """ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        if session_id not in self.session_states:
            return False
        self.session_states[session_id].update(updates)
        return True
    
    def remove_session(self, session_id: str) -> bool:
        """ì„¸ì…˜ ì œê±°"""
        if session_id in self.session_states:
            del self.session_states[session_id]
        if session_id in self.active_orchestrators:
            del self.active_orchestrators[session_id]
        return True
    
    def get_session_or_error(self, session_id: str) -> tuple[Optional[Dict[str, Any]], Optional[Dict]]:
        """ì„¸ì…˜ ìƒíƒœë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ì—ëŸ¬ ë°˜í™˜"""
        session_state = self.session_states.get(session_id)
        interview_logger.info(f"DEBUG: get_session_or_error - self.session_statesì—ì„œ {session_id} ì¡°íšŒ ê²°ê³¼: {bool(session_state)}. í˜„ì¬ self.session_states í‚¤: {self.session_states.keys()}")
        if not session_state:
            interview_logger.error(f"ERROR: get_session_or_error - ì„¸ì…˜ {session_id}ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŒ.")
            return None, {"error": "ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜ IDì…ë‹ˆë‹¤."}
        if session_state.get('is_completed', False):
            return None, {"error": "ì´ë¯¸ ì™„ë£Œëœ ë©´ì ‘ì…ë‹ˆë‹¤."}
        return session_state, None

    async def _create_ai_persona(self, ai_candidate_model: AICandidateModel, company_id: str, position: str):
        try:
            persona = await asyncio.to_thread(
                ai_candidate_model.create_persona_for_interview, company_id, position
            )
            return persona if persona else ai_candidate_model._create_default_persona(company_id, position)
        except Exception as e:
            interview_logger.error(
                f"AI í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹¤íŒ¨(ì•ˆì „ í´ë°± ì ìš©): company_id={company_id}, position={position}, error={e}",
                exc_info=True
            )
            # ëª¨ë¸ ë‚´ë¶€ ì˜ˆì™¸ê°€ ë°œìƒí•´ë„ ì„œë¹„ìŠ¤ëŠ” ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ë¡œ ê³„ì† ì§„í–‰
            return ai_candidate_model._create_default_persona(company_id, position)

    async def _resolve_ai_resume_id(self, session_like: Dict[str, Any]) -> Optional[int]:
        """ê°€ëŠ¥í•œ ë‹¨ì„œë¡œ AI ì´ë ¥ì„œ IDë¥¼ ìœ ì¶”í•©ë‹ˆë‹¤."""
        try:
            # 1) ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì‚¬ìš©
            if session_like.get('ai_resume_id'):
                return int(session_like['ai_resume_id'])

            client = get_supabase_client()

            # 2) position_idê°€ ìˆìœ¼ë©´ í•´ë‹¹ í¬ì§€ì…˜ì˜ ai_resume ì¤‘ í•˜ë‚˜ ì„ íƒ
            position_id = session_like.get('position_id')
            if position_id:
                res = client.table('ai_resume').select('ai_resume_id').eq('position_id', position_id).limit(1).execute()
                if res.data:
                    return int(res.data[0]['ai_resume_id'])

            # 3) posting_idë¡œ position_idë¥¼ ë³µì› í›„ ì¬ì‹œë„
            posting_id = session_like.get('posting_id')
            if posting_id:
                try:
                    posting = await existing_tables_service.get_posting_by_id(posting_id)
                    if posting and posting.get('position_id'):
                        res = client.table('ai_resume').select('ai_resume_id').eq('position_id', posting['position_id']).limit(1).execute()
                        if res.data:
                            return int(res.data[0]['ai_resume_id'])
                except Exception:
                    pass

            # 4) ìµœí›„ ìˆ˜ë‹¨: ì•„ë¬´ ai_resume í•œ ê°œ
            res_any = client.table('ai_resume').select('ai_resume_id').limit(1).execute()
            if res_any.data:
                return int(res_any.data[0]['ai_resume_id'])
        except Exception as e:
            interview_logger.warning(f"ai_resume_id ìœ ì¶” ì‹¤íŒ¨: {e}")
        return None

    def _get_orchestrator_or_error(self, session_id: str) -> tuple[Optional[Orchestrator], Optional[Dict]]:
        orchestrator = self.active_orchestrators.get(session_id)
        if not orchestrator:
            return None, {"error": "ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜ IDì…ë‹ˆë‹¤."}
        if orchestrator.state.get('is_completed', False):
            return None, {"error": "ì´ë¯¸ ì™„ë£Œëœ ë©´ì ‘ì…ë‹ˆë‹¤."}
        return orchestrator, None

    async def submit_user_answer(self, session_id: str, user_answer: str, time_spent: float = None) -> Dict[str, Any]:
        try:
            interview_logger.info(f"DEBUG: submit_user_answer - í˜¸ì¶œë¨ (session_id: {session_id}). í˜„ì¬ self.session_states í‚¤: {self.session_states.keys()}")
            session_state, error = self.get_session_or_error(session_id)
            if error: 
                return error

            interview_logger.info(f"ğŸ‘¤ ì‚¬ìš©ì ë‹µë³€ ì œì¶œ: {session_id}")
            
            print(f"[Client] -> [InterviewService]")
            print(json.dumps({
                "session_id": session_id,
                "user_answer": user_answer,
                "time_spent": time_spent
            }, indent=2, ensure_ascii=False))
            
            # Orchestratorê°€ ëª¨ë“  ê²ƒì„ ì²˜ë¦¬
            orchestrator = self.active_orchestrators.get(session_id)
            if not orchestrator:
                return {"error": "Orchestratorë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            interview_logger.info(f"DEBUG: submit_user_answer - get_session_or_error í˜¸ì¶œ ì§ì „ (session_id: {session_id})")
            result = await orchestrator.process_user_answer(user_answer, time_spent)

            # ë©´ì ‘ì´ ì™„ë£Œë˜ë©´ í”¼ë“œë°± í‰ê°€ë¥¼ ë°±ê·¸ë¼ìš´ë“œë¡œ íŠ¸ë¦¬ê±°
            try:
                if isinstance(result, dict) and result.get('status') == 'completed':
                    interview_logger.info(f"ğŸ ì™„ë£Œ ìƒíƒœ ìˆ˜ì‹ . í”¼ë“œë°± íŠ¸ë¦¬ê±° ì‹¤í–‰: session_id={session_id}")
                    asyncio.create_task(self.trigger_feedback_for_session(session_id))
            except Exception as e:
                interview_logger.error(f"âŒ í”¼ë“œë°± íŠ¸ë¦¬ê±° ì‹¤íŒ¨: session_id={session_id}, error={e}")

            return result

        except Exception as e:
            interview_logger.error(f"ì‚¬ìš©ì ë‹µë³€ ì œì¶œ ì˜¤ë¥˜: {e}", exc_info=True)
            return {"error": f"ë‹µë³€ ì œì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

    async def start_ai_competition(self, settings: Dict[str, Any], start_time: float = None) -> Dict[str, Any]:
        try:
            interview_logger.info(f"DEBUG: start_ai_competition - í•¨ìˆ˜ ì‹œì‘. settings: {settings.get('candidate_name')}")
            session_id = f"comp_{uuid.uuid4().hex[:12]}"
            interview_logger.info(f"DEBUG: start_ai_competition - ìƒì„±ëœ session_id: {session_id}")
            # íšŒì‚¬ ì‹ë³„ì ë¶„ë¦¬: ëª¨ë¸/í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ ì½”ë“œ vs. DBìš© ìˆ«ì ID
            company_code_for_persona = self.get_company_id(settings['company'])  # ì˜ˆ: 'naver', 'kakao'
            company_numeric_id = settings.get('company_id')  # DBì˜ ì •ìˆ˜ IDì¼ ìˆ˜ ìˆìŒ
            ai_persona = await self._create_ai_persona(self.ai_candidate_model, company_code_for_persona, settings['position'])
            ai_resume_id = getattr(ai_persona, 'resume_id', None) if ai_persona else None

            # ë³´ê°•: personaì—ì„œ ëª» ë°›ì€ ê²½ìš° ë‹¤ì–‘í•œ ë‹¨ì„œë¡œ ìœ ì¶”
            if not ai_resume_id:
                ai_resume_id = await self._resolve_ai_resume_id(settings)
            
            # ì„¸ì…˜ ìƒíƒœ ìƒì„±
            initial_settings = {
                'total_question_limit': 2,  # ë””ë²„ê¹…ìš© - ì‹¤ì œ ìš´ì˜ì‹œì—ëŠ” 15ë¡œ ë³€ê²½
                'company_id': company_code_for_persona,  # ëª¨ë¸/ì§ˆë¬¸ ìƒì„± ë¡œì§ê³¼ í˜¸í™˜ë˜ëŠ” ë¬¸ìì—´ ì½”ë“œ ìœ ì§€
                'company_numeric_id': company_numeric_id,  # DB ì—°ë™ì„ ìœ„í•œ ìˆ«ì ID ë³„ë„ ë³´ê´€
                'position': settings['position'],
                'position_id': settings.get('position_id'),
                'posting_id': settings.get('posting_id'),
                'user_id': settings.get('user_id'),
                'user_name': settings['candidate_name'],
                'ai_persona': ai_persona,
                'ai_resume_id': int(ai_resume_id) if ai_resume_id else None
            }
            # ì‚¬ìš©ì ì´ë ¥ì„œ IDë¥¼ ì„¸ì…˜ì— ì €ì¥ (ìˆìœ¼ë©´)
            if settings.get('user_resume_id'):
                try:
                    initial_settings['user_resume_id'] = int(settings['user_resume_id'])
                except Exception:
                    initial_settings['user_resume_id'] = None

            # --- â–¼â–¼â–¼ ë°”ë¡œ ì´ ë¶€ë¶„ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”! â–¼â–¼â–¼ ---
            initial_settings['calibration_data'] = settings.get('calibration_data')
            interview_logger.info(f"DEBUG: start_ai_competition - create_session_state í˜¸ì¶œ ì§ì „ (session_id: {session_id})")
            session_state = self.create_session_state(session_id, initial_settings)
            interview_logger.info(f"DEBUG: start_ai_competition - create_session_state í˜¸ì¶œ ì™„ë£Œ (session_id: {session_id}, keys: {session_state.keys()})")
            
            # Orchestrator ìƒì„± - ì—ì´ì „íŠ¸ë“¤ë„ ì „ë‹¬
            orchestrator = Orchestrator(
                session_id=session_id, 
                session_state=session_state,
                question_generator=self.question_generator,
                ai_candidate_model=self.ai_candidate_model
            )
            self.active_orchestrators[session_id] = orchestrator
            interview_logger.info(f"DEBUG: start_ai_competition - Orchestrator í™œì„±í™” ì™„ë£Œ (session_id: {session_id}). í˜„ì¬ active_orchestrators í‚¤: {self.active_orchestrators.keys()}")
            
            interview_logger.info(f"AI ê²½ìŸ ë©´ì ‘ ì‹œì‘: {session_id}")
            
            print(f"[Client] -> [InterviewService]")
            print(json.dumps(settings, indent=2, ensure_ascii=False))
            
            # âš¡ INTROë§Œ ì²˜ë¦¬í•˜ê³  ì¦‰ì‹œ API ì‘ë‹µ (ì†ë„ ìµœì í™”)
            result = await orchestrator._process_initial_flow()
            # session_idëŠ” ì´ë¯¸ _process_initial_flowì—ì„œ í¬í•¨ë¨

            # ğŸ” DEBUG: ìµœì¢… API ì‘ë‹µ êµ¬ì¡° í™•ì¸
            print(f"[ğŸ” API_RESPONSE_DEBUG] === ìµœì¢… API ì‘ë‹µ êµ¬ì¡° ë¶„ì„ ===")
            print(f"[ğŸ” API_RESPONSE_DEBUG] result íƒ€ì…: {type(result)}")
            print(f"[ğŸ” API_RESPONSE_DEBUG] result í‚¤ë“¤: {list(result.keys()) if isinstance(result, dict) else 'Not a dict'}")
            
            if isinstance(result, dict):
                for key, value in result.items():
                    if key in ['intro_audio', 'first_question_audio']:
                        print(f"[ğŸ” API_RESPONSE_DEBUG] {key}: {bool(value)} ({type(value).__name__}) - ê¸¸ì´: {len(str(value)) if value else 0}")
                    else:
                        print(f"[ğŸ” API_RESPONSE_DEBUG] {key}: {bool(value)} ({type(value).__name__})")
                        if key == 'first_question' and value:
                            print(f"[ğŸ” API_RESPONSE_DEBUG] first_question ë‚´ìš©: {str(value)[:50]}...")
            
            print(f"[ğŸ” API_RESPONSE_DEBUG] === FastAPIë¡œ ì „ë‹¬ë  result ===")
            
            interview_logger.info(f"DEBUG: start_ai_competition - ìµœì¢… ì‘ë‹µ ë°˜í™˜ ì§ì „ (session_id: {session_id})")
            return result

        except Exception as e:
            interview_logger.error(f"AI ê²½ìŸ ë©´ì ‘ ì‹œì‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return {"error": f"ë©´ì ‘ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

    def get_interview_flow_status(self, session_id: str) -> Dict[str, Any]:
        """í˜„ì¬ ë©´ì ‘ ì§„í–‰ ìƒíƒœì™€ ë‹¤ìŒ ì•¡ì…˜ì„ ë°˜í™˜"""
        session_state, error = self.get_session_or_error(session_id)
        if error:
            return error
        
        return session_state

    async def trigger_feedback_for_session(self, session_id: str) -> None:
        """ë©´ì ‘ ì™„ë£Œ ì‹œ ì„¸ì…˜ì˜ QA íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í”¼ë“œë°± í‰ê°€/ê³„íšì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰"""
        try:
            from llm.feedback.api_models import QuestionAnswerPair
            from llm.feedback.api_service import InterviewEvaluationService
            import os
            import glob
            interview_logger.info(f"í”¼ë“œë°± íŠ¸ë¦¬ê±° ì‹œì‘: {session_id}")
            await asyncio.sleep(15)  # CPU ì‚¬ìš© ì—†ì´ 5ì´ˆ ë¹„ë™ê¸° ëŒ€ê¸°
            interview_logger.info(f"í”¼ë“œë°± íŠ¸ë¦¬ê±° ì¢…ë£Œ: {session_id}")
            session_state = self.session_states.get(session_id)
            if not session_state:
                return

            qa_history = session_state.get('qa_history', [])
            if not qa_history:
                return

            user_id = session_state.get('user_id')
            # í‰ê°€ ì„œë¹„ìŠ¤ëŠ” ìˆ«ì company_idë¥¼ ìš”êµ¬í•˜ë¯€ë¡œ numeric ìš°ì„  ì‚¬ìš©
            company_id = session_state.get('company_numeric_id') or session_state.get('company_id')
            position_id = session_state.get('position_id')
            posting_id = session_state.get('posting_id')
            ai_resume_id = session_state.get('ai_resume_id') or await self._resolve_ai_resume_id(session_state)
            user_resume_id = session_state.get('user_resume_id')

            # í•„ìˆ˜ ê°’(company_id, user_id)ì´ ì—†ìœ¼ë©´ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
            interview_logger.info(f"ğŸ” í”¼ë“œë°± ì‹¤í–‰ ì¡°ê±´ ì²´í¬: company_id={company_id}, user_id={user_id}")
            if not company_id or not user_id:
                interview_logger.warning(f"âš ï¸ í•„ìˆ˜ê°’ ëˆ„ë½ìœ¼ë¡œ í”¼ë“œë°± ì‹¤í–‰ ì¤‘ë‹¨: company_id={company_id}, user_id={user_id}")
                return

            # ì‚¬ìš©ì/AI ë¶„ë¦¬
            user_qas = [qa for qa in qa_history if qa.get('answerer') == 'user']
            ai_qas = [qa for qa in qa_history if qa.get('answerer') == 'ai']
            interview_logger.info(f"ğŸ“Š QA íˆìŠ¤í† ë¦¬ ë¶„ì„: user_qas={len(user_qas)}ê°œ, ai_qas={len(ai_qas)}ê°œ")

            # QuestionAnswerPair ëª©ë¡ ìƒì„±
            def build_pairs(items: list) -> list:
                pairs: list[QuestionAnswerPair] = []
                for qa in items:
                    pairs.append(QuestionAnswerPair(
                        question=qa.get('question', ''),
                        answer=qa.get('answer', ''),
                        duration=qa.get('duration') or 120,
                        question_level=qa.get('question_level') or 1,
                    ))
                return pairs

            evaluation_service = InterviewEvaluationService()
            shared_interview_id = None

            # í†µí•© í‰ê°€ (ì‚¬ìš©ìì™€ AI ì§€ì›ìë¥¼ í•˜ë‚˜ì˜ interview ì„¸ì…˜ì— ì €ì¥)
            if user_qas or ai_qas:
                interview_logger.info(f"ğŸ”„ í†µí•© ë©´ì ‘ í‰ê°€ ì‹œì‘: user={len(user_qas)}ê°œ, ai={len(ai_qas)}ê°œ ì§ˆë¬¸")
                
                user_pairs = build_pairs(user_qas) if user_qas else []
                ai_pairs = build_pairs(ai_qas) if ai_qas else []
                
                # ìƒˆë¡œìš´ í†µí•© í‰ê°€ ë©”ì„œë“œ í˜¸ì¶œ
                combined_eval = evaluation_service.evaluate_combined_interview(
                    user_id=user_id,
                    user_qas=user_pairs,
                    ai_qas=ai_pairs,
                    ai_resume_id=ai_resume_id,
                    user_resume_id=user_resume_id,
                    posting_id=posting_id,
                    company_id=company_id,
                    position_id=position_id
                )
                
                if combined_eval and combined_eval.get('success'):
                    shared_interview_id = combined_eval['interview_id']
                    interview_logger.info(f"âœ… í†µí•© ë©´ì ‘ í‰ê°€ ì™„ë£Œ: interview_id={shared_interview_id}")
                    interview_logger.info(f"ğŸ“Š í‰ê°€ ê²°ê³¼: ì‚¬ìš©ì ì ìˆ˜={combined_eval.get('user_score', 0):.2f}, AI ì ìˆ˜={combined_eval.get('ai_score', 0):.2f}")
                    
                    # ğŸ†• ì‹œì„  ë¶„ì„ ë°ì´í„° ì§€ì—° ì²˜ë¦¬ (Pre-signed URL ê¸°ë°˜)
                    if shared_interview_id:
                        interview_logger.info(f"â³ ì‹œì„  ë¶„ì„ ì™„ë£Œ ëŒ€ê¸° ì¤‘... (5ì´ˆ ì¶”ê°€ ì§€ì—°)")
                        await asyncio.sleep(5)  # í”„ë¡ íŠ¸ì—”ë“œ gaze ë¶„ì„ ì™„ë£Œë¥¼ ìœ„í•œ ì¶”ê°€ ëŒ€ê¸°
                        await self._process_gaze_data_after_evaluation(shared_interview_id, session_id, user_id)
                    
                    # ê°œì„  ê³„íš ìƒì„±
                    try:
                        evaluation_service.generate_interview_plans(shared_interview_id)
                        interview_logger.info(f"âœ… ë©´ì ‘ ê³„íš ìƒì„± ì™„ë£Œ: interview_id={shared_interview_id}")
                    except Exception as e:
                        interview_logger.error(f"âŒ ë©´ì ‘ ê³„íš ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
                else:
                    interview_logger.error(f"âŒ í†µí•© ë©´ì ‘ í‰ê°€ ì‹¤íŒ¨: {combined_eval}")
            else:
                interview_logger.warning(f"âš ï¸ ì‚¬ìš©ì/AI QA ëª¨ë‘ ì—†ì–´ì„œ í‰ê°€ë¥¼ ê±´ë„ˆëœ€")

        except Exception as e:
            interview_logger.error(f"âŒ í”¼ë“œë°± ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}", exc_info=True)
            return

    async def _process_gaze_data_after_evaluation(self, interview_id: int, session_id: str, user_id: int) -> None:
        """
        ë©´ì ‘ í‰ê°€ ì™„ë£Œ í›„ ì‹œì„  ë¶„ì„ ë°ì´í„° ì§€ì—° ì²˜ë¦¬ (DB ê¸°ë°˜)
        
        Pre-signed URL ê¸°ë°˜ ì—…ë¡œë“œ í”Œë¡œìš°ì—ì„œ interview_idê°€ í™•ì •ëœ í›„:
        1. DBì—ì„œ session_idì— í•´ë‹¹í•˜ëŠ” ë¯¸ì²˜ë¦¬ ì‹œì„  ë¶„ì„ ê²°ê³¼ ì°¾ê¸°
        2. ì°¾ì€ gaze_analysis ë ˆì½”ë“œì— interview_id ì—…ë°ì´íŠ¸
        3. media_files í…Œì´ë¸”ì— ê´€ë ¨ ë ˆì½”ë“œ ì‚½ì…
        """
        try:
            interview_logger.info(f"ğŸš€ [GAZE_LINK] ì‹œì„  ë°ì´í„° ì—°ê²° ì‹œì‘: interview_id={interview_id}, session_id={session_id}, user_id={user_id}")
            
            supabase_client = get_supabase_client()

            # 1. DBì—ì„œ session_idë¡œ ë¯¸ì²˜ë¦¬ ì‹œì„  ë¶„ì„ ê²°ê³¼ ì°¾ê¸°
            interview_logger.info(f"ğŸ” [GAZE_LINK] DB ê²€ìƒ‰ ì¡°ê±´: user_id={user_id}, session_id={session_id}, interview_id=null")
            
            query_result = supabase_client.table("gaze_analysis").select("*") \
                .eq("user_id", user_id) \
                .eq("session_id", session_id) \
                .is_("interview_id", "null") \
                .order("created_at", desc=True).limit(1).execute()

            interview_logger.info(f"ğŸ” [GAZE_LINK] DB ê²€ìƒ‰ ê²°ê³¼: {len(query_result.data) if query_result.data else 0}ê°œ ë ˆì½”ë“œ ë°œê²¬")

            if not query_result.data:
                interview_logger.warning(f"âš ï¸ [GAZE_LINK] ì²« ë²ˆì§¸ ì‹œë„ ì‹¤íŒ¨ - 3ì´ˆ í›„ ì¬ì‹œë„")
                await asyncio.sleep(3)  # 3ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
                
                # ì¬ì‹œë„
                query_result = supabase_client.table("gaze_analysis").select("*") \
                    .eq("user_id", user_id) \
                    .eq("session_id", session_id) \
                    .is_("interview_id", "null") \
                    .order("created_at", desc=True).limit(1).execute()
                
                if not query_result.data:
                    interview_logger.warning(f"âš ï¸ [GAZE_LINK] ì„¸ì…˜ {session_id}ì— ëŒ€í•œ ë¯¸ì²˜ë¦¬ ì‹œì„  ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì¬ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨)")
                    # ì „ì²´ gaze_analysis í…Œì´ë¸”ì—ì„œ ìµœê·¼ ë ˆì½”ë“œë“¤ë„ í™•ì¸í•´ë³´ì
                    all_recent = supabase_client.table("gaze_analysis").select("gaze_id, interview_id, user_id, session_id, created_at") \
                        .order("created_at", desc=True).limit(3).execute()
                    interview_logger.info(f"ğŸ” [GAZE_LINK] ìµœê·¼ gaze_analysis ë ˆì½”ë“œë“¤: {all_recent.data}")
                    return

            gaze_record = query_result.data[0]
            gaze_id = gaze_record['gaze_id']
            s3_key_found = gaze_record.get('s3_key')
            
            interview_logger.info(f"âœ… [GAZE_LINK] ì‹œì„  ë¶„ì„ ê²°ê³¼ ë°œê²¬: gaze_id={gaze_id}, s3_key={s3_key_found}")

            # 2. ì°¾ì€ gaze_analysis ë ˆì½”ë“œì— interview_id ì—…ë°ì´íŠ¸
            interview_logger.info(f"ğŸ“ [GAZE_LINK] interview_id ì—…ë°ì´íŠ¸ ì‹œë„: gaze_id={gaze_id} -> interview_id={interview_id}")
            
            update_response = supabase_client.table("gaze_analysis") \
                .update({"interview_id": interview_id}) \
                .eq("gaze_id", gaze_id) \
                .execute()

            if not update_response.data:
                interview_logger.error(f"âŒ [GAZE_LINK] gaze_analysis ë ˆì½”ë“œ(id:{gaze_id})ì— interview_id ì—…ë°ì´íŠ¸ ì‹¤íŒ¨.")
                # ì‹¤íŒ¨í•´ë„ ì¼ë‹¨ ê³„ì† ì§„í–‰
            else:
                interview_logger.info(f"âœ… [GAZE_LINK] gaze_analysis ë ˆì½”ë“œ(id:{gaze_id})ì— interview_id({interview_id}) ì—…ë°ì´íŠ¸ ì™„ë£Œ.")

            # 3. media_files í…Œì´ë¸”ì— ë ˆì½”ë“œ ì‚½ì… (s3_keyê°€ ìˆì„ ë•Œë§Œ)
            if s3_key_found:
                try:
                    import os
                    AWS_REGION = os.getenv('AWS_REGION', 'ap-northeast-2')
                    BUCKET_NAME = 'betago-s3'
                    file_name = os.path.basename(s3_key_found)
                    s3_url = f"https://{BUCKET_NAME}.s3.{AWS_REGION}.amazonaws.com/{s3_key_found}"

                    media_data_to_insert = {
                        'user_id': user_id,
                        'interview_id': interview_id,
                        'file_name': file_name,
                        'file_type': 'video',
                        's3_url': s3_url,
                        's3_key': s3_key_found
                        # metadata í•„ë“œ ì œê±°ë¨ (DBì— í•´ë‹¹ ì»¬ëŸ¼ ì—†ìŒ)
                    }                
                    interview_logger.info(f"ğŸ’¾ [GAZE_LINK] media_files í…Œì´ë¸” ì‚½ì… ì‹œë„: {media_data_to_insert}")
                    insert_result = supabase_client.table('media_files').insert(media_data_to_insert).execute()

                    if insert_result.data:
                        final_media_id = insert_result.data[0]['media_id']
                        interview_logger.info(f"âœ… [GAZE_LINK] media_files ë ˆì½”ë“œ ì‚½ì… ì™„ë£Œ: media_id={final_media_id}")
                    else:
                        raise Exception(f"media_files ì‚½ì… ì‹¤íŒ¨: {getattr(insert_result, 'error', 'Unknown error')}")

                except Exception as e:
                    interview_logger.error(f"âŒ [GAZE_LINK] media_files ì‚½ì… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
                    # ì´ ë‹¨ê³„ ì‹¤íŒ¨ëŠ” ì „ì²´ë¥¼ ì¤‘ë‹¨ì‹œí‚¤ì§€ ì•ŠìŒ
            else:
                interview_logger.info(f"âš ï¸ [GAZE_LINK] s3_keyê°€ ì—†ì–´ì„œ media_files ì‚½ì…ì„ ê±´ë„ˆëœ€")

            interview_logger.info(f"ğŸ‰ [GAZE_LINK] ì‹œì„  ë¶„ì„ ë°ì´í„° ì§€ì—° ì²˜ë¦¬ ì™„ë£Œ: interview_id={interview_id}, session_id={session_id}")

        except Exception as e:
            interview_logger.error(f"âŒ [GAZE_LINK] ì‹œì„  ë¶„ì„ ë°ì´í„° ì§€ì—° ì²˜ë¦¬ ì‹¤íŒ¨: session_id={session_id}, interview_id={interview_id}, error={str(e)}", exc_info=True)

