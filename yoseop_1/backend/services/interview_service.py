import json
import json
from typing import Dict, Any, List, Optional
import asyncio
import uuid
import time
from llm.interviewer.question_generator import QuestionGenerator
from llm.candidate.model import AICandidateModel, CandidatePersona
from llm.shared.models import AnswerRequest, QuestionType, LLMProvider
from llm.candidate.quality_controller import QualityLevel
<<<<<<< HEAD
from llm.shared.constants import ALLOWED_FILE_EXTENSIONS, MAX_FILE_SIZE
from llm.shared.logging_config import interview_logger, performance_logger

# í˜¸í™˜ì„±ì„ ìœ„í•œ InterviewSession í´ë˜ìŠ¤ import
from backend.models.session import InterviewSession

# ğŸ”¥ llm/session ì˜ì¡´ì„± ì™„ì „ ì œê±° - ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
# from llm.session import SessionManager, InterviewSession, ComparisonSession  # REMOVED

# ë¬¸ì„œ ì²˜ë¦¬ ë° í”¼ë“œë°± ì„œë¹„ìŠ¤
from llm.interviewer.document_processor import DocumentProcessor, UserProfile
from llm.feedback.service import FeedbackService

# ğŸ†• ë©´ì ‘ ì„¸ì…˜ì˜ ëª¨ë“  ìƒíƒœë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤ (í„´ ê´€ë¦¬ ìƒíƒœ í¬í•¨)
@dataclass
class SessionState:
    session_id: str
    company_id: str
    position: str
    user_name: str
    
    # LLM ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
    question_generator: QuestionGenerator
    ai_candidate_model: AICandidateModel
    ai_persona: CandidatePersona
    ai_quality_level: QualityLevel = QualityLevel.AVERAGE  # ğŸ†• AI ì§€ì›ì ë‚œì´ë„
    
    # ë©´ì ‘ ì§„í–‰ ìƒíƒœ
    qa_history: List[Dict[str, Any]] = field(default_factory=list)
    is_completed: bool = False
    total_question_limit: int = 15
    questions_asked_count: int = 0
    current_interviewer_index: int = 0
    interviewer_roles: List[str] = field(default_factory=lambda: ['HR', 'TECH', 'COLLABORATION'])
    interviewer_turn_state: Dict[str, Any] = field(default_factory=lambda: {
        'HR': {'main_question_asked': False, 'follow_up_count': 0},
        'TECH': {'main_question_asked': False, 'follow_up_count': 0},
        'COLLABORATION': {'main_question_asked': False, 'follow_up_count': 0}
    })
    
    def get_current_interviewer(self) -> str:
        return self.interviewer_roles[self.current_interviewer_index]

=======
from llm.shared.logging_config import interview_logger
>>>>>>> backend-orchestrator

from backend.services.Orchestrator import Orchestrator

class InterviewService:
    def __init__(self):
        # ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ (Orchestratorì˜ stateë¥¼ ì—¬ê¸°ë¡œ ì´ê´€)
        self.session_states: Dict[str, Dict[str, Any]] = {}
        self.active_orchestrators: Dict[str, Orchestrator] = {}
        self.question_generator = QuestionGenerator()
        self.ai_candidate_model = AICandidateModel()
        
        # ì—ì´ì „íŠ¸ í•¸ë“¤ëŸ¬ëŠ” Orchestratorë¡œ ì´ê´€ë¨
        
        self.company_name_map = {
            "ë„¤ì´ë²„": "naver", "ì¹´ì¹´ì˜¤": "kakao", "ë¼ì¸": "line",
            "ë¼ì¸í”ŒëŸ¬ìŠ¤": "ë¼ì¸í”ŒëŸ¬ìŠ¤", "ì¿ íŒ¡": "coupang", "ë°°ë‹¬ì˜ë¯¼ì¡±": "baemin",
            "ë‹¹ê·¼ë§ˆì¼“": "daangn", "í† ìŠ¤": "toss"
        }

    def get_company_id(self, company_name: str) -> str:
        return self.company_name_map.get(company_name, company_name.lower())

    # ì„¸ì…˜ ê´€ë¦¬ ë©”ì„œë“œë“¤
    def get_active_sessions(self) -> List[str]:
        """í˜„ì¬ í™œì„± ì„¸ì…˜ IDë“¤ì„ ë°˜í™˜"""
        return list(self.session_states.keys())
    
    def get_session_state(self, session_id: str) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • ì„¸ì…˜ì˜ ìƒíƒœë¥¼ ë°˜í™˜"""
        return self.session_states.get(session_id)
    
    def has_active_session(self, session_id: str) -> bool:
        """ì„¸ì…˜ì´ í™œì„± ìƒíƒœì¸ì§€ í™•ì¸"""
        return session_id in self.session_states
    
    def create_session_state(self, session_id: str, initial_settings: Dict[str, Any]) -> Dict[str, Any]:
        """ìƒˆë¡œìš´ ì„¸ì…˜ ìƒíƒœ ìƒì„±"""
        session_state = {
            "turn_count": 0,
            "current_question": None,
            "qa_history": [],
            "is_completed": False,
            "start_time": time.perf_counter(),
            **initial_settings
        }
        self.session_states[session_id] = session_state
        return session_state
    
    def update_session_state(self, session_id: str, updates: Dict[str, Any]) -> bool:
        """ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        if session_id not in self.session_states:
            return False
        self.session_states[session_id].update(updates)
        return True
    
    def remove_session(self, session_id: str) -> bool:
        """ì„¸ì…˜ ì œê±°"""
        if session_id in self.session_states:
            del self.session_states[session_id]
        if session_id in self.active_orchestrators:
            del self.active_orchestrators[session_id]
        return True
    
    def get_session_or_error(self, session_id: str) -> tuple[Optional[Dict[str, Any]], Optional[Dict]]:
        """ì„¸ì…˜ ìƒíƒœë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ì—ëŸ¬ ë°˜í™˜"""
        session_state = self.session_states.get(session_id)
        if not session_state:
            return None, {"error": "ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜ IDì…ë‹ˆë‹¤."}
        if session_state.get('is_completed', False):
            return None, {"error": "ì´ë¯¸ ì™„ë£Œëœ ë©´ì ‘ì…ë‹ˆë‹¤."}
        return session_state, None

    async def _create_ai_persona(self, ai_candidate_model: AICandidateModel, company_id: str, position: str):
        persona = await asyncio.to_thread(
            ai_candidate_model.create_persona_for_interview, company_id, position
        )
        return persona if persona else ai_candidate_model._create_default_persona(company_id, position)

    def _get_orchestrator_or_error(self, session_id: str) -> tuple[Optional[Orchestrator], Optional[Dict]]:
        orchestrator = self.active_orchestrators.get(session_id)
        if not orchestrator:
            return None, {"error": "ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜ IDì…ë‹ˆë‹¤."}
        if orchestrator.state.get('is_completed', False):
            return None, {"error": "ì´ë¯¸ ì™„ë£Œëœ ë©´ì ‘ì…ë‹ˆë‹¤."}
        return orchestrator, None

    async def submit_user_answer(self, session_id: str, user_answer: str, time_spent: float = None) -> Dict[str, Any]:
        try:
            session_state, error = self.get_session_or_error(session_id)
            if error: 
                return error

            interview_logger.info(f"ğŸ‘¤ ì‚¬ìš©ì ë‹µë³€ ì œì¶œ: {session_id}")
            
<<<<<<< HEAD
            company_id = self.get_company_id(settings['company'])

            # ğŸ†• ë‚œì´ë„ ë³€í™˜
            difficulty_map = {
                'ì´ˆê¸‰': QualityLevel.VERY_POOR,
                'ì¤‘ê¸‰': QualityLevel.AVERAGE,
                'ê³ ê¸‰': QualityLevel.EXCELLENT
            }
            quality_level = difficulty_map.get(settings.get('difficulty', 'ì¤‘ê¸‰'), QualityLevel.AVERAGE)
            self._log_interview_event("SET_DIFFICULTY", session_id, f"ì„¤ì •ëœ ë‚œì´ë„: {settings.get('difficulty')} -> {quality_level.name}")
=======
            print(f"[Client] -> [InterviewService]")
            print(json.dumps({
                "session_id": session_id,
                "user_answer": user_answer,
                "time_spent": time_spent
            }, indent=2, ensure_ascii=False))
>>>>>>> backend-orchestrator
            
            # Orchestratorê°€ ëª¨ë“  ê²ƒì„ ì²˜ë¦¬
            orchestrator = self.active_orchestrators.get(session_id)
            if not orchestrator:
                return {"error": "Orchestratorë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            result = await orchestrator.process_user_answer(user_answer, time_spent)
            
<<<<<<< HEAD
            # 3. ì„¸ì…˜ ìƒíƒœ ê°ì²´ ìƒì„± ë° ì €ì¥ (ê³µí†µ ë¡œì§ ì‚¬ìš©)
            session_state = self._create_session_state(
                session_id, company_id, settings, question_generator, 
                ai_candidate_model, ai_persona, is_regular_interview=False
            )
            session_state.ai_quality_level = quality_level  # ğŸ†• ì„¸ì…˜ì— ë‚œì´ë„ ì €ì¥
            self.active_sessions[session_id] = session_state
            
            # 4. ì²« ì§ˆë¬¸ ìƒì„± (ê³µí†µ ë¡œì§ ì‚¬ìš©)
            first_question = self._generate_first_question(session_state)
            
            self._log_interview_event("AI_SESSION_CREATED", session_id, f"AI: {ai_persona.name}")
            
            return self._create_success_response(
                "ìƒˆë¡œìš´ AI ê²½ìŸ ë©´ì ‘ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
                {
                    "question": first_question,
                    "ai_name": ai_persona.name,
                    "total_questions": session_state.total_question_limit
                },
                session_id
            )
        except Exception as e:
            return self._handle_interview_error(e, "AI ê²½ìŸ ë©´ì ‘ ì‹œì‘", session_id)
    
    
    
    async def get_ai_answer(self, session_id: str, question_id: str) -> Dict[str, Any]:
        """AI ì§€ì›ìì˜ ë‹µë³€ ìƒì„±"""
        try:
            # URL ë””ì½”ë”©
            import urllib.parse
            decoded_session_id = urllib.parse.unquote(session_id)
            
            # ì„¸ì…˜ IDì—ì„œ íšŒì‚¬ì™€ í¬ì§€ì…˜ íŒŒì‹±
            session_parts = decoded_session_id.split('_')
            company_id = session_parts[0] if len(session_parts) > 0 else "naver"
            position = "_".join(session_parts[1:-1]) if len(session_parts) > 2 else "ë°±ì—”ë“œ ê°œë°œ"
            
            # ğŸ—‘ï¸ ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ - ìƒˆë¡œìš´ ì¤‘ì•™ ê´€ì œ ì‹œìŠ¤í…œ ì‚¬ìš©
            # from llm.session.interviewer_session import InterviewerSession
            
            # InterviewerSession ì„ì‹œ ìƒì„±í•˜ì—¬ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°
            temp_session = InterviewerSession(company_id, position, "ì¶˜ì‹ì´")
            first_question_data = temp_session.start()
            
            if first_question_data:
                question_content = first_question_data["question"]
                question_intent = first_question_data.get("intent", "ì¼ë°˜ì ì¸ í‰ê°€")
                question_type = first_question_data.get("interviewer_type", "HR")
            else:
                # í´ë°± ì§ˆë¬¸
                if question_id == "q_1":
                    question_content = "ì¶˜ì‹ì´, ìê¸°ì†Œê°œë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
                    question_intent = "ì§€ì›ìì˜ ê¸°ë³¸ ì •ë³´ì™€ ì„±ê²©, ì—­ëŸ‰ì„ íŒŒì•…"
                    question_type = "INTRO"
                elif question_id == "q_2":
                    question_content = f"ì¶˜ì‹ì´ê»˜ì„œ ë„¤ì´ë²„ì— ì§€ì›í•˜ê²Œ ëœ ë™ê¸°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
                    question_intent = "íšŒì‚¬ì— ëŒ€í•œ ê´€ì‹¬ë„ì™€ ì§€ì› ë™ê¸° íŒŒì•…"
                    question_type = "MOTIVATION"
                else:
                    question_content = "ì¶˜ì‹ì´ì— ëŒ€í•´ ë” ì•Œë ¤ì£¼ì„¸ìš”."
                    question_intent = "ì¼ë°˜ì ì¸ í‰ê°€"
                    question_type = "HR"
            
            # AI ë‹µë³€ ìƒì„±
            from llm.candidate.model import AnswerRequest
            from llm.shared.models import QuestionType
            
            # QuestionType ë§¤í•‘
            question_type_map = {
                "INTRO": QuestionType.INTRO,
                "MOTIVATION": QuestionType.MOTIVATION,
                "HR": QuestionType.HR,
                "TECH": QuestionType.TECH,
                "COLLABORATION": QuestionType.COLLABORATION
            }
            
            answer_request = AnswerRequest(
                question_content=question_content,
                question_type=question_type_map.get(question_type, QuestionType.HR),
                question_intent=question_intent,
                company_id=company_id,
                position=position,
                quality_level=QualityLevel.GOOD,
                llm_provider="openai_gpt4o_mini"
            )
            
            # ğŸ”„ ë‹¨ë… AI ë‹µë³€ ìƒì„± (ì„¸ì…˜ ì—†ìŒ - ë§¤ë²ˆ ìƒˆë¡œìš´ í˜ë¥´ì†Œë‚˜)
            interview_logger.info(f"ğŸ­ [STANDALONE AI] ë‹¨ë… AI ë‹µë³€ ìƒì„± (ì„¸ì…˜ ë¬´ê´€): {company_id} - {position}")
            ai_answer = self.ai_candidate_model.generate_answer(answer_request, persona=None)
            
            if not ai_answer:
                raise Exception("AI ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            return {
                "question": question_content,
                "questionType": question_type,
                "questionIntent": question_intent,
                "answer": ai_answer.answer_content,
                "time_spent": 60,
                "score": 85,
                "quality_level": ai_answer.quality_level.value,
                "persona_name": ai_answer.persona_name
            }
            
        except Exception as e:
            interview_logger.error(f"AI ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            raise Exception(f"AI ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # ===== ê²°ê³¼ ë° ê¸°ë¡ =====
    
    # async def get_interview_history(self, user_id: str = None) -> Dict[str, Any]:
    #     """ë©´ì ‘ ê¸°ë¡ ì¡°íšŒ - ìƒˆë¡œìš´ ì¤‘ì•™ ê´€ì œ ì‹œìŠ¤í…œ ë° ê¸°ì¡´ ì‹œìŠ¤í…œ ëª¨ë‘ ì§€ì› - UNUSED"""
    #     try:
    #         completed_sessions = []
    #         
    #         # ìƒˆë¡œìš´ ì¤‘ì•™ ê´€ì œ ì‹œìŠ¤í…œ ì„¸ì…˜ë“¤ ì¶”ê°€
    #         for session_id, session_state in self.active_sessions.items():
    #             if session_state.is_completed:
    #                 completed_sessions.append({
    #                     "session_id": session_id,
    #                     "settings": {
    #                         "company": session_state.company_id,
    #                         "position": session_state.position,
    #                         "user_name": session_state.user_name
    #                     },
    #                     "completed_at": "",
    #                     "total_score": 85,  # ê¸°ë³¸ê°’
    #                     "type": "central_control",
    #                     "questions_asked": session_state.questions_asked_count,
    #                     "ai_name": session_state.ai_persona.name
    #                 })
    #         
    #         # ğŸ”¥ SessionManager ì˜ì¡´ì„± ì™„ì „ ì œê±° - ì˜¤ì§ active_sessionsë§Œ ì‚¬ìš©
    #         # ë©”ëª¨: ê¸°ì¡´ SessionManager ì„¸ì…˜ë“¤ì€ ë” ì´ìƒ ì§€ì›í•˜ì§€ ì•ŠìŒ
    #         
    #         return {
    #             "total_interviews": len(completed_sessions),
    #             "interviews": completed_sessions
    #         }
    #         
    #     except Exception as e:
    #         interview_logger.error(f"ê¸°ë¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
    #         raise Exception(f"ê¸°ë¡ì„ ì¡°íšŒí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # ğŸ”„ ì™„ì „íˆ ìƒˆë¡œìš´ ë¡œì§ìœ¼ë¡œ êµì²´
    async def process_competition_turn(self, session_id: str, user_answer: str) -> Dict[str, Any]:
        try:
            session_state = self.active_sessions.get(session_id)
            if not session_state or session_state.is_completed:
                raise ValueError("ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ì´ë¯¸ ì¢…ë£Œëœ ì„¸ì…˜ IDì…ë‹ˆë‹¤.")
            
            # 1. ì‚¬ìš©ì ë‹µë³€ ë° ì´ì „ ì§ˆë¬¸ ê¸°ë¡
            last_qa = session_state.qa_history[-1]
            last_qa["user_answer"] = user_answer
            previous_question_obj = last_qa["question"]
            previous_question_text = previous_question_obj["question"]
            
            # 2. AI ë‹µë³€ ìƒì„±
            answer_request = AnswerRequest(
                question_content=previous_question_text,
                question_type=QuestionType.from_string(previous_question_obj.get("interviewer_type", "HR")),
                question_intent=previous_question_obj.get("intent", ""),
                company_id=session_state.company_id,
                position=session_state.position,
                quality_level=session_state.ai_quality_level,  # ğŸ†• ì„¸ì…˜ì— ì €ì¥ëœ ë‚œì´ë„ ì‚¬ìš©
                llm_provider=LLMProvider.OPENAI_GPT4O
            )
            ai_answer_response = await asyncio.to_thread(
                session_state.ai_candidate_model.generate_answer, request=answer_request, persona=session_state.ai_persona
            )
            ai_answer_content = ai_answer_response.answer_content
            last_qa["ai_answer"] = ai_answer_content
            
            # 3. ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±ì„ ìœ„í•œ ëª¨ë“  ë¡œì§ì„ ì—¬ê¸°ì„œ ì§ì ‘ ìˆ˜í–‰
            # 3-1. ë©´ì ‘ ì¢…ë£Œ ì¡°ê±´ í™•ì¸
            if session_state.questions_asked_count >= session_state.total_question_limit:
                session_state.is_completed = True
                next_question = {'question': 'ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.', 'intent': 'ë©´ì ‘ ì¢…ë£Œ', 
                                'interviewer_type': 'SYSTEM', 'is_final': True}
            # 3-2. ë‘ ë²ˆì§¸ ê³ ì • ì§ˆë¬¸ (ì§€ì›ë™ê¸°)
            elif session_state.questions_asked_count == 1:
                next_question = session_state.question_generator.generate_fixed_question(1, session_state.company_id, 
                                                                                        {"name": session_state.user_name})
            # 3-3. í„´ì œ ì‹œìŠ¤í…œì— ë”°ë¥¸ ì§ˆë¬¸ ìƒì„±
            else:
                current_interviewer = session_state.get_current_interviewer()
                turn_state = session_state.interviewer_turn_state[current_interviewer]
                
                # ë©”ì¸ ì§ˆë¬¸ ì•ˆí–ˆìœ¼ë©´ ë©”ì¸ ì§ˆë¬¸ ìƒì„±
                if not turn_state['main_question_asked']:
                    next_question = await asyncio.to_thread(
                        session_state.question_generator.generate_question_by_role,
                        interviewer_role=current_interviewer, company_id=session_state.company_id,
                        user_resume={"name": session_state.user_name, "position": session_state.position}
                    )
                    turn_state['main_question_asked'] = True
                # ê¼¬ë¦¬ ì§ˆë¬¸ ìƒì„± (ìµœëŒ€ 2ê°œë¡œ ìˆ˜ì •)
                elif turn_state['follow_up_count'] < 2:  # 1ê°œì—ì„œ 2ê°œë¡œ ë³€ê²½
                    company_info = session_state.question_generator.companies_data.get(session_state.company_id, {})
                    next_question = await asyncio.to_thread(
                        session_state.question_generator.generate_follow_up_question,
                        previous_question=previous_question_text, user_answer=user_answer, chun_sik_answer=ai_answer_content,
                        company_info=company_info, interviewer_role=current_interviewer,
                        user_resume={"name": session_state.user_name, "position": session_state.position}
                    )
                    turn_state['follow_up_count'] += 1
                # í„´ ì „í™˜
                else:
                    # í˜„ì¬ ë©´ì ‘ê´€ í„´ ì´ˆê¸°í™” ë° ë‹¤ìŒ ë©´ì ‘ê´€ìœ¼ë¡œ ì¸ë±ìŠ¤ ë³€ê²½
                    turn_state['main_question_asked'] = False
                    turn_state['follow_up_count'] = 0
                    session_state.current_interviewer_index = (session_state.current_interviewer_index + 1) % len(session_state.interviewer_roles)
                    
                    # ìƒˆë¡œìš´ ë©´ì ‘ê´€ì˜ ë©”ì¸ ì§ˆë¬¸ ìƒì„±
                    new_interviewer = session_state.get_current_interviewer()
                    next_question = await asyncio.to_thread(
                        session_state.question_generator.generate_question_by_role,
                        interviewer_role=new_interviewer, company_id=session_state.company_id,
                        user_resume={"name": session_state.user_name, "position": session_state.position}
                    )
                    session_state.interviewer_turn_state[new_interviewer]['main_question_asked'] = True
            
            # 4. ìƒíƒœ ì—…ë°ì´íŠ¸ (ê³µí†µ ë¡œì§ ì‚¬ìš©)
            if not next_question.get('is_final'):
                self._increment_question_count(session_state, next_question)
            
            interview_logger.info(f"ğŸ”„ [New Arch] Turn processed: {session_id}, Next question by {next_question.get('interviewer_type')}")
            
            return {
                "status": "success", "ai_answer": {"content": ai_answer_content},
                "next_question": next_question, "interview_status": "completed" if session_state.is_completed else "continue",
                "progress": {
                    "current": session_state.questions_asked_count, "total": session_state.total_question_limit,
                    "percentage": self._calculate_progress(session_state)
                }
            }
        except Exception as e:
            interview_logger.error(f"ê²½ìŸ ë©´ì ‘ í„´ ì²˜ë¦¬ ì˜¤ë¥˜: {e}", exc_info=True)
            raise
    
    # ===== ë ˆê±°ì‹œ/í˜¸í™˜ì„± (DEPRECATED) =====
    
    # async def start_turn_based_interview(self, settings: Dict[str, Any]) -> Dict[str, Any]:
    #     """í„´ì œ ë©´ì ‘ ì‹œì‘ - ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ, start_ai_competition ì‚¬ìš© ê¶Œì¥ - UNUSED"""
    #     try:
    #         company_id = self.get_company_id(settings['company'])
    #         
    #         # ì„¸ì…˜ ID ìƒì„±
    #         session_id = f"turn_{company_id}_{settings['position']}_{uuid.uuid4().hex[:8]}"
    #         
    #         # ì‚¬ìš©ì ì´ë ¥ì„œ ì •ë³´ (ì„ì‹œ)
    #         user_resume = {
    #             'name': settings['candidate_name'],
    #             'career_years': '3',
    #             'technical_skills': ['Python', 'Django', 'PostgreSQL', 'AWS']
    #         }
    #         
    #         # AI ì§€ì›ì í˜ë¥´ì†Œë‚˜ ìƒì„±
    #         from llm.candidate.model import CandidatePersona
    #         ai_persona = CandidatePersona(
    #             name='ì¶˜ì‹ì´', summary='3ë…„ì°¨ Python ë°±ì—”ë“œ ê°œë°œì',
    #             background={'career_years': '3', 'current_position': 'ë°±ì—”ë“œ ê°œë°œì'},
    #             technical_skills=['Python', 'Django', 'PostgreSQL', 'AWS'],
    #             projects=[{'name': 'ì´ì»¤ë¨¸ìŠ¤ í”Œë«í¼', 'description': 'ëŒ€ìš©ëŸ‰ íŠ¸ë˜í”½ ì²˜ë¦¬'}],
    #             experiences=[{'company': 'ìŠ¤íƒ€íŠ¸ì—…', 'position': 'ê°œë°œì', 'period': '3ë…„'}],
    #             strengths=['ë¬¸ì œ í•´ê²°', 'í•™ìŠµ ëŠ¥ë ¥'], weaknesses=['ì™„ë²½ì£¼ì˜'],
    #             motivation='ì¢‹ì€ ì„œë¹„ìŠ¤ë¥¼ ë§Œë“¤ê³  ì‹¶ì–´ì„œ',
    #             inferred_personal_experiences=[{'experience': 'ì„±ì¥', 'lesson': 'ëŠì„ì—†ëŠ” í•™ìŠµ'}],
    #             career_goal='ì‹œë‹ˆì–´ ê°œë°œìë¡œ ì„±ì¥', personality_traits=['ì¹œê·¼í•¨', 'ì „ë¬¸ì„±'],
    #             interview_style='ìƒí˜¸ì‘ìš©ì ', resume_id=1
    #         )
    #         
    #         # ì„¸ì…˜ ìƒíƒœ ì €ì¥ (ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ì €ì¥)
    #         if not hasattr(self, 'turn_based_sessions'):
    #             self.turn_based_sessions = {}
    #         
    #         self.turn_based_sessions[session_id] = {
    #             'user_resume': user_resume,
    #             'ai_persona': ai_persona,
    #             'company_id': company_id,
    #             'qa_history': [],
    #             'user_answers': [],
    #             'ai_answers': [],
    #             'created_at': time.time()
    #         }
    #         
    #         # ì²« ì§ˆë¬¸ ìƒì„±
    #         first_question = self.interviewer_service.generate_next_question(
    #             user_resume, ai_persona, company_id
    #         )
    #         
    #         interview_logger.info(f"í„´ì œ ë©´ì ‘ ì‹œì‘ - ì„¸ì…˜ ID: {session_id}")
    #         
    #         return {
    #             "session_id": session_id,
    #             "question": first_question,
    #             "total_question_limit": self.interviewer_service.total_question_limit,
    #             "current_interviewer": self.interviewer_service._get_current_interviewer(),
    #             "questions_asked": self.interviewer_service.questions_asked_count,
    #             "message": "í„´ì œ ë©´ì ‘ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
    #         }
    #         
    #     except Exception as e:
    #         interview_logger.error(f"í„´ì œ ë©´ì ‘ ì‹œì‘ ì˜¤ë¥˜: {str(e)}")
    #         raise Exception(f"í„´ì œ ë©´ì ‘ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    # 
    # async def get_turn_based_question(self, session_id: str, user_answer: str = None) -> Dict[str, Any]:
    #     """í„´ì œ ë©´ì ‘ ë‹¤ìŒ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸° - UNUSED"""
    #     try:
    #         if not hasattr(self, 'turn_based_sessions') or session_id not in self.turn_based_sessions:
    #             raise ValueError("ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    #         
    #         session_data = self.turn_based_sessions[session_id]
    #         
    #         # ì‚¬ìš©ì ë‹µë³€ ì €ì¥
    #         if user_answer:
    #             session_data['user_answers'].append(user_answer)
    #             
    #             # AI ë‹µë³€ ìƒì„± (ê°„ë‹¨í•œ êµ¬í˜„)
    #             ai_answer = "ì €ëŠ” ê¸°ìˆ ì  ì™„ì„±ë„ë¥¼ ì¤‘ì‹œí•˜ë©°, ì½”ë“œ ë¦¬ë·°ì™€ í…ŒìŠ¤íŠ¸ë¥¼ í†µí•´ ì•ˆì •ì ì¸ ì„œë¹„ìŠ¤ë¥¼ ë§Œë“¤ë ¤ê³  ë…¸ë ¥í•©ë‹ˆë‹¤."
    #             session_data['ai_answers'].append(ai_answer)
    #         
    #         # ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±
    #         next_question = self.interviewer_service.generate_next_question(
    #             session_data['user_resume'],
    #             session_data['ai_persona'], 
    #             session_data['company_id'],
    #             session_data['qa_history'],
    #             user_answer,
    #             session_data['ai_answers'][-1] if session_data['ai_answers'] else None
    #         )
    #         
    #         # ë©´ì ‘ ì¢…ë£Œ í™•ì¸
    #         if next_question.get('is_final'):
    #             return {
    #                 "completed": True,
    #                 "message": next_question['question'],
    #                 "final_stats": {
    #                     "total_questions": self.interviewer_service.questions_asked_count,
    #                     "interviewer_stats": self.interviewer_service.interviewer_turn_state
    #                 }
    #             }
    #         
    #         # í„´ ì „í™˜ í™•ì¸
    #         if next_question.get('force_turn_switch'):
    #             # ë‹¤ì‹œ ì§ˆë¬¸ ìƒì„± ì‹œë„
    #             next_question = self.interviewer_service.generate_next_question(
    #                 session_data['user_resume'],
    #                 session_data['ai_persona'], 
    #                 session_data['company_id'],
    #                 session_data['qa_history']
    #             )
    #         
    #         # QA íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
    #         session_data['qa_history'].append({
    #             'question': next_question['question'],
    #             'interviewer_type': next_question['interviewer_type']
    #         })
    #         
    #         return {
    #             "question": next_question,
    #             "session_stats": {
    #                 "questions_asked": self.interviewer_service.questions_asked_count,
    #                 "remaining_questions": self.interviewer_service.total_question_limit - self.interviewer_service.questions_asked_count,
    #                 "current_interviewer": self.interviewer_service._get_current_interviewer(),
    #                 "turn_states": self.interviewer_service.interviewer_turn_state
    #             }
    #         }
    #         
    #     except Exception as e:
    #         interview_logger.error(f"í„´ì œ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {str(e)}")
    #         raise Exception(f"ì§ˆë¬¸ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # ===== í—¬í¼ ë©”ì„œë“œë“¤ =====
    
    async def _generate_personalized_profile(self, documents: List[str]) -> UserProfile:
        """ë¬¸ì„œ ê¸°ë°˜ ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„± (í•„ìš”ì‹œ ì‚¬ìš©)"""
        try:
            profile = None
            
            for doc_path in documents:
                if os.path.exists(doc_path):
                    profile = await asyncio.to_thread(
                        self.document_processor.process_document, 
                        doc_path
                    )
                    break
            
            if not profile:
                # ê¸°ë³¸ í”„ë¡œí•„ ìƒì„±
                profile = UserProfile(
                    name="ì§€ì›ì",
                    background={"career_years": "3", "education": "ëŒ€í•™êµ ì¡¸ì—…"},
                    technical_skills=["Java", "Spring", "MySQL"],
                    projects=[{"name": "ì›¹ ì„œë¹„ìŠ¤ ê°œë°œ", "description": "ë°±ì—”ë“œ API ê°œë°œ"}],
                    experiences=[{"company": "ì´ì „ íšŒì‚¬", "role": "ë°±ì—”ë“œ ê°œë°œì", "duration": "2ë…„"}],
                    strengths=["ë¬¸ì œí•´ê²°ëŠ¥ë ¥", "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜"],
                    keywords=["ê°œë°œ", "í˜‘ì—…", "ì„±ì¥"],
                    career_goal="ì‹œë‹ˆì–´ ê°œë°œìë¡œ ì„±ì¥",
                    unique_points=["ë¹ ë¥¸ í•™ìŠµ ëŠ¥ë ¥"]
                )
            
            return profile
            
        except Exception as e:
            interview_logger.error(f"í”„ë¡œí•„ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return None
    
    async def _analyze_document_async(self, file_path: Path) -> Dict:
        """ë¬¸ì„œ ë¶„ì„ (ë¹„ë™ê¸°)"""
        try:
            result = await asyncio.get_event_loop().run_in_executor(
                None,
                self.document_processor.process_document,
                str(file_path)
            )
=======
>>>>>>> backend-orchestrator
            return result

        except Exception as e:
            interview_logger.error(f"ì‚¬ìš©ì ë‹µë³€ ì œì¶œ ì˜¤ë¥˜: {e}", exc_info=True)
            return {"error": f"ë‹µë³€ ì œì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

    async def start_ai_competition(self, settings: Dict[str, Any], start_time: float = None) -> Dict[str, Any]:
        try:
            session_id = f"comp_{uuid.uuid4().hex[:12]}"
            company_id = self.get_company_id(settings['company'])
            ai_persona = await self._create_ai_persona(self.ai_candidate_model, company_id, settings['position'])
            
            # ì„¸ì…˜ ìƒíƒœ ìƒì„±
            initial_settings = {
                'total_question_limit': 15,
                'company_id': company_id,
                'position': settings['position'],
                'user_name': settings['candidate_name'],
                'ai_persona': ai_persona
            }
            
            session_state = self.create_session_state(session_id, initial_settings)
            
            # Orchestrator ìƒì„± - ì—ì´ì „íŠ¸ë“¤ë„ ì „ë‹¬
            orchestrator = Orchestrator(
                session_id=session_id, 
                session_state=session_state,
                question_generator=self.question_generator,
                ai_candidate_model=self.ai_candidate_model
            )
            self.active_orchestrators[session_id] = orchestrator
            
            interview_logger.info(f"AI ê²½ìŸ ë©´ì ‘ ì‹œì‘: {session_id}")
            
            print(f"[Client] -> [InterviewService]")
            print(json.dumps(settings, indent=2, ensure_ascii=False))
            
            # Orchestratorê°€ ì²« í”Œë¡œìš°ë¥¼ ì²˜ë¦¬
            result = await orchestrator._process_complete_flow()
            result['session_id'] = session_id

            return result

        except Exception as e:
            interview_logger.error(f"AI ê²½ìŸ ë©´ì ‘ ì‹œì‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return {"error": f"ë©´ì ‘ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

    def get_interview_flow_status(self, session_id: str) -> Dict[str, Any]:
        """í˜„ì¬ ë©´ì ‘ ì§„í–‰ ìƒíƒœì™€ ë‹¤ìŒ ì•¡ì…˜ì„ ë°˜í™˜"""
        session_state, error = self.get_session_or_error(session_id)
        if error:
            return error
        
        return session_state

