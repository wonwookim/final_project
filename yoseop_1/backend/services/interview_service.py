import json
import json
from typing import Dict, Any, List, Optional
import asyncio
import uuid
import time
from llm.interviewer.question_generator import QuestionGenerator
from llm.candidate.model import AICandidateModel, CandidatePersona
from llm.shared.models import AnswerRequest, QuestionType, LLMProvider
from llm.candidate.quality_controller import QualityLevel
from llm.shared.logging_config import interview_logger

from backend.services.Orchestrator import Orchestrator

class InterviewService:
    def __init__(self):
        self.active_orchestrators: Dict[str, Orchestrator] = {}
        self.question_generator = QuestionGenerator()
        self.ai_candidate_model = AICandidateModel()
        self.company_name_map = {
            "ë„¤ì´ë²„": "naver", "ì¹´ì¹´ì˜¤": "kakao", "ë¼ì¸": "line",
            "ë¼ì¸í”ŒëŸ¬ìŠ¤": "ë¼ì¸í”ŒëŸ¬ìŠ¤", "ì¿ íŒ¡": "coupang", "ë°°ë‹¬ì˜ë¯¼ì¡±": "baemin",
            "ë‹¹ê·¼ë§ˆì¼“": "daangn", "í† ìŠ¤": "toss"
        }

    def get_company_id(self, company_name: str) -> str:
        return self.company_name_map.get(company_name, company_name.lower())

    def get_active_sessions(self) -> List[str]:
        """í˜„ì¬ í™œì„± ì„¸ì…˜ IDë“¤ì„ ë°˜í™˜"""
        return list(self.active_orchestrators.keys())
    
    def get_session_state(self, session_id: str) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • ì„¸ì…˜ì˜ ìƒíƒœë¥¼ ë°˜í™˜"""
        orchestrator = self.active_orchestrators.get(session_id)
        return orchestrator.get_current_state() if orchestrator else None
    
    def has_active_session(self, session_id: str) -> bool:
        """ì„¸ì…˜ì´ í™œì„± ìƒíƒœì¸ì§€ í™•ì¸"""
        return session_id in self.active_orchestrators

    async def _create_ai_persona(self, ai_candidate_model: AICandidateModel, company_id: str, position: str):
        persona = await asyncio.to_thread(
            ai_candidate_model.create_persona_for_interview, company_id, position
        )
        return persona if persona else ai_candidate_model._create_default_persona(company_id, position)

    def _get_orchestrator_or_error(self, session_id: str) -> tuple[Optional[Orchestrator], Optional[Dict]]:
        orchestrator = self.active_orchestrators.get(session_id)
        if not orchestrator:
            return None, {"error": "ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜ IDì…ë‹ˆë‹¤."}
        if orchestrator.state.get('is_completed', False):
            return None, {"error": "ì´ë¯¸ ì™„ë£Œëœ ë©´ì ‘ì…ë‹ˆë‹¤."}
        return orchestrator, None

    async def start_ai_competition(self, settings: Dict[str, Any], start_time: float = None) -> Dict[str, Any]:
        try:
            session_id = f"comp_{uuid.uuid4().hex[:12]}"
            company_id = self.get_company_id(settings['company'])
            ai_persona = await self._create_ai_persona(self.ai_candidate_model, company_id, settings['position'])
            
            orchestrator_settings = {
                'total_question_limit': 15,
                'company_id': company_id,
                'position': settings['position'],
                'user_name': settings['candidate_name'],
                'ai_persona': ai_persona
            }
            
            orchestrator = Orchestrator(session_id, orchestrator_settings)
            self.active_orchestrators[session_id] = orchestrator
            
            interview_logger.info(f"AI ê²½ìŸ ë©´ì ‘ ì‹œì‘: {session_id}")
            
            # Orchestratorì—ê²Œ ì²« í–‰ë™ì„ ìš”ì²­í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ë°›ìŒ
            initial_message = orchestrator._decide_next_message()
            print(f"[InterviewService] â¡ï¸ [Orchestrator]")
            print(json.dumps(initial_message, indent=2, ensure_ascii=False))
            
            # í•´ë‹¹ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ì—¬ ë©´ì ‘ì˜ ì²« ë‹¨ê³„ë¥¼ ì‹œì‘
            result = await self._process_orchestrator_message(session_id, initial_message)
            print(f"[InterviewService] â¡ï¸ [Client]")
            print(json.dumps(result, indent=2, ensure_ascii=False))
            return result

        except Exception as e:
            interview_logger.error(f"AI ê²½ìŸ ë©´ì ‘ ì‹œì‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return {"error": f"ë©´ì ‘ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

    async def submit_user_answer(self, session_id: str, user_answer: str, time_spent: float = None) -> Dict[str, Any]:
        try:
            orchestrator, error = self._get_orchestrator_or_error(session_id)
            if error: 
                return error

            interview_logger.info(f"ğŸ‘¤ ì‚¬ìš©ì ë‹µë³€ ì œì¶œ: {session_id}")
            
            # ì‚¬ìš©ì ë‹µë³€ì„ Orchestratorê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í‘œì¤€ ë©”ì‹œì§€ë¡œ ë³€í™˜
            user_message_to_orchestrator = Orchestrator.create_agent_message(
                session_id=session_id,
                task="answer_generated",
                from_agent="user",
                content_text=user_answer,
                turn_count=orchestrator.state.get('turn_count', 0),
                duration=time_spent
            )
            print(f"[InterviewService] â¡ï¸ [Orchestrator]")
            print(json.dumps(user_message_to_orchestrator, indent=2, ensure_ascii=False))
            
            # OrchestratorëŠ” ì´ ë©”ì‹œì§€ë¥¼ ë°›ì•„ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ê³ , ë‹¤ìŒ í–‰ë™ ë©”ì‹œì§€ë¥¼ ë°˜í™˜
            next_message_from_orchestrator = orchestrator.handle_message(user_message_to_orchestrator)
            
            # Orchestratorê°€ ê²°ì •í•œ ë‹¤ìŒ í–‰ë™ì„ ì²˜ë¦¬
            result = await self._process_orchestrator_message(session_id, next_message_from_orchestrator)
            print(f"[InterviewService] â¡ï¸ [Client]")
            print(json.dumps(result, indent=2, ensure_ascii=False))
            return result

        except Exception as e:
            interview_logger.error(f"ì‚¬ìš©ì ë‹µë³€ ì œì¶œ ì˜¤ë¥˜: {e}", exc_info=True)
            return {"error": f"ë‹µë³€ ì œì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

    async def _process_orchestrator_message(self, session_id: str, message: Dict[str, Any]) -> Dict[str, Any]:
        """Orchestratorì˜ ë©”ì‹œì§€ë¥¼ ë°›ì•„ ì‹¤ì œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ë‹¤ì‹œ Orchestratorì—ê²Œ ì „ë‹¬"""
        
        orchestrator, error = self._get_orchestrator_or_error(session_id)
        if error:
            return error

        task = message.get("metadata", {}).get("task")
        next_agent = message.get("metadata", {}).get("next_agent")
        content = message.get("content", {}).get("content")

        print(f"[InterviewService] â¬…ï¸ [Orchestrator]")
        print(json.dumps(message, indent=2, ensure_ascii=False))

        interview_logger.info(f"ğŸ”„ Processing task: {task} for agent: {next_agent}")

        if task == "end_interview":
            return {
                "status": "completed",
                "message": "ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "qa_history": orchestrator.state.get('qa_history', [])
            }

        elif task == "generate_question":
            # 1. ë©´ì ‘ê´€ì—ê²Œ ì§ˆë¬¸ ìƒì„± ìš”ì²­
            question_content = await self._request_question_from_interviewer(orchestrator)
            
            # 2. ìƒì„±ëœ ì§ˆë¬¸ì„ Orchestratorì—ê²Œ í‘œì¤€ ë©”ì‹œì§€ë¡œ ì „ë‹¬
            response_message_to_orchestrator = Orchestrator.create_agent_message(
                session_id=session_id,
                task="question_generated",
                from_agent="interviewer",
                content_text=question_content,
                turn_count=orchestrator.state.get('turn_count', 0)
            )
            print(f"[InterviewService] â¡ï¸ [Orchestrator]")
            print(json.dumps(response_message_to_orchestrator, indent=2, ensure_ascii=False))
            
            next_message_from_orchestrator = orchestrator.handle_message(response_message_to_orchestrator)
            
            # 3. Orchestratorê°€ ê²°ì •í•œ ë‹¤ìŒ í–‰ë™ ì²˜ë¦¬
            return await self._process_orchestrator_message(session_id, next_message_from_orchestrator)

        elif task == "generate_answer":
            if next_agent == "user":
                # ì‚¬ìš©ì ë‹µë³€ ëŒ€ê¸° ìƒíƒœ ë°˜í™˜
                return {
                    "status": "waiting_for_user",
                    "question": orchestrator.state.get('current_question'),
                    "message": "ë‹µë³€ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
                }
            elif next_agent == "ai":
                # AIì—ê²Œ ë‹µë³€ ìƒì„± ìš”ì²­
                ai_answer = await self._request_answer_from_ai_candidate(orchestrator, content)
                
                # ìƒì„±ëœ ë‹µë³€ì„ Orchestratorì—ê²Œ í‘œì¤€ ë©”ì‹œì§€ë¡œ ì „ë‹¬
                response_message_to_orchestrator = Orchestrator.create_agent_message(
                    session_id=session_id,
                    task="answer_generated",
                    from_agent="ai",
                    content_text=ai_answer,
                    turn_count=orchestrator.state.get('turn_count', 0)
                )
                print(f"[InterviewService] â¡ï¸ [Orchestrator]")
                print(json.dumps(response_message_to_orchestrator, indent=2, ensure_ascii=False))
                
                next_message_from_orchestrator = orchestrator.handle_message(response_message_to_orchestrator)
                
                # Orchestratorê°€ ê²°ì •í•œ ë‹¤ìŒ í–‰ë™ ì²˜ë¦¬
                return await self._process_orchestrator_message(session_id, next_message_from_orchestrator)
        
        return {"error": f"ì•Œ ìˆ˜ ì—†ëŠ” task: {task} ë˜ëŠ” next_agent: {next_agent}"}
                

    async def _request_question_from_interviewer(self, orchestrator: Orchestrator) -> str:
        """ë©´ì ‘ê´€(QuestionGenerator)ì—ê²Œ ì§ˆë¬¸ ìƒì„±ì„ ìš”ì²­í•˜ê³ , í…ìŠ¤íŠ¸ ê²°ê³¼ë§Œ ë°˜í™˜"""
        try:
            interview_logger.info(f"ğŸ“¤ ë©´ì ‘ê´€ì—ê²Œ ì§ˆë¬¸ ìƒì„± ìš”ì²­: {orchestrator.state['session_id']}")
            
            # QuestionGeneratorì—ê²Œ ìƒíƒœ ê°ì²´(state)ë¥¼ ì „ë‹¬í•˜ì—¬ ì§ˆë¬¸ ìƒì„±
            question_data = await asyncio.to_thread(
                self.question_generator.generate_question_with_orchestrator_state,
                orchestrator.get_current_state()
            )
            return question_data.get('question', 'ë‹¤ìŒ ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ê°€ìš”?')
            
        except Exception as e:
            interview_logger.error(f"ë©´ì ‘ê´€ ì§ˆë¬¸ ìš”ì²­ ì˜¤ë¥˜: {e}", exc_info=True)
            return "ì£„ì†¡í•©ë‹ˆë‹¤, ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    async def _request_answer_from_ai_candidate(self, orchestrator: Orchestrator, question: str) -> str:
        """AI ì§€ì›ìì—ê²Œ ë‹µë³€ ìƒì„±ì„ ìš”ì²­í•˜ê³ , í…ìŠ¤íŠ¸ ê²°ê³¼ë§Œ ë°˜í™˜"""
        try:
            interview_logger.info(f"ğŸ“¤ AI ì§€ì›ìì—ê²Œ ë‹µë³€ ìš”ì²­: {orchestrator.state['session_id']}")
            
            state = orchestrator.get_current_state()
            ai_persona = state.get('ai_persona')
            
            # ë‹µë³€ ìƒì„± ìš”ì²­ êµ¬ì„±
            answer_request = AnswerRequest(
                question_content=question,
                question_type=QuestionType.HR, # TODO: ì§ˆë¬¸ ìœ í˜•ì„ stateì—ì„œ ê°€ì ¸ì˜¤ë„ë¡ ê°œì„ 
                question_intent="ë©´ì ‘ê´€ì˜ ì§ˆë¬¸",
                company_id=state.get('company_id'),
                position=state.get('position'),
                quality_level=QualityLevel.AVERAGE,
                llm_provider=LLMProvider.OPENAI_GPT4O
            )
            
            response = await asyncio.to_thread(
                self.ai_candidate_model.generate_answer,
                request=answer_request,
                persona=ai_persona
            )
            return response.answer_content
            
        except Exception as e:
            interview_logger.error(f"AI ì§€ì›ì ë‹µë³€ ìš”ì²­ ì˜¤ë¥˜: {e}", exc_info=True)
            return "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    def get_interview_flow_status(self, session_id: str) -> Dict[str, Any]:
        """í˜„ì¬ ë©´ì ‘ ì§„í–‰ ìƒíƒœì™€ ë‹¤ìŒ ì•¡ì…˜ì„ ë°˜í™˜"""
        orchestrator, error = self._get_orchestrator_or_error(session_id)
        if error:
            return error
        
        return orchestrator.get_current_state()

