import json
import json
from typing import Dict, Any, List, Optional
import asyncio
import uuid
import time
import boto3
import os
from llm.interviewer.question_generator import QuestionGenerator
from llm.candidate.model import AICandidateModel, CandidatePersona
from llm.shared.models import AnswerRequest, QuestionType, LLMProvider
from llm.candidate.quality_controller import QualityLevel
from llm.shared.logging_config import interview_logger

from backend.services.Orchestrator import Orchestrator
from backend.services.supabase_client import get_supabase_client
from backend.services.existing_tables_service import existing_tables_service
from backend.services.gaze_service import gaze_analyzer
class InterviewService:
    def __init__(self):
        # ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ (Orchestratorì˜ stateë¥¼ ì—¬ê¸°ë¡œ ì´ê´€)
        self.session_states: Dict[str, Dict[str, Any]] = {}
        self.active_orchestrators: Dict[str, Orchestrator] = {}
        self.question_generator = QuestionGenerator()
        self.ai_candidate_model = AICandidateModel()
        
        # ì—ì´ì „íŠ¸ í•¸ë“¤ëŸ¬ëŠ” Orchestratorë¡œ ì´ê´€ë¨
        
        self.company_name_map = {
            "ë„¤ì´ë²„": "naver", "ì¹´ì¹´ì˜¤": "kakao", "ë¼ì¸": "line",
            "ë¼ì¸í”ŒëŸ¬ìŠ¤": "ë¼ì¸í”ŒëŸ¬ìŠ¤", "ì¿ íŒ¡": "coupang", "ë°°ë‹¬ì˜ë¯¼ì¡±": "baemin",
            "ë‹¹ê·¼ë§ˆì¼“": "daangn", "í† ìŠ¤": "toss"
        }

    def get_company_id(self, company_name: str) -> str:
        return self.company_name_map.get(company_name, company_name.lower())

    # ì„¸ì…˜ ê´€ë¦¬ ë©”ì„œë“œë“¤
    def get_active_sessions(self) -> List[str]:
        """í˜„ì¬ í™œì„± ì„¸ì…˜ IDë“¤ì„ ë°˜í™˜"""
        return list(self.session_states.keys())
    
    def get_session_state(self, session_id: str) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • ì„¸ì…˜ì˜ ìƒíƒœë¥¼ ë°˜í™˜"""
        return self.session_states.get(session_id)
    
    def has_active_session(self, session_id: str) -> bool:
        """ì„¸ì…˜ì´ í™œì„± ìƒíƒœì¸ì§€ í™•ì¸"""
        return session_id in self.session_states
    
    def create_session_state(self, session_id: str, initial_settings: Dict[str, Any]) -> Dict[str, Any]:
        """ìƒˆë¡œìš´ ì„¸ì…˜ ìƒíƒœ ìƒì„±"""
        session_state = {
            "turn_count": 0,
            "current_question": None,
            "qa_history": [],
            "is_completed": False,
            "start_time": time.perf_counter(),
            # ğŸ†• ê¼¬ë¦¬ ì§ˆë¬¸ ê´€ë¦¬ë¥¼ ìœ„í•œ í•„ë“œë“¤ ì¶”ê°€
            "interviewer_turn_state": {
                'HR': {'main_question_asked': False, 'follow_up_count': 0},
                'TECH': {'main_question_asked': False, 'follow_up_count': 0},
                'COLLABORATION': {'main_question_asked': False, 'follow_up_count': 0}
            },
            "current_interviewer": None,
            # ğŸ†• TTS í†µí•© í: {'type': 'ìœ í˜•', 'content': 'TTSí•  í…ìŠ¤íŠ¸'} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ ì €ì¥
            "tts_queue": [],
            # ğŸ†• ì¤‘ë³µ ì œê±°: qa_historyì—ì„œ ìµœì‹  ë°ì´í„° ì¶”ì¶œ
            **initial_settings
        }
        self.session_states[session_id] = session_state
        interview_logger.info(f"DEBUG: create_session_state - ì„¸ì…˜ {session_id}ì´(ê°€) self.session_statesì— ì¶”ê°€ë¨. í˜„ì¬ self.session_states í‚¤: {self.session_states.keys()}")
        return session_state
    
    def update_session_state(self, session_id: str, updates: Dict[str, Any]) -> bool:
        """ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        if session_id not in self.session_states:
            return False
        self.session_states[session_id].update(updates)
        return True
    
    def remove_session(self, session_id: str) -> bool:
        """ì„¸ì…˜ ì œê±°"""
        if session_id in self.session_states:
            del self.session_states[session_id]
        if session_id in self.active_orchestrators:
            del self.active_orchestrators[session_id]
        return True
    
    def get_session_or_error(self, session_id: str) -> tuple[Optional[Dict[str, Any]], Optional[Dict]]:
        """ì„¸ì…˜ ìƒíƒœë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ì—ëŸ¬ ë°˜í™˜"""
        session_state = self.session_states.get(session_id)
        interview_logger.info(f"DEBUG: get_session_or_error - self.session_statesì—ì„œ {session_id} ì¡°íšŒ ê²°ê³¼: {bool(session_state)}. í˜„ì¬ self.session_states í‚¤: {self.session_states.keys()}")
        if not session_state:
            interview_logger.error(f"ERROR: get_session_or_error - ì„¸ì…˜ {session_id}ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŒ.")
            return None, {"error": "ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜ IDì…ë‹ˆë‹¤."}
        if session_state.get('is_completed', False):
            return None, {"error": "ì´ë¯¸ ì™„ë£Œëœ ë©´ì ‘ì…ë‹ˆë‹¤."}
        return session_state, None

    async def _create_ai_persona(self, ai_candidate_model: AICandidateModel, company_id: str, position: str):
        try:
            persona = await asyncio.to_thread(
                ai_candidate_model.create_persona_for_interview, company_id, position
            )
            return persona if persona else ai_candidate_model._create_default_persona(company_id, position)
        except Exception as e:
            interview_logger.error(
                f"AI í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹¤íŒ¨(ì•ˆì „ í´ë°± ì ìš©): company_id={company_id}, position={position}, error={e}",
                exc_info=True
            )
            # ëª¨ë¸ ë‚´ë¶€ ì˜ˆì™¸ê°€ ë°œìƒí•´ë„ ì„œë¹„ìŠ¤ëŠ” ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ë¡œ ê³„ì† ì§„í–‰
            return ai_candidate_model._create_default_persona(company_id, position)

    async def _resolve_ai_resume_id(self, session_like: Dict[str, Any]) -> Optional[int]:
        """ê°€ëŠ¥í•œ ë‹¨ì„œë¡œ AI ì´ë ¥ì„œ IDë¥¼ ìœ ì¶”í•©ë‹ˆë‹¤."""
        try:
            # 1) ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì‚¬ìš©
            if session_like.get('ai_resume_id'):
                return int(session_like['ai_resume_id'])

            client = get_supabase_client()

            # 2) position_idê°€ ìˆìœ¼ë©´ í•´ë‹¹ í¬ì§€ì…˜ì˜ ai_resume ì¤‘ í•˜ë‚˜ ì„ íƒ
            position_id = session_like.get('position_id')
            if position_id:
                res = client.table('ai_resume').select('ai_resume_id').eq('position_id', position_id).limit(1).execute()
                if res.data:
                    return int(res.data[0]['ai_resume_id'])

            # 3) posting_idë¡œ position_idë¥¼ ë³µì› í›„ ì¬ì‹œë„
            posting_id = session_like.get('posting_id')
            if posting_id:
                try:
                    posting = await existing_tables_service.get_posting_by_id(posting_id)
                    if posting and posting.get('position_id'):
                        res = client.table('ai_resume').select('ai_resume_id').eq('position_id', posting['position_id']).limit(1).execute()
                        if res.data:
                            return int(res.data[0]['ai_resume_id'])
                except Exception:
                    pass

            # 4) ìµœí›„ ìˆ˜ë‹¨: ì•„ë¬´ ai_resume í•œ ê°œ
            res_any = client.table('ai_resume').select('ai_resume_id').limit(1).execute()
            if res_any.data:
                return int(res_any.data[0]['ai_resume_id'])
        except Exception as e:
            interview_logger.warning(f"ai_resume_id ìœ ì¶” ì‹¤íŒ¨: {e}")
        return None

    def _get_orchestrator_or_error(self, session_id: str) -> tuple[Optional[Orchestrator], Optional[Dict]]:
        orchestrator = self.active_orchestrators.get(session_id)
        if not orchestrator:
            return None, {"error": "ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜ IDì…ë‹ˆë‹¤."}
        if orchestrator.state.get('is_completed', False):
            return None, {"error": "ì´ë¯¸ ì™„ë£Œëœ ë©´ì ‘ì…ë‹ˆë‹¤."}
        return orchestrator, None

    async def submit_user_answer(self, session_id: str, user_answer: str, time_spent: float = None) -> Dict[str, Any]:
        try:
            interview_logger.info(f"DEBUG: submit_user_answer - í˜¸ì¶œë¨ (session_id: {session_id}). í˜„ì¬ self.session_states í‚¤: {self.session_states.keys()}")
            session_state, error = self.get_session_or_error(session_id)
            if error: 
                return error

            interview_logger.info(f"ğŸ‘¤ ì‚¬ìš©ì ë‹µë³€ ì œì¶œ: {session_id}")
            
            print(f"[Client] -> [InterviewService]")
            print(json.dumps({
                "session_id": session_id,
                "user_answer": user_answer,
                "time_spent": time_spent
            }, indent=2, ensure_ascii=False))
            
            # Orchestratorê°€ ëª¨ë“  ê²ƒì„ ì²˜ë¦¬
            orchestrator = self.active_orchestrators.get(session_id)
            if not orchestrator:
                return {"error": "Orchestratorë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            interview_logger.info(f"DEBUG: submit_user_answer - get_session_or_error í˜¸ì¶œ ì§ì „ (session_id: {session_id})")
            result = await orchestrator.process_user_answer(user_answer, time_spent)

            # ë©´ì ‘ì´ ì™„ë£Œë˜ë©´ í”¼ë“œë°± í‰ê°€ë¥¼ ë°±ê·¸ë¼ìš´ë“œë¡œ íŠ¸ë¦¬ê±°
            try:
                if isinstance(result, dict) and result.get('status') == 'completed':
                    interview_logger.info(f"ğŸ ì™„ë£Œ ìƒíƒœ ìˆ˜ì‹ . í”¼ë“œë°± íŠ¸ë¦¬ê±° ì‹¤í–‰: session_id={session_id}")
                    asyncio.create_task(self.trigger_feedback_for_session(session_id))
            except Exception as e:
                interview_logger.error(f"âŒ í”¼ë“œë°± íŠ¸ë¦¬ê±° ì‹¤íŒ¨: session_id={session_id}, error={e}")

            return result

        except Exception as e:
            interview_logger.error(f"ì‚¬ìš©ì ë‹µë³€ ì œì¶œ ì˜¤ë¥˜: {e}", exc_info=True)
            return {"error": f"ë‹µë³€ ì œì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

    async def start_ai_competition(self, settings: Dict[str, Any], start_time: float = None) -> Dict[str, Any]:
        try:
            interview_logger.info(f"DEBUG: start_ai_competition - í•¨ìˆ˜ ì‹œì‘. settings: {settings.get('candidate_name')}")
            session_id = f"comp_{uuid.uuid4().hex[:12]}"
            interview_logger.info(f"DEBUG: start_ai_competition - ìƒì„±ëœ session_id: {session_id}")
            # íšŒì‚¬ ì‹ë³„ì ë¶„ë¦¬: ëª¨ë¸/í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ ì½”ë“œ vs. DBìš© ìˆ«ì ID
            company_code_for_persona = self.get_company_id(settings['company'])  # ì˜ˆ: 'naver', 'kakao'
            company_numeric_id = settings.get('company_id')  # DBì˜ ì •ìˆ˜ IDì¼ ìˆ˜ ìˆìŒ
            ai_persona = await self._create_ai_persona(self.ai_candidate_model, company_code_for_persona, settings['position'])
            ai_resume_id = getattr(ai_persona, 'resume_id', None) if ai_persona else None

            # ë³´ê°•: personaì—ì„œ ëª» ë°›ì€ ê²½ìš° ë‹¤ì–‘í•œ ë‹¨ì„œë¡œ ìœ ì¶”
            if not ai_resume_id:
                ai_resume_id = await self._resolve_ai_resume_id(settings)
            
            # ì„¸ì…˜ ìƒíƒœ ìƒì„±
            initial_settings = {
                'total_question_limit': 2,  # ë””ë²„ê¹…ìš© - ì‹¤ì œ ìš´ì˜ì‹œì—ëŠ” 15ë¡œ ë³€ê²½
                'company_id': company_code_for_persona,  # ëª¨ë¸/ì§ˆë¬¸ ìƒì„± ë¡œì§ê³¼ í˜¸í™˜ë˜ëŠ” ë¬¸ìì—´ ì½”ë“œ ìœ ì§€
                'company_numeric_id': company_numeric_id,  # DB ì—°ë™ì„ ìœ„í•œ ìˆ«ì ID ë³„ë„ ë³´ê´€
                'position': settings['position'],
                'position_id': settings.get('position_id'),
                'posting_id': settings.get('posting_id'),
                'user_id': settings.get('user_id'),
                'user_name': settings['candidate_name'],
                'ai_persona': ai_persona,
                'ai_resume_id': int(ai_resume_id) if ai_resume_id else None
            }
            # ì‚¬ìš©ì ì´ë ¥ì„œ IDë¥¼ ì„¸ì…˜ì— ì €ì¥ (ìˆìœ¼ë©´)
            if settings.get('user_resume_id'):
                try:
                    initial_settings['user_resume_id'] = int(settings['user_resume_id'])
                except Exception:
                    initial_settings['user_resume_id'] = None

            # --- â–¼â–¼â–¼ ë°”ë¡œ ì´ ë¶€ë¶„ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”! â–¼â–¼â–¼ ---
            initial_settings['calibration_data'] = settings.get('calibration_data')
            interview_logger.info(f"DEBUG: start_ai_competition - create_session_state í˜¸ì¶œ ì§ì „ (session_id: {session_id})")
            session_state = self.create_session_state(session_id, initial_settings)
            interview_logger.info(f"DEBUG: start_ai_competition - create_session_state í˜¸ì¶œ ì™„ë£Œ (session_id: {session_id}, keys: {session_state.keys()})")
            
            # Orchestrator ìƒì„± - ì—ì´ì „íŠ¸ë“¤ë„ ì „ë‹¬
            orchestrator = Orchestrator(
                session_id=session_id, 
                session_state=session_state,
                question_generator=self.question_generator,
                ai_candidate_model=self.ai_candidate_model
            )
            self.active_orchestrators[session_id] = orchestrator
            interview_logger.info(f"DEBUG: start_ai_competition - Orchestrator í™œì„±í™” ì™„ë£Œ (session_id: {session_id}). í˜„ì¬ active_orchestrators í‚¤: {self.active_orchestrators.keys()}")
            
            interview_logger.info(f"AI ê²½ìŸ ë©´ì ‘ ì‹œì‘: {session_id}")
            
            print(f"[Client] -> [InterviewService]")
            print(json.dumps(settings, indent=2, ensure_ascii=False))
            
            # âš¡ INTROë§Œ ì²˜ë¦¬í•˜ê³  ì¦‰ì‹œ API ì‘ë‹µ (ì†ë„ ìµœì í™”)
            result = await orchestrator._process_initial_flow()
            # session_idëŠ” ì´ë¯¸ _process_initial_flowì—ì„œ í¬í•¨ë¨

            # ğŸ” DEBUG: ìµœì¢… API ì‘ë‹µ êµ¬ì¡° í™•ì¸
            print(f"[ğŸ” API_RESPONSE_DEBUG] === ìµœì¢… API ì‘ë‹µ êµ¬ì¡° ë¶„ì„ ===")
            print(f"[ğŸ” API_RESPONSE_DEBUG] result íƒ€ì…: {type(result)}")
            print(f"[ğŸ” API_RESPONSE_DEBUG] result í‚¤ë“¤: {list(result.keys()) if isinstance(result, dict) else 'Not a dict'}")
            
            if isinstance(result, dict):
                for key, value in result.items():
                    if key in ['intro_audio', 'first_question_audio']:
                        print(f"[ğŸ” API_RESPONSE_DEBUG] {key}: {bool(value)} ({type(value).__name__}) - ê¸¸ì´: {len(str(value)) if value else 0}")
                    else:
                        print(f"[ğŸ” API_RESPONSE_DEBUG] {key}: {bool(value)} ({type(value).__name__})")
                        if key == 'first_question' and value:
                            print(f"[ğŸ” API_RESPONSE_DEBUG] first_question ë‚´ìš©: {str(value)[:50]}...")
            
            print(f"[ğŸ” API_RESPONSE_DEBUG] === FastAPIë¡œ ì „ë‹¬ë  result ===")
            
            interview_logger.info(f"DEBUG: start_ai_competition - ìµœì¢… ì‘ë‹µ ë°˜í™˜ ì§ì „ (session_id: {session_id})")
            return result

        except Exception as e:
            interview_logger.error(f"AI ê²½ìŸ ë©´ì ‘ ì‹œì‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return {"error": f"ë©´ì ‘ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

    def get_interview_flow_status(self, session_id: str) -> Dict[str, Any]:
        """í˜„ì¬ ë©´ì ‘ ì§„í–‰ ìƒíƒœì™€ ë‹¤ìŒ ì•¡ì…˜ì„ ë°˜í™˜"""
        session_state, error = self.get_session_or_error(session_id)
        if error:
            return error
        
        return session_state

    async def trigger_feedback_for_session(self, session_id: str) -> None:
        """ë©´ì ‘ ì™„ë£Œ ì‹œ ì„¸ì…˜ì˜ QA íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í”¼ë“œë°± í‰ê°€/ê³„íšì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰"""
        try:
            from llm.feedback.api_models import QuestionAnswerPair
            from llm.feedback.api_service import InterviewEvaluationService
            import os
            import glob
            interview_logger.info(f"í”¼ë“œë°± íŠ¸ë¦¬ê±° ì‹œì‘: {session_id}")
            await asyncio.sleep(5)  # CPU ì‚¬ìš© ì—†ì´ 5ì´ˆ ë¹„ë™ê¸° ëŒ€ê¸°
            interview_logger.info(f"í”¼ë“œë°± íŠ¸ë¦¬ê±° ì¢…ë£Œ: {session_id}")
            session_state = self.session_states.get(session_id)
            if not session_state:
                return

            qa_history = session_state.get('qa_history', [])
            if not qa_history:
                return

            user_id = session_state.get('user_id')
            # í‰ê°€ ì„œë¹„ìŠ¤ëŠ” ìˆ«ì company_idë¥¼ ìš”êµ¬í•˜ë¯€ë¡œ numeric ìš°ì„  ì‚¬ìš©
            company_id = session_state.get('company_numeric_id') or session_state.get('company_id')
            position_id = session_state.get('position_id')
            posting_id = session_state.get('posting_id')
            ai_resume_id = session_state.get('ai_resume_id') or await self._resolve_ai_resume_id(session_state)
            user_resume_id = session_state.get('user_resume_id')

            # í•„ìˆ˜ ê°’(company_id, user_id)ì´ ì—†ìœ¼ë©´ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
            interview_logger.info(f"ğŸ” í”¼ë“œë°± ì‹¤í–‰ ì¡°ê±´ ì²´í¬: company_id={company_id}, user_id={user_id}")
            if not company_id or not user_id:
                interview_logger.warning(f"âš ï¸ í•„ìˆ˜ê°’ ëˆ„ë½ìœ¼ë¡œ í”¼ë“œë°± ì‹¤í–‰ ì¤‘ë‹¨: company_id={company_id}, user_id={user_id}")
                return

            # ì‚¬ìš©ì/AI ë¶„ë¦¬
            user_qas = [qa for qa in qa_history if qa.get('answerer') == 'user']
            ai_qas = [qa for qa in qa_history if qa.get('answerer') == 'ai']
            interview_logger.info(f"ğŸ“Š QA íˆìŠ¤í† ë¦¬ ë¶„ì„: user_qas={len(user_qas)}ê°œ, ai_qas={len(ai_qas)}ê°œ")

            # QuestionAnswerPair ëª©ë¡ ìƒì„±
            def build_pairs(items: list) -> list:
                pairs: list[QuestionAnswerPair] = []
                for qa in items:
                    pairs.append(QuestionAnswerPair(
                        question=qa.get('question', ''),
                        answer=qa.get('answer', ''),
                        duration=qa.get('duration') or 120,
                        question_level=qa.get('question_level') or 1,
                    ))
                return pairs

            evaluation_service = InterviewEvaluationService()
            shared_interview_id = None

            # í†µí•© í‰ê°€ (ì‚¬ìš©ìì™€ AI ì§€ì›ìë¥¼ í•˜ë‚˜ì˜ interview ì„¸ì…˜ì— ì €ì¥)
            if user_qas or ai_qas:
                interview_logger.info(f"ğŸ”„ í†µí•© ë©´ì ‘ í‰ê°€ ì‹œì‘: user={len(user_qas)}ê°œ, ai={len(ai_qas)}ê°œ ì§ˆë¬¸")
                
                user_pairs = build_pairs(user_qas) if user_qas else []
                ai_pairs = build_pairs(ai_qas) if ai_qas else []
                
                # ìƒˆë¡œìš´ í†µí•© í‰ê°€ ë©”ì„œë“œ í˜¸ì¶œ
                combined_eval = evaluation_service.evaluate_combined_interview(
                    user_id=user_id,
                    user_qas=user_pairs,
                    ai_qas=ai_pairs,
                    ai_resume_id=ai_resume_id,
                    user_resume_id=user_resume_id,
                    posting_id=posting_id,
                    company_id=company_id,
                    position_id=position_id
                )
                
                if combined_eval and combined_eval.get('success'):
                    shared_interview_id = combined_eval['interview_id']
                    interview_logger.info(f"âœ… í†µí•© ë©´ì ‘ í‰ê°€ ì™„ë£Œ: interview_id={shared_interview_id}")
                    interview_logger.info(f"ğŸ“Š í‰ê°€ ê²°ê³¼: ì‚¬ìš©ì ì ìˆ˜={combined_eval.get('user_score', 0):.2f}, AI ì ìˆ˜={combined_eval.get('ai_score', 0):.2f}")
                    
                    # ğŸ†• ì„ì‹œ ì‹œì„  ì¶”ì  íŒŒì¼ ì²˜ë¦¬ (interview_id ìƒì„± í›„)
                    if shared_interview_id:
                        await self._process_temporary_gaze_file(session_id, shared_interview_id)
                        # ğŸ†• ì‹œì„  ë¶„ì„ ë°ì´í„° ì§€ì—° ì²˜ë¦¬ (Pre-signed URL ê¸°ë°˜)
                        await self._process_gaze_data_after_evaluation(shared_interview_id, session_id, user_id)
                    
                    # ê°œì„  ê³„íš ìƒì„±
                    try:
                        evaluation_service.generate_interview_plans(shared_interview_id)
                        interview_logger.info(f"âœ… ë©´ì ‘ ê³„íš ìƒì„± ì™„ë£Œ: interview_id={shared_interview_id}")
                    except Exception as e:
                        interview_logger.error(f"âŒ ë©´ì ‘ ê³„íš ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
                else:
                    interview_logger.error(f"âŒ í†µí•© ë©´ì ‘ í‰ê°€ ì‹¤íŒ¨: {combined_eval}")
            else:
                interview_logger.warning(f"âš ï¸ ì‚¬ìš©ì/AI QA ëª¨ë‘ ì—†ì–´ì„œ í‰ê°€ë¥¼ ê±´ë„ˆëœ€")

        except Exception as e:
            interview_logger.error(f"âŒ í”¼ë“œë°± ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}", exc_info=True)
            return

    async def _process_temporary_gaze_file(self, session_id: str, interview_id: int) -> None:
        """ì„ì‹œ íŒŒì¼ì„ Boto3ë¡œ S3ì— ì—…ë¡œë“œí•˜ê³ , ê·¸ ë©”íƒ€ë°ì´í„°ë¥¼ Supabase DBì— ì €ì¥í•œ í›„, ë¶„ì„ì„ íŠ¸ë¦¬ê±°"""
        try:
            from datetime import datetime
            import glob

            # 1. ì„ì‹œ íŒŒì¼ ì°¾ê¸°
            temp_folder = "backend/uploads/temp_gaze"
            temp_files = glob.glob(os.path.join(temp_folder, f"{session_id}.*"))

            if not temp_files:
                interview_logger.info(f"ğŸ” ì„¸ì…˜ {session_id}ì— ëŒ€í•œ ì„ì‹œ ì‹œì„  ì¶”ì  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return

            temp_file_path = temp_files[0]
            interview_logger.info(f"ğŸ“ ì„ì‹œ íŒŒì¼ ë°œê²¬: {temp_file_path}")

            # 2. Boto3 S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            access_key = os.getenv('AWS_ACCESS_KEY_ID')
            secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')
            region = os.getenv('AWS_REGION', 'ap-northeast-2')
            bucket_name = 'betago-s3'

            if not access_key or not secret_key:
                interview_logger.error("âŒ AWS ìê²©ì¦ëª…ì´ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return

            s3_client = boto3.client('s3', aws_access_key_id=access_key, aws_secret_access_key=secret_key, region_name=region)

            # 3. S3ì— ì—…ë¡œë“œí•  ê²½ë¡œ ë° íŒŒì¼ëª… ê²°ì •
            file_extension = os.path.splitext(temp_file_path)[1]
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            s3_key = f"gaze_tracking/{interview_id}/gaze_video_{timestamp}{file_extension}"

            # 4. S3ì— íŒŒì¼ ì—…ë¡œë“œ
            interview_logger.info(f"ğŸ“¤ S3ì— íŒŒì¼ ì—…ë¡œë“œ ì‹œì‘: Bucket={bucket_name}, Key={s3_key}")
            s3_client.upload_file(temp_file_path, bucket_name, s3_key)
            interview_logger.info(f"âœ… S3 ì—…ë¡œë“œ ì„±ê³µ: {s3_key}")

            # 5. Supabase DBì— ë©”íƒ€ë°ì´í„° ì €ì¥
            try:
                supabase_db_client = get_supabase_client()

                # ì„¸ì…˜ì—ì„œ user_id ê°€ì ¸ì˜¤ê¸°
                session_state = self.session_states.get(session_id)
                user_id = session_state.get('user_id') if session_state else None
                if not user_id:
                    raise Exception(f"ì„¸ì…˜({session_id})ì—ì„œ user_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                # S3 URL ë° íŒŒì¼ í¬ê¸° ê³„ì‚°
                s3_url = f"https://{bucket_name}.s3.{region}.amazonaws.com/{s3_key}"
                file_size = os.path.getsize(temp_file_path)

                # DB ìŠ¤í‚¤ë§ˆì— ë§ëŠ” ë°ì´í„° êµ¬ì„±
                media_data_to_insert = {
                    'user_id': user_id,
                    'interview_id': interview_id,
                    'file_name': os.path.basename(s3_key),
                    'file_type': 'video',
                    's3_url': s3_url,
                    's3_key': s3_key,
                    'file_size': file_size,
                }

                interview_logger.info(f"ğŸ’¾ DBì— ì €ì¥í•  ë©”íƒ€ë°ì´í„°: {media_data_to_insert}")
                insert_result = supabase_db_client.table('media_files').insert(media_data_to_insert).execute()

                if insert_result.data:
                    media_record_id = insert_result.data[0]['media_id']
                    interview_logger.info(f"âœ… Supabase DBì— ë¯¸ë””ì–´ ë©”íƒ€ë°ì´í„° ì €ì¥ ì„±ê³µ. media_id: {media_record_id}")
                else:
                    raise Exception(f"DB insert ì‹¤íŒ¨: {getattr(insert_result, 'error', 'Unknown error')}")

            except Exception as db_error:
                interview_logger.error(f"âŒ ë¯¸ë””ì–´ ë©”íƒ€ë°ì´í„° DB ì €ì¥ ì‹¤íŒ¨: {db_error}", exc_info=True)
                return

            # 6. ì‹œì„  ë¶„ì„ ì„œë¹„ìŠ¤ í˜¸ì¶œ
            try:
                interview_logger.info(f"ğŸ“Š ì‹œì„  ë¶„ì„ ì‹œì‘: interview_id={interview_id}, s3_path={s3_key}")
                session_state = self.session_states.get(session_id)

                # 6-1. ì„¸ì…˜ì—ì„œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                calibration_data = session_state.get('calibration_data')
                if not calibration_data:
                    raise Exception(f"ì„¸ì…˜({session_id})ì—ì„œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                calibration_points = calibration_data.get('calibration_points')
                initial_face_size = calibration_data.get('initial_face_size')

                if not calibration_points:
                     raise Exception(f"ì„¸ì…˜({session_id})ì˜ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°ì— points ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

                # 6-2. gaze_analyzerë¡œ ë¶„ì„ ì‹¤í–‰
                analysis_result = gaze_analyzer.analyze_video_from_s3(
                    bucket=bucket_name,
                    key=s3_key,
                    calibration_points=calibration_points,
                    initial_face_size=initial_face_size
                )

                # 6-3. ë¶„ì„ ê²°ê³¼ë¥¼ DBì— ì €ì¥ (ê°ì²´ ì†ì„± ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •)
                if analysis_result:
                    try:
                        supabase_client = get_supabase_client()

                        # video_metadata JSON ê°ì²´ êµ¬ì„±
                        video_metadata = {
                            "total_frames": getattr(analysis_result, 'total_frames', 0),
                            "analyzed_frames": getattr(analysis_result, 'analyzed_frames', 0),
                            "in_range_ratio": getattr(analysis_result, 'in_range_ratio', 0),
                            "analysis_duration_sec": getattr(analysis_result, 'analysis_duration', 0),
                            "feedback_summary": getattr(analysis_result, 'feedback', "N/A")
                        }

                        # DBì— ì €ì¥í•  ë°ì´í„° êµ¬ì„± (ì‚¬ìš©ì í…Œì´ë¸” ìŠ¤í‚¤ë§ˆì— ë§ì¶¤)
                        data_to_insert = {
                            "interview_id": interview_id,
                            "user_id": user_id,
                            "gaze_score": getattr(analysis_result, 'gaze_score', 0),
                            "jitter_score": getattr(analysis_result, 'jitter_score', 0),
                            "compliance_score": getattr(analysis_result, 'compliance_score', 0),
                            "stability_rating": getattr(analysis_result, 'stability_rating', "Error"),
                            "gaze_points": getattr(analysis_result, 'gaze_points', []),
                            "calibration_points": getattr(analysis_result, 'calibration_points', []),
                            "video_metadata": video_metadata
                        }

                        interview_logger.info(f"ğŸ’¾ ì‹œì„  ë¶„ì„ ê²°ê³¼ DB ì €ì¥ ì‹œë„: interview_id={interview_id}")

                        insert_res = supabase_client.table('gaze_analysis').insert(data_to_insert).execute()

                        if insert_res.data:
                            interview_logger.info(f"âœ… ì‹œì„  ë¶„ì„ ê²°ê³¼ DB ì €ì¥ ì„±ê³µ. gaze_id: {insert_res.data[0].get('gaze_id')}")
                        else:
                            error_details = getattr(insert_res, 'error', 'Unknown error')
                            raise Exception(f"DB insert ì‹¤íŒ¨: {error_details}")

                    except Exception as db_save_error:
                        interview_logger.error(f"âŒ ì‹œì„  ë¶„ì„ ê²°ê³¼ DB ì €ì¥ ì‹¤íŒ¨: {db_save_error}", exc_info=True)
                else:
                    interview_logger.error(f"âŒ ì‹œì„  ë¶„ì„ ì‹¤íŒ¨: analysis_resultê°€ ì—†ìŠµë‹ˆë‹¤.")

            except Exception as analysis_error:
                interview_logger.error(f"âŒ ì‹œì„  ë¶„ì„ ë˜ëŠ” ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {analysis_error}", exc_info=True)

        except Exception as e:
            interview_logger.error(f"âŒ ì„ì‹œ ì‹œì„  ì¶”ì  íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: session_id={session_id}, error={str(e)}", exc_info=True)
        finally:
            # 7. ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if 'temp_file_path' in locals() and os.path.exists(temp_file_path):
                try:
                    os.remove(temp_file_path)
                    interview_logger.info(f"ğŸ—‘ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {temp_file_path}")
                except Exception as cleanup_error:
                    interview_logger.error(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {str(cleanup_error)}")

    async def _process_gaze_data_after_evaluation(self, interview_id: int, session_id: str, user_id: int) -> None:
        """
        ë©´ì ‘ í‰ê°€ ì™„ë£Œ í›„ ì‹œì„  ë¶„ì„ ë°ì´í„° ì§€ì—° ì²˜ë¦¬
        
        Pre-signed URL ê¸°ë°˜ ì—…ë¡œë“œ í”Œë¡œìš°ì—ì„œ interview_idê°€ í™•ì •ëœ í›„:
        1. analysis_tasksì—ì„œ í•´ë‹¹ ì„¸ì…˜ì˜ ì‹œì„  ë¶„ì„ ê²°ê³¼ ì°¾ê¸°
        2. media_files í…Œì´ë¸”ì— ë ˆì½”ë“œ ì‚½ì…
        3. gaze_analysis í…Œì´ë¸”ì— ë¶„ì„ ê²°ê³¼ ì €ì¥
        """
        try:
            from backend.routers.gaze import analysis_tasks
            import os
            
            interview_logger.info(f"ğŸ“Š ë©´ì ‘ í‰ê°€ í›„ ì‹œì„  ë°ì´í„° ì²˜ë¦¬ ì‹œì‘: interview_id={interview_id}, session_id={session_id}")

            # 1. analysis_tasksì—ì„œ í•´ë‹¹ ì„¸ì…˜ì˜ ë¶„ì„ ê²°ê³¼ ì°¾ê¸°
            session_task_data = None
            session_task_id = None
            
            for task_id, task_info in analysis_tasks.items():
                if (task_info.get("session_id") == session_id and 
                    task_info.get("user_id") == user_id and 
                    task_info.get("status") == "completed"):
                    session_task_data = task_info
                    session_task_id = task_id
                    break

            if not session_task_data:
                interview_logger.info(f"ğŸ“ ì„¸ì…˜ {session_id}ì— ëŒ€í•œ ì™„ë£Œëœ ì‹œì„  ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Pre-signed URL ì—…ë¡œë“œê°€ ì—†ì—ˆê±°ë‚˜ ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                return

            s3_key_found = session_task_data.get("s3_key")
            temp_media_id_found = session_task_data.get("temp_media_id")
            analysis_result = session_task_data.get("analysis_result")  # ì›ë³¸ ë¶„ì„ ê²°ê³¼ ê°ì²´

            interview_logger.info(f"âœ… ì‹œì„  ë¶„ì„ ê²°ê³¼ ë°œê²¬: task_id={session_task_id}, s3_key={s3_key_found}")

            # 2. media_files í…Œì´ë¸”ì— ë ˆì½”ë“œ ì‚½ì…
            try:
                supabase_db_client = get_supabase_client()
                
                # S3 URL ë° íŒŒì¼ ì •ë³´ ìƒì„±
                BUCKET_NAME = 'betago-s3'
                AWS_REGION = os.getenv('AWS_REGION', 'ap-northeast-2')
                file_name = os.path.basename(s3_key_found)
                s3_url = f"https://{BUCKET_NAME}.s3.{AWS_REGION}.amazonaws.com/{s3_key_found}"

                media_data_to_insert = {
                    'user_id': user_id,
                    'interview_id': interview_id,  # í™•ì •ëœ interview_id ì‚¬ìš©
                    'file_name': file_name,
                    'file_type': 'video',
                    's3_url': s3_url,
                    's3_key': s3_key_found,
                    'media_id': temp_media_id_found,  # ì„ì‹œ media_idë¥¼ ìµœì¢… media_idë¡œ ì‚¬ìš©
                    'metadata': {
                        'type': 'gaze_tracking',
                        'purpose': 'gaze_analysis',
                        'delayed_insert': True,
                        'original_session_id': session_id
                    }
                }

                interview_logger.info(f"ğŸ’¾ media_files í…Œì´ë¸” ì‚½ì… ì‹œë„: {media_data_to_insert}")
                insert_result = supabase_db_client.table('media_files').insert(media_data_to_insert).execute()

                if insert_result.data:
                    final_media_id = insert_result.data[0]['media_id']
                    interview_logger.info(f"âœ… media_files ë ˆì½”ë“œ ì‚½ì… ì™„ë£Œ: media_id={final_media_id}")
                else:
                    raise Exception(f"media_files ì‚½ì… ì‹¤íŒ¨: {getattr(insert_result, 'error', 'Unknown error')}")

            except Exception as e:
                interview_logger.error(f"âŒ media_files ì‚½ì… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
                return

            # 3. gaze_analysis í…Œì´ë¸”ì— ë¶„ì„ ê²°ê³¼ ì €ì¥ (analysis_resultê°€ ìˆëŠ” ê²½ìš°)
            if analysis_result:
                try:
                    supabase_client = get_supabase_client()

                    # video_metadata JSON ê°ì²´ êµ¬ì„±
                    video_metadata = {
                        "total_frames": getattr(analysis_result, 'total_frames', 0),
                        "analyzed_frames": getattr(analysis_result, 'analyzed_frames', 0),
                        "in_range_ratio": getattr(analysis_result, 'in_range_ratio', 0),
                        "analysis_duration_sec": getattr(analysis_result, 'analysis_duration', 0),
                        "feedback_summary": getattr(analysis_result, 'feedback', "N/A"),
                        "delayed_processing": True,
                        "source_session_id": session_id
                    }

                    # DBì— ì €ì¥í•  ë°ì´í„° êµ¬ì„±
                    gaze_data_to_insert = {
                        "interview_id": interview_id,
                        "user_id": user_id,
                        "gaze_score": getattr(analysis_result, 'gaze_score', 0),
                        "jitter_score": getattr(analysis_result, 'jitter_score', 0),
                        "compliance_score": getattr(analysis_result, 'compliance_score', 0),
                        "stability_rating": getattr(analysis_result, 'stability_rating', "Unknown"),
                        "gaze_points": getattr(analysis_result, 'gaze_points', []),
                        "calibration_points": getattr(analysis_result, 'calibration_points', []),
                        "video_metadata": video_metadata
                    }

                    interview_logger.info(f"ğŸ’¾ gaze_analysis í…Œì´ë¸” ì‚½ì… ì‹œë„: interview_id={interview_id}")
                    gaze_insert_result = supabase_client.table('gaze_analysis').insert(gaze_data_to_insert).execute()

                    if gaze_insert_result.data:
                        gaze_id = gaze_insert_result.data[0].get('gaze_id')
                        interview_logger.info(f"âœ… gaze_analysis ë ˆì½”ë“œ ì‚½ì… ì™„ë£Œ: gaze_id={gaze_id}")
                    else:
                        error_details = getattr(gaze_insert_result, 'error', 'Unknown error')
                        raise Exception(f"gaze_analysis ì‚½ì… ì‹¤íŒ¨: {error_details}")

                except Exception as e:
                    interview_logger.error(f"âŒ gaze_analysis ì‚½ì… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)

            # 4. analysis_tasksì—ì„œ ì²˜ë¦¬ëœ task ì •ë¦¬ (ì„ íƒì )
            try:
                if session_task_id in analysis_tasks:
                    analysis_tasks[session_task_id]['processed'] = True
                    analysis_tasks[session_task_id]['linked_interview_id'] = interview_id
                    interview_logger.info(f"ğŸ§¹ analysis_task {session_task_id} ì²˜ë¦¬ ì™„ë£Œ í‘œì‹œ")
            except Exception as cleanup_error:
                interview_logger.warning(f"âš ï¸ analysis_task ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {cleanup_error}")

            interview_logger.info(f"âœ… ì‹œì„  ë¶„ì„ ë°ì´í„° ì§€ì—° ì²˜ë¦¬ ì™„ë£Œ: interview_id={interview_id}, session_id={session_id}")

        except Exception as e:
            interview_logger.error(f"âŒ ì‹œì„  ë¶„ì„ ë°ì´í„° ì§€ì—° ì²˜ë¦¬ ì‹¤íŒ¨: session_id={session_id}, interview_id={interview_id}, error={str(e)}", exc_info=True)

