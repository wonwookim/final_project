import json
import json
from typing import Dict, Any, List, Optional
import asyncio
import uuid
import time
from llm.interviewer.question_generator import QuestionGenerator
from llm.candidate.model import AICandidateModel, CandidatePersona
from llm.shared.models import AnswerRequest, QuestionType, LLMProvider
from llm.candidate.quality_controller import QualityLevel
from llm.shared.logging_config import interview_logger

from backend.services.Orchestrator import Orchestrator
from backend.services.supabase_client import get_supabase_client
from backend.services.existing_tables_service import existing_tables_service

class InterviewService:
    def __init__(self):
        # ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ (Orchestratorì˜ stateë¥¼ ì—¬ê¸°ë¡œ ì´ê´€)
        self.session_states: Dict[str, Dict[str, Any]] = {}
        self.active_orchestrators: Dict[str, Orchestrator] = {}
        self.question_generator = QuestionGenerator()
        self.ai_candidate_model = AICandidateModel()
        
        # ì—ì´ì „íŠ¸ í•¸ë“¤ëŸ¬ëŠ” Orchestratorë¡œ ì´ê´€ë¨
        
        self.company_name_map = {
            "ë„¤ì´ë²„": "naver", "ì¹´ì¹´ì˜¤": "kakao", "ë¼ì¸": "line",
            "ë¼ì¸í”ŒëŸ¬ìŠ¤": "ë¼ì¸í”ŒëŸ¬ìŠ¤", "ì¿ íŒ¡": "coupang", "ë°°ë‹¬ì˜ë¯¼ì¡±": "baemin",
            "ë‹¹ê·¼ë§ˆì¼“": "daangn", "í† ìŠ¤": "toss"
        }

    def get_company_id(self, company_name: str) -> str:
        return self.company_name_map.get(company_name, company_name.lower())

    # ì„¸ì…˜ ê´€ë¦¬ ë©”ì„œë“œë“¤
    def get_active_sessions(self) -> List[str]:
        """í˜„ì¬ í™œì„± ì„¸ì…˜ IDë“¤ì„ ë°˜í™˜"""
        return list(self.session_states.keys())
    
    def get_session_state(self, session_id: str) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • ì„¸ì…˜ì˜ ìƒíƒœë¥¼ ë°˜í™˜"""
        return self.session_states.get(session_id)
    
    def has_active_session(self, session_id: str) -> bool:
        """ì„¸ì…˜ì´ í™œì„± ìƒíƒœì¸ì§€ í™•ì¸"""
        return session_id in self.session_states
    
    def create_session_state(self, session_id: str, initial_settings: Dict[str, Any]) -> Dict[str, Any]:
        """ìƒˆë¡œìš´ ì„¸ì…˜ ìƒíƒœ ìƒì„±"""
        session_state = {
            "turn_count": 0,
            "current_question": None,
            "qa_history": [],
            "is_completed": False,
            "start_time": time.perf_counter(),
            # ğŸ†• ê¼¬ë¦¬ ì§ˆë¬¸ ê´€ë¦¬ë¥¼ ìœ„í•œ í•„ë“œë“¤ ì¶”ê°€
            "interviewer_turn_state": {
                'HR': {'main_question_asked': False, 'follow_up_count': 0},
                'TECH': {'main_question_asked': False, 'follow_up_count': 0},
                'COLLABORATION': {'main_question_asked': False, 'follow_up_count': 0}
            },
            "current_interviewer": None,
            # ğŸ†• TTS í†µí•© í: {'type': 'ìœ í˜•', 'content': 'TTSí•  í…ìŠ¤íŠ¸'} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ ì €ì¥
            "tts_queue": [],
            # ğŸ†• ì¤‘ë³µ ì œê±°: qa_historyì—ì„œ ìµœì‹  ë°ì´í„° ì¶”ì¶œ
            **initial_settings
        }
        self.session_states[session_id] = session_state
        return session_state
    
    def update_session_state(self, session_id: str, updates: Dict[str, Any]) -> bool:
        """ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        if session_id not in self.session_states:
            return False
        self.session_states[session_id].update(updates)
        return True
    
    def remove_session(self, session_id: str) -> bool:
        """ì„¸ì…˜ ì œê±°"""
        if session_id in self.session_states:
            del self.session_states[session_id]
        if session_id in self.active_orchestrators:
            del self.active_orchestrators[session_id]
        return True
    
    def get_session_or_error(self, session_id: str) -> tuple[Optional[Dict[str, Any]], Optional[Dict]]:
        """ì„¸ì…˜ ìƒíƒœë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ì—ëŸ¬ ë°˜í™˜"""
        session_state = self.session_states.get(session_id)
        if not session_state:
            return None, {"error": "ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜ IDì…ë‹ˆë‹¤."}
        if session_state.get('is_completed', False):
            return None, {"error": "ì´ë¯¸ ì™„ë£Œëœ ë©´ì ‘ì…ë‹ˆë‹¤."}
        return session_state, None

    async def _create_ai_persona(self, ai_candidate_model: AICandidateModel, company_id: str, position: str):
        try:
            persona = await asyncio.to_thread(
                ai_candidate_model.create_persona_for_interview, company_id, position
            )
            return persona if persona else ai_candidate_model._create_default_persona(company_id, position)
        except Exception as e:
            interview_logger.error(
                f"AI í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹¤íŒ¨(ì•ˆì „ í´ë°± ì ìš©): company_id={company_id}, position={position}, error={e}",
                exc_info=True
            )
            # ëª¨ë¸ ë‚´ë¶€ ì˜ˆì™¸ê°€ ë°œìƒí•´ë„ ì„œë¹„ìŠ¤ëŠ” ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ë¡œ ê³„ì† ì§„í–‰
            return ai_candidate_model._create_default_persona(company_id, position)

    async def _resolve_ai_resume_id(self, session_like: Dict[str, Any]) -> Optional[int]:
        """ê°€ëŠ¥í•œ ë‹¨ì„œë¡œ AI ì´ë ¥ì„œ IDë¥¼ ìœ ì¶”í•©ë‹ˆë‹¤."""
        try:
            # 1) ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì‚¬ìš©
            if session_like.get('ai_resume_id'):
                return int(session_like['ai_resume_id'])

            client = get_supabase_client()

            # 2) position_idê°€ ìˆìœ¼ë©´ í•´ë‹¹ í¬ì§€ì…˜ì˜ ai_resume ì¤‘ í•˜ë‚˜ ì„ íƒ
            position_id = session_like.get('position_id')
            if position_id:
                res = client.table('ai_resume').select('ai_resume_id').eq('position_id', position_id).limit(1).execute()
                if res.data:
                    return int(res.data[0]['ai_resume_id'])

            # 3) posting_idë¡œ position_idë¥¼ ë³µì› í›„ ì¬ì‹œë„
            posting_id = session_like.get('posting_id')
            if posting_id:
                try:
                    posting = await existing_tables_service.get_posting_by_id(posting_id)
                    if posting and posting.get('position_id'):
                        res = client.table('ai_resume').select('ai_resume_id').eq('position_id', posting['position_id']).limit(1).execute()
                        if res.data:
                            return int(res.data[0]['ai_resume_id'])
                except Exception:
                    pass

            # 4) ìµœí›„ ìˆ˜ë‹¨: ì•„ë¬´ ai_resume í•œ ê°œ
            res_any = client.table('ai_resume').select('ai_resume_id').limit(1).execute()
            if res_any.data:
                return int(res_any.data[0]['ai_resume_id'])
        except Exception as e:
            interview_logger.warning(f"ai_resume_id ìœ ì¶” ì‹¤íŒ¨: {e}")
        return None

    def _get_orchestrator_or_error(self, session_id: str) -> tuple[Optional[Orchestrator], Optional[Dict]]:
        orchestrator = self.active_orchestrators.get(session_id)
        if not orchestrator:
            return None, {"error": "ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜ IDì…ë‹ˆë‹¤."}
        if orchestrator.state.get('is_completed', False):
            return None, {"error": "ì´ë¯¸ ì™„ë£Œëœ ë©´ì ‘ì…ë‹ˆë‹¤."}
        return orchestrator, None

    async def submit_user_answer(self, session_id: str, user_answer: str, time_spent: float = None) -> Dict[str, Any]:
        try:
            session_state, error = self.get_session_or_error(session_id)
            if error: 
                return error

            interview_logger.info(f"ğŸ‘¤ ì‚¬ìš©ì ë‹µë³€ ì œì¶œ: {session_id}")
            
            print(f"[Client] -> [InterviewService]")
            print(json.dumps({
                "session_id": session_id,
                "user_answer": user_answer,
                "time_spent": time_spent
            }, indent=2, ensure_ascii=False))
            
            # Orchestratorê°€ ëª¨ë“  ê²ƒì„ ì²˜ë¦¬
            orchestrator = self.active_orchestrators.get(session_id)
            if not orchestrator:
                return {"error": "Orchestratorë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            result = await orchestrator.process_user_answer(user_answer, time_spent)

            # ë©´ì ‘ì´ ì™„ë£Œë˜ë©´ í”¼ë“œë°± í‰ê°€ë¥¼ ë°±ê·¸ë¼ìš´ë“œë¡œ íŠ¸ë¦¬ê±°
            try:
                if isinstance(result, dict) and result.get('status') == 'completed':
                    interview_logger.info(f"ğŸ ì™„ë£Œ ìƒíƒœ ìˆ˜ì‹ . í”¼ë“œë°± íŠ¸ë¦¬ê±° ì‹¤í–‰: session_id={session_id}")
                    asyncio.create_task(self.trigger_feedback_for_session(session_id))
            except Exception as e:
                interview_logger.error(f"âŒ í”¼ë“œë°± íŠ¸ë¦¬ê±° ì‹¤íŒ¨: session_id={session_id}, error={e}")

            return result

        except Exception as e:
            interview_logger.error(f"ì‚¬ìš©ì ë‹µë³€ ì œì¶œ ì˜¤ë¥˜: {e}", exc_info=True)
            return {"error": f"ë‹µë³€ ì œì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

    async def start_ai_competition(self, settings: Dict[str, Any], start_time: float = None) -> Dict[str, Any]:
        try:
            session_id = f"comp_{uuid.uuid4().hex[:12]}"
            # íšŒì‚¬ ì‹ë³„ì ë¶„ë¦¬: ëª¨ë¸/í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ ì½”ë“œ vs. DBìš© ìˆ«ì ID
            company_code_for_persona = self.get_company_id(settings['company'])  # ì˜ˆ: 'naver', 'kakao'
            company_numeric_id = settings.get('company_id')  # DBì˜ ì •ìˆ˜ IDì¼ ìˆ˜ ìˆìŒ
            ai_persona = await self._create_ai_persona(self.ai_candidate_model, company_code_for_persona, settings['position'])
            ai_resume_id = getattr(ai_persona, 'resume_id', None) if ai_persona else None

            # ë³´ê°•: personaì—ì„œ ëª» ë°›ì€ ê²½ìš° ë‹¤ì–‘í•œ ë‹¨ì„œë¡œ ìœ ì¶”
            if not ai_resume_id:
                ai_resume_id = await self._resolve_ai_resume_id(settings)
            
            # ì„¸ì…˜ ìƒíƒœ ìƒì„±
            initial_settings = {
                'total_question_limit': 3,  # ë””ë²„ê¹…ìš© - ì‹¤ì œ ìš´ì˜ì‹œì—ëŠ” 15ë¡œ ë³€ê²½
                'company_id': company_code_for_persona,  # ëª¨ë¸/ì§ˆë¬¸ ìƒì„± ë¡œì§ê³¼ í˜¸í™˜ë˜ëŠ” ë¬¸ìì—´ ì½”ë“œ ìœ ì§€
                'company_numeric_id': company_numeric_id,  # DB ì—°ë™ì„ ìœ„í•œ ìˆ«ì ID ë³„ë„ ë³´ê´€
                'position': settings['position'],
                'position_id': settings.get('position_id'),
                'posting_id': settings.get('posting_id'),
                'user_id': settings.get('user_id'),
                'user_name': settings['candidate_name'],
                'ai_persona': ai_persona,
                'ai_resume_id': int(ai_resume_id) if ai_resume_id else None
            }
            # ì‚¬ìš©ì ì´ë ¥ì„œ IDë¥¼ ì„¸ì…˜ì— ì €ì¥ (ìˆìœ¼ë©´)
            if settings.get('user_resume_id'):
                try:
                    initial_settings['user_resume_id'] = int(settings['user_resume_id'])
                except Exception:
                    initial_settings['user_resume_id'] = None
            
            session_state = self.create_session_state(session_id, initial_settings)
            
            # Orchestrator ìƒì„± - ì—ì´ì „íŠ¸ë“¤ë„ ì „ë‹¬
            orchestrator = Orchestrator(
                session_id=session_id, 
                session_state=session_state,
                question_generator=self.question_generator,
                ai_candidate_model=self.ai_candidate_model
            )
            self.active_orchestrators[session_id] = orchestrator
            
            interview_logger.info(f"AI ê²½ìŸ ë©´ì ‘ ì‹œì‘: {session_id}")
            
            print(f"[Client] -> [InterviewService]")
            print(json.dumps(settings, indent=2, ensure_ascii=False))
            
            # âš¡ INTROë§Œ ì²˜ë¦¬í•˜ê³  ì¦‰ì‹œ API ì‘ë‹µ (ì†ë„ ìµœì í™”)
            result = await orchestrator._process_initial_flow()
            # session_idëŠ” ì´ë¯¸ _process_initial_flowì—ì„œ í¬í•¨ë¨

            # ğŸ” DEBUG: ìµœì¢… API ì‘ë‹µ êµ¬ì¡° í™•ì¸
            print(f"[ğŸ” API_RESPONSE_DEBUG] === ìµœì¢… API ì‘ë‹µ êµ¬ì¡° ë¶„ì„ ===")
            print(f"[ğŸ” API_RESPONSE_DEBUG] result íƒ€ì…: {type(result)}")
            print(f"[ğŸ” API_RESPONSE_DEBUG] result í‚¤ë“¤: {list(result.keys()) if isinstance(result, dict) else 'Not a dict'}")
            
            if isinstance(result, dict):
                for key, value in result.items():
                    if key in ['intro_audio', 'first_question_audio']:
                        print(f"[ğŸ” API_RESPONSE_DEBUG] {key}: {bool(value)} ({type(value).__name__}) - ê¸¸ì´: {len(str(value)) if value else 0}")
                    else:
                        print(f"[ğŸ” API_RESPONSE_DEBUG] {key}: {bool(value)} ({type(value).__name__})")
                        if key == 'first_question' and value:
                            print(f"[ğŸ” API_RESPONSE_DEBUG] first_question ë‚´ìš©: {str(value)[:50]}...")
            
            print(f"[ğŸ” API_RESPONSE_DEBUG] === FastAPIë¡œ ì „ë‹¬ë  result ===")
            
            return result

        except Exception as e:
            interview_logger.error(f"AI ê²½ìŸ ë©´ì ‘ ì‹œì‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return {"error": f"ë©´ì ‘ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

    def get_interview_flow_status(self, session_id: str) -> Dict[str, Any]:
        """í˜„ì¬ ë©´ì ‘ ì§„í–‰ ìƒíƒœì™€ ë‹¤ìŒ ì•¡ì…˜ì„ ë°˜í™˜"""
        session_state, error = self.get_session_or_error(session_id)
        if error:
            return error
        
        return session_state

    async def trigger_feedback_for_session(self, session_id: str) -> None:
        """ë©´ì ‘ ì™„ë£Œ ì‹œ ì„¸ì…˜ì˜ QA íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í”¼ë“œë°± í‰ê°€/ê³„íšì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰"""
        try:
            from llm.feedback.api_models import QuestionAnswerPair
            from llm.feedback.api_service import InterviewEvaluationService
            import os
            import glob
            interview_logger.info(f"í”¼ë“œë°± íŠ¸ë¦¬ê±° ì‹œì‘: {session_id}")
            await asyncio.sleep(5)  # CPU ì‚¬ìš© ì—†ì´ 5ì´ˆ ë¹„ë™ê¸° ëŒ€ê¸°
            interview_logger.info(f"í”¼ë“œë°± íŠ¸ë¦¬ê±° ì¢…ë£Œ: {session_id}")
            session_state = self.session_states.get(session_id)
            if not session_state:
                return

            qa_history = session_state.get('qa_history', [])
            if not qa_history:
                return

            user_id = session_state.get('user_id')
            # í‰ê°€ ì„œë¹„ìŠ¤ëŠ” ìˆ«ì company_idë¥¼ ìš”êµ¬í•˜ë¯€ë¡œ numeric ìš°ì„  ì‚¬ìš©
            company_id = session_state.get('company_numeric_id') or session_state.get('company_id')
            position_id = session_state.get('position_id')
            posting_id = session_state.get('posting_id')
            ai_resume_id = session_state.get('ai_resume_id') or await self._resolve_ai_resume_id(session_state)
            user_resume_id = session_state.get('user_resume_id')

            # í•„ìˆ˜ ê°’(company_id, user_id)ì´ ì—†ìœ¼ë©´ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
            interview_logger.info(f"ğŸ” í”¼ë“œë°± ì‹¤í–‰ ì¡°ê±´ ì²´í¬: company_id={company_id}, user_id={user_id}")
            if not company_id or not user_id:
                interview_logger.warning(f"âš ï¸ í•„ìˆ˜ê°’ ëˆ„ë½ìœ¼ë¡œ í”¼ë“œë°± ì‹¤í–‰ ì¤‘ë‹¨: company_id={company_id}, user_id={user_id}")
                return

            # ì‚¬ìš©ì/AI ë¶„ë¦¬
            user_qas = [qa for qa in qa_history if qa.get('answerer') == 'user']
            ai_qas = [qa for qa in qa_history if qa.get('answerer') == 'ai']
            interview_logger.info(f"ğŸ“Š QA íˆìŠ¤í† ë¦¬ ë¶„ì„: user_qas={len(user_qas)}ê°œ, ai_qas={len(ai_qas)}ê°œ")

            # QuestionAnswerPair ëª©ë¡ ìƒì„±
            def build_pairs(items: list) -> list:
                pairs: list[QuestionAnswerPair] = []
                for qa in items:
                    pairs.append(QuestionAnswerPair(
                        question=qa.get('question', ''),
                        answer=qa.get('answer', ''),
                        duration=qa.get('duration') or 120,
                        question_level=qa.get('question_level') or 1,
                    ))
                return pairs

            evaluation_service = InterviewEvaluationService()
            shared_interview_id = None

            # í†µí•© í‰ê°€ (ì‚¬ìš©ìì™€ AI ì§€ì›ìë¥¼ í•˜ë‚˜ì˜ interview ì„¸ì…˜ì— ì €ì¥)
            if user_qas or ai_qas:
                interview_logger.info(f"ğŸ”„ í†µí•© ë©´ì ‘ í‰ê°€ ì‹œì‘: user={len(user_qas)}ê°œ, ai={len(ai_qas)}ê°œ ì§ˆë¬¸")
                
                user_pairs = build_pairs(user_qas) if user_qas else []
                ai_pairs = build_pairs(ai_qas) if ai_qas else []
                
                # ìƒˆë¡œìš´ í†µí•© í‰ê°€ ë©”ì„œë“œ í˜¸ì¶œ
                combined_eval = evaluation_service.evaluate_combined_interview(
                    user_id=user_id,
                    user_qas=user_pairs,
                    ai_qas=ai_pairs,
                    ai_resume_id=ai_resume_id,
                    user_resume_id=user_resume_id,
                    posting_id=posting_id,
                    company_id=company_id,
                    position_id=position_id
                )
                
                if combined_eval and combined_eval.get('success'):
                    shared_interview_id = combined_eval['interview_id']
                    interview_logger.info(f"âœ… í†µí•© ë©´ì ‘ í‰ê°€ ì™„ë£Œ: interview_id={shared_interview_id}")
                    interview_logger.info(f"ğŸ“Š í‰ê°€ ê²°ê³¼: ì‚¬ìš©ì ì ìˆ˜={combined_eval.get('user_score', 0):.2f}, AI ì ìˆ˜={combined_eval.get('ai_score', 0):.2f}")
                    
                    # ğŸ†• ì„ì‹œ ì‹œì„  ì¶”ì  íŒŒì¼ ì²˜ë¦¬ (interview_id ìƒì„± í›„)
                    if shared_interview_id:
                        await self._process_temporary_gaze_file(session_id, shared_interview_id)
                    
                    # ê°œì„  ê³„íš ìƒì„±
                    try:
                        evaluation_service.generate_interview_plans(shared_interview_id)
                        interview_logger.info(f"âœ… ë©´ì ‘ ê³„íš ìƒì„± ì™„ë£Œ: interview_id={shared_interview_id}")
                    except Exception as e:
                        interview_logger.error(f"âŒ ë©´ì ‘ ê³„íš ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
                else:
                    interview_logger.error(f"âŒ í†µí•© ë©´ì ‘ í‰ê°€ ì‹¤íŒ¨: {combined_eval}")
            else:
                interview_logger.warning(f"âš ï¸ ì‚¬ìš©ì/AI QA ëª¨ë‘ ì—†ì–´ì„œ í‰ê°€ë¥¼ ê±´ë„ˆëœ€")

        except Exception as e:
            interview_logger.error(f"âŒ í”¼ë“œë°± ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}", exc_info=True)
            return

    async def _process_temporary_gaze_file(self, session_id: str, interview_id: int) -> None:
        """ì„ì‹œ ì‹œì„  ì¶”ì  íŒŒì¼ì„ Supabaseì— ì—…ë¡œë“œí•˜ê³  ë¶„ì„ì„ íŠ¸ë¦¬ê±°"""
        try:
            import os
            import glob
            from datetime import datetime

            temp_folder = "backend/uploads/temp_gaze"
            
            # session_idë¡œ ì„ì‹œ íŒŒì¼ ì°¾ê¸°
            temp_files = glob.glob(os.path.join(temp_folder, f"{session_id}.*"))
            
            if not temp_files:
                interview_logger.info(f"ğŸ” ì„¸ì…˜ {session_id}ì— ëŒ€í•œ ì„ì‹œ ì‹œì„  ì¶”ì  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            temp_file_path = temp_files[0]  # ì²« ë²ˆì§¸ ë§¤ì¹­ íŒŒì¼ ì‚¬ìš©
            interview_logger.info(f"ğŸ“ ì„ì‹œ íŒŒì¼ ë°œê²¬: {temp_file_path}")
            
            # Supabase í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
            supabase_client = get_supabase_client()
            
            # íŒŒì¼ í™•ì¥ì ì¶”ì¶œ
            file_extension = os.path.splitext(temp_file_path)[1]
            
            # Supabase Storageì— ì—…ë¡œë“œí•  ê²½ë¡œ ìƒì„±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            storage_path = f"gaze_tracking/{interview_id}/gaze_video_{timestamp}{file_extension}"
            
            # íŒŒì¼ì„ Supabase Storageì— ì—…ë¡œë“œ
            with open(temp_file_path, 'rb') as file:
                file_data = file.read()
                
                result = supabase_client.storage.from_('betago-s3').upload(
                    path=storage_path,
                    file=file_data,
                    file_options={
                        "content-type": "video/webm" if file_extension == ".webm" else "video/mp4"
                    }
                )
                
                if result.error:
                    raise Exception(f"Supabase ì—…ë¡œë“œ ì‹¤íŒ¨: {result.error}")
                
                interview_logger.info(f"âœ… Supabase ì—…ë¡œë“œ ì„±ê³µ: {storage_path}")
            
            # TODO: ì—¬ê¸°ì„œ ì‹œì„  ë¶„ì„ API í˜¸ì¶œ (ê¸°ì¡´ /gaze/analyze ì—”ë“œí¬ì¸íŠ¸ í™œìš©)
            # í˜„ì¬ëŠ” íŒŒì¼ ì—…ë¡œë“œê¹Œì§€ë§Œ êµ¬í˜„
            interview_logger.info(f"ğŸ“Š ì‹œì„  ë¶„ì„ íŠ¸ë¦¬ê±° ì˜ˆì •: interview_id={interview_id}, file_path={storage_path}")
            
        except Exception as e:
            interview_logger.error(f"âŒ ì„ì‹œ ì‹œì„  ì¶”ì  íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: session_id={session_id}, error={str(e)}", exc_info=True)
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            try:
                temp_folder = "backend/uploads/temp_gaze"
                temp_files = glob.glob(os.path.join(temp_folder, f"{session_id}.*"))
                
                for temp_file in temp_files:
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
                        interview_logger.info(f"ğŸ—‘ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {temp_file}")
            except Exception as cleanup_error:
                interview_logger.error(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {str(cleanup_error)}")

