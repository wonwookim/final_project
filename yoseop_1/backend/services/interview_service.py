#!/usr/bin/env python3
"""
ë©´ì ‘ ì„œë¹„ìŠ¤
ëª¨ë“  ë©´ì ‘ ê´€ë ¨ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ë‹´ë‹¹í•˜ëŠ” ì„œë¹„ìŠ¤ ê³„ì¸µ
- Backend ì¤‘ì•™ ê´€ì œ ì‹œìŠ¤í…œ: ëª¨ë“  ë©´ì ‘ ìƒíƒœì™€ íë¦„ì„ ì§ì ‘ ê´€ë¦¬
"""

import asyncio
import os
import json
import uuid
import random
from typing import Dict, List, Any, Optional
from pathlib import Path
from dataclasses import dataclass, field

# ğŸ†• í•„ìš”í•œ ëª¨ë“ˆ ì§ì ‘ ì„í¬íŠ¸
from llm.interviewer.question_generator import QuestionGenerator  # service.py ëŒ€ì‹  question_generator.pyë¥¼ ì§ì ‘ ì‚¬ìš©
from llm.candidate.model import AICandidateModel, CandidatePersona
from llm.shared.models import AnswerRequest, QuestionType, QuestionAnswer, LLMProvider
from llm.candidate.quality_controller import QualityLevel
from llm.shared.constants import ALLOWED_FILE_EXTENSIONS, MAX_FILE_SIZE
from llm.shared.logging_config import interview_logger, performance_logger

# í˜¸í™˜ì„±ì„ ìœ„í•œ InterviewSession í´ë˜ìŠ¤ import
from backend.models.session import InterviewSession

# ğŸ”¥ llm/session ì˜ì¡´ì„± ì™„ì „ ì œê±° - ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
# from llm.session import SessionManager, InterviewSession, ComparisonSession  # REMOVED

# ë¬¸ì„œ ì²˜ë¦¬ ë° í”¼ë“œë°± ì„œë¹„ìŠ¤
from llm.interviewer.document_processor import DocumentProcessor, UserProfile
from llm.feedback.service import FeedbackService

# ğŸ†• ë©´ì ‘ ì„¸ì…˜ì˜ ëª¨ë“  ìƒíƒœë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤ (í„´ ê´€ë¦¬ ìƒíƒœ í¬í•¨)
@dataclass
class SessionState:
    session_id: str
    company_id: str
    position: str
    user_name: str
    
    # LLM ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
    question_generator: QuestionGenerator
    ai_candidate_model: AICandidateModel
    ai_persona: CandidatePersona
    
    # ë©´ì ‘ ì§„í–‰ ìƒíƒœ
    qa_history: List[Dict[str, Any]] = field(default_factory=list)
    is_completed: bool = False
    total_question_limit: int = 15
    questions_asked_count: int = 0
    current_interviewer_index: int = 0
    interviewer_roles: List[str] = field(default_factory=lambda: ['HR', 'TECH', 'COLLABORATION'])
    interviewer_turn_state: Dict[str, Any] = field(default_factory=lambda: {
        'HR': {'main_question_asked': False, 'follow_up_count': 0},
        'TECH': {'main_question_asked': False, 'follow_up_count': 0},
        'COLLABORATION': {'main_question_asked': False, 'follow_up_count': 0}
    })
    
    def get_current_interviewer(self) -> str:
        return self.interviewer_roles[self.current_interviewer_index]



class InterviewService:
    """ë©´ì ‘ ì„œë¹„ìŠ¤ - ëª¨ë“  ë©´ì ‘ ê´€ë ¨ ë¡œì§ì„ ë‹´ë‹¹"""
    
    def __init__(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”. ëª¨ë“  ì„¸ì…˜ì„ ì§ì ‘ ê´€ë¦¬í•©ë‹ˆë‹¤."""
        self.active_sessions: Dict[str, SessionState] = {}  # ğŸ†• ì„¸ì…˜ ì €ì¥ì†Œ
        
        # ğŸ”¥ SessionManager ì™„ì „ ì œê±° - ëª¨ë“  ì„¸ì…˜ì„ active_sessionsì—ì„œ ì§ì ‘ ê´€ë¦¬
        # self.session_manager = SessionManager()  # REMOVED
        
        # ë³´ì¡° ì„œë¹„ìŠ¤ë“¤
        self.document_processor = DocumentProcessor()
        self.ai_candidate_model = AICandidateModel()
        self.feedback_service = FeedbackService()
        
        # íšŒì‚¬ ì´ë¦„ ë§¤í•‘
        self.company_name_map = {
            "ë„¤ì´ë²„": "naver",
            "ì¹´ì¹´ì˜¤": "kakao", 
            "ë¼ì¸": "line",
            "ë¼ì¸í”ŒëŸ¬ìŠ¤": "ë¼ì¸í”ŒëŸ¬ìŠ¤",
            "ì¿ íŒ¡": "coupang",
            "ë°°ë‹¬ì˜ë¯¼ì¡±": "baemin",
            "ë‹¹ê·¼ë§ˆì¼“": "daangn", 
            "í† ìŠ¤": "toss"
        }
    
    def get_company_id(self, company_name: str) -> str:
        """íšŒì‚¬ ì´ë¦„ì„ IDë¡œ ë³€í™˜"""
        return self.company_name_map.get(company_name, company_name.lower())
    
    async def start_interview(self, settings: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ”¥ ìƒˆë¡œìš´ ì¤‘ì•™ ê´€ì œ ë°©ì‹ìœ¼ë¡œ ì¼ë°˜ ë©´ì ‘ ì‹œì‘"""
        try:
            interview_logger.info("ğŸ¯ [Central Control] Regular Interview Start")
            session_id = f"reg_{uuid.uuid4().hex[:12]}"
            company_id = self.get_company_id(settings['company'])
            
            # 1. LLM ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            question_generator = QuestionGenerator()
            ai_candidate_model = AICandidateModel()
            
            # 2. AI í˜ë¥´ì†Œë‚˜ ìƒì„± (ì¼ë°˜ ë©´ì ‘ìš©)
            ai_persona = await asyncio.to_thread(
                ai_candidate_model.create_persona_for_interview, company_id, settings['position']
            )
            if not ai_persona:
                ai_persona = ai_candidate_model._create_default_persona(company_id, settings['position'])
            
            # 3. ìƒˆë¡œìš´ ì„¸ì…˜ ìƒíƒœ ê°ì²´ ìƒì„± ë° ì €ì¥ (ì¼ë°˜ ë©´ì ‘ìš© ì„¤ì •)
            session_state = SessionState(
                session_id=session_id, company_id=company_id, position=settings['position'],
                user_name=settings['candidate_name'], question_generator=question_generator,
                ai_candidate_model=ai_candidate_model, ai_persona=ai_persona,
                total_question_limit=20  # ì¼ë°˜ ë©´ì ‘ì€ 20ê°œ ì§ˆë¬¸
            )
            session_state.interviewer_roles = ['GENERAL']  # ì¼ë°˜ ë©´ì ‘ì€ ë‹¨ì¼ ë©´ì ‘ê´€
            session_state.interviewer_turn_state = {
                'GENERAL': {'main_question_asked': False, 'follow_up_count': 0}
            }
            self.active_sessions[session_id] = session_state
            
            # 4. ì²« ì§ˆë¬¸ ìƒì„± (ìê¸°ì†Œê°œ)
            first_question = session_state.question_generator.generate_fixed_question(0, company_id)
            session_state.questions_asked_count += 1
            session_state.qa_history.append({"question": first_question, "user_answer": None, "ai_answer": None})
            
            interview_logger.info(f"âœ… [Central Control] Regular interview session created: {session_id}")
            
            return {
                "session_id": session_id, "question": first_question,
                "total_questions": session_state.total_question_limit,
                "message": "ë©´ì ‘ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
            }
            
        except Exception as e:
            interview_logger.error(f"ë©´ì ‘ ì‹œì‘ ì˜¤ë¥˜: {e}", exc_info=True)
            raise
    
    async def upload_document(self, file_data: Dict[str, Any]) -> Dict[str, Any]:
        """ë¬¸ì„œ ì—…ë¡œë“œ ë° ë¶„ì„"""
        try:
            # íŒŒì¼ ê²€ì¦
            filename = file_data['filename']
            content = file_data['content']
            
            if not filename.lower().endswith(tuple(ALLOWED_FILE_EXTENSIONS)):
                raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
            
            # íŒŒì¼ ì €ì¥
            upload_dir = Path("uploads")
            upload_dir.mkdir(exist_ok=True)
            
            file_path = upload_dir / f"{uuid.uuid4()}_{filename}"
            
            with open(file_path, "wb") as buffer:
                buffer.write(content)
            
            # ë¬¸ì„œ ë¶„ì„
            analyzed_content = await self._analyze_document_async(file_path)
            
            return {
                "file_id": str(file_path),
                "analyzed_content": analyzed_content,
                "message": "ë¬¸ì„œ ì—…ë¡œë“œ ë° ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
            }
            
        except Exception as e:
            interview_logger.error(f"ë¬¸ì„œ ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
            raise Exception(f"ë¬¸ì„œ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    async def get_next_question(self, session_id: str) -> Dict[str, Any]:
        """ğŸ”¥ ìƒˆë¡œìš´ ì¤‘ì•™ ê´€ì œ ë°©ì‹ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°"""
        try:
            session_state = self.active_sessions.get(session_id)
            if not session_state:
                return {"error": "ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜ IDì…ë‹ˆë‹¤."}
            
            # ë©´ì ‘ ì™„ë£Œ í™•ì¸
            if session_state.is_completed or session_state.questions_asked_count >= session_state.total_question_limit:
                return {"completed": True, "message": "ëª¨ë“  ì§ˆë¬¸ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."}
            
            # ë‹¤ìŒ ì§ˆë¬¸ ìƒì„± ë¡œì§
            next_question = None
            
            # ì²« ë²ˆì§¸ ê³ ì • ì§ˆë¬¸ (ìê¸°ì†Œê°œ)
            if session_state.questions_asked_count == 0:
                next_question = session_state.question_generator.generate_fixed_question(0, session_state.company_id)
            # ë‘ ë²ˆì§¸ ê³ ì • ì§ˆë¬¸ (ì§€ì›ë™ê¸°)
            elif session_state.questions_asked_count == 1:
                next_question = session_state.question_generator.generate_fixed_question(1, session_state.company_id, 
                                                                                        {"name": session_state.user_name})
            # ë™ì  ì§ˆë¬¸ ìƒì„±
            else:
                current_interviewer = session_state.get_current_interviewer()
                next_question = await asyncio.to_thread(
                    session_state.question_generator.generate_question_by_role,
                    interviewer_role=current_interviewer, company_id=session_state.company_id,
                    user_resume={"name": session_state.user_name, "position": session_state.position}
                )
            
            if not next_question:
                return {"error": "ì§ˆë¬¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}
            
            # ì§„í–‰ë¥  ê³„ì‚°
            progress = (session_state.questions_asked_count / session_state.total_question_limit) * 100
            
            return {
                "question": {
                    "id": f"q_{session_state.questions_asked_count + 1}",
                    "question": next_question.get("question", ""),
                    "category": next_question.get("interviewer_type", "GENERAL"),
                    "intent": next_question.get("intent", ""),
                    "time_limit": 120,
                    "keywords": []
                },
                "question_index": session_state.questions_asked_count + 1,
                "total_questions": session_state.total_question_limit,
                "progress": progress
            }
            
        except Exception as e:
            interview_logger.error(f"ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}", exc_info=True)
            raise
    
    async def submit_answer(self, answer_data: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ”¥ ìƒˆë¡œìš´ ì¤‘ì•™ ê´€ì œ ë°©ì‹ìœ¼ë¡œ ë‹µë³€ ì œì¶œ ë° ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±"""
        try:
            session_id = answer_data['session_id']
            user_answer = answer_data['answer']
            
            session_state = self.active_sessions.get(session_id)
            if not session_state:
                return {"error": "ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜ IDì…ë‹ˆë‹¤."}
            
            if session_state.is_completed:
                return {"error": "ì´ë¯¸ ì™„ë£Œëœ ë©´ì ‘ì…ë‹ˆë‹¤."}
            
            # 1. ì‚¬ìš©ì ë‹µë³€ ê¸°ë¡
            if session_state.qa_history:
                last_qa = session_state.qa_history[-1]
                last_qa["user_answer"] = user_answer
            
            # 2. ë‹¤ìŒ ì§ˆë¬¸ ìƒì„± ë˜ëŠ” ë©´ì ‘ ì¢…ë£Œ ì²˜ë¦¬
            if session_state.questions_asked_count >= session_state.total_question_limit:
                session_state.is_completed = True
                return {
                    "status": "interview_complete",
                    "message": "ë©´ì ‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                    "total_questions": session_state.questions_asked_count
                }
            
            # 3. ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±
            next_question = None
            
            # ë‘ ë²ˆì§¸ ê³ ì • ì§ˆë¬¸ (ì§€ì›ë™ê¸°)
            if session_state.questions_asked_count == 1:
                next_question = session_state.question_generator.generate_fixed_question(1, session_state.company_id, 
                                                                                        {"name": session_state.user_name})
            # ë™ì  ì§ˆë¬¸ ìƒì„±
            else:
                current_interviewer = session_state.get_current_interviewer()
                turn_state = session_state.interviewer_turn_state.get(current_interviewer, {})
                
                # ë©”ì¸ ì§ˆë¬¸ ì•ˆí–ˆìœ¼ë©´ ë©”ì¸ ì§ˆë¬¸ ìƒì„±
                if not turn_state.get('main_question_asked', False):
                    next_question = await asyncio.to_thread(
                        session_state.question_generator.generate_question_by_role,
                        interviewer_role=current_interviewer, company_id=session_state.company_id,
                        user_resume={"name": session_state.user_name, "position": session_state.position}
                    )
                    turn_state['main_question_asked'] = True
                # ê¼¬ë¦¬ ì§ˆë¬¸ ìƒì„± (ìµœëŒ€ 2ê°œ)
                elif turn_state.get('follow_up_count', 0) < 2:
                    # ì´ì „ ì§ˆë¬¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    if len(session_state.qa_history) >= 2:
                        prev_qa = session_state.qa_history[-2]
                        previous_question_text = prev_qa["question"].get("question", "")
                        company_info = session_state.question_generator.companies_data.get(session_state.company_id, {})
                        
                        next_question = await asyncio.to_thread(
                            session_state.question_generator.generate_follow_up_question,
                            previous_question=previous_question_text, user_answer=user_answer, chun_sik_answer="",
                            company_info=company_info, interviewer_role=current_interviewer,
                            user_resume={"name": session_state.user_name, "position": session_state.position}
                        )
                        turn_state['follow_up_count'] = turn_state.get('follow_up_count', 0) + 1
                    else:
                        # ê¼¬ë¦¬ ì§ˆë¬¸ ìƒì„± ì¡°ê±´ ë¶€ì¡±
                        next_question = await asyncio.to_thread(
                            session_state.question_generator.generate_question_by_role,
                            interviewer_role=current_interviewer, company_id=session_state.company_id,
                            user_resume={"name": session_state.user_name, "position": session_state.position}
                        )
                # í„´ ì „í™˜
                else:
                    # ë‹¤ìŒ ë©´ì ‘ê´€ìœ¼ë¡œ ì „í™˜
                    session_state.current_interviewer_index = (session_state.current_interviewer_index + 1) % len(session_state.interviewer_roles)
                    new_interviewer = session_state.get_current_interviewer()
                    
                    next_question = await asyncio.to_thread(
                        session_state.question_generator.generate_question_by_role,
                        interviewer_role=new_interviewer, company_id=session_state.company_id,
                        user_resume={"name": session_state.user_name, "position": session_state.position}
                    )
                    session_state.interviewer_turn_state[new_interviewer]['main_question_asked'] = True
            
            # 4. ìƒíƒœ ì—…ë°ì´íŠ¸
            if next_question:
                session_state.questions_asked_count += 1
                session_state.qa_history.append({"question": next_question, "user_answer": None, "ai_answer": None})
                
                return {
                    "status": "success",
                    "message": "ë‹µë³€ì´ ì„±ê³µì ìœ¼ë¡œ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤.",
                    "next_question": next_question,
                    "answered_count": session_state.questions_asked_count,
                    "total_questions": session_state.total_question_limit,
                    "progress": (session_state.questions_asked_count / session_state.total_question_limit) * 100
                }
            else:
                session_state.is_completed = True
                return {
                    "status": "interview_complete",
                    "message": "ë©´ì ‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                    "total_questions": session_state.questions_asked_count
                }
            
        except Exception as e:
            interview_logger.error(f"ë‹µë³€ ì œì¶œ ì˜¤ë¥˜: {e}", exc_info=True)
            raise
    
    async def get_interview_results(self, session_id: str) -> Dict[str, Any]:
        """ë©´ì ‘ ê²°ê³¼ ì¡°íšŒ - ìƒˆë¡œìš´ ì¤‘ì•™ ê´€ì œ ì‹œìŠ¤í…œ ë° ê¸°ì¡´ ì‹œìŠ¤í…œ ëª¨ë‘ ì§€ì›"""
        try:
            # ìƒˆë¡œìš´ ì¤‘ì•™ ê´€ì œ ì‹œìŠ¤í…œ ì„¸ì…˜ì¸ì§€ í™•ì¸
            if session_id in self.active_sessions:
                session_state = self.active_sessions[session_id]
                
                # ê°„ë‹¨í•œ ê²°ê³¼ ìƒì„± (ì‹¤ì œë¡œëŠ” LLM ê¸°ë°˜ í‰ê°€ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ)
                total_questions = len(session_state.qa_history)
                
                return {
                    "session_id": session_id,
                    "company": session_state.company_id,
                    "position": session_state.position,
                    "candidate": session_state.user_name,
                    "ai_name": session_state.ai_persona.name,
                    "total_questions": total_questions,
                    "questions_asked": session_state.questions_asked_count,
                    "is_completed": session_state.is_completed,
                    "interviewer_stats": session_state.interviewer_turn_state,
                    "qa_history": session_state.qa_history,
                    "message": "ìƒˆë¡œìš´ ì¤‘ì•™ ê´€ì œ ì‹œìŠ¤í…œ ê²°ê³¼"
                }
            
            # ğŸ”¥ SessionManager ì˜ì¡´ì„± ì™„ì „ ì œê±° - ëª¨ë“  ì„¸ì…˜ì„ active_sessionsì—ì„œ ì²˜ë¦¬
            else:
                return {"error": f"ì„¸ì…˜ ID '{session_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ì¤‘ì•™ ê´€ì œ ì‹œìŠ¤í…œë§Œ ì§€ì›ë©ë‹ˆë‹¤."}
            
        except Exception as e:
            interview_logger.error(f"ê²°ê³¼ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            raise Exception(f"ê²°ê³¼ë¥¼ ì¡°íšŒí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # ğŸ”„ ì™„ì „íˆ ìƒˆë¡œìš´ ë¡œì§ìœ¼ë¡œ êµì²´
    async def start_ai_competition(self, settings: Dict[str, Any]) -> Dict[str, Any]:
        try:
            interview_logger.info("ğŸ¯ [New Arch] Backend-Controlling Interview Start")
            session_id = f"comp_{uuid.uuid4().hex[:12]}"
            company_id = self.get_company_id(settings['company'])
            
            # 1. LLM ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            question_generator = QuestionGenerator()
            ai_candidate_model = AICandidateModel()
            
            # 2. AI í˜ë¥´ì†Œë‚˜ ìƒì„±
            ai_persona = await asyncio.to_thread(
                ai_candidate_model.create_persona_for_interview, company_id, settings['position']
            )
            if not ai_persona:
                ai_persona = ai_candidate_model._create_default_persona(company_id, settings['position'])
            
            # 3. ìƒˆë¡œìš´ ì„¸ì…˜ ìƒíƒœ ê°ì²´ ìƒì„± ë° ì €ì¥
            session_state = SessionState(
                session_id=session_id, company_id=company_id, position=settings['position'],
                user_name=settings['candidate_name'], question_generator=question_generator,
                ai_candidate_model=ai_candidate_model, ai_persona=ai_persona
            )
            self.active_sessions[session_id] = session_state
            
            # 4. ì²« ì§ˆë¬¸ ìƒì„± (ìê¸°ì†Œê°œ)
            first_question = session_state.question_generator.generate_fixed_question(0, company_id)
            session_state.questions_asked_count += 1
            session_state.qa_history.append({"question": first_question, "user_answer": None, "ai_answer": None})
            
            interview_logger.info(f"âœ… [New Arch] New session created: {session_id}")
            
            return {
                "session_id": session_id, "question": first_question,
                "ai_name": ai_persona.name, "total_questions": session_state.total_question_limit,
                "message": "ìƒˆë¡œìš´ AI ê²½ìŸ ë©´ì ‘ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
            }
        except Exception as e:
            interview_logger.error(f"AI ê²½ìŸ ë©´ì ‘ ì‹œì‘ ì˜¤ë¥˜: {e}", exc_info=True)
            raise
    
    
    
    async def get_ai_answer(self, session_id: str, question_id: str) -> Dict[str, Any]:
        """AI ì§€ì›ìì˜ ë‹µë³€ ìƒì„±"""
        try:
            # URL ë””ì½”ë”©
            import urllib.parse
            decoded_session_id = urllib.parse.unquote(session_id)
            
            # ì„¸ì…˜ IDì—ì„œ íšŒì‚¬ì™€ í¬ì§€ì…˜ íŒŒì‹±
            session_parts = decoded_session_id.split('_')
            company_id = session_parts[0] if len(session_parts) > 0 else "naver"
            position = "_".join(session_parts[1:-1]) if len(session_parts) > 2 else "ë°±ì—”ë“œ ê°œë°œ"
            
            # ğŸ—‘ï¸ ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ - ìƒˆë¡œìš´ ì¤‘ì•™ ê´€ì œ ì‹œìŠ¤í…œ ì‚¬ìš©
            # from llm.session.interviewer_session import InterviewerSession
            
            # InterviewerSession ì„ì‹œ ìƒì„±í•˜ì—¬ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°
            temp_session = InterviewerSession(company_id, position, "ì¶˜ì‹ì´")
            first_question_data = temp_session.start()
            
            if first_question_data:
                question_content = first_question_data["question"]
                question_intent = first_question_data.get("intent", "ì¼ë°˜ì ì¸ í‰ê°€")
                question_type = first_question_data.get("interviewer_type", "HR")
            else:
                # í´ë°± ì§ˆë¬¸
                if question_id == "q_1":
                    question_content = "ì¶˜ì‹ì´, ìê¸°ì†Œê°œë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
                    question_intent = "ì§€ì›ìì˜ ê¸°ë³¸ ì •ë³´ì™€ ì„±ê²©, ì—­ëŸ‰ì„ íŒŒì•…"
                    question_type = "INTRO"
                elif question_id == "q_2":
                    question_content = f"ì¶˜ì‹ì´ê»˜ì„œ ë„¤ì´ë²„ì— ì§€ì›í•˜ê²Œ ëœ ë™ê¸°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
                    question_intent = "íšŒì‚¬ì— ëŒ€í•œ ê´€ì‹¬ë„ì™€ ì§€ì› ë™ê¸° íŒŒì•…"
                    question_type = "MOTIVATION"
                else:
                    question_content = "ì¶˜ì‹ì´ì— ëŒ€í•´ ë” ì•Œë ¤ì£¼ì„¸ìš”."
                    question_intent = "ì¼ë°˜ì ì¸ í‰ê°€"
                    question_type = "HR"
            
            # AI ë‹µë³€ ìƒì„±
            from llm.candidate.model import AnswerRequest
            from llm.shared.models import QuestionType
            
            # QuestionType ë§¤í•‘
            question_type_map = {
                "INTRO": QuestionType.INTRO,
                "MOTIVATION": QuestionType.MOTIVATION,
                "HR": QuestionType.HR,
                "TECH": QuestionType.TECH,
                "COLLABORATION": QuestionType.COLLABORATION
            }
            
            answer_request = AnswerRequest(
                question_content=question_content,
                question_type=question_type_map.get(question_type, QuestionType.HR),
                question_intent=question_intent,
                company_id=company_id,
                position=position,
                quality_level=QualityLevel.GOOD,
                llm_provider="openai_gpt4o_mini"
            )
            
            # ğŸ”„ ë‹¨ë… AI ë‹µë³€ ìƒì„± (ì„¸ì…˜ ì—†ìŒ - ë§¤ë²ˆ ìƒˆë¡œìš´ í˜ë¥´ì†Œë‚˜)
            interview_logger.info(f"ğŸ­ [STANDALONE AI] ë‹¨ë… AI ë‹µë³€ ìƒì„± (ì„¸ì…˜ ë¬´ê´€): {company_id} - {position}")
            ai_answer = self.ai_candidate_model.generate_answer(answer_request, persona=None)
            
            if not ai_answer:
                raise Exception("AI ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            return {
                "question": question_content,
                "questionType": question_type,
                "questionIntent": question_intent,
                "answer": ai_answer.answer_content,
                "time_spent": 60,
                "score": 85,
                "quality_level": ai_answer.quality_level.value,
                "persona_name": ai_answer.persona_name
            }
            
        except Exception as e:
            interview_logger.error(f"AI ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            raise Exception(f"AI ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    
    
    async def get_interview_history(self, user_id: str = None) -> Dict[str, Any]:
        """ë©´ì ‘ ê¸°ë¡ ì¡°íšŒ - ìƒˆë¡œìš´ ì¤‘ì•™ ê´€ì œ ì‹œìŠ¤í…œ ë° ê¸°ì¡´ ì‹œìŠ¤í…œ ëª¨ë‘ ì§€ì›"""
        try:
            completed_sessions = []
            
            # ìƒˆë¡œìš´ ì¤‘ì•™ ê´€ì œ ì‹œìŠ¤í…œ ì„¸ì…˜ë“¤ ì¶”ê°€
            for session_id, session_state in self.active_sessions.items():
                if session_state.is_completed:
                    completed_sessions.append({
                        "session_id": session_id,
                        "settings": {
                            "company": session_state.company_id,
                            "position": session_state.position,
                            "user_name": session_state.user_name
                        },
                        "completed_at": "",
                        "total_score": 85,  # ê¸°ë³¸ê°’
                        "type": "central_control",
                        "questions_asked": session_state.questions_asked_count,
                        "ai_name": session_state.ai_persona.name
                    })
            
            # ğŸ”¥ SessionManager ì˜ì¡´ì„± ì™„ì „ ì œê±° - ì˜¤ì§ active_sessionsë§Œ ì‚¬ìš©
            # ë©”ëª¨: ê¸°ì¡´ SessionManager ì„¸ì…˜ë“¤ì€ ë” ì´ìƒ ì§€ì›í•˜ì§€ ì•ŠìŒ
            
            return {
                "total_interviews": len(completed_sessions),
                "interviews": completed_sessions
            }
            
        except Exception as e:
            interview_logger.error(f"ê¸°ë¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            raise Exception(f"ê¸°ë¡ì„ ì¡°íšŒí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # ğŸ”„ ì™„ì „íˆ ìƒˆë¡œìš´ ë¡œì§ìœ¼ë¡œ êµì²´
    async def process_competition_turn(self, session_id: str, user_answer: str) -> Dict[str, Any]:
        try:
            session_state = self.active_sessions.get(session_id)
            if not session_state or session_state.is_completed:
                raise ValueError("ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ì´ë¯¸ ì¢…ë£Œëœ ì„¸ì…˜ IDì…ë‹ˆë‹¤.")
            
            # 1. ì‚¬ìš©ì ë‹µë³€ ë° ì´ì „ ì§ˆë¬¸ ê¸°ë¡
            last_qa = session_state.qa_history[-1]
            last_qa["user_answer"] = user_answer
            previous_question_obj = last_qa["question"]
            previous_question_text = previous_question_obj["question"]
            
            # 2. AI ë‹µë³€ ìƒì„±
            answer_request = AnswerRequest(
                question_content=previous_question_text,
                question_type=QuestionType.from_string(previous_question_obj.get("interviewer_type", "HR")),
                question_intent=previous_question_obj.get("intent", ""),
                company_id=session_state.company_id,
                position=session_state.position,
                quality_level=QualityLevel.AVERAGE,
                llm_provider=LLMProvider.OPENAI_GPT4O
            )
            ai_answer_response = await asyncio.to_thread(
                session_state.ai_candidate_model.generate_answer, request=answer_request, persona=session_state.ai_persona
            )
            ai_answer_content = ai_answer_response.answer_content
            last_qa["ai_answer"] = ai_answer_content
            
            # 3. ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±ì„ ìœ„í•œ ëª¨ë“  ë¡œì§ì„ ì—¬ê¸°ì„œ ì§ì ‘ ìˆ˜í–‰
            # 3-1. ë©´ì ‘ ì¢…ë£Œ ì¡°ê±´ í™•ì¸
            if session_state.questions_asked_count >= session_state.total_question_limit:
                session_state.is_completed = True
                next_question = {'question': 'ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.', 'intent': 'ë©´ì ‘ ì¢…ë£Œ', 
                                'interviewer_type': 'SYSTEM', 'is_final': True}
            # 3-2. ë‘ ë²ˆì§¸ ê³ ì • ì§ˆë¬¸ (ì§€ì›ë™ê¸°)
            elif session_state.questions_asked_count == 1:
                next_question = session_state.question_generator.generate_fixed_question(1, session_state.company_id, 
                                                                                        {"name": session_state.user_name})
            # 3-3. í„´ì œ ì‹œìŠ¤í…œì— ë”°ë¥¸ ì§ˆë¬¸ ìƒì„±
            else:
                current_interviewer = session_state.get_current_interviewer()
                turn_state = session_state.interviewer_turn_state[current_interviewer]
                
                # ë©”ì¸ ì§ˆë¬¸ ì•ˆí–ˆìœ¼ë©´ ë©”ì¸ ì§ˆë¬¸ ìƒì„±
                if not turn_state['main_question_asked']:
                    next_question = await asyncio.to_thread(
                        session_state.question_generator.generate_question_by_role,
                        interviewer_role=current_interviewer, company_id=session_state.company_id,
                        user_resume={"name": session_state.user_name, "position": session_state.position}
                    )
                    turn_state['main_question_asked'] = True
                # ê¼¬ë¦¬ ì§ˆë¬¸ ìƒì„± (ìµœëŒ€ 2ê°œë¡œ ìˆ˜ì •)
                elif turn_state['follow_up_count'] < 2:  # 1ê°œì—ì„œ 2ê°œë¡œ ë³€ê²½
                    company_info = session_state.question_generator.companies_data.get(session_state.company_id, {})
                    next_question = await asyncio.to_thread(
                        session_state.question_generator.generate_follow_up_question,
                        previous_question=previous_question_text, user_answer=user_answer, chun_sik_answer=ai_answer_content,
                        company_info=company_info, interviewer_role=current_interviewer,
                        user_resume={"name": session_state.user_name, "position": session_state.position}
                    )
                    turn_state['follow_up_count'] += 1
                # í„´ ì „í™˜
                else:
                    # í˜„ì¬ ë©´ì ‘ê´€ í„´ ì´ˆê¸°í™” ë° ë‹¤ìŒ ë©´ì ‘ê´€ìœ¼ë¡œ ì¸ë±ìŠ¤ ë³€ê²½
                    turn_state['main_question_asked'] = False
                    turn_state['follow_up_count'] = 0
                    session_state.current_interviewer_index = (session_state.current_interviewer_index + 1) % len(session_state.interviewer_roles)
                    
                    # ìƒˆë¡œìš´ ë©´ì ‘ê´€ì˜ ë©”ì¸ ì§ˆë¬¸ ìƒì„±
                    new_interviewer = session_state.get_current_interviewer()
                    next_question = await asyncio.to_thread(
                        session_state.question_generator.generate_question_by_role,
                        interviewer_role=new_interviewer, company_id=session_state.company_id,
                        user_resume={"name": session_state.user_name, "position": session_state.position}
                    )
                    session_state.interviewer_turn_state[new_interviewer]['main_question_asked'] = True
            
            # 4. ìƒíƒœ ì—…ë°ì´íŠ¸
            if not next_question.get('is_final'):
                session_state.questions_asked_count += 1
                session_state.qa_history.append({"question": next_question, "user_answer": None, "ai_answer": None})
            
            interview_logger.info(f"ğŸ”„ [New Arch] Turn processed: {session_id}, Next question by {next_question.get('interviewer_type')}")
            
            return {
                "status": "success", "ai_answer": {"content": ai_answer_content},
                "next_question": next_question, "interview_status": "completed" if session_state.is_completed else "continue",
                "progress": {
                    "current": session_state.questions_asked_count, "total": session_state.total_question_limit,
                    "percentage": (session_state.questions_asked_count / session_state.total_question_limit) * 100
                }
            }
        except Exception as e:
            interview_logger.error(f"ê²½ìŸ ë©´ì ‘ í„´ ì²˜ë¦¬ ì˜¤ë¥˜: {e}", exc_info=True)
            raise
    
    # ğŸ—‘ï¸ ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë©”ì„œë“œë“¤ (ê¸°ì¡´ ì‹œìŠ¤í…œ í˜¸í™˜ìš©ìœ¼ë¡œ ìœ ì§€)
    
    async def start_turn_based_interview(self, settings: Dict[str, Any]) -> Dict[str, Any]:
        """í„´ì œ ë©´ì ‘ ì‹œì‘ - ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ, start_ai_competition ì‚¬ìš© ê¶Œì¥"""
        try:
            company_id = self.get_company_id(settings['company'])
            
            # ì„¸ì…˜ ID ìƒì„±
            session_id = f"turn_{company_id}_{settings['position']}_{uuid.uuid4().hex[:8]}"
            
            # ì‚¬ìš©ì ì´ë ¥ì„œ ì •ë³´ (ì„ì‹œ)
            user_resume = {
                'name': settings['candidate_name'],
                'career_years': '3',
                'technical_skills': ['Python', 'Django', 'PostgreSQL', 'AWS']
            }
            
            # AI ì§€ì›ì í˜ë¥´ì†Œë‚˜ ìƒì„±
            from llm.candidate.model import CandidatePersona
            ai_persona = CandidatePersona(
                name='ì¶˜ì‹ì´', summary='3ë…„ì°¨ Python ë°±ì—”ë“œ ê°œë°œì',
                background={'career_years': '3', 'current_position': 'ë°±ì—”ë“œ ê°œë°œì'},
                technical_skills=['Python', 'Django', 'PostgreSQL', 'AWS'],
                projects=[{'name': 'ì´ì»¤ë¨¸ìŠ¤ í”Œë«í¼', 'description': 'ëŒ€ìš©ëŸ‰ íŠ¸ë˜í”½ ì²˜ë¦¬'}],
                experiences=[{'company': 'ìŠ¤íƒ€íŠ¸ì—…', 'position': 'ê°œë°œì', 'period': '3ë…„'}],
                strengths=['ë¬¸ì œ í•´ê²°', 'í•™ìŠµ ëŠ¥ë ¥'], weaknesses=['ì™„ë²½ì£¼ì˜'],
                motivation='ì¢‹ì€ ì„œë¹„ìŠ¤ë¥¼ ë§Œë“¤ê³  ì‹¶ì–´ì„œ',
                inferred_personal_experiences=[{'experience': 'ì„±ì¥', 'lesson': 'ëŠì„ì—†ëŠ” í•™ìŠµ'}],
                career_goal='ì‹œë‹ˆì–´ ê°œë°œìë¡œ ì„±ì¥', personality_traits=['ì¹œê·¼í•¨', 'ì „ë¬¸ì„±'],
                interview_style='ìƒí˜¸ì‘ìš©ì ', resume_id=1
            )
            
            # ì„¸ì…˜ ìƒíƒœ ì €ì¥ (ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ì €ì¥)
            if not hasattr(self, 'turn_based_sessions'):
                self.turn_based_sessions = {}
            
            self.turn_based_sessions[session_id] = {
                'user_resume': user_resume,
                'ai_persona': ai_persona,
                'company_id': company_id,
                'qa_history': [],
                'user_answers': [],
                'ai_answers': [],
                'created_at': time.time()
            }
            
            # ì²« ì§ˆë¬¸ ìƒì„±
            first_question = self.interviewer_service.generate_next_question(
                user_resume, ai_persona, company_id
            )
            
            interview_logger.info(f"í„´ì œ ë©´ì ‘ ì‹œì‘ - ì„¸ì…˜ ID: {session_id}")
            
            return {
                "session_id": session_id,
                "question": first_question,
                "total_question_limit": self.interviewer_service.total_question_limit,
                "current_interviewer": self.interviewer_service._get_current_interviewer(),
                "questions_asked": self.interviewer_service.questions_asked_count,
                "message": "í„´ì œ ë©´ì ‘ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
            }
            
        except Exception as e:
            interview_logger.error(f"í„´ì œ ë©´ì ‘ ì‹œì‘ ì˜¤ë¥˜: {str(e)}")
            raise Exception(f"í„´ì œ ë©´ì ‘ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    async def get_turn_based_question(self, session_id: str, user_answer: str = None) -> Dict[str, Any]:
        """í„´ì œ ë©´ì ‘ ë‹¤ìŒ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°"""
        try:
            if not hasattr(self, 'turn_based_sessions') or session_id not in self.turn_based_sessions:
                raise ValueError("ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            session_data = self.turn_based_sessions[session_id]
            
            # ì‚¬ìš©ì ë‹µë³€ ì €ì¥
            if user_answer:
                session_data['user_answers'].append(user_answer)
                
                # AI ë‹µë³€ ìƒì„± (ê°„ë‹¨í•œ êµ¬í˜„)
                ai_answer = "ì €ëŠ” ê¸°ìˆ ì  ì™„ì„±ë„ë¥¼ ì¤‘ì‹œí•˜ë©°, ì½”ë“œ ë¦¬ë·°ì™€ í…ŒìŠ¤íŠ¸ë¥¼ í†µí•´ ì•ˆì •ì ì¸ ì„œë¹„ìŠ¤ë¥¼ ë§Œë“¤ë ¤ê³  ë…¸ë ¥í•©ë‹ˆë‹¤."
                session_data['ai_answers'].append(ai_answer)
            
            # ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±
            next_question = self.interviewer_service.generate_next_question(
                session_data['user_resume'],
                session_data['ai_persona'], 
                session_data['company_id'],
                session_data['qa_history'],
                user_answer,
                session_data['ai_answers'][-1] if session_data['ai_answers'] else None
            )
            
            # ë©´ì ‘ ì¢…ë£Œ í™•ì¸
            if next_question.get('is_final'):
                return {
                    "completed": True,
                    "message": next_question['question'],
                    "final_stats": {
                        "total_questions": self.interviewer_service.questions_asked_count,
                        "interviewer_stats": self.interviewer_service.interviewer_turn_state
                    }
                }
            
            # í„´ ì „í™˜ í™•ì¸
            if next_question.get('force_turn_switch'):
                # ë‹¤ì‹œ ì§ˆë¬¸ ìƒì„± ì‹œë„
                next_question = self.interviewer_service.generate_next_question(
                    session_data['user_resume'],
                    session_data['ai_persona'], 
                    session_data['company_id'],
                    session_data['qa_history']
                )
            
            # QA íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            session_data['qa_history'].append({
                'question': next_question['question'],
                'interviewer_type': next_question['interviewer_type']
            })
            
            return {
                "question": next_question,
                "session_stats": {
                    "questions_asked": self.interviewer_service.questions_asked_count,
                    "remaining_questions": self.interviewer_service.total_question_limit - self.interviewer_service.questions_asked_count,
                    "current_interviewer": self.interviewer_service._get_current_interviewer(),
                    "turn_states": self.interviewer_service.interviewer_turn_state
                }
            }
            
        except Exception as e:
            interview_logger.error(f"í„´ì œ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {str(e)}")
            raise Exception(f"ì§ˆë¬¸ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # í—¬í¼ ë©”ì†Œë“œë“¤
    
    async def _generate_personalized_profile(self, documents: List[str]) -> UserProfile:
        """ë¬¸ì„œ ê¸°ë°˜ ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„± (í•„ìš”ì‹œ ì‚¬ìš©)"""
        try:
            profile = None
            
            for doc_path in documents:
                if os.path.exists(doc_path):
                    profile = await asyncio.to_thread(
                        self.document_processor.process_document, 
                        doc_path
                    )
                    break
            
            if not profile:
                # ê¸°ë³¸ í”„ë¡œí•„ ìƒì„±
                profile = UserProfile(
                    name="ì§€ì›ì",
                    background={"career_years": "3", "education": "ëŒ€í•™êµ ì¡¸ì—…"},
                    technical_skills=["Java", "Spring", "MySQL"],
                    projects=[{"name": "ì›¹ ì„œë¹„ìŠ¤ ê°œë°œ", "description": "ë°±ì—”ë“œ API ê°œë°œ"}],
                    experiences=[{"company": "ì´ì „ íšŒì‚¬", "role": "ë°±ì—”ë“œ ê°œë°œì", "duration": "2ë…„"}],
                    strengths=["ë¬¸ì œí•´ê²°ëŠ¥ë ¥", "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜"],
                    keywords=["ê°œë°œ", "í˜‘ì—…", "ì„±ì¥"],
                    career_goal="ì‹œë‹ˆì–´ ê°œë°œìë¡œ ì„±ì¥",
                    unique_points=["ë¹ ë¥¸ í•™ìŠµ ëŠ¥ë ¥"]
                )
            
            return profile
            
        except Exception as e:
            interview_logger.error(f"í”„ë¡œí•„ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return None
    
    async def _analyze_document_async(self, file_path: Path) -> Dict:
        """ë¬¸ì„œ ë¶„ì„ (ë¹„ë™ê¸°)"""
        try:
            result = await asyncio.get_event_loop().run_in_executor(
                None,
                self.document_processor.process_document,
                str(file_path)
            )
            return result
        except Exception as e:
            interview_logger.error(f"ë¬¸ì„œ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {}