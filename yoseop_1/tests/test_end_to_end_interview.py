#!/usr/bin/env python3
"""
End-to-End ë©´ì ‘ ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸
ëª©í‘œ: ì‹¤ì œ ë©´ì ‘ê³¼ ë™ì¼í•œ ì „ì²´ ì‹œí€€ìŠ¤ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ë©°, ê° ë‹¨ê³„ë³„ ëª¨ë¸ ì„±ëŠ¥ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€

ë©´ì ‘ ìˆœì„œ:
1. ì•„ì´ìŠ¤ë¸Œë ˆì´í‚¹ (2í„´)
2. HR ë©´ì ‘ê´€ (2í„´) 
3. ê¸°ìˆ (TECH) ë©´ì ‘ê´€ (2í„´)
4. í˜‘ì—…(COLLABORATION) ë©´ì ‘ê´€ (2í„´)
ì´ 8í„´ì˜ ì™„ì „í•œ ë©´ì ‘ ì‚¬ì´í´
"""

import sys
import os
import json
import time
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    # í•µì‹¬ ì„œë¹„ìŠ¤ ì„í¬íŠ¸
    print("ğŸ”„ E2E í…ŒìŠ¤íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸ ì¤‘...")
    
    from llm.shared.models import QuestionType, AnswerRequest
    from llm.candidate.model import CandidatePersona, AICandidateModel, POSITION_MAPPING
    from llm.interviewer.service import InterviewerService
    from llm.candidate.quality_controller import QualityLevel
    from llm.core.llm_manager import LLMProvider
    from llm.shared.company_data_loader import get_company_loader
    
    print("âœ… ëª¨ë“  ëª¨ë“ˆ ì„í¬íŠ¸ ì™„ë£Œ")
    
except ImportError as e:
    print(f"âŒ í•„ìˆ˜ ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)


class EndToEndInterviewSimulator:
    """ì‹¤ì œ ë©´ì ‘ê³¼ ë™ì¼í•œ E2E ì‹œë®¬ë ˆì´ì…˜ ë° ì„±ëŠ¥ í‰ê°€"""
    
    def __init__(self):
        """ì‹œë®¬ë ˆì´í„° ì´ˆê¸°í™”"""
        self.company_id = "naver"  # ë„¤ì´ë²„ë¡œ ê³ ì •
        self.position = "ë°±ì—”ë“œ"
        self.total_turns = 8  # ì´ 8í„´
        
        # ë©´ì ‘ê´€ ìˆœì„œ ì •ì˜ (2í„´ì”©)
        self.interview_sequence = [
            {"turns": [1, 2], "type": "ICEBREAKING", "interviewer": "ì•„ì´ìŠ¤ë¸Œë ˆì´í‚¹"},
            {"turns": [3, 4], "type": QuestionType.HR, "interviewer": "HR ë©´ì ‘ê´€"},  
            {"turns": [5, 6], "type": QuestionType.TECH, "interviewer": "ê¸°ìˆ  ë©´ì ‘ê´€"},
            {"turns": [7, 8], "type": QuestionType.COLLABORATION, "interviewer": "í˜‘ì—… ë©´ì ‘ê´€"}
        ]
        
        # ê²°ê³¼ ì €ì¥
        self.simulation_results = {
            "timestamp": datetime.now().isoformat(),
            "test_scenario": "E2E ì „ì²´ ë©´ì ‘ ì‹œë®¬ë ˆì´ì…˜ (8í„´)",
            "company": "ë„¤ì´ë²„",
            "position": "ë°±ì—”ë“œ",
            "total_turns": self.total_turns,
            "turns": [],
            "performance_summary": {},
            "conversation_flow": []
        }
        
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.ai_candidate = AICandidateModel()
        self.interviewer_service = InterviewerService()
        self.company_loader = get_company_loader()
        
        # í˜ë¥´ì†Œë‚˜ ì €ì¥
        self.persona = None
        
        print(f"âœ… E2E ì‹œë®¬ë ˆì´í„° ì´ˆê¸°í™” ì™„ë£Œ (ì´ {self.total_turns}í„´)")
    
    def get_current_interview_context(self, turn_number: int) -> Dict[str, Any]:
        """í˜„ì¬ í„´ì˜ ë©´ì ‘ ë§¥ë½ ì •ë³´ ë°˜í™˜"""
        for sequence in self.interview_sequence:
            if turn_number in sequence["turns"]:
                return {
                    "turn_number": turn_number,
                    "question_type": sequence["type"],
                    "interviewer_name": sequence["interviewer"],
                    "is_first_turn_of_interviewer": turn_number == sequence["turns"][0],
                    "is_followup": turn_number == sequence["turns"][1]
                }
        return {}
    
    def generate_persona_once(self) -> bool:
        """í˜ë¥´ì†Œë‚˜ ìµœì´ˆ 1íšŒ ìƒì„±"""
        print("\n" + "="*80)
        print("ğŸ­ 1ë‹¨ê³„: í˜ë¥´ì†Œë‚˜ ìƒì„±")
        print("="*80)
        
        try:
            # ì‹¤ì œ AICandidateModel í˜¸ì¶œ
            self.persona = self.ai_candidate.create_persona_for_interview("ë„¤ì´ë²„", "ë°±ì—”ë“œ")
            
            if not self.persona:
                print("âŒ í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹¤íŒ¨")
                return False
            
            print(f"âœ… í˜ë¥´ì†Œë‚˜ ìƒì„± ì„±ê³µ: {self.persona.name}")
            print(f"   ë°°ê²½: {self.persona.background.get('current_position', 'ì‹ ì…')} ({self.persona.background.get('career_years', '0')}ë…„)")
            print(f"   ê¸°ìˆ  ìŠ¤íƒ: {', '.join(self.persona.technical_skills[:5])}")
            
            # ê²°ê³¼ì— í˜ë¥´ì†Œë‚˜ ì •ë³´ ì €ì¥
            self.simulation_results["persona"] = {
                "name": self.persona.name,
                "background": self.persona.background,
                "technical_skills": self.persona.technical_skills,
                "projects": self.persona.projects,
                "strengths": self.persona.strengths
            }
            
            return True
            
        except Exception as e:
            print(f"âŒ í˜ë¥´ì†Œë‚˜ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def generate_question_for_turn(self, turn_number: int) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • í„´ì˜ ì§ˆë¬¸ ìƒì„±"""
        context = self.get_current_interview_context(turn_number)
        
        print(f"\nğŸ¯ Turn {turn_number}: {context['interviewer_name']} ì§ˆë¬¸ ìƒì„±")
        
        try:
            # ì´ì „ ëŒ€í™” ê¸°ë¡ ì¤€ë¹„
            previous_qa_pairs = []
            for turn_data in self.simulation_results["turns"]:
                if "question" in turn_data and "answer" in turn_data:
                    previous_qa_pairs.append({
                        "question": turn_data["question"]["content"],
                        "user_answer": turn_data["answer"]["content"],
                        "chun_sik_answer": turn_data["answer"]["content"]  # E2E í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ë™ì¼
                    })
            
            # InterviewerServiceì˜ ì‹¤ì œ API ì‚¬ìš©
            if context["question_type"] == "ICEBREAKING":
                # ì•„ì´ìŠ¤ë¸Œë ˆì´í‚¹ì€ íŠ¹ë³„ ì²˜ë¦¬
                if turn_number == 1:
                    question_result = {
                        "question": "ì•ˆë…•í•˜ì„¸ìš”! ë¨¼ì € ê°„ë‹¨í•œ ìê¸°ì†Œê°œë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤.",
                        "intent": "ì§€ì›ìì˜ ê¸°ë³¸ ì •ë³´ì™€ ì„±ê²©ì„ íŒŒì•…í•˜ì—¬ ë©´ì ‘ ë¶„ìœ„ê¸°ë¥¼ ì¡°ì„±",
                        "question_type": "INTRO",
                        "interviewer_role": "ì•„ì´ìŠ¤ë¸Œë ˆì´í‚¹"
                    }
                else:
                    # 2í„´ì§¸ëŠ” ê°„ë‹¨í•œ ê¼¬ë¦¬ ì§ˆë¬¸
                    question_result = {
                        "question": "ìê¸°ì†Œê°œì—ì„œ ì–¸ê¸‰í•˜ì‹  ê²½í—˜ì— ëŒ€í•´ ì¢€ ë” ìì„¸íˆ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                        "intent": "ìê¸°ì†Œê°œ ë‚´ìš© ì‹¬í™” íƒêµ¬",
                        "question_type": "FOLLOW_UP",
                        "interviewer_role": "ì•„ì´ìŠ¤ë¸Œë ˆì´í‚¹"
                    }
            else:
                # ë”ë¯¸ ì‚¬ìš©ì ì´ë ¥ì„œ ìƒì„± (E2E í…ŒìŠ¤íŠ¸ìš©)
                user_resume = {
                    "name": "í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì",
                    "position": self.position,
                    "experience": "ì‹ ì…",
                    "skills": ["Python", "JavaScript"],
                    "projects": ["ê°œì¸ í”„ë¡œì íŠ¸"]
                }
                
                # InterviewerService.generate_next_question í˜¸ì¶œ
                question_result = self.interviewer_service.generate_next_question(
                    user_resume=user_resume,
                    chun_sik_persona=self.persona,
                    company_id=self.company_id,
                    previous_qa_pairs=previous_qa_pairs,
                    user_answer=previous_qa_pairs[-1]["user_answer"] if previous_qa_pairs else None,
                    chun_sik_answer=previous_qa_pairs[-1]["chun_sik_answer"] if previous_qa_pairs else None
                )
            
            if question_result and "question" in question_result:
                print(f"âœ… ì§ˆë¬¸ ìƒì„± ì„±ê³µ: {question_result['question'][:50]}...")
                return {
                    "content": question_result["question"],
                    "intent": question_result.get("intent", ""),
                    "question_type": question_result.get("question_type", str(context["question_type"])),
                    "interviewer": question_result.get("interviewer_role", context["interviewer_name"])
                }
            else:
                print("âŒ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨")
                return None
                
        except Exception as e:
            print(f"âŒ ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def generate_answer_for_question(self, question: str, turn_number: int) -> Optional[Dict[str, Any]]:
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±"""
        print(f"ğŸ’¬ Turn {turn_number}: ë‹µë³€ ìƒì„± ì¤‘...")
        
        try:
            # AnswerRequest ìƒì„±  
            answer_request = AnswerRequest(
                question_content=question,
                question_type=QuestionType.GENERAL,
                question_intent="ì¼ë°˜ ì§ˆë¬¸",
                company_id=self.company_id,
                position=self.position,
                quality_level=QualityLevel.VERY_GOOD,
                llm_provider=LLMProvider.OPENAI_GPT4O_MINI
            )
            
            # AICandidateModel.generate_answer í˜¸ì¶œ (í˜ë¥´ì†Œë‚˜ ì „ë‹¬)
            answer_result = self.ai_candidate.generate_answer(answer_request, persona=self.persona)
            
            if answer_result and hasattr(answer_result, 'answer_content') and answer_result.answer_content:
                answer_content = answer_result.answer_content
                print(f"âœ… ë‹µë³€ ìƒì„± ì„±ê³µ: {answer_content[:50]}...")
                
                return {
                    "content": answer_content,
                    "quality_level": str(answer_result.quality_level) if hasattr(answer_result, 'quality_level') else "VERY_GOOD",
                    "length": len(answer_content.split())
                }
            else:
                print("âŒ ë‹µë³€ ìƒì„± ì‹¤íŒ¨")
                return None
                
        except Exception as e:
            print(f"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def evaluate_turn_performance(self, turn_number: int, question: Dict[str, Any], answer: Dict[str, Any]) -> Dict[str, Any]:
        """í„´ë³„ ì„±ëŠ¥ í‰ê°€"""
        print(f"ğŸ“Š Turn {turn_number}: ì„±ëŠ¥ í‰ê°€ ì¤‘...")
        
        evaluation = {
            "turn_number": turn_number,
            "question_evaluation": {},
            "answer_evaluation": {},
            "overall_score": 0,
            "feedback": []
        }
        
        # ì§ˆë¬¸ í’ˆì§ˆ í‰ê°€
        question_content = question["content"]
        persona_keywords = self.persona.technical_skills + [self.persona.name]
        
        # í˜ë¥´ì†Œë‚˜ ì—°ê´€ì„± ì²´í¬
        persona_relevance = sum(1 for keyword in persona_keywords if keyword.lower() in question_content.lower())
        
        evaluation["question_evaluation"] = {
            "persona_relevance_score": min(persona_relevance * 10, 50),  # ìµœëŒ€ 50ì 
            "question_length": len(question_content.split()),
            "has_specific_context": len(question_content.split()) > 10,
            "interviewer_type": question["interviewer"]
        }
        
        # ë‹µë³€ í’ˆì§ˆ í‰ê°€  
        answer_content = answer["content"]
        
        # í˜ë¥´ì†Œë‚˜ ì¼ê´€ì„± ì²´í¬
        persona_consistency = sum(1 for skill in self.persona.technical_skills[:3] if skill.lower() in answer_content.lower())
        
        # êµ¬ì²´ì  ì‚¬ë¡€ í¬í•¨ ì—¬ë¶€
        has_examples = any(word in answer_content.lower() for word in ["í”„ë¡œì íŠ¸", "ê²½í—˜", "êµ¬í˜„", "ê°œë°œ", "ì‚¬ìš©"])
        
        evaluation["answer_evaluation"] = {
            "persona_consistency_score": min(persona_consistency * 15, 45),  # ìµœëŒ€ 45ì 
            "has_specific_examples": has_examples,
            "answer_length": answer["length"],
            "quality_level": answer["quality_level"]
        }
        
        # ì „ì²´ ì ìˆ˜ ê³„ì‚° (0-100)
        question_score = evaluation["question_evaluation"]["persona_relevance_score"]
        answer_score = evaluation["answer_evaluation"]["persona_consistency_score"]
        length_bonus = min(answer["length"] // 10, 15)  # ê¸¸ì´ ë³´ë„ˆìŠ¤ ìµœëŒ€ 15ì 
        
        evaluation["overall_score"] = min(question_score + answer_score + length_bonus, 100)
        
        # í”¼ë“œë°± ìƒì„±
        feedback = []
        
        if persona_relevance > 0:
            feedback.append(f"âœ… [ì§ˆë¬¸ í’ˆì§ˆ] í˜ë¥´ì†Œë‚˜ì˜ {persona_relevance}ê°œ í‚¤ì›Œë“œì™€ ì—°ê´€ëœ ì¢‹ì€ ì§ˆë¬¸ì…ë‹ˆë‹¤.")
        else:
            feedback.append("âš ï¸  [ì§ˆë¬¸ í’ˆì§ˆ] í˜ë¥´ì†Œë‚˜ì™€ ì—°ê´€ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        
        if has_examples:
            feedback.append("âœ… [ë‹µë³€ í’ˆì§ˆ] êµ¬ì²´ì ì¸ ê²½í—˜ê³¼ ì‚¬ë¡€ë¥¼ í¬í•¨í•œ ì¢‹ì€ ë‹µë³€ì…ë‹ˆë‹¤.")
        else:
            feedback.append("âš ï¸  [ë‹µë³€ í’ˆì§ˆ] ë” êµ¬ì²´ì ì¸ ì‚¬ë¡€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        if evaluation["overall_score"] >= 70:
            feedback.append(f"ğŸ¯ [ì „ì²´ í‰ê°€] {evaluation['overall_score']}ì  - ìš°ìˆ˜í•œ ì§ˆì˜ì‘ë‹µì…ë‹ˆë‹¤.")
        elif evaluation["overall_score"] >= 50:
            feedback.append(f"ğŸ“ˆ [ì „ì²´ í‰ê°€] {evaluation['overall_score']}ì  - ë³´í†µ ìˆ˜ì¤€ì˜ ì§ˆì˜ì‘ë‹µì…ë‹ˆë‹¤.")
        else:
            feedback.append(f"ğŸ“‰ [ì „ì²´ í‰ê°€] {evaluation['overall_score']}ì  - ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        evaluation["feedback"] = feedback
        
        # ì‹¤ì‹œê°„ í”¼ë“œë°± ì¶œë ¥
        print("\nğŸ“Š ì‹¤ì‹œê°„ ì„±ëŠ¥ í‰ê°€:")
        for fb in feedback:
            print(f"   {fb}")
        print(f"   í„´ ì ìˆ˜: {evaluation['overall_score']}/100")
        
        return evaluation
    
    def run_complete_simulation(self) -> bool:
        """ì „ì²´ E2E ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰"""
        print("\n" + "ğŸš€" + "="*78 + "ğŸš€")
        print("ğŸ¬ E2E ì „ì²´ ë©´ì ‘ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘")
        print("ğŸš€" + "="*78 + "ğŸš€")
        
        start_time = time.time()
        
        # 1. í˜ë¥´ì†Œë‚˜ ìƒì„±
        if not self.generate_persona_once():
            return False
        
        # 2. 8í„´ ë©´ì ‘ ì§„í–‰
        total_score = 0
        successful_turns = 0
        
        for turn in range(1, self.total_turns + 1):
            print(f"\n{'='*20} TURN {turn}/{self.total_turns} {'='*20}")
            
            # ì§ˆë¬¸ ìƒì„±
            question = self.generate_question_for_turn(turn)
            if not question:
                print(f"âŒ Turn {turn} ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨")
                continue
            
            # ë‹µë³€ ìƒì„±  
            answer = self.generate_answer_for_question(question["content"], turn)
            if not answer:
                print(f"âŒ Turn {turn} ë‹µë³€ ìƒì„± ì‹¤íŒ¨")
                continue
            
            # ì„±ëŠ¥ í‰ê°€
            evaluation = self.evaluate_turn_performance(turn, question, answer)
            
            # ê²°ê³¼ ì €ì¥
            turn_result = {
                "turn_number": turn,
                "question": question,
                "answer": answer,
                "evaluation": evaluation,
                "timestamp": datetime.now().isoformat()
            }
            
            self.simulation_results["turns"].append(turn_result)
            self.simulation_results["conversation_flow"].append({
                "turn": turn,
                "interviewer": question["interviewer"], 
                "question": question["content"],
                "answer": answer["content"]
            })
            
            total_score += evaluation["overall_score"]
            successful_turns += 1
            
            print(f"âœ… Turn {turn} ì™„ë£Œ (ì ìˆ˜: {evaluation['overall_score']}/100)")
        
        # 3. ìµœì¢… ì„±ëŠ¥ ìš”ì•½
        end_time = time.time()
        execution_time = end_time - start_time
        
        self.simulation_results["performance_summary"] = {
            "total_turns_completed": successful_turns,
            "success_rate": (successful_turns / self.total_turns) * 100,
            "average_score": total_score / successful_turns if successful_turns > 0 else 0,
            "total_score": total_score,
            "execution_time_seconds": execution_time,
            "performance_grade": self._get_performance_grade(total_score / successful_turns if successful_turns > 0 else 0)
        }
        
        print(f"\nğŸ E2E ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ!")
        print(f"   ì™„ë£Œ í„´ ìˆ˜: {successful_turns}/{self.total_turns}")
        print(f"   í‰ê·  ì ìˆ˜: {self.simulation_results['performance_summary']['average_score']:.1f}/100")
        print(f"   ì‹¤í–‰ ì‹œê°„: {execution_time:.1f}ì´ˆ")
        
        return successful_turns > 0
    
    def _get_performance_grade(self, avg_score: float) -> str:
        """í‰ê·  ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„±ëŠ¥ ë“±ê¸‰ ë°˜í™˜"""
        if avg_score >= 90:
            return "Aê¸‰ (ìµœìš°ìˆ˜)"
        elif avg_score >= 80:
            return "Bê¸‰ (ìš°ìˆ˜)"
        elif avg_score >= 70:
            return "Cê¸‰ (ë³´í†µ)"
        elif avg_score >= 60:
            return "Dê¸‰ (ê°œì„ í•„ìš”)"
        else:
            return "Fê¸‰ (ë¶€ì¡±)"
    
    def save_results(self) -> str:
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        # test_results ë””ë ‰í† ë¦¬ ìƒì„±
        results_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "test_results")
        os.makedirs(results_dir, exist_ok=True)
        
        # íŒŒì¼ëª… ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"e2e_interview_result_{timestamp}.json"
        filepath = os.path.join(results_dir, filename)
        
        # JSON ì €ì¥
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.simulation_results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filepath}")
        return filepath


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ­ E2E ì „ì²´ ë©´ì ‘ ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    simulator = EndToEndInterviewSimulator()
    
    # ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
    success = simulator.run_complete_simulation()
    
    if success:
        # ê²°ê³¼ ì €ì¥
        result_file = simulator.save_results()
        
        print("\n" + "ğŸ‰" + "="*78 + "ğŸ‰")
        print("âœ… E2E ë©´ì ‘ ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("ğŸ‰" + "="*78 + "ğŸ‰")
        print(f"ğŸ“Š ì„±ëŠ¥ ìš”ì•½:")
        summary = simulator.simulation_results["performance_summary"]
        print(f"   â€¢ ì™„ë£Œìœ¨: {summary['success_rate']:.1f}%")
        print(f"   â€¢ í‰ê·  ì ìˆ˜: {summary['average_score']:.1f}/100")
        print(f"   â€¢ ì„±ëŠ¥ ë“±ê¸‰: {summary['performance_grade']}")
        print(f"   â€¢ ì‹¤í–‰ ì‹œê°„: {summary['execution_time_seconds']:.1f}ì´ˆ")
        print(f"ğŸ“„ ìƒì„¸ ê²°ê³¼: {result_file}")
    else:
        print("\nâŒ E2E ì‹œë®¬ë ˆì´ì…˜ì´ ì‹¤íŒ¨í•˜ì˜€ìŠµë‹ˆë‹¤.")
        return 1
    
    return 0


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)