# llm/session/interviewer_session.py

# ðŸš« DEPRECATED - ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
# backend/services/interview_service.pyì˜ ìƒˆë¡œìš´ ì¤‘ì•™ ê´€ì œ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ì„¸ìš”

import uuid
from typing import Dict, List, Any, Optional, TYPE_CHECKING
# from llm.interviewer.service import InterviewerService  # ðŸ—‘ï¸ DEPRECATED

if TYPE_CHECKING:
    from llm.candidate.model import CandidatePersona, AICandidateModel

class InterviewerSession:
    """
    ðŸš« DEPRECATED - ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
    
    backend/services/interview_service.pyì˜ SessionState ë° ì¤‘ì•™ ê´€ì œ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ì„¸ìš”.
    
    ê¸°ì¡´ ì„¤ëª…: InterviewerServiceë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë™ì  í„´ì œ ë©´ì ‘ì˜ ìƒíƒœë¥¼ ê´€ë¦¬í•˜ëŠ” ì„¸ì…˜ í´ëž˜ìŠ¤.
    """
    def __init__(self, company_id: str, position: str, user_name: str):
        """
        ðŸš« DEPRECATED - ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”!
        backend/services/interview_service.pyì˜ start_ai_competition()ì„ ì‚¬ìš©í•˜ì„¸ìš”.
        """
        raise DeprecationWarning(
            "ðŸš« InterviewerSessionì€ ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
            "backend/services/interview_service.pyì˜ ìƒˆë¡œìš´ ì¤‘ì•™ ê´€ì œ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ì„¸ìš”."
        )
        
        # ðŸ—‘ï¸ ê¸°ì¡´ ì½”ë“œ ì£¼ì„ ì²˜ë¦¬
        # self.session_id = f"interviewer_comp_{uuid.uuid4().hex[:8]}"
        # self.company_id = company_id
        # self.position = position
        # self.user_name = user_name

        # # ì˜ì¡´ì„± ê°ì²´ ì´ˆê¸°í™”
        # self.interviewer_service = InterviewerService(total_question_limit=15)
        # self.ai_candidate_model = AICandidateModel()

        # ì„¸ì…˜ ìƒíƒœ
        self.user_resume: Dict[str, Any] = {'name': user_name, 'position': position}
        self.ai_persona: Optional['CandidatePersona'] = None
        self.qa_history: List[Dict[str, Any]] = []
        self.last_question: Optional[Dict[str, Any]] = None

        # í„´ ê´€ë¦¬ ìƒíƒœ
        self.user_answer: Optional[str] = None
        self.ai_answer: Optional[str] = None

    def start(self) -> Dict[str, Any]:
        """ë©´ì ‘ì„ ì‹œìž‘í•˜ê³  ì²« ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        self.ai_persona = self.ai_candidate_model.create_persona_for_interview(self.company_id, self.position)
        if not self.ai_persona:
            raise ValueError(f"AI íŽ˜ë¥´ì†Œë‚˜ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {self.company_id} - {self.position}")

        return self.get_next_question()

    def get_next_question(self) -> Dict[str, Any]:
        """ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒì„±í•˜ê³  ì„¸ì…˜ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        next_question_data = self.interviewer_service.generate_next_question(
            user_resume=self.user_resume,
            chun_sik_persona=self.ai_persona,
            company_id=self.company_id,
            previous_qa_pairs=self.qa_history,
            user_answer=self.user_answer,
            chun_sik_answer=self.ai_answer
        )

        # ë‹¤ìŒ í„´ì„ ìœ„í•´ ë‹µë³€ ì´ˆê¸°í™”
        self.user_answer = None
        self.ai_answer = None

        if not next_question_data.get('is_final'):
            self.last_question = next_question_data
            self.qa_history.append({
                "question": next_question_data.get('question'),
                "interviewer": next_question_data.get('interviewer_type'),
                "user_answer": None,
                "ai_answer": None
            })

        return next_question_data

    def record_user_answer(self, answer: str):
        """ì‚¬ìš©ìž ë‹µë³€ì„ ê¸°ë¡í•©ë‹ˆë‹¤."""
        self.user_answer = answer
        if self.qa_history:
            self.qa_history[-1]['user_answer'] = answer

    def generate_and_record_ai_answer(self) -> str:
        """í˜„ìž¬ ì§ˆë¬¸ì— ëŒ€í•œ AI ë‹µë³€ì„ ìƒì„±í•˜ê³  ê¸°ë¡í•©ë‹ˆë‹¤."""
        from llm.shared.models import AnswerRequest, QuestionType
        from llm.candidate.quality_controller import QualityLevel

        if not self.last_question:
            raise ValueError("AIì˜ ë‹µë³€ì„ ìƒì„±í•  ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")

        request = AnswerRequest(
            question_content=self.last_question['question'],
            question_type=QuestionType.from_str(self.last_question.get('interviewer_type', 'HR')),
            question_intent=self.last_question.get('intent', ''),
            company_id=self.company_id,
            position=self.position,
            quality_level=QualityLevel.GOOD,
            llm_provider="openai_gpt4o_mini"
        )

        response = self.ai_candidate_model.generate_answer(request, persona=self.ai_persona)
        if response.error:
            raise RuntimeError(f"AI ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {response.error}")

        self.ai_answer = response.answer_content
        if self.qa_history:
            self.qa_history[-1]['ai_answer'] = self.ai_answer

        return self.ai_answer

    def is_complete(self) -> bool:
        """ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        return self.interviewer_service.questions_asked_count >= self.interviewer_service.total_question_limit