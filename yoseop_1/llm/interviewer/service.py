#!/usr/bin/env python3
"""
ê°œì¸í™”ëœ ë©´ì ‘ ì‹œìŠ¤í…œ
ì‚¬ìš©ì í”„ë¡œí•„ì„ ê¸°ë°˜ìœ¼ë¡œ ë§ì¶¤í˜• ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ì‹œìŠ¤í…œ
ì½”ë“œ ì •ë¦¬ ë° êµ¬ì¡° ê°œì„  ë²„ì „
"""

import json
import random
import os
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
import openai
from datetime import datetime
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

from ..shared.models import QuestionType, QuestionAnswer
from ..session.models import InterviewSession
from .document_processor import DocumentProcessor, UserProfile
from ..shared.constants import GPT_MODEL, MAX_TOKENS, TEMPERATURE, QUESTION_SECTIONS
from ..shared.utils import parse_career_years, get_difficulty_level, safe_json_load, extract_question_and_intent
from .prompt_templates import InterviewPromptTemplates
from .conversation_context import ConversationContext
# ğŸ”„ FinalInterviewSystem ëŒ€ì‹  SessionManager ì‚¬ìš©
from ..session import SessionManager

class PersonalizedInterviewSession(InterviewSession):
    """ê°œì¸í™”ëœ ë©´ì ‘ ì„¸ì…˜"""
    
    def __init__(self, company_id: str, position: str, candidate_name: str, user_profile: UserProfile):
        super().__init__(company_id, position, candidate_name)
        self.user_profile = user_profile
        
        # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì ì´ˆê¸°í™”
        self.conversation_context = ConversationContext(
            company_id=company_id,
            position=position,
            persona_name=candidate_name
        )
        
        # ê°œì¸í™”ëœ ì§ˆë¬¸ ê³„íš (ì‚¬ìš©ì ë°°ê²½ì— ë”°ë¼ ë™ì  ì¡°ì •)
        self.question_plan = self._create_personalized_plan()
    
    def add_qa_pair(self, qa_pair: QuestionAnswer):
        """ì§ˆë¬¸-ë‹µë³€ ìŒ ì¶”ê°€ (ì»¨í…ìŠ¤íŠ¸ ì¶”ì  í¬í•¨)"""
        super().add_qa_pair(qa_pair)
        
        # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ì— ì§ˆë¬¸-ë‹µë³€ ì¶”ê°€
        if hasattr(self, 'conversation_context'):
            self.conversation_context.add_question_answer(
                qa_pair.question_content,
                qa_pair.answer_content,
                qa_pair.question_type
            )
    
    def _create_personalized_plan(self) -> List[Dict[str, Any]]:
        """ì‚¬ìš©ì í”„ë¡œí•„ì— ë”°ë¥¸ ê°œì¸í™”ëœ ì§ˆë¬¸ ê³„íš"""
        
        # ê¸°ë³¸ ì§ˆë¬¸ (ëª¨ë“  ë©´ì ‘ì ê³µí†µ)
        base_plan = [
            {"type": QuestionType.INTRO, "focus": "self_introduction", "personalized": False, "fixed": True},
            {"type": QuestionType.MOTIVATION, "focus": "application_reason", "personalized": False, "fixed": True}
        ]
        
        # ê²½ë ¥ ë…„ìˆ˜ íŒŒì‹± (ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©)
        career_years_str = self.user_profile.background.get("career_years", "0")
        career_years = parse_career_years(career_years_str)
        
        # ê¸°ìˆ  ìŠ¤í‚¬ê³¼ í”„ë¡œì íŠ¸ ìˆ˜ ê³„ì‚°
        tech_skills_count = len(self.user_profile.technical_skills)
        projects_count = len(self.user_profile.projects)
        
        if career_years >= 3:  # ê²½ë ¥ì (ì´ 18ê°œ ì§ˆë¬¸)
            additional_questions = [
                # ì¸ì‚¬ ì˜ì—­ (2ê°œ ê³ ì • + 2ê°œ ìƒì„±) - ìˆœìˆ˜ ì¸ì„± ì¤‘ì‹¬
                {"type": QuestionType.HR, "focus": "personality", "personalized": False, "fixed": True, "section": "hr"},
                {"type": QuestionType.HR, "focus": "values", "personalized": False, "fixed": True, "section": "hr"},
                {"type": QuestionType.HR, "focus": "growth_mindset", "personalized": True, "fixed": False},
                {"type": QuestionType.HR, "focus": "leadership_style", "personalized": True, "fixed": False},
                
                # ê¸°ìˆ  ì˜ì—­ (2ê°œ ê³ ì • + 3ê°œ ìƒì„±) - ìˆœìˆ˜ ê¸°ìˆ  ì¤‘ì‹¬
                {"type": QuestionType.TECH, "focus": "expertise", "personalized": False, "fixed": True, "section": "technical"},
                {"type": QuestionType.TECH, "focus": "architecture", "personalized": False, "fixed": True, "section": "technical"},
                {"type": QuestionType.TECH, "focus": "problem_solving", "personalized": True, "fixed": False},
                {"type": QuestionType.TECH, "focus": "innovation", "personalized": True, "fixed": False},
                {"type": QuestionType.TECH, "focus": "learning", "personalized": True, "fixed": False},
                
                # í˜‘ì—… ì˜ì—­ (1ê°œ ê³ ì • + 2ê°œ ìƒì„±) - ìˆœìˆ˜ í˜‘ì—… ì¤‘ì‹¬
                {"type": QuestionType.COLLABORATION, "focus": "teamwork", "personalized": False, "fixed": True, "section": "collaboration"},
                {"type": QuestionType.COLLABORATION, "focus": "communication", "personalized": True, "fixed": False},
                {"type": QuestionType.COLLABORATION, "focus": "conflict_resolution", "personalized": True, "fixed": False},
                
                # ì‹¬í™” ì§ˆë¬¸ (3ê°œ ìƒì„±)
                {"type": QuestionType.FOLLOWUP, "focus": "career", "personalized": True, "fixed": False},
                {"type": QuestionType.FOLLOWUP, "focus": "future_goals", "personalized": True, "fixed": False},
                {"type": QuestionType.FOLLOWUP, "focus": "company_contribution", "personalized": True, "fixed": False}
            ]
        elif career_years >= 1:  # ì£¼ë‹ˆì–´ (ì´ 16ê°œ ì§ˆë¬¸)
            additional_questions = [
                # ì¸ì‚¬ ì˜ì—­ (2ê°œ ê³ ì • + 2ê°œ ìƒì„±) - ìˆœìˆ˜ ì¸ì„± ì¤‘ì‹¬
                {"type": QuestionType.HR, "focus": "personality", "personalized": False, "fixed": True, "section": "hr"},
                {"type": QuestionType.HR, "focus": "values", "personalized": False, "fixed": True, "section": "hr"},
                {"type": QuestionType.HR, "focus": "growth", "personalized": True, "fixed": False},
                {"type": QuestionType.HR, "focus": "adaptability", "personalized": True, "fixed": False},
                
                # ê¸°ìˆ  ì˜ì—­ (2ê°œ ê³ ì • + 3ê°œ ìƒì„±) - ìˆœìˆ˜ ê¸°ìˆ  ì¤‘ì‹¬
                {"type": QuestionType.TECH, "focus": "skills", "personalized": False, "fixed": True, "section": "technical"},
                {"type": QuestionType.TECH, "focus": "recent_learning", "personalized": False, "fixed": True, "section": "technical"},
                {"type": QuestionType.TECH, "focus": "problem_solving", "personalized": True, "fixed": False},
                {"type": QuestionType.TECH, "focus": "technical_depth", "personalized": True, "fixed": False},
                {"type": QuestionType.TECH, "focus": "learning_ability", "personalized": True, "fixed": False},
                
                # í˜‘ì—… ì˜ì—­ (2ê°œ ê³ ì • + 2ê°œ ìƒì„±) - ìˆœìˆ˜ í˜‘ì—… ì¤‘ì‹¬
                {"type": QuestionType.COLLABORATION, "focus": "teamwork", "personalized": False, "fixed": True, "section": "collaboration"},
                {"type": QuestionType.COLLABORATION, "focus": "communication", "personalized": False, "fixed": True, "section": "collaboration"},
                {"type": QuestionType.COLLABORATION, "focus": "team_contribution", "personalized": True, "fixed": False},
                {"type": QuestionType.COLLABORATION, "focus": "peer_learning", "personalized": True, "fixed": False},
                
                # ì‹¬í™” ì§ˆë¬¸ (1ê°œ ìƒì„±)
                {"type": QuestionType.FOLLOWUP, "focus": "career_growth", "personalized": True, "fixed": False}
            ]
        else:  # ì‹ ì… (ì´ 13ê°œ ì§ˆë¬¸)
            additional_questions = [
                # ì¸ì‚¬ ì˜ì—­ (2ê°œ ê³ ì • + 2ê°œ ìƒì„±) - ìˆœìˆ˜ ì¸ì„± ì¤‘ì‹¬
                {"type": QuestionType.HR, "focus": "personality", "personalized": False, "fixed": True, "section": "hr"},
                {"type": QuestionType.HR, "focus": "values", "personalized": False, "fixed": True, "section": "hr"},
                {"type": QuestionType.HR, "focus": "potential", "personalized": True, "fixed": False},
                {"type": QuestionType.HR, "focus": "enthusiasm", "personalized": True, "fixed": False},
                
                # ê¸°ìˆ  ì˜ì—­ (2ê°œ ê³ ì • + 2ê°œ ìƒì„±) - ìˆœìˆ˜ ê¸°ìˆ  ì¤‘ì‹¬
                {"type": QuestionType.TECH, "focus": "fundamentals", "personalized": False, "fixed": True, "section": "technical"},
                {"type": QuestionType.TECH, "focus": "learning", "personalized": False, "fixed": True, "section": "technical"},
                {"type": QuestionType.TECH, "focus": "project_experience", "personalized": True, "fixed": False},
                {"type": QuestionType.TECH, "focus": "passion", "personalized": True, "fixed": False},
                
                # í˜‘ì—… ì˜ì—­ (1ê°œ ê³ ì • + 2ê°œ ìƒì„±) - ìˆœìˆ˜ í˜‘ì—… ì¤‘ì‹¬
                {"type": QuestionType.COLLABORATION, "focus": "teamwork", "personalized": False, "fixed": True, "section": "collaboration"},
                {"type": QuestionType.COLLABORATION, "focus": "communication", "personalized": True, "fixed": False},
                {"type": QuestionType.COLLABORATION, "focus": "willingness_to_learn", "personalized": True, "fixed": False},
                
                # ì‹¬í™” ì§ˆë¬¸ (1ê°œ ìƒì„±)
                {"type": QuestionType.FOLLOWUP, "focus": "growth_mindset", "personalized": True, "fixed": False}
            ]
        
        return base_plan + additional_questions

class PersonalizedInterviewSystem(SessionManager):
    """ê°œì¸í™”ëœ ë©´ì ‘ ì‹œìŠ¤í…œ"""
    
    def __init__(self, api_key: str = None, companies_data_path: str = "llm/shared/data/companies_data.json"):
        super().__init__(api_key, companies_data_path)
        self.document_processor = DocumentProcessor(api_key or os.getenv('OPENAI_API_KEY'))
        self.fixed_questions = self._load_fixed_questions()
        self.question_cache = {}  # ì§ˆë¬¸ ìºì‹œ ì¶”ê°€
        
        # ìƒˆë¡œìš´ íšŒì‚¬ ë°ì´í„° ë¡œë” ì‚¬ìš©
        from ..shared.company_data_loader import get_company_loader
        self.company_loader = get_company_loader()
    
    def _load_fixed_questions(self) -> Dict[str, List[Dict]]:
        """ê³ ì • ì§ˆë¬¸ ë°ì´í„° ë¡œë“œ"""
        default_structure = {
            "hr_questions": [], 
            "technical_questions": [], 
            "collaboration_questions": []
        }
        return safe_json_load("llm/interviewer/data/fixed_questions.json", default_structure)
    
    def _get_fixed_question(self, section: str, difficulty_level: int = None) -> Optional[Dict]:
        """ì„¹ì…˜ë³„ ê³ ì • ì§ˆë¬¸ ìºì‹œëœ ì„ íƒ"""
        cache_key = f"{section}_{difficulty_level or 'all'}"
        
        # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
        if cache_key in self.question_cache:
            return self.question_cache[cache_key]
            
        questions = self.fixed_questions.get(QUESTION_SECTIONS.get(section, ""), [])
        if not questions:
            return None
            
        # ë‚œì´ë„ë³„ í•„í„°ë§ (ì„ íƒì‚¬í•­)
        if difficulty_level:
            filtered_questions = [q for q in questions if q.get("level", 1) == difficulty_level]
            questions = filtered_questions if filtered_questions else questions
        
        selected_question = random.choice(questions) if questions else None
        
        # ìºì‹œì— ì €ì¥ (ê°„ë‹¨í•œ ìºì‹±)
        if selected_question:
            self.question_cache[cache_key] = selected_question
            
        return selected_question
    
    def _build_previous_answers_context(self, session: PersonalizedInterviewSession) -> str:
        """ì´ì „ ë‹µë³€ì—ì„œ ì°¸ê³ í•  ë§Œí•œ ë‚´ìš© ì¶”ì¶œ"""
        if not session.conversation_history:
            return ""
        
        context_parts = []
        for i, qa in enumerate(session.conversation_history[-3:]):  # ìµœê·¼ 3ê°œ ë‹µë³€ë§Œ
            if qa.answer_content and len(qa.answer_content.strip()) > 20:  # ì˜ë¯¸ìˆëŠ” ë‹µë³€ë§Œ
                context_parts.append(f"- {qa.question_content[:50]}... â†’ {qa.answer_content[:100]}...")
        
        return "\n".join(context_parts) if context_parts else ""
    
    def start_personalized_interview(self, company_id: str, position: str, candidate_name: str, 
                                   user_profile: UserProfile) -> str:
        """ê°œì¸í™”ëœ ë©´ì ‘ ì‹œì‘"""
        
        company_data = self.get_company_data(company_id)
        if not company_data:
            raise ValueError(f"íšŒì‚¬ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {company_id}")
        
        session = PersonalizedInterviewSession(company_id, position, candidate_name, user_profile)
        self.sessions[session.session_id] = session
        
        return session.session_id
    
    def get_session(self, session_id: str) -> Optional[PersonalizedInterviewSession]:
        """ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸°"""
        return self.sessions.get(session_id)
    
    def get_current_question(self, session_id: str) -> Optional[Dict[str, Any]]:
        """í˜„ì¬ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°"""
        session = self.get_session(session_id)
        if not session:
            return None
        
        # í˜„ì¬ ì§ˆë¬¸ì´ ìˆìœ¼ë©´ ë°˜í™˜
        if session.conversation_history:
            last_qa = session.conversation_history[-1]
            return {
                "question_id": f"q_{len(session.conversation_history)}",
                "question_type": "current",
                "question_content": last_qa.question_content,
                "question_intent": last_qa.question_intent or "í˜„ì¬ ì§ˆë¬¸",
                "progress": f"{len(session.conversation_history)}/{len(session.question_plan)}",
                "personalized": True
            }
        
        # í˜„ì¬ ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì§ˆë¬¸ ìƒì„±
        return self.get_next_question(session_id)
    
    def _generate_personalized_question(self, session: PersonalizedInterviewSession, 
                                      company_data: Dict[str, Any], question_plan: Dict[str, Any]) -> Tuple[str, str]:
        """ê°œì¸í™”ëœ ì§ˆë¬¸ ìƒì„±"""
        
        question_type = question_plan["type"]
        focus = question_plan.get("focus", "general")
        is_fixed = question_plan.get("fixed", False)
        section = question_plan.get("section", "")
        
        # ê¸°ë³¸ ì§ˆë¬¸ ì²˜ë¦¬ (INTRO, MOTIVATION)
        if question_type == QuestionType.INTRO:
            return (
                f"{session.candidate_name}ë‹˜, ìê¸°ì†Œê°œë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤.",
                "ì§€ì›ìì˜ ê¸°ë³¸ ì •ë³´ì™€ ì„±ê²©, ì—­ëŸ‰ì„ íŒŒì•…"
            )
        elif question_type == QuestionType.MOTIVATION:
            return (
                f"ì €í¬ {company_data['name']}ì— ì§€ì›í•˜ì‹  ë™ê¸°ë¥¼ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                "íšŒì‚¬ì— ëŒ€í•œ ê´€ì‹¬ë„ì™€ ì§€ì› ë™ê¸° íŒŒì•…"
            )
        
        # ê³ ì • ì§ˆë¬¸ ë°ì´í„°ì—ì„œ ì„ íƒ
        if is_fixed and section:
            career_years_str = session.user_profile.background.get("career_years", "0")
            career_years = parse_career_years(career_years_str)
            difficulty_level = get_difficulty_level(career_years)
            
            fixed_question = self._get_fixed_question(section, difficulty_level)
            if fixed_question:
                return (
                    fixed_question["content"],
                    fixed_question["intent"]
                )
        
        # ê°œì¸í™”ëœ ì§ˆë¬¸ ìƒì„±
        print(f"ğŸ¯ ê°œì¸í™” ì§ˆë¬¸ ìƒì„± ì‹œì‘ - {question_type.value}, focus: {focus}")
        context = self._build_personalized_context(session, company_data)
        
        # ê³ ì • ì§ˆë¬¸ ë‹µë³€ ì°¸ê³ ë¥¼ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        previous_answers_context = self._build_previous_answers_context(session)
        if previous_answers_context:
            context += f"\n\nì´ì „ ë‹µë³€ ì°¸ê³ ì‚¬í•­:\n{previous_answers_context}"
        
        prompt = self._create_personalized_prompt(question_type, focus, context, session.candidate_name)
        print(f"ğŸ“ LLM í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ - ê¸¸ì´: {len(prompt)} ê¸€ì")
        
        try:
            print(f"ğŸ¤– OpenAI API í˜¸ì¶œ ì¤‘...")
            response = self.client.chat.completions.create(
                model=GPT_MODEL,
                messages=[
                    {"role": "system", "content": InterviewPromptTemplates.get_system_prompt(company_data['name'])},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE
            )
            
            result = response.choices[0].message.content.strip()
            print(f"âœ… OpenAI ì‘ë‹µ ë°›ìŒ: {result[:100]}...")
            
            # ì œì–´ ë¬¸ìì™€ íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬
            import re
            result = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', result)  # ì œì–´ ë¬¸ì ì œê±°
            result = re.sub(r'\*\*', '', result)  # ë§ˆí¬ë‹¤ìš´ ì œê±°
            result = re.sub(r'^\d+\.\s*', '', result)  # ë²ˆí˜¸ ì œê±°
            result = re.sub(r'\n+', ' ', result)  # ê°œí–‰ ë¬¸ìë¥¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜
            
            final_result = extract_question_and_intent(result)
            print(f"ğŸ¯ ìµœì¢… ì§ˆë¬¸: {final_result[0]}")
            return final_result
            
        except Exception as e:
            print(f"ê°œì¸í™” ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return self._get_fallback_personalized_question(question_type, focus, session.candidate_name)
    
    def _build_personalized_context(self, session: PersonalizedInterviewSession, company_data: Dict[str, Any]) -> str:
        """ê°œì¸í™”ëœ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± - 7ê°œ íšŒì‚¬ ìƒì„¸ ì •ë³´ í™œìš©"""
        
        profile = session.user_profile
        
        # íšŒì‚¬ë³„ ìƒì„¸ ì •ë³´ ì¶”ì¶œ
        company_name = company_data.get('name', 'íšŒì‚¬')
        company_id = company_data.get('id', 'unknown')
        talent_profile = company_data.get('talent_profile', '')
        core_competencies = company_data.get('core_competencies', [])
        tech_focus = company_data.get('tech_focus', [])
        interview_keywords = company_data.get('interview_keywords', [])
        company_culture = company_data.get('company_culture', {})
        technical_challenges = company_data.get('technical_challenges', [])
        interviewer_personas = company_data.get('interviewer_personas', {})
        
        # UserProfile ê°ì²´ì¸ì§€ í™•ì¸í•˜ê³  ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
        if hasattr(profile, 'background'):
            # ì •ìƒì ì¸ UserProfile ê°ì²´
            context = f"""
=== ğŸ¢ {company_name} ì±„ìš© ì»¨í…ìŠ¤íŠ¸ ===
â€¢ ì¸ì¬ìƒ: {talent_profile}
â€¢ í•µì‹¬ ì—­ëŸ‰: {', '.join(core_competencies[:3])}
â€¢ ê¸°ìˆ  í¬ì»¤ìŠ¤: {', '.join(tech_focus[:4])}
â€¢ ë©´ì ‘ í‚¤ì›Œë“œ: {', '.join(interview_keywords[:5])}

=== ğŸ¯ íšŒì‚¬ ë¬¸í™” ë° ê°€ì¹˜ê´€ ===
â€¢ ì—…ë¬´ ìŠ¤íƒ€ì¼: {company_culture.get('work_style', 'í˜‘ì—… ì¤‘ì‹¬')}
â€¢ ì˜ì‚¬ê²°ì • ë°©ì‹: {company_culture.get('decision_making', 'ë°ì´í„° ê¸°ë°˜')}
â€¢ í•µì‹¬ ê°€ì¹˜: {', '.join(company_culture.get('core_values', [])[:3])}

=== ğŸ”§ ê¸°ìˆ ì  ë„ì „ê³¼ì œ ===
"""
            for i, challenge in enumerate(technical_challenges[:3], 1):
                context += f"{i}. {challenge}\n"
            
            context += f"""
=== ğŸ‘¤ ì§€ì›ì í”„ë¡œí•„ ===
ì´ë¦„: {profile.name}
ê²½ë ¥: {profile.background.get('career_years', '0')}ë…„
í˜„ì¬ ì§ì±…: {profile.background.get('current_position', 'ì‹ ì…')}
ì£¼ìš” ê¸°ìˆ : {', '.join(profile.technical_skills[:5]) if profile.technical_skills else 'ì—†ìŒ'}

=== ğŸ“‹ ì£¼ìš” í”„ë¡œì íŠ¸ ===
"""
            for i, project in enumerate(profile.projects[:3], 1):
                context += f"{i}. {project.get('name', 'í”„ë¡œì íŠ¸')}: {project.get('description', '')}\n"
                context += f"   ê¸°ìˆ ìŠ¤íƒ: {', '.join(project.get('tech_stack', []))}\n"
            
            context += f"""
=== â­ ê°•ì  ë° íŠ¹ì§• ===
ì£¼ìš” ê°•ì : {', '.join(profile.strengths[:3]) if profile.strengths else 'ì—†ìŒ'}
ì°¨ë³„í™” í¬ì¸íŠ¸: {', '.join(profile.unique_points[:2]) if profile.unique_points else 'ì—†ìŒ'}
ì»¤ë¦¬ì–´ ëª©í‘œ: {profile.career_goal}

=== ğŸ¤ ë©´ì ‘ê´€ í˜ë¥´ì†Œë‚˜ ì •ë³´ ===
"""
            for persona_type, persona_info in list(interviewer_personas.items())[:2]:
                context += f"â€¢ {persona_info.get('name', persona_type)}: {persona_info.get('role', '')}\n"
                context += f"  íŠ¹ì§•: {persona_info.get('personality', '')}\n"
        else:
            # dict í˜•íƒœ ë˜ëŠ” ê¸°íƒ€ í˜•íƒœì¸ ê²½ìš° - íšŒì‚¬ ì •ë³´ ìš°ì„  í™œìš©
            print(f"âš ï¸ profileì´ UserProfile ê°ì²´ê°€ ì•„ë‹™ë‹ˆë‹¤: {type(profile)}")
            profile_dict = profile if isinstance(profile, dict) else {
                'name': 'ì§€ì›ì',
                'background': {'career_years': '0', 'current_position': 'ì‹ ì…'},
                'technical_skills': [],
                'projects': [],
                'strengths': [],
                'unique_points': [],
                'career_goal': 'ì„±ì¥'
            }
            
            context = f"""
=== ğŸ¢ {company_name} ì±„ìš© ì»¨í…ìŠ¤íŠ¸ ===
â€¢ ì¸ì¬ìƒ: {talent_profile}
â€¢ í•µì‹¬ ì—­ëŸ‰: {', '.join(core_competencies[:3])}
â€¢ ê¸°ìˆ  í¬ì»¤ìŠ¤: {', '.join(tech_focus[:4])}
â€¢ ë©´ì ‘ í‚¤ì›Œë“œ: {', '.join(interview_keywords[:5])}

=== ğŸ¯ íšŒì‚¬ ë¬¸í™” ë° ê°€ì¹˜ê´€ ===
â€¢ ì—…ë¬´ ìŠ¤íƒ€ì¼: {company_culture.get('work_style', 'í˜‘ì—… ì¤‘ì‹¬')}
â€¢ ì˜ì‚¬ê²°ì • ë°©ì‹: {company_culture.get('decision_making', 'ë°ì´í„° ê¸°ë°˜')}
â€¢ í•µì‹¬ ê°€ì¹˜: {', '.join(company_culture.get('core_values', [])[:3])}

=== ğŸ‘¤ ì§€ì›ì í”„ë¡œí•„ ===
ì´ë¦„: {profile_dict.get('name', 'ì§€ì›ì')}
ê²½ë ¥: {profile_dict.get('background', {}).get('career_years', '0')}ë…„
í˜„ì¬ ì§ì±…: {profile_dict.get('background', {}).get('current_position', 'ì‹ ì…')}
ì£¼ìš” ê¸°ìˆ : {', '.join(profile_dict.get('technical_skills', [])[:5]) if profile_dict.get('technical_skills') else 'ì—†ìŒ'}

=== ğŸ“‹ ì£¼ìš” í”„ë¡œì íŠ¸ ===
"""
            projects = profile_dict.get('projects', [])
            for i, project in enumerate(projects[:3], 1):
                context += f"{i}. {project.get('name', 'í”„ë¡œì íŠ¸')}: {project.get('description', '')}\n"
                context += f"   ê¸°ìˆ ìŠ¤íƒ: {', '.join(project.get('tech_stack', []))}\n"
            
            context += f"""
=== â­ ê°•ì  ë° íŠ¹ì§• ===
ì£¼ìš” ê°•ì : {', '.join(profile_dict.get('strengths', [])[:3]) if profile_dict.get('strengths') else 'ì—†ìŒ'}
ì°¨ë³„í™” í¬ì¸íŠ¸: {', '.join(profile_dict.get('unique_points', [])[:2]) if profile_dict.get('unique_points') else 'ì—†ìŒ'}
ì»¤ë¦¬ì–´ ëª©í‘œ: {profile_dict.get('career_goal', 'ì„±ì¥')}
"""
        
        # ì´ì „ ëŒ€í™” ìš”ì•½ ì¶”ê°€
        if session.conversation_history:
            context += f"""

=== ğŸ’¬ ì´ì „ ëŒ€í™” ìš”ì•½ ===
"""
            for i, qa in enumerate(session.conversation_history[-3:], 1):  # ìµœê·¼ 3ê°œë§Œ
                context += f"{i}. [{qa.question_type.value}] {qa.question_content[:50]}...\n"
                context += f"   ë‹µë³€: {qa.answer_content[:100]}...\n"
        
        return context
    
    def _create_personalized_prompt(self, question_type: QuestionType, focus: str, context: str, candidate_name: str) -> str:
        """ê°œì¸í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        prompts = {
            QuestionType.MOTIVATION: f"""
{context}

ìœ„ ì§€ì›ìì˜ ë°°ê²½ê³¼ {candidate_name}ë‹˜ì˜ ì»¤ë¦¬ì–´ ëª©í‘œë¥¼ ê³ ë ¤í•˜ì—¬, 
{candidate_name}ë‹˜ì´ ì´ íšŒì‚¬ì— ì§€ì›í•œ êµ¬ì²´ì ì¸ ë™ê¸°ë¥¼ ë¬»ëŠ” ë§ì¶¤í˜• ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ì§€ì›ìì˜ ê²½í—˜ê³¼ ëª©í‘œê°€ íšŒì‚¬ì˜ ë¹„ì „ê³¼ ì–´ë–»ê²Œ ì—°ê²°ë˜ëŠ”ì§€ íƒìƒ‰í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

ê°„ê²°í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ í•˜ë‚˜ë§Œ ìƒì„±í•˜ì„¸ìš”.

í˜•ì‹:
ì§ˆë¬¸ ë‚´ìš©
ì˜ë„: ì´ ì§ˆë¬¸ì˜ í‰ê°€ ëª©ì 
""",
            
            QuestionType.HR: f"""
{context}

ìœ„ ì§€ì›ìì˜ ë°°ê²½ì„ ê³ ë ¤í•˜ì—¬ **ì¸ì„± ì˜ì—­({focus})**ì„ í‰ê°€í•˜ëŠ” ë§ì¶¤í˜• ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

**ì¸ì„± ì§ˆë¬¸ ê¸°ì¤€:**
- ì„±ê²©, ê°€ì¹˜ê´€, ì¸ìƒê´€, íƒœë„
- ìŠ¤íŠ¸ë ˆìŠ¤ ëŒ€ì²˜ ë°©ì‹, ê°ˆë“± í•´ê²° ë°©ì‹  
- ê°œì¸ì  ì„±ì¥, ìê¸°ê³„ë°œ, ëª©í‘œ ì„¤ì •
- ë„ë•ì  íŒë‹¨, ì±…ì„ê°, ì„±ì‹¤ì„±

**í˜‘ì—…ì´ë‚˜ ê¸°ìˆ ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì€ ì œì™¸**í•˜ê³  ìˆœìˆ˜í•˜ê²Œ ì§€ì›ìì˜ ì¸ì„±ì„ ì•Œì•„ë³¼ ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì„ ë§Œë“œì„¸ìš”.

ê°„ê²°í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ í•˜ë‚˜ë§Œ ìƒì„±í•˜ì„¸ìš”.

í˜•ì‹:
ì§ˆë¬¸ ë‚´ìš©
ì˜ë„: ì´ ì§ˆë¬¸ì˜ í‰ê°€ ëª©ì 
""",
            
            QuestionType.TECH: f"""
{context}

ìœ„ ì§€ì›ìì˜ ê¸°ìˆ  ìŠ¤íƒê³¼ í”„ë¡œì íŠ¸ ê²½í—˜ì„ ê³ ë ¤í•˜ì—¬ **ê¸°ìˆ  ì˜ì—­({focus})**ì„ í‰ê°€í•˜ëŠ” ë§ì¶¤í˜• ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

**ê¸°ìˆ  ì§ˆë¬¸ ê¸°ì¤€:**
- í”„ë¡œê·¸ë˜ë° ì–¸ì–´, í”„ë ˆì„ì›Œí¬, ë„êµ¬ ì‚¬ìš© ê²½í—˜
- í”„ë¡œì íŠ¸ êµ¬í˜„, ì•„í‚¤í…ì²˜ ì„¤ê³„, ì„±ëŠ¥ ìµœì í™”
- ê¸°ìˆ ì  ë¬¸ì œ í•´ê²°, ë””ë²„ê¹…, íŠ¸ëŸ¬ë¸”ìŠˆíŒ…
- ìƒˆë¡œìš´ ê¸°ìˆ  í•™ìŠµ, ê¸°ìˆ  íŠ¸ë Œë“œ ì´í•´

**ì¸ì„±ì´ë‚˜ í˜‘ì—…ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì€ ì œì™¸**í•˜ê³  ìˆœìˆ˜í•˜ê²Œ ê¸°ìˆ ì  ì—­ëŸ‰ì„ í‰ê°€í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì„ ë§Œë“œì„¸ìš”.

ê°„ê²°í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ í•˜ë‚˜ë§Œ ìƒì„±í•˜ì„¸ìš”.

í˜•ì‹:
ì§ˆë¬¸ ë‚´ìš©
ì˜ë„: ì´ ì§ˆë¬¸ì˜ í‰ê°€ ëª©ì 
""",
            
            QuestionType.COLLABORATION: f"""
{context}

ìœ„ ì§€ì›ìì˜ ê²½ë ¥ê³¼ í”„ë¡œì íŠ¸ ê²½í—˜ì„ ê³ ë ¤í•˜ì—¬ **í˜‘ì—… ì˜ì—­({focus})**ì„ í‰ê°€í•˜ëŠ” ë§ì¶¤í˜• ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

**í˜‘ì—… ì§ˆë¬¸ ê¸°ì¤€:**
- íŒ€ì›Œí¬, íŒ€ ë‚´ ì—­í•  ìˆ˜í–‰, íŒ€ì›ê³¼ì˜ ì†Œí†µ
- ê°ˆë“± ìƒí™© í•´ê²°, ì˜ê²¬ ì¡°ìœ¨, í•©ì˜ ë„ì¶œ
- ë¦¬ë”ì‹­, íŒ”ë¡œì›Œì‹­, ë©˜í† ë§
- í¬ë¡œìŠ¤ íŒ€ í˜‘ì—…, ì´í•´ê´€ê³„ì ì†Œí†µ

**ê°œì¸ì  ì¸ì„±ì´ë‚˜ ìˆœìˆ˜ ê¸°ìˆ ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì€ ì œì™¸**í•˜ê³  ìˆœìˆ˜í•˜ê²Œ í˜‘ì—… ëŠ¥ë ¥ì„ í‰ê°€í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì„ ë§Œë“œì„¸ìš”.

ê°„ê²°í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ í•˜ë‚˜ë§Œ ìƒì„±í•˜ì„¸ìš”.

í˜•ì‹:
ì§ˆë¬¸ ë‚´ìš©
ì˜ë„: ì´ ì§ˆë¬¸ì˜ í‰ê°€ ëª©ì 
""",
            
            QuestionType.FOLLOWUP: f"""
{context}

ìœ„ ì§€ì›ìì˜ ë‹µë³€ê³¼ ë°°ê²½ì„ ë°”íƒ•ìœ¼ë¡œ {focus} ê´€ë ¨ ì‹¬í™” ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ì§€ì›ìì˜ ê°€ì¥ ì¸ìƒì ì¸ ê²½í—˜ì´ë‚˜ ê°•ì ì„ ë” ê¹Šì´ íƒêµ¬í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

ê°„ê²°í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ í•˜ë‚˜ë§Œ ìƒì„±í•˜ì„¸ìš”.

í˜•ì‹:
ì§ˆë¬¸ ë‚´ìš©
ì˜ë„: ì´ ì§ˆë¬¸ì˜ í‰ê°€ ëª©ì 
"""
        }
        
        return prompts.get(question_type, f"""
{context}

ìœ„ ì§€ì›ìì˜ ë°°ê²½ì„ ê³ ë ¤í•˜ì—¬ {question_type.value} ì˜ì—­ì„ í‰ê°€í•˜ëŠ” ë§ì¶¤í˜• ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ê°„ê²°í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ í•˜ë‚˜ë§Œ ìƒì„±í•˜ì„¸ìš”.

í˜•ì‹:
ì§ˆë¬¸ ë‚´ìš©
ì˜ë„: ì´ ì§ˆë¬¸ì˜ í‰ê°€ ëª©ì 
""")
    
    def _get_fallback_personalized_question(self, question_type: QuestionType, focus: str, candidate_name: str) -> Tuple[str, str]:
        """ê°œì¸í™” ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ì§ˆë¬¸"""
        
        fallback_questions = {
            (QuestionType.HR, "growth"): (
                f"{candidate_name}ë‹˜ì˜ ì„±ì¥ ê³¼ì •ì—ì„œ ê°€ì¥ í° ë³€í™”ë‚˜ ê¹¨ë‹¬ìŒì´ ìˆì—ˆë˜ ê²½í—˜ì„ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                "ê°œì¸ì  ì„±ì¥ê³¼ í•™ìŠµ ëŠ¥ë ¥ í‰ê°€"
            ),
            (QuestionType.TECH, "problem_solving"): (
                f"{candidate_name}ë‹˜ì´ ê¸°ìˆ ì ìœ¼ë¡œ ê°€ì¥ ì–´ë ¤ì› ë˜ ë¬¸ì œë¥¼ ì–´ë–»ê²Œ í•´ê²°í•˜ì…¨ë‚˜ìš”?",
                "ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ê³¼ ê¸°ìˆ ì  ì‚¬ê³ ë ¥ í‰ê°€"
            ),
            (QuestionType.COLLABORATION, "teamwork"): (
                f"{candidate_name}ë‹˜ì˜ íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ê°ˆë“±ì´ ìˆì—ˆì„ ë•Œ ì–´ë–»ê²Œ í•´ê²°í•˜ì…¨ë‚˜ìš”?",
                "í˜‘ì—… ëŠ¥ë ¥ê³¼ ê°ˆë“± í•´ê²° ëŠ¥ë ¥ í‰ê°€"
            )
        }
        
        key = (question_type, focus)
        if key in fallback_questions:
            return fallback_questions[key]
        
        return (
            f"{candidate_name}ë‹˜ì˜ ê²½í—˜ì— ëŒ€í•´ ë” ìì„¸íˆ ë§ì”€í•´ ì£¼ì„¸ìš”.",
            f"{question_type.value} ì˜ì—­ ê¸°ë³¸ í‰ê°€"
        )
    
    def _generate_personalized_question_with_duplicate_check(self, session: PersonalizedInterviewSession, 
                                                           company_data: Dict[str, Any], 
                                                           question_plan: Dict[str, Any]) -> Tuple[str, str]:
        """ì¤‘ë³µ ë°©ì§€ê°€ ê°•í™”ëœ ê°œì¸í™” ì§ˆë¬¸ ìƒì„±"""
        
        # ê¸°ì¡´ ì§ˆë¬¸ ìƒì„± ë¡œì§ ì‚¬ìš©
        question_content, question_intent = self._generate_personalized_question(
            session, company_data, question_plan
        )
        
        # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ê°€ ë‹¤ì–‘ì„± ì ìš©
        if hasattr(session, 'conversation_context'):
            # ëœ íƒìƒ‰ëœ ì£¼ì œ ìš°ì„  í™œìš©
            underexplored_topics = session.conversation_context.get_underexplored_topics()
            focus_suggestions = session.conversation_context.suggest_next_question_focus()
            
            if underexplored_topics and focus_suggestions.get('suggested_new_angles'):
                # ìƒˆë¡œìš´ ê°ë„ë¡œ ì§ˆë¬¸ ì¬ìƒì„±
                additional_context = f"ìƒˆë¡œìš´ ì ‘ê·¼ ë°©í–¥: {', '.join(focus_suggestions['suggested_new_angles'][:2])}"
                question_content = self._enhance_question_with_context(
                    question_content, additional_context, session
                )
        
        return question_content, question_intent
    
    def _generate_alternative_question(self, session: PersonalizedInterviewSession, 
                                     question_plan: Dict[str, Any]) -> Tuple[str, str]:
        """ëŒ€ì•ˆ ì§ˆë¬¸ ìƒì„± (ì¤‘ë³µ ë°œìƒ ì‹œ)"""
        
        if not hasattr(session, 'conversation_context'):
            return self._generate_fallback_question(session, question_plan)
        
        # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ëŒ€ì•ˆ ì§ˆë¬¸ ìƒì„±
        focus_suggestions = session.conversation_context.suggest_next_question_focus()
        underexplored_topics = session.conversation_context.get_underexplored_topics()
        
        if underexplored_topics:
            # ëœ íƒìƒ‰ëœ ì£¼ì œë¡œ ëŒ€ì•ˆ ì§ˆë¬¸ ìƒì„±
            topic = underexplored_topics[0]
            question_content = self._create_topic_specific_question(topic, session, question_plan)
            question_intent = f"{topic.value} ì˜ì—­ ì‹¬í™” íƒìƒ‰"
        else:
            # ê¸°ì¡´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¬í™” ì§ˆë¬¸ ìƒì„±
            question_content = self._create_deepdive_question(session, question_plan)
            question_intent = f"{question_plan['type'].value} ì˜ì—­ ì‹¬í™” ì§ˆë¬¸"
        
        return question_content, question_intent
    
    def _enhance_question_with_context(self, base_question: str, additional_context: str, 
                                     session: PersonalizedInterviewSession) -> str:
        """ì»¨í…ìŠ¤íŠ¸ë¥¼ í™œìš©í•œ ì§ˆë¬¸ í–¥ìƒ"""
        
        try:
            prompt = f"""
ê¸°ë³¸ ì§ˆë¬¸: {base_question}
ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸: {additional_context}
ì§€ì›ì ë°°ê²½: {session.user_profile.background}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°ë³¸ ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ì´ê³  ì°¨ë³„í™”ëœ ì§ˆë¬¸ìœ¼ë¡œ ê°œì„ í•´ì£¼ì„¸ìš”.
ê¸°ì¡´ ì§ˆë¬¸ì˜ ì˜ë„ëŠ” ìœ ì§€í•˜ë˜, ìƒˆë¡œìš´ ê´€ì ì´ë‚˜ êµ¬ì²´ì ì¸ ìƒí™©ì„ ì¶”ê°€í•˜ì—¬ ë” í’ë¶€í•œ ë‹µë³€ì„ ì´ëŒì–´ë‚¼ ìˆ˜ ìˆë„ë¡ í•´ì£¼ì„¸ìš”.

ê°œì„ ëœ ì§ˆë¬¸:"""

            # í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                print("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return base_question
                
            client = openai.OpenAI(api_key=api_key)
            response = client.chat.completions.create(
                model=GPT_MODEL,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=200,
                temperature=0.8
            )
            
            enhanced_question = response.choices[0].message.content.strip()
            return enhanced_question if enhanced_question else base_question
            
        except Exception as e:
            print(f"âš ï¸ ì§ˆë¬¸ í–¥ìƒ ì¤‘ ì˜¤ë¥˜: {e}")
            return base_question
    
    def _create_topic_specific_question(self, topic, session: PersonalizedInterviewSession, 
                                      question_plan: Dict[str, Any]) -> str:
        """íŠ¹ì • ì£¼ì œì— ëŒ€í•œ ì§ˆë¬¸ ìƒì„± (HR vs í˜‘ì—… ëª…í™•íˆ êµ¬ë¶„)"""
        
        # HR ì „ìš© ì§ˆë¬¸ (ê°œì¸ ì¸ì„±, ê°€ì¹˜ê´€, ì„±ì¥)
        hr_questions = {
            "ê°œì¸ ë°°ê²½": [
                "ë³¸ì¸ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ í‘œí˜„í•œë‹¤ë©´ ì–´ë–»ê²Œ ë§ì”€í•˜ì‹œê² ì–´ìš”?",
                "ì¸ìƒì—ì„œ ê°€ì¥ ì†Œì¤‘í•˜ê²Œ ìƒê°í•˜ëŠ” ê°€ì¹˜ê´€ì´ ë¬´ì—‡ì¸ê°€ìš”?",
                "ì§€ê¸ˆì˜ ë³¸ì¸ì„ ë§Œë“  ê°€ì¥ ì¤‘ìš”í•œ ê²½í—˜ì´ë‚˜ ì‚¬ê±´ì´ ìˆë‹¤ë©´ ë¬´ì—‡ì¸ê°€ìš”?",
                "ì–´ë ¤ìš´ ìƒí™©ì—ì„œ ë³¸ì¸ì„ ì§€íƒ±í•´ì£¼ëŠ” í˜ì€ ë¬´ì—‡ì¸ê°€ìš”?"
            ],
            "í•™ìŠµ ëŠ¥ë ¥": [
                "ìƒˆë¡œìš´ ê²ƒì„ ë°°ìš¸ ë•Œ ë³¸ì¸ë§Œì˜ ë°©ì‹ì´ë‚˜ ìŠµê´€ì´ ìˆë‚˜ìš”?",
                "ì‹¤íŒ¨ë‚˜ ì¢Œì ˆì„ ê²½í—˜í–ˆì„ ë•Œ ì–´ë–»ê²Œ ê·¹ë³µí•˜ì‹œë‚˜ìš”?",
                "ìµœê·¼ì— ê°œì¸ì ìœ¼ë¡œ ë„ì „í•´ë³¸ ìƒˆë¡œìš´ ì¼ì´ ìˆë‹¤ë©´ ë¬´ì—‡ì¸ê°€ìš”?",
                "ë³¸ì¸ì˜ ì„±ì¥ì— ê°€ì¥ í° ì˜í–¥ì„ ì¤€ ì‚¬ëŒì´ë‚˜ ê²½í—˜ì€ ë¬´ì—‡ì¸ê°€ìš”?"
            ],
            "ì»¤ë¦¬ì–´ ëª©í‘œ": [
                "5ë…„ í›„ ë³¸ì¸ì˜ ëª¨ìŠµì„ ì–´ë–»ê²Œ ê·¸ë¦¬ê³  ê³„ì‹ ê°€ìš”?",
                "ë³¸ì¸ì´ ì¶”êµ¬í•˜ëŠ” ì´ìƒì ì¸ ì¼ì˜ ì˜ë¯¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                "ê°œì¸ì ì¸ ì„±ì·¨ê°ì„ ëŠë¼ëŠ” ìˆœê°„ì€ ì–¸ì œì¸ê°€ìš”?",
                "ë³¸ì¸ì˜ ë¡¤ëª¨ë¸ì´ë‚˜ ì¡´ê²½í•˜ëŠ” ì¸ë¬¼ì´ ìˆë‹¤ë©´ ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
            ]
        }
        
        # í˜‘ì—… ì „ìš© ì§ˆë¬¸ (íŒ€ì›Œí¬, ì†Œí†µ, ë¦¬ë”ì‹­)
        collaboration_questions = {
            "íŒ€ í˜‘ì—…": [
                "íŒ€ì—ì„œ ì˜ê²¬ ì¶©ëŒì´ ìˆì„ ë•Œ ì–´ë–»ê²Œ í•´ê²°í•˜ì‹œë‚˜ìš”?",
                "íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ë³¸ì¸ì´ ì£¼ë¡œ ë§¡ê²Œ ë˜ëŠ” ì—­í• ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                "ì–´ë ¤ìš´ íŒ€ì›ê³¼ í•¨ê»˜ ì¼í•´ì•¼ í•  ë•Œ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì ‘ê·¼í•˜ì‹œë‚˜ìš”?",
                "íŒ€ì˜ ë¶„ìœ„ê¸°ë‚˜ íš¨ìœ¨ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ì–´ë–¤ ë…¸ë ¥ì„ í•˜ì‹œë‚˜ìš”?"
            ],
            "ì†Œí†µ ëŠ¥ë ¥": [
                "ë³µì¡í•œ ê¸°ìˆ ì  ë‚´ìš©ì„ ë¹„ì „ë¬¸ê°€ì—ê²Œ ì„¤ëª…í•  ë•Œ ì–´ë–¤ ë°©ì‹ì„ ì‚¬ìš©í•˜ì‹œë‚˜ìš”?",
                "ë‹¤ë¥¸ ì‚¬ëŒê³¼ ì˜ê²¬ì´ ë‹¤ë¥¼ ë•Œ ì–´ë–»ê²Œ ì†Œí†µí•˜ì‹œë‚˜ìš”?",
                "íŒ€ íšŒì˜ì—ì„œ ë³¸ì¸ì˜ ì˜ê²¬ì„ ì–´ë–»ê²Œ í‘œí˜„í•˜ê³  ì „ë‹¬í•˜ì‹œë‚˜ìš”?",
                "ìƒëŒ€ë°©ì˜ ì´ì•¼ê¸°ë¥¼ ë“£ê³  ì´í•´í•˜ëŠ” ë³¸ì¸ë§Œì˜ ë°©ë²•ì´ ìˆë‚˜ìš”?"
            ],
            "ë¦¬ë”ì‹­": [
                "íŒ€ì„ ì´ëŒì–´ë³¸ ê²½í—˜ì´ ìˆë‹¤ë©´ ì–´ë–¤ ë¦¬ë”ì‹­ ìŠ¤íƒ€ì¼ì„ ì¶”êµ¬í•˜ì‹œë‚˜ìš”?",
                "í›„ë°°ë‚˜ ë™ë£Œì—ê²Œ ë„ì›€ì„ ì¤„ ë•Œ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì ‘ê·¼í•˜ì‹œë‚˜ìš”?",
                "ê°ˆë“± ìƒí™©ì—ì„œ ì¤‘ì¬ì ì—­í• ì„ í•´ë³¸ ê²½í—˜ì´ ìˆë‚˜ìš”?",
                "íŒ€ì˜ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ì–´ë–»ê²Œ ë™ê¸°ë¶€ì—¬ë¥¼ í•˜ì‹œë‚˜ìš”?"
            ]
        }
        
        # ê¸°íƒ€ ì£¼ì œ
        other_questions = {
            "ê¸°ìˆ  ì—­ëŸ‰": [
                "ìµœê·¼ì— ìƒˆë¡œ í•™ìŠµí•œ ê¸°ìˆ ì´ë‚˜ ë„êµ¬ê°€ ìˆë‹¤ë©´ ì–´ë–¤ ê³„ê¸°ë¡œ ì‹œì‘í•˜ê²Œ ë˜ì—ˆë‚˜ìš”?",
                "ê¸°ìˆ ì ìœ¼ë¡œ ê°€ì¥ ë„ì „ì ì´ì—ˆë˜ ë¬¸ì œë¥¼ ì–´ë–»ê²Œ í•´ê²°í•˜ì…¨ë‚˜ìš”?",
                "í˜„ì¬ ì—…ê³„ íŠ¸ë Œë“œ ì¤‘ì—ì„œ ê°€ì¥ ì£¼ëª©í•˜ê³  ìˆëŠ” ê¸°ìˆ ì€ ë¬´ì—‡ì¸ê°€ìš”?"
            ],
            "í”„ë¡œì íŠ¸ ê²½í—˜": [
                "í”„ë¡œì íŠ¸ ì§„í–‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ë³€ìˆ˜ê°€ ìƒê²¼ì„ ë•Œ ì–´ë–»ê²Œ ëŒ€ì²˜í•˜ì…¨ë‚˜ìš”?",
                "ê°€ì¥ ê¸°ì–µì— ë‚¨ëŠ” í”„ë¡œì íŠ¸ì™€ ê·¸ ì´ìœ ë¥¼ ë§ì”€í•´ì£¼ì„¸ìš”.",
                "ì‹¤íŒ¨í–ˆë˜ í”„ë¡œì íŠ¸ê°€ ìˆë‹¤ë©´, ê·¸ ê²½í—˜ì—ì„œ ì–»ì€ êµí›ˆì€ ë¬´ì—‡ì¸ê°€ìš”?"
            ]
        }
        
        # ì§ˆë¬¸ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ ì§ˆë¬¸ í’€ ì„ íƒ
        question_type = question_plan.get("type", QuestionType.GENERAL)
        
        if question_type == QuestionType.HR:
            questions = hr_questions.get(topic.value, hr_questions.get("ê°œì¸ ë°°ê²½", []))
        elif question_type == QuestionType.COLLABORATION:
            questions = collaboration_questions.get(topic.value, collaboration_questions.get("íŒ€ í˜‘ì—…", []))
        else:
            questions = other_questions.get(topic.value, ["ë³¸ì¸ì˜ ê²½í—˜ì— ëŒ€í•´ ìì„¸íˆ ë§ì”€í•´ì£¼ì„¸ìš”."])
        
        if not questions:
            questions = ["ë³¸ì¸ì˜ ê²½í—˜ì— ëŒ€í•´ ìì„¸íˆ ë§ì”€í•´ì£¼ì„¸ìš”."]
        
        return random.choice(questions)
    
    def _create_deepdive_question(self, session: PersonalizedInterviewSession, 
                                question_plan: Dict[str, Any]) -> str:
        """ê¸°ì¡´ ì •ë³´ ê¸°ë°˜ ì‹¬í™” ì§ˆë¬¸ ìƒì„±"""
        
        # ê¸°ì¡´ ë‹µë³€ì—ì„œ ì–¸ê¸‰ëœ í‚¤ì›Œë“œ í™œìš©
        if hasattr(session, 'conversation_context'):
            memory = session.conversation_context.memory
            
            if memory.mentioned_projects:
                project = list(memory.mentioned_projects)[0]
                return f"{project}ì—ì„œ ê°€ì¥ ê¸°ì–µì— ë‚¨ëŠ” ê¸°ìˆ ì  ë„ì „ê³¼ í•´ê²° ê³¼ì •ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
            
            if memory.mentioned_technologies:
                tech = list(memory.mentioned_technologies)[0]
                return f"{tech} ê¸°ìˆ ì„ ì„ íƒí•œ ì´ìœ ì™€ ì‹¤ì œ ì‚¬ìš© ê²½í—˜ì—ì„œì˜ ì¥ë‹¨ì ì„ ë§ì”€í•´ì£¼ì„¸ìš”."
        
        # ê¸°ë³¸ ì‹¬í™” ì§ˆë¬¸
        return "ì§€ê¸ˆê¹Œì§€ ë§ì”€í•´ì£¼ì‹  ê²½í—˜ ì¤‘ì—ì„œ ê°€ì¥ ìë‘ìŠ¤ëŸ¬ìš´ ì„±ê³¼ì™€ ê·¸ ê³¼ì •ì„ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."
    
    def _generate_fallback_question(self, session: PersonalizedInterviewSession, 
                                  question_plan: Dict[str, Any]) -> Tuple[str, str]:
        """ê¸°ë³¸ ëŒ€ì²´ ì§ˆë¬¸ (ì»¨í…ìŠ¤íŠ¸ ì—†ì„ ë•Œ)"""
        
        fallback_questions = {
            QuestionType.HR: ("ë³¸ì¸ì˜ ê°•ì  ì¤‘ í•˜ë‚˜ë¥¼ êµ¬ì²´ì ì¸ ì‚¬ë¡€ì™€ í•¨ê»˜ ì„¤ëª…í•´ì£¼ì„¸ìš”.", "HR ì—­ëŸ‰ í‰ê°€"),
            QuestionType.TECH: ("ê°€ì¥ ìì‹  ìˆëŠ” ê¸°ìˆ  ìŠ¤íƒê³¼ ê·¸ ì´ìœ ë¥¼ ë§ì”€í•´ì£¼ì„¸ìš”.", "ê¸°ìˆ  ì—­ëŸ‰ í‰ê°€"),
            QuestionType.COLLABORATION: ("íŒ€ì›Œí¬ì—ì„œ ì¤‘ìš”í•˜ë‹¤ê³  ìƒê°í•˜ëŠ” ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?", "í˜‘ì—… ëŠ¥ë ¥ í‰ê°€"),
            QuestionType.FOLLOWUP: ("ì§€ê¸ˆê¹Œì§€ì˜ ë‹µë³€ ì¤‘ ë” ìì„¸íˆ ì„¤ëª…í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì´ ìˆë‚˜ìš”?", "ì‹¬í™” ì§ˆë¬¸")
        }
        
        return fallback_questions.get(
            question_plan["type"], 
            ("ë³¸ì¸ì— ëŒ€í•´ ë” ìì„¸íˆ ë§ì”€í•´ì£¼ì„¸ìš”.", "ì¼ë°˜ ì§ˆë¬¸")
        )
    
    def generate_organic_followup(self, session: PersonalizedInterviewSession, 
                                last_answer: str) -> Optional[Dict[str, Any]]:
        """ìœ ê¸°ì  í›„ì† ì§ˆë¬¸ ìƒì„± (ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„)"""
        
        if not hasattr(session, 'conversation_context'):
            return None
        
        context = session.conversation_context
        memory = context.memory
        
        # ë§ˆì§€ë§‰ ë‹µë³€ì—ì„œ í¥ë¯¸ë¡œìš´ í¬ì¸íŠ¸ ì¶”ì¶œ
        interesting_points = self._extract_interesting_points(last_answer)
        
        if not interesting_points:
            return None
        
        # ê°€ì¥ ìœ ê¸°ì ì¸ í›„ì† ì§ˆë¬¸ ìƒì„±
        followup_question = self._create_organic_followup(
            interesting_points, session, context
        )
        
        return {
            "question_id": f"followup_{session.current_question_count + 1}",
            "question_type": "ìœ ê¸°ì  í›„ì†",
            "question_content": followup_question,
            "question_intent": "ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ì‹¬í™”",
            "is_organic": True,
            "based_on": interesting_points[:2]  # ê¸°ë°˜ì´ ëœ í¬ì¸íŠ¸ë“¤
        }
    
    def _extract_interesting_points(self, answer: str) -> List[str]:
        """ë‹µë³€ì—ì„œ í¥ë¯¸ë¡œìš´ í¬ì¸íŠ¸ ì¶”ì¶œ"""
        
        interesting_points = []
        answer_lower = answer.lower()
        
        # êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ì„±ê³¼ ì–¸ê¸‰
        import re
        numbers = re.findall(r'(\d+(?:[%ë°°ê°œëª…ê±´ì´ˆë¶„ë…„ì›”]|ì‹œê°„|ëª…|ê°œ|ë°°|í”„ë¡œì íŠ¸))', answer)
        for num in numbers:
            interesting_points.append(f"êµ¬ì²´ì  ì„±ê³¼: {num}")
        
        # ê¸°ìˆ ì´ë‚˜ ë„êµ¬ ì–¸ê¸‰
        tech_keywords = ["python", "java", "react", "spring", "docker", "aws", "mysql", "redis"]
        mentioned_tech = [tech for tech in tech_keywords if tech in answer_lower]
        for tech in mentioned_tech:
            interesting_points.append(f"ê¸°ìˆ  ì–¸ê¸‰: {tech}")
        
        # ê°ì •ì´ë‚˜ ëŠë‚Œ í‘œí˜„
        emotion_keywords = ["ì–´ë ¤ì› ", "í˜ë“¤ì—ˆ", "í¥ë¯¸ë¡œì› ", "ì¬ë¯¸ìˆì—ˆ", "ë³´ëŒ", "ì„±ì·¨ê°", "ì•„ì‰¬ì› "]
        mentioned_emotions = [emotion for emotion in emotion_keywords if emotion in answer]
        for emotion in mentioned_emotions:
            interesting_points.append(f"ê°ì • í‘œí˜„: {emotion}")
        
        # í”„ë¡œì íŠ¸ë‚˜ ê²½í—˜ ì–¸ê¸‰
        if "í”„ë¡œì íŠ¸" in answer or "ê²½í—˜" in answer:
            interesting_points.append("í”„ë¡œì íŠ¸/ê²½í—˜ ì–¸ê¸‰")
        
        # ë¬¸ì œë‚˜ í•´ê²° ì–¸ê¸‰
        if any(word in answer for word in ["ë¬¸ì œ", "í•´ê²°", "ê°œì„ ", "ìµœì í™”"]):
            interesting_points.append("ë¬¸ì œí•´ê²° ì–¸ê¸‰")
        
        return interesting_points[:3]  # ìµœëŒ€ 3ê°œ
    
    def _create_organic_followup(self, interesting_points: List[str], 
                               session: PersonalizedInterviewSession,
                               context) -> str:
        """ìœ ê¸°ì ì¸ í›„ì† ì§ˆë¬¸ ìƒì„±"""
        
        # ê°€ì¥ í¥ë¯¸ë¡œìš´ í¬ì¸íŠ¸ ì„ íƒ
        primary_point = interesting_points[0] if interesting_points else None
        
        if not primary_point:
            return "ê·¸ ê²½í—˜ì— ëŒ€í•´ ì¡°ê¸ˆ ë” ìì„¸íˆ ë“¤ë ¤ì£¼ì‹œê² ì–´ìš”?"
        
        # í¬ì¸íŠ¸ ìœ í˜•ë³„ í›„ì† ì§ˆë¬¸ íŒ¨í„´
        if "êµ¬ì²´ì  ì„±ê³¼" in primary_point:
            return f"ë°©ê¸ˆ ë§ì”€í•˜ì‹  {primary_point.split(': ')[1]}ì´ë¼ëŠ” ì„±ê³¼ê°€ ì¸ìƒì ì´ë„¤ìš”. ê·¸ ì„±ê³¼ë¥¼ ë‹¬ì„±í•˜ê¸°ê¹Œì§€ ì–´ë–¤ ê³¼ì •ì´ ìˆì—ˆëŠ”ì§€ ë” ìì„¸íˆ ì„¤ëª…í•´ì£¼ì‹œê² ì–´ìš”?"
        
        elif "ê¸°ìˆ  ì–¸ê¸‰" in primary_point:
            tech_name = primary_point.split(': ')[1]
            return f"{tech_name}ë¥¼ ì–¸ê¸‰í•´ì£¼ì…¨ëŠ”ë°, ì‹¤ì œë¡œ ì‚¬ìš©í•´ë³´ì‹œë©´ì„œ ì–´ë–¤ ì ì´ ê°€ì¥ ì¸ìƒì ì´ì—ˆë‚˜ìš”?"
        
        elif "ê°ì • í‘œí˜„" in primary_point:
            emotion = primary_point.split(': ')[1]
            if emotion in ["ì–´ë ¤ì› ", "í˜ë“¤ì—ˆ"]:
                return "ê·¸ëŸ° ì–´ë ¤ì›€ì„ ì–´ë–»ê²Œ ê·¹ë³µí•˜ì…¨ëŠ”ì§€ ê¶ê¸ˆí•˜ë„¤ìš”. ë‹¹ì‹œ ìƒí™©ì„ ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?"
            elif emotion in ["í¥ë¯¸ë¡œì› ", "ì¬ë¯¸ìˆì—ˆ", "ë³´ëŒ"]:
                return f"ê·¸ {emotion}ë‹¤ê³  í•˜ì‹  ë¶€ë¶„ì— ëŒ€í•´ ë” ë“¤ì–´ë³´ê³  ì‹¶ì–´ìš”. ì–´ë–¤ ì ì´ íŠ¹íˆ ê·¸ë¬ë‚˜ìš”?"
        
        elif "í”„ë¡œì íŠ¸/ê²½í—˜ ì–¸ê¸‰" in primary_point:
            return "ê·¸ í”„ë¡œì íŠ¸ì—ì„œ ë³¸ì¸ì´ ë§¡ìœ¼ì‹  ì—­í• ê³¼ ê¸°ì—¬í•œ ë¶€ë¶„ì„ ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì‹œê² ì–´ìš”?"
        
        elif "ë¬¸ì œí•´ê²° ì–¸ê¸‰" in primary_point:
            return "ë¬¸ì œ í•´ê²° ê³¼ì •ì´ í¥ë¯¸ë¡­ë„¤ìš”. ê·¸ë•Œ ì–´ë–¤ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•˜ì…¨ê³ , ë‹¤ë¥¸ ëŒ€ì•ˆë„ ê³ ë ¤í•´ë³´ì…¨ë‚˜ìš”?"
        
        # ê¸°ë³¸ í›„ì† ì§ˆë¬¸
        return "ê·¸ ë¶€ë¶„ì— ëŒ€í•´ ì¢€ ë” ìì„¸í•œ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?"
    
    def enhance_conversation_naturalness(self, session: PersonalizedInterviewSession) -> Dict[str, Any]:
        """ëŒ€í™”ì˜ ìì—°ìŠ¤ëŸ¬ì›€ í–¥ìƒì„ ìœ„í•œ ë©”íƒ€ ì •ë³´ ì œê³µ"""
        
        if not hasattr(session, 'conversation_context'):
            return {}
        
        context = session.conversation_context
        summary = context.get_conversation_summary()
        
        return {
            "conversation_depth": len(context.question_history),
            "topic_coverage": summary['topic_coverage'],
            "natural_transition_points": self._identify_transition_points(context),
            "conversation_rhythm": self._analyze_conversation_rhythm(context),
            "suggested_tone": self._suggest_conversation_tone(context)
        }
    
    def _identify_transition_points(self, context) -> List[str]:
        """ëŒ€í™” ì „í™˜ì  ì‹ë³„"""
        
        transition_points = []
        
        # ì£¼ì œ ì „í™˜ì´ í•„ìš”í•œ ì‹œì  ì‹ë³„
        for topic, tracker in context.topic_trackers.items():
            if tracker.coverage_score > 0.7:  # ì¶©ë¶„íˆ ë‹¤ë¤„ì§„ ì£¼ì œ
                transition_points.append(f"{topic.value} ì£¼ì œì—ì„œ ì „í™˜ ê°€ëŠ¥")
        
        # ë‹µë³€ ê¸¸ì´ íŒ¨í„´ ë¶„ì„
        if len(context.answer_history) >= 3:
            recent_lengths = [len(answer) for answer in context.answer_history[-3:]]
            avg_length = sum(recent_lengths) / len(recent_lengths)
            
            if avg_length < 100:
                transition_points.append("ë‹µë³€ì´ ì§§ì•„ì§ - ì£¼ì œ ë³€ê²½ ê³ ë ¤")
            elif avg_length > 500:
                transition_points.append("ë‹µë³€ì´ ê¸¸ì–´ì§ - ìš”ì•½ ì§ˆë¬¸ ê³ ë ¤")
        
        return transition_points
    
    def _analyze_conversation_rhythm(self, context) -> Dict[str, Any]:
        """ëŒ€í™” ë¦¬ë“¬ ë¶„ì„"""
        
        rhythm = {
            "pace": "normal",
            "depth_level": "medium",
            "engagement": "medium"
        }
        
        if len(context.question_history) > 0:
            # ì§ˆë¬¸ ê°„ ì‹œê°„ ê°„ê²© (êµ¬í˜„ ì‹œ ì¶”ê°€)
            # ë‹µë³€ ê¸¸ì´ ë³€í™” íŒ¨í„´
            if len(context.answer_history) >= 2:
                length_trend = len(context.answer_history[-1]) - len(context.answer_history[-2])
                if length_trend > 100:
                    rhythm["engagement"] = "increasing"
                elif length_trend < -100:
                    rhythm["engagement"] = "decreasing"
        
        return rhythm
    
    def _suggest_conversation_tone(self, context) -> str:
        """ëŒ€í™” í†¤ ì œì•ˆ"""
        
        # ì¶”ì¶œëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í†¤ ê²°ì •
        if len(context.memory.achievements) > 2:
            return "achievement_focused"  # ì„±ì·¨ ì¤‘ì‹¬
        elif len(context.memory.mentioned_technologies) > 3:
            return "technical_deep_dive"  # ê¸°ìˆ  ì‹¬í™”
        elif len(context.used_keywords) > 15:
            return "comprehensive"  # í¬ê´„ì 
        else:
            return "exploratory"  # íƒìƒ‰ì 
    
    def get_next_question(self, session_id: str) -> Optional[Dict[str, Any]]:
        """ë‹¤ìŒ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸° (ê°œì¸í™” ì§€ì› + ì¤‘ë³µ ë°©ì§€)"""
        
        session = self.sessions.get(session_id)
        if not session or session.is_complete():
            return None
        
        company_data = self.get_company_data(session.company_id)
        question_plan = session.get_next_question_plan()
        
        if not question_plan:
            return None
        
        # ë¹ ë¥¸ ì‹œì‘ì„ ìœ„í•´ ì¤‘ë³µ ê²€ì‚¬ ìµœì í™”
        # ì²« ë²ˆì§¸ ì§ˆë¬¸ì´ê±°ë‚˜ ê³ ì • ì§ˆë¬¸ì¸ ê²½ìš° ì¤‘ë³µ ê²€ì‚¬ ê±´ë„ˆë›°ê¸°
        skip_duplicate_check = (session.current_question_count == 0 or question_plan.get("fixed", False))
        
        max_attempts = 1 if skip_duplicate_check else 3
        for attempt in range(max_attempts):
            # ê°œì¸í™”ëœ ì§ˆë¬¸ ìƒì„±
            if isinstance(session, PersonalizedInterviewSession) and question_plan.get("personalized", False):
                question_content, question_intent = self._generate_personalized_question_with_duplicate_check(
                    session, company_data, question_plan
                )
            else:
                # PersonalizedInterviewSessionì— ë§ëŠ” ì§ˆë¬¸ ìƒì„±
                question_content, question_intent = self._generate_personalized_question(
                    session, company_data, question_plan
                )
            
            # ì¤‘ë³µ ê²€ì‚¬ (PersonalizedInterviewSessionë§Œ, ì²« ì§ˆë¬¸ ì œì™¸)
            if isinstance(session, PersonalizedInterviewSession) and not skip_duplicate_check:
                is_duplicate, similar_question, similarity = session.conversation_context.check_question_duplicate(question_content)
                
                if not is_duplicate:
                    break  # ì¤‘ë³µì´ ì•„ë‹ˆë©´ ì‚¬ìš©
                else:
                    print(f"âš ï¸ ì¤‘ë³µ ì§ˆë¬¸ ê°ì§€ (ìœ ì‚¬ë„: {similarity:.2f}): {similar_question[:50]}...")
                    if attempt == max_attempts - 1:
                        print("ğŸ”„ ëŒ€ì•ˆ ì§ˆë¬¸ ìƒì„± ì¤‘...")
                        # ë§ˆì§€ë§‰ ì‹œë„ì—ì„œëŠ” ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ëŒ€ì•ˆ ì§ˆë¬¸ ìƒì„±
                        question_content, question_intent = self._generate_alternative_question(session, question_plan)
            else:
                break  # ì¤‘ë³µ ê²€ì‚¬ ê±´ë„ˆë›°ê¸° ë˜ëŠ” ì¼ë°˜ ì„¸ì…˜
        
        return {
            "question_id": f"q_{session.current_question_count + 1}",
            "question_type": question_plan["type"].value,
            "question_content": question_content,
            "question_intent": question_intent,
            "progress": f"{session.current_question_count + 1}/{len(session.question_plan)}",
            "personalized": question_plan.get("personalized", False),
            "fixed": question_plan.get("fixed", False),
            "focus": question_plan.get("focus", "general")
        }

if __name__ == "__main__":
    print("ğŸ¯ ê°œì¸í™”ëœ ë©´ì ‘ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    
    # ìƒ˜í”Œ ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„±
    sample_profile = UserProfile(
        name="ê¹€ê°œë°œ",
        background={
            "career_years": "3",
            "current_position": "ë°±ì—”ë“œ ê°œë°œì",
            "education": ["ì»´í“¨í„°ê³µí•™ê³¼ ì¡¸ì—…"]
        },
        technical_skills=["Python", "Django", "PostgreSQL", "AWS", "Docker"],
        projects=[
            {
                "name": "ì´ì»¤ë¨¸ìŠ¤ í”Œë«í¼",
                "description": "ëŒ€ìš©ëŸ‰ íŠ¸ë˜í”½ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ êµ¬ì¶•",
                "tech_stack": ["Python", "Django", "Redis", "PostgreSQL"],
                "role": "ë°±ì—”ë“œ ë¦¬ë“œ",
                "period": "6ê°œì›”"
            }
        ],
        experiences=[
            {
                "company": "ìŠ¤íƒ€íŠ¸ì—… A",
                "position": "ë°±ì—”ë“œ ê°œë°œì",
                "period": "2021-2024",
                "achievements": ["API ì„±ëŠ¥ 30% ê°œì„ ", "ì‹ ê·œ ì„œë¹„ìŠ¤ ëŸ°ì¹­"]
            }
        ],
        strengths=["ë¬¸ì œ í•´ê²° ëŠ¥ë ¥", "ë¹ ë¥¸ í•™ìŠµë ¥", "íŒ€ì›Œí¬"],
        keywords=["ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤", "ì„±ëŠ¥ ìµœì í™”", "íŒ€ ë¦¬ë”ì‹­"],
        career_goal="ê¸°ìˆ  ë¦¬ë”ë¡œ ì„±ì¥í•˜ì—¬ ì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ë¥¼ ì„¤ê³„í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.",
        unique_points=["ëŒ€ìš©ëŸ‰ íŠ¸ë˜í”½ ê²½í—˜", "íŒ€ ë¦¬ë”© ê²½í—˜"]
    )
    
    # ê°œì¸í™”ëœ ë©´ì ‘ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ (ìë™ìœ¼ë¡œ .envì—ì„œ API í‚¤ ë¡œë“œ)
    system = PersonalizedInterviewSystem()
    
    try:
        session_id = system.start_personalized_interview("naver", "ë°±ì—”ë“œ ê°œë°œì", "ê¹€ê°œë°œ", sample_profile)
        print(f"\nâœ… ê°œì¸í™”ëœ ë©´ì ‘ ì„¸ì…˜ ì‹œì‘: {session_id}")
        
        # ì²« ë²ˆì§¸ ì§ˆë¬¸ ìƒì„±
        question = system.get_next_question(session_id)
        print(f"\nğŸ“ ì²« ë²ˆì§¸ ì§ˆë¬¸:")
        print(f"ìœ í˜•: {question['question_type']}")
        print(f"ê°œì¸í™”: {question['personalized']}")
        print(f"ì§ˆë¬¸: {question['question_content']}")
        print(f"ì˜ë„: {question['question_intent']}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")