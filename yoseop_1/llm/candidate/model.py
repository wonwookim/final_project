#!/usr/bin/env python3
"""
AI ì§€ì›ì ëª¨ë¸
ê° íšŒì‚¬ë³„ í•©ê²© ìˆ˜ì¤€ì˜ ì§€ì›ì í˜ë¥´ì†Œë‚˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë©´ì ‘ ë‹µë³€ì„ ìƒì„±
"""

import json
import random
import os
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

from ..core.llm_manager import LLMManager, LLMProvider, LLMResponse
from .quality_controller import AnswerQualityController, QualityLevel
from ..shared.models import QuestionType, QuestionAnswer, CandidatePersona, AnswerRequest, AnswerResponse
from ..session.models import InterviewSession
from ..shared.utils import safe_json_load

# ëª¨ë¸ë³„ AI ì§€ì›ì ì´ë¦„ ë§¤í•‘
AI_CANDIDATE_NAMES = {
    LLMProvider.OPENAI_GPT4: "ì¶˜ì‹ì´",
    LLMProvider.OPENAI_GPT35: "ì¶˜ì‹ì´", 
    LLMProvider.OPENAI_GPT4O_MINI: "ì¶˜ì‹ì´",
    LLMProvider.GOOGLE_GEMINI_PRO: "ì œë¯¸ë‹ˆ",      # í–¥í›„ ì¶”ê°€
    LLMProvider.GOOGLE_GEMINI_FLASH: "ì œë¯¸ë‹ˆ",    # í–¥í›„ ì¶”ê°€
    LLMProvider.KT_BELIEF: "ë¯¿ìŒì´"               # í–¥í›„ ì¶”ê°€
}

# â†“ ì•„ë˜ í´ë˜ìŠ¤ë“¤ì€ llm.shared.modelsì—ì„œ importí•˜ì—¬ ì‚¬ìš©
# CandidatePersona, AnswerRequest, AnswerResponseëŠ” ì´ë¯¸ shared/models.pyì— ì •ì˜ë¨

class AICandidateSession(InterviewSession):
    """AI ì§€ì›ì ì „ìš© ë©´ì ‘ ì„¸ì…˜ - ë©´ì ‘ìì™€ ë™ì¼í•œ í”Œë¡œìš°"""
    
    def __init__(self, company_id: str, position: str, persona: CandidatePersona):
        super().__init__(company_id, position, persona.name)
        self.persona = persona
        self.ai_answers: List[QuestionAnswer] = []
        
        # ë©´ì ‘ìì™€ ë™ì¼í•œ 20ê°œ ì§ˆë¬¸ ê³„íš ì‚¬ìš©
        # ì´ë¯¸ ë¶€ëª¨ í´ë˜ìŠ¤ì—ì„œ self.question_planì´ 20ê°œë¡œ ì„¤ì •ë¨
        
    def add_ai_answer(self, qa_pair: QuestionAnswer):
        """AI ë‹µë³€ ì¶”ê°€"""
        self.ai_answers.append(qa_pair)
        self.current_question_count += 1
        
    def get_persona_context(self) -> str:
        """í˜ë¥´ì†Œë‚˜ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        context = f"""
=== AI ì§€ì›ì í˜ë¥´ì†Œë‚˜ ì •ë³´ ===
ì´ë¦„: {self.persona.name}
ê²½ë ¥: {self.persona.background.get('career_years', '0')}ë…„
í˜„ì¬ ì§ì±…: {self.persona.background.get('current_position', 'ì§€ì›ì')}
ì£¼ìš” ê¸°ìˆ : {', '.join(self.persona.technical_skills[:5])}
ê°•ì : {', '.join(self.persona.strengths[:3])}
ì»¤ë¦¬ì–´ ëª©í‘œ: {self.persona.career_goal}
ì„±ê²© íŠ¹ì„±: {', '.join(self.persona.personality_traits)}
ë©´ì ‘ ìŠ¤íƒ€ì¼: {self.persona.interview_style}

=== ì£¼ìš” í”„ë¡œì íŠ¸ ===
"""
        for i, project in enumerate(self.persona.projects[:2], 1):
            context += f"{i}. {project.get('name', 'í”„ë¡œì íŠ¸')}: {project.get('description', '')}\n"
            context += f"   ê¸°ìˆ ìŠ¤íƒ: {', '.join(project.get('tech_stack', []))}\n"
            if project.get('achievements'):
                context += f"   ì„±ê³¼: {', '.join(project['achievements'])}\n"
        
        context += f"""
=== ì—…ë¬´ ê²½í—˜ ===
"""
        for exp in self.persona.experiences[:2]:
            context += f"- {exp.get('company', 'íšŒì‚¬')}: {exp.get('position', 'ê°œë°œì')} ({exp.get('period', 'ê¸°ê°„')})\n"
            if exp.get('achievements'):
                context += f"  ì„±ê³¼: {', '.join(exp['achievements'])}\n"
        
        return context
    
    def get_previous_answers_context(self) -> str:
        """ì´ì „ ë‹µë³€ ì»¨í…ìŠ¤íŠ¸ (ì¼ê´€ì„± ìœ ì§€ìš©)"""
        if not self.ai_answers:
            return ""
        
        context = "\n=== ì´ì „ ë‹µë³€ ë‚´ì—­ (ì¼ê´€ì„± ìœ ì§€) ===\n"
        for i, qa in enumerate(self.ai_answers[-3:], 1):  # ìµœê·¼ 3ê°œë§Œ
            context += f"{i}. [{qa.question_type.value}] {qa.question_content}\n"
            context += f"   ë‹µë³€: {qa.answer_content[:100]}...\n\n"
        
        return context

class AICandidateModel:
    """AI ì§€ì›ì ëª¨ë¸ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, api_key: str = None):
        self.llm_manager = LLMManager()
        self.quality_controller = AnswerQualityController()
        self.candidate_personas = self._load_candidate_personas()
        self.companies_data = self._load_companies_data()
        
        # AI ì§€ì›ì ì„¸ì…˜ ê´€ë¦¬
        self.ai_sessions: Dict[str, 'AICandidateSession'] = {}
        self.fixed_questions = self._load_fixed_questions()
        
        # API í‚¤ ìë™ ë¡œë“œ (.env íŒŒì¼ì—ì„œ)
        if not api_key:
            api_key = os.getenv('OPENAI_API_KEY')
        
        # ê¸°ë³¸ OpenAI ëª¨ë¸ ë“±ë¡
        if api_key:
            self.llm_manager.register_model(LLMProvider.OPENAI_GPT4O_MINI, api_key=api_key)
            self.llm_manager.register_model(LLMProvider.OPENAI_GPT4, api_key=api_key)
            self.llm_manager.register_model(LLMProvider.OPENAI_GPT35, api_key=api_key)
        else:
            print("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ì§ì ‘ ì „ë‹¬í•˜ì„¸ìš”.")
    
    def _load_candidate_personas(self) -> Dict[str, CandidatePersona]:
        """í•©ê²©ì í˜ë¥´ì†Œë‚˜ ë°ì´í„° ë¡œë“œ"""
        # ì‹¤ì œ í˜ë¥´ì†Œë‚˜ íŒŒì¼ ë¡œë“œ ì‹œë„
        personas_data = safe_json_load("llm/data/candidate_personas.json", {"personas": {}})
        
        if personas_data.get("personas"):
            # ì‹¤ì œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ íŒŒì‹±
            print(f"âœ… í˜ë¥´ì†Œë‚˜ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {list(personas_data['personas'].keys())}")
            return self._parse_personas_data(personas_data["personas"])
        
        # íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
        print("âš ï¸ í˜ë¥´ì†Œë‚˜ íŒŒì¼ ì—†ìŒ, ê¸°ë³¸ ë°ì´í„° ì‚¬ìš©")
        default_personas = {
            "naver": CandidatePersona(
                company_id="naver",
                name="ê¹€ë„¤ì´ë²„",
                background={
                    "career_years": "5",
                    "current_position": "ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œì",
                    "education": ["ì»´í“¨í„°ê³µí•™ê³¼ ì¡¸ì—…", "ê´€ë ¨ ìê²©ì¦"]
                },
                technical_skills=["Java", "Spring", "MySQL", "Redis", "Kafka", "Elasticsearch"],
                projects=[
                    {
                        "name": "ëŒ€ìš©ëŸ‰ ê²€ìƒ‰ ì‹œìŠ¤í…œ ìµœì í™”",
                        "description": "ì¼ì¼ 10ì–µê±´ ê²€ìƒ‰ ì¿¼ë¦¬ ì²˜ë¦¬ ì„±ëŠ¥ ê°œì„ ",
                        "tech_stack": ["Java", "Elasticsearch", "Redis"],
                        "role": "ë°±ì—”ë“œ ë¦¬ë“œ",
                        "achievements": ["ì‘ë‹µì‹œê°„ 40% ê°œì„ ", "ì„œë²„ ë¹„ìš© 30% ì ˆê°"]
                    }
                ],
                experiences=[
                    {
                        "company": "ìŠ¤íƒ€íŠ¸ì—… A",
                        "position": "ë°±ì—”ë“œ ê°œë°œì",
                        "period": "2019-2024",
                        "achievements": ["ê²€ìƒ‰ì—”ì§„ ì„±ëŠ¥ ê°œì„ ", "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ êµ¬ì¶•"]
                    }
                ],
                strengths=["ëŒ€ìš©ëŸ‰ ì‹œìŠ¤í…œ ì„¤ê³„", "ì„±ëŠ¥ ìµœì í™”", "ê¸°ìˆ  ë¦¬ë”ì‹­"],
                achievements=["ê²€ìƒ‰ ì‹œìŠ¤í…œ íŠ¹í—ˆ ì¶œì›", "ì‚¬ë‚´ ê¸°ìˆ  ì„¸ë¯¸ë‚˜ ë°œí‘œ"],
                career_goal="ê¸€ë¡œë²Œ ê²€ìƒ‰ í”Œë«í¼ì˜ ê¸°ìˆ  ì•„í‚¤í…íŠ¸ë¡œ ì„±ì¥",
                personality_traits=["ë¶„ì„ì ", "ì™„ë²½ì£¼ì˜", "í˜‘ì—… ì¤‘ì‹œ"],
                interview_style="ë…¼ë¦¬ì ì´ê³  ë°ì´í„° ì¤‘ì‹¬ì ",
                success_factors=["ê¸°ìˆ ì  ê¹Šì´", "ëŒ€ê·œëª¨ ì‹œìŠ¤í…œ ê²½í—˜", "ì„±ëŠ¥ ìµœì í™” ëŠ¥ë ¥"]
            ),
            "kakao": CandidatePersona(
                company_id="kakao",
                name="ë°•ì¹´ì¹´ì˜¤",
                background={
                    "career_years": "4",
                    "current_position": "í”Œë«í¼ ê°œë°œì",
                    "education": ["ì»´í“¨í„°ê³µí•™ê³¼ ì¡¸ì—…"]
                },
                technical_skills=["Node.js", "React", "MongoDB", "Docker", "Kubernetes"],
                projects=[
                    {
                        "name": "ë©”ì‹œì§• í”Œë«í¼ MSA ì „í™˜",
                        "description": "ëª¨ë†€ë¦¬ì‹ì—ì„œ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ë¡œ ì•„í‚¤í…ì²˜ ì „í™˜",
                        "tech_stack": ["Node.js", "Docker", "Kubernetes"],
                        "role": "í”Œë«í¼ ê°œë°œì",
                        "achievements": ["ë°°í¬ ì‹œê°„ 80% ë‹¨ì¶•", "ì¥ì•  ë³µêµ¬ ì‹œê°„ 50% ê°œì„ "]
                    }
                ],
                experiences=[
                    {
                        "company": "IT ìŠ¤íƒ€íŠ¸ì—…",
                        "position": "í’€ìŠ¤íƒ ê°œë°œì",
                        "period": "2020-2024",
                        "achievements": ["í”Œë«í¼ ì•„í‚¤í…ì²˜ ì„¤ê³„", "ê°œë°œ ë¬¸í™” ê°œì„ "]
                    }
                ],
                strengths=["í”Œë«í¼ ì„¤ê³„", "MSA ì•„í‚¤í…ì²˜", "ì‚¬íšŒì  ê°€ì¹˜ ì¶”êµ¬"],
                achievements=["ì‚¬ë‚´ í•´ì»¤í†¤ ìš°ìŠ¹", "ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬"],
                career_goal="ì‚¬íšŒì  ê°€ì¹˜ë¥¼ ì°½ì¶œí•˜ëŠ” í”Œë«í¼ ì•„í‚¤í…íŠ¸",
                personality_traits=["ê°œë°©ì ", "ì°½ì˜ì ", "ì‚¬íšŒì  ê°€ì¹˜ ì¤‘ì‹œ"],
                interview_style="í˜‘ë ¥ì ì´ê³  ê°€ì¹˜ ì¤‘ì‹¬ì ",
                success_factors=["í”Œë«í¼ ê²½í—˜", "í˜‘ì—… ëŠ¥ë ¥", "ì‚¬íšŒì  ê°€ì¹˜ ì¸ì‹"]
            )
        }
        
        return default_personas
    
    def _load_companies_data(self) -> Dict[str, Any]:
        """íšŒì‚¬ ë°ì´í„° ë¡œë“œ"""
        return safe_json_load("llm/shared/data/companies_data.json", {"companies": []})
    
    def _load_fixed_questions(self) -> Dict[str, List[Dict]]:
        """ê³ ì • ì§ˆë¬¸ ë°ì´í„° ë¡œë“œ"""
        return safe_json_load("llm/interviewer/data/fixed_questions.json", {
            "hr_questions": [], 
            "technical_questions": [], 
            "collaboration_questions": []
        })
    
    def start_ai_interview(self, company_id: str, position: str) -> str:
        """AI ì§€ì›ì ë©´ì ‘ ì‹œì‘ (ë©´ì ‘ìì™€ ë™ì¼í•œ í”Œë¡œìš°)"""
        persona = self.get_persona(company_id)
        if not persona:
            raise ValueError(f"íšŒì‚¬ {company_id}ì˜ AI ì§€ì›ì í˜ë¥´ì†Œë‚˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # AI ì„¸ì…˜ ìƒì„±
        ai_session = AICandidateSession(company_id, position, persona)
        self.ai_sessions[ai_session.session_id] = ai_session
        
        return ai_session.session_id
    
    def get_ai_next_question(self, ai_session_id: str) -> Optional[Dict[str, Any]]:
        """AI ì§€ì›ì ë‹¤ìŒ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸° (ë©´ì ‘ìì™€ ë™ì¼í•œ êµ¬ì¡°)"""
        ai_session = self.ai_sessions.get(ai_session_id)
        if not ai_session or ai_session.is_complete():
            return None
        
        # í˜„ì¬ ì§ˆë¬¸ ê³„íš ê°€ì ¸ì˜¤ê¸°
        question_plan = ai_session.get_next_question_plan()
        if not question_plan:
            return None
        
        # ë©´ì ‘ìì™€ ë™ì¼í•œ ì§ˆë¬¸ ìƒì„± ë¡œì§
        question_content, question_intent = self._generate_ai_question(
            ai_session, question_plan
        )
        
        return {
            "question_id": f"ai_q_{ai_session.current_question_count + 1}",
            "question_type": question_plan["type"].value,
            "question_content": question_content,
            "question_intent": question_intent,
            "progress": f"{ai_session.current_question_count + 1}/{len(ai_session.question_plan)}",
            "personalized": False  # AIëŠ” í‘œì¤€ ì§ˆë¬¸ ì‚¬ìš©
        }
    
    def _generate_ai_question(self, ai_session: AICandidateSession, question_plan: Dict) -> tuple[str, str]:
        """AI ì§€ì›ììš© ì§ˆë¬¸ ìƒì„± (ë©´ì ‘ìì™€ ë™ì¼í•œ ë¡œì§)"""
        question_type = question_plan["type"]
        
        # AI ì´ë¦„ ê°€ì ¸ì˜¤ê¸° (ì¶˜ì‹ì´)
        ai_name = self.get_ai_name(LLMProvider.OPENAI_GPT35)
        
        # ì²« ë‘ ì§ˆë¬¸ì€ ì™„ì „íˆ ê³ ì • (AI ì „ìš© - honorific í¬í•¨)
        if question_type == QuestionType.INTRO:
            return (
                f"{ai_name}ë‹˜, ìê¸°ì†Œê°œë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤.",
                "ì§€ì›ìì˜ ê¸°ë³¸ ë°°ê²½, ê²½ë ¥, ì„±ê²©ì„ íŒŒì•…í•˜ì—¬ ë©´ì ‘ ë¶„ìœ„ê¸°ë¥¼ ì¡°ì„±"
            )
        elif question_type == QuestionType.MOTIVATION:
            company_data = self._get_company_data(ai_session.company_id)
            return (
                f"{ai_name}ë‹˜ê»˜ì„œ {company_data.get('name', 'ì €í¬ íšŒì‚¬')}ì— ì§€ì›í•˜ê²Œ ëœ ë™ê¸°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                "íšŒì‚¬ì— ëŒ€í•œ ê´€ì‹¬ë„, ì§€ì› ì˜ì§€, íšŒì‚¬ ì´í•´ë„ë¥¼ í‰ê°€"
            )
        
        # ê³ ì • ì§ˆë¬¸ í’€ì—ì„œ ì„ íƒ
        if question_type == QuestionType.HR:
            questions = self.fixed_questions.get("hr_questions", [])
        elif question_type == QuestionType.TECH:
            questions = self.fixed_questions.get("technical_questions", [])
        elif question_type == QuestionType.COLLABORATION:
            questions = self.fixed_questions.get("collaboration_questions", [])
        else:
            # FOLLOWUPì´ë‚˜ ê¸°íƒ€ ì§ˆë¬¸ì€ ë™ì  ìƒì„±
            return self._generate_dynamic_question(ai_session, question_type)
        
        # ì´ë¯¸ ì‚¬ìš©ëœ ì§ˆë¬¸ ì œì™¸
        used_questions = set()
        for qa in ai_session.ai_answers:
            used_questions.add(qa.question_content)
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì§ˆë¬¸ í•„í„°ë§
        available_questions = [q for q in questions if q["content"] not in used_questions]
        
        if available_questions:
            # ë ˆë²¨ì— ë”°ë¼ ì •ë ¬ëœ ì§ˆë¬¸ ì„ íƒ
            current_question_index = ai_session.current_question_count
            if current_question_index < len(available_questions):
                selected_question = available_questions[current_question_index % len(available_questions)]
            else:
                selected_question = available_questions[0]
            
            # ì§ˆë¬¸ì— AI ì´ë¦„ í˜¸ì¹­ ì¶”ê°€
            ai_name = self.get_ai_name(LLMProvider.OPENAI_GPT35)
            question_content = self._add_honorific_to_question(selected_question["content"], ai_name)
            return question_content, selected_question["intent"]
        
        # í´ë°± ì§ˆë¬¸
        ai_name = self.get_ai_name(LLMProvider.OPENAI_GPT35)
        return self._get_fallback_question(question_type, ai_name)
    
    def _generate_dynamic_question(self, ai_session: AICandidateSession, question_type: QuestionType) -> tuple[str, str]:
        """ë™ì  ì§ˆë¬¸ ìƒì„± (ì‹¬í™” ì§ˆë¬¸ ë“±)"""
        context = ai_session.get_previous_answers_context()
        company_data = self._get_company_data(ai_session.company_id)
        
        if question_type == QuestionType.FOLLOWUP:
            # ì´ì „ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ì‹¬í™” ì§ˆë¬¸
            if ai_session.ai_answers:
                last_answer = ai_session.ai_answers[-1]
                return (
                    f"ë°©ê¸ˆ ë§ì”€í•˜ì‹  {last_answer.question_content[:30]}... ë¶€ë¶„ì— ëŒ€í•´ ì¢€ ë” ìì„¸íˆ ì„¤ëª…í•´ ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?",
                    "ì´ì „ ë‹µë³€ì˜ êµ¬ì²´ì ì¸ ì‚¬ë¡€ë‚˜ ê²½í—˜ì˜ ë””í…Œì¼ íƒêµ¬"
                )
        
        ai_name = self.get_ai_name(LLMProvider.OPENAI_GPT35)
        return f"{ai_name}ë‹˜ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ìŠµë‹ˆë‹¤.", "ì¼ë°˜ì ì¸ ì§ˆë¬¸"
    
    def _get_fallback_question(self, question_type: QuestionType, persona_name: str) -> tuple[str, str]:
        """í´ë°± ì§ˆë¬¸ (ë©´ì ‘ìì™€ ë™ì¼)"""
        fallback_questions = {
            QuestionType.INTRO: (f"{persona_name}ë‹˜, ê°„ë‹¨í•œ ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.", "ê¸°ë³¸ ë°°ê²½ íŒŒì•…"),
            QuestionType.MOTIVATION: (f"{persona_name}ë‹˜ì´ ì €í¬ íšŒì‚¬ì— ì§€ì›í•˜ê²Œ ëœ ë™ê¸°ê°€ ê¶ê¸ˆí•©ë‹ˆë‹¤.", "ì§€ì› ë™ê¸° íŒŒì•…"),
            QuestionType.HR: (f"{persona_name}ë‹˜ì˜ ì¥ì ê³¼ ì„±ì¥í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì€ ë¬´ì—‡ì¸ê°€ìš”?", "ê°œì¸ì  íŠ¹ì„± í‰ê°€"),
            QuestionType.TECH: (f"{persona_name}ë‹˜ì˜ ê¸°ìˆ ì  ê²½í—˜ì— ëŒ€í•´ ë§ì”€í•´ ì£¼ì„¸ìš”.", "ê¸°ìˆ  ì—­ëŸ‰ í‰ê°€"),
            QuestionType.COLLABORATION: (f"{persona_name}ë‹˜ì˜ íŒ€ í˜‘ì—… ê²½í—˜ì„ ê³µìœ í•´ ì£¼ì„¸ìš”.", "í˜‘ì—… ëŠ¥ë ¥ í‰ê°€"),
            QuestionType.FOLLOWUP: (f"{persona_name}ë‹˜ì´ ê°€ì¥ ìì‹  ìˆëŠ” ê²½í—˜ì„ ë” ìì„¸íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”.", "ì‹¬í™” íƒêµ¬")
        }
        return fallback_questions.get(question_type, (f"{persona_name}ë‹˜, ë³¸ì¸ì— ëŒ€í•´ ë§ì”€í•´ ì£¼ì„¸ìš”.", "ì¼ë°˜ì ì¸ ì§ˆë¬¸"))
    
    def _add_honorific_to_question(self, question_content: str, ai_name: str) -> str:
        """ì§ˆë¬¸ì— AI ì´ë¦„ í˜¸ì¹­ ì¶”ê°€"""
        # ì´ë¯¸ í˜¸ì¹­ì´ í¬í•¨ëœ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
        if "ë‹˜" in question_content or ai_name in question_content:
            return question_content
        
        # ì§ˆë¬¸ ì•ì— í˜¸ì¹­ ì¶”ê°€
        return f"{ai_name}ë‹˜, {question_content}"

    def generate_ai_answer_for_question(self, ai_session_id: str, question_data: Dict[str, Any]) -> AnswerResponse:
        """íŠ¹ì • ì§ˆë¬¸ì— ëŒ€í•œ AI ë‹µë³€ ìƒì„± (ì¼ê´€ì„± ìœ ì§€)"""
        ai_session = self.ai_sessions.get(ai_session_id)
        if not ai_session:
            return AnswerResponse(
                answer_content="",
                quality_level=QualityLevel(8),
                llm_provider=LLMProvider.OPENAI_GPT4O_MINI,
                persona_name="Unknown",
                confidence_score=0.0,
                response_time=0.0,
                reasoning="AI ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ",
                error=f"AI ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ai_session_id}"
            )
        
        # ì¼ê´€ì„± ìˆëŠ” ë‹µë³€ ìƒì„±ì„ ìœ„í•œ ìš”ì²­ êµ¬ì„±
        request = AnswerRequest(
            question_content=question_data["question_content"],
            question_type=QuestionType(question_data["question_type"]),
            question_intent=question_data["question_intent"],
            company_id=ai_session.company_id,
            position=ai_session.position,
            quality_level=QualityLevel(8),  # ê³ í’ˆì§ˆ ë‹µë³€
            llm_provider=LLMProvider.OPENAI_GPT4O_MINI,
            additional_context=ai_session.get_previous_answers_context()
        )
        
        # ë‹µë³€ ìƒì„±
        answer_response = self.generate_answer(request)
        
        # AI ì„¸ì…˜ì— ë‹µë³€ ì €ì¥
        if not answer_response.error:
            qa_pair = QuestionAnswer(
                question_id=question_data["question_id"],
                question_type=QuestionType(question_data["question_type"]),
                question_content=question_data["question_content"],
                answer_content=answer_response.answer_content,
                timestamp=datetime.now(),
                question_intent=question_data["question_intent"]
            )
            ai_session.add_ai_answer(qa_pair)
        
        return answer_response
    
    def _parse_personas_data(self, personas_data: Dict) -> Dict[str, CandidatePersona]:
        """í˜ë¥´ì†Œë‚˜ ë°ì´í„° íŒŒì‹±"""
        personas = {}
        for company_id, data in personas_data.items():
            personas[company_id] = CandidatePersona(
                company_id=company_id,
                name=data.get("name", f"ì§€ì›ì_{company_id}"),
                background=data.get("background", {}),
                technical_skills=data.get("technical_skills", []),
                projects=data.get("projects", []),
                experiences=data.get("experiences", []),
                strengths=data.get("strengths", []),
                achievements=data.get("achievements", []),
                career_goal=data.get("career_goal", ""),
                personality_traits=data.get("personality_traits", []),
                interview_style=data.get("interview_style", ""),
                success_factors=data.get("success_factors", [])
            )
        return personas
    
    def get_persona(self, company_id: str) -> Optional[CandidatePersona]:
        """íšŒì‚¬ë³„ í˜ë¥´ì†Œë‚˜ ì¡°íšŒ"""
        print(f"ğŸ” í˜ë¥´ì†Œë‚˜ ì¡°íšŒ ìš”ì²­: {company_id}")
        print(f"ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ í˜ë¥´ì†Œë‚˜: {list(self.candidate_personas.keys())}")
        persona = self.candidate_personas.get(company_id)
        if persona:
            print(f"âœ… í˜ë¥´ì†Œë‚˜ ì°¾ìŒ: {persona.name}")
        else:
            print(f"âŒ í˜ë¥´ì†Œë‚˜ ì—†ìŒ: {company_id}")
        return persona
    
    def generate_answer(self, request: AnswerRequest) -> AnswerResponse:
        """ì§ˆë¬¸ì— ëŒ€í•œ AI ì§€ì›ì ë‹µë³€ ìƒì„±"""
        start_time = datetime.now()
        
        # í˜ë¥´ì†Œë‚˜ ì¡°íšŒ
        persona = self.get_persona(request.company_id)
        if not persona:
            return AnswerResponse(
                answer_content="",
                quality_level=request.quality_level,
                llm_provider=request.llm_provider,
                persona_name="Unknown",
                confidence_score=0.0,
                response_time=0.0,
                reasoning="í˜ë¥´ì†Œë‚˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ",
                error=f"íšŒì‚¬ {request.company_id}ì˜ í˜ë¥´ì†Œë‚˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
        
        # íšŒì‚¬ ë°ì´í„° ì¡°íšŒ
        company_data = self._get_company_data(request.company_id)
        
        # ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self._build_answer_prompt(request, persona, company_data)
        system_prompt = self._build_system_prompt(persona, company_data, request.question_type, request.llm_provider)
        
        # í’ˆì§ˆ ë ˆë²¨ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ì¡°ì •
        quality_prompt = self.quality_controller.generate_quality_prompt(
            prompt, 
            request.quality_level,
            request.question_type.value
        )
        
        # LLM ì‘ë‹µ ìƒì„±
        llm_response = self.llm_manager.generate_response(
            request.llm_provider,
            quality_prompt,
            system_prompt
        )
        
        # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
        response_time = (datetime.now() - start_time).total_seconds()
        
        # ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
        confidence_score = self._calculate_confidence_score(llm_response, request.quality_level)
        
        # ë‹µë³€ í›„ì²˜ë¦¬
        processed_answer = self._post_process_answer(llm_response.content, request.quality_level)
        
        # ëª¨ë¸ì— ë”°ë¥¸ AI ì´ë¦„ ê²°ì •
        ai_name = self.get_ai_name(request.llm_provider)
        
        return AnswerResponse(
            answer_content=processed_answer,
            quality_level=request.quality_level,
            llm_provider=request.llm_provider,
            persona_name=ai_name,  # ëª¨ë¸ë³„ ê³ ì • ì´ë¦„ ì‚¬ìš©
            confidence_score=confidence_score,
            response_time=response_time,
            reasoning=f"{ai_name}ì˜ {request.company_id} ë©´ì ‘ ë‹µë³€ (í’ˆì§ˆ ë ˆë²¨: {request.quality_level.value})",
            error=llm_response.error,
            metadata={
                "token_count": llm_response.token_count,
                "company_id": request.company_id,
                "question_type": request.question_type.value,
                "original_prompt_length": len(prompt)
            }
        )
    
    def _get_relevant_personal_experiences(self, persona: CandidatePersona, question_content: str) -> str:
        """ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê°œì¸ì  ê²½í—˜ ì„ ë³„"""
        
        # í˜ë¥´ì†Œë‚˜ì—ì„œ ê°œì¸ ê²½í—˜ ì¶”ì¶œ
        personal_experiences = self._get_persona_attribute(persona, 'personal_experiences', [])
        if not personal_experiences:
            return "ê°œì¸ì  ê²½í—˜: ì„±ì‹¤í•˜ê³  ê¾¸ì¤€íˆ ë…¸ë ¥í•˜ëŠ” ì„±ê²©ìœ¼ë¡œ, ì–´ë ¤ìš´ ìƒí™©ì—ì„œë„ í¬ê¸°í•˜ì§€ ì•Šê³  ëê¹Œì§€ ìµœì„ ì„ ë‹¤í•˜ëŠ” ê²ƒì„ ì¤‘ìš”í•˜ê²Œ ìƒê°í•©ë‹ˆë‹¤."
        
        # ì§ˆë¬¸ ë‚´ìš©ì— ë”°ë¼ ê´€ë ¨ ê²½í—˜ ì„ ë³„
        question_lower = question_content.lower()
        relevant_experiences = []
        
        # í‚¤ì›Œë“œ ë§¤í•‘
        keyword_category_map = {
            "ê°€ì¹˜ê´€": ["ê°€ì¹˜ê´€í˜•ì„±", "ê°œì¸ë„ì „"],
            "ì„±ê²©": ["ì¸ê°„ê´€ê³„", "ê°œì¸ë„ì „"],
            "ê°•ì ": ["í•™ì°½ì‹œì ˆ", "ê°œì¸ë„ì „", "ì‹¤íŒ¨ê·¹ë³µ"],
            "ì•½ì ": ["ì‹¤íŒ¨ê·¹ë³µ", "ì¸ê°„ê´€ê³„"],
            "ì„±ì¥": ["ê°œì¸ë„ì „", "ì‹¤íŒ¨ê·¹ë³µ", "í•™ì°½ì‹œì ˆ"],
            "ëª©í‘œ": ["ê°€ì¹˜ê´€í˜•ì„±", "ê°œì¸ë„ì „"],
            "ë„ì „": ["ê°œì¸ë„ì „", "ì‹¤íŒ¨ê·¹ë³µ"],
            "í˜‘ì—…": ["ì¸ê°„ê´€ê³„", "í•™ì°½ì‹œì ˆ"],
            "ì†Œí†µ": ["ì¸ê°„ê´€ê³„", "í•™ì°½ì‹œì ˆ"],
            "ë¦¬ë”ì‹­": ["í•™ì°½ì‹œì ˆ", "ì¸ê°„ê´€ê³„"],
            "ì‹¤íŒ¨": ["ì‹¤íŒ¨ê·¹ë³µ"],
            "ì–´ë ¤ì›€": ["ì‹¤íŒ¨ê·¹ë³µ", "ê°€ì¹˜ê´€í˜•ì„±"]
        }
        
        # ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
        matched_categories = set()
        for keyword, categories in keyword_category_map.items():
            if keyword in question_lower:
                matched_categories.update(categories)
        
        # ê´€ë ¨ ê²½í—˜ ì„ ë³„
        for exp in personal_experiences:
            if not matched_categories or exp.get('category') in matched_categories:
                relevant_experiences.append(exp)
        
        # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ ì„ ë³„
        if not relevant_experiences:
            relevant_experiences = personal_experiences[:3]
        else:
            relevant_experiences = relevant_experiences[:3]
        
        # ê²½í—˜ë“¤ì„ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…
        experience_text = ""
        for i, exp in enumerate(relevant_experiences, 1):
            experience_text += f"""
{i}. [{exp.get('category', 'ê°œì¸ê²½í—˜')}] {exp.get('experience', '')}
   ë°°ìš´ ì : {exp.get('lesson', '')}
   ê°ì •: {exp.get('emotion', '')}
"""
        
        return experience_text.strip()
    
    def _get_persona_attribute(self, persona: CandidatePersona, attr_name: str, default_value):
        """í˜ë¥´ì†Œë‚˜ ì†ì„± ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # í˜ë¥´ì†Œë‚˜ ê°ì²´ì—ì„œ ì§ì ‘ ì†ì„± ì ‘ê·¼
            if hasattr(persona, attr_name):
                return getattr(persona, attr_name)
            
            # ì‚¬ì „ í˜•íƒœë¡œ ì ‘ê·¼ (í˜ë¥´ì†Œë‚˜ê°€ dictì¸ ê²½ìš°)
            if hasattr(persona, '__dict__') and attr_name in persona.__dict__:
                return persona.__dict__[attr_name]
            
            # JSON ë°ì´í„°ì—ì„œ ì§ì ‘ ë¡œë“œí•œ ê²½ìš° - _raw_data ì†ì„± í™•ì¸
            if hasattr(persona, '_raw_data') and attr_name in persona._raw_data:
                return persona._raw_data[attr_name]
            
            # í˜ë¥´ì†Œë‚˜ ë”•ì…”ë„ˆë¦¬ì—ì„œ ì§ì ‘ ì ‘ê·¼ ì‹œë„
            persona_dict = self._get_persona_dict(persona.company_id, persona.name)
            if persona_dict and attr_name in persona_dict:
                return persona_dict[attr_name]
                
            return default_value
        except:
            return default_value
    
    def _get_persona_dict(self, company_id: str, persona_name: str) -> Dict[str, Any]:
        """í˜ë¥´ì†Œë‚˜ ë”•ì…”ë„ˆë¦¬ ì§ì ‘ ì¡°íšŒ"""
        try:
            personas = self.personas_data.get("personas", {})
            if company_id in personas:
                return personas[company_id]
            return {}
        except:
            return {}
    
    def _get_company_data(self, company_id: str) -> Dict[str, Any]:
        """íšŒì‚¬ ë°ì´í„° ì¡°íšŒ"""
        for company in self.companies_data.get("companies", []):
            if company["id"] == company_id:
                return company
        return {}
    
    def get_ai_name(self, llm_provider: LLMProvider) -> str:
        """ëª¨ë¸ì— ë”°ë¥¸ AI ì§€ì›ì ì´ë¦„ ë°˜í™˜"""
        return AI_CANDIDATE_NAMES.get(llm_provider, "ì¶˜ì‹ì´")  # ê¸°ë³¸ê°’: ì¶˜ì‹ì´
    
    def _build_system_prompt(self, persona: CandidatePersona, company_data: Dict, question_type: QuestionType, llm_provider: LLMProvider = LLMProvider.OPENAI_GPT35) -> str:
        """ì§ˆë¬¸ íƒ€ì…ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        
        # AI ì´ë¦„ ê²°ì • (ëª¨ë¸ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì„¤ì •)
        ai_name = self.get_ai_name(llm_provider)
        
        base_info = f"""ë‹¹ì‹ ì€ {company_data.get('name', 'íšŒì‚¬')} ë©´ì ‘ì— ì°¸ì—¬í•œ ìš°ìˆ˜í•œ ì§€ì›ìì…ë‹ˆë‹¤.

=== ì¤‘ìš”: ë‹¹ì‹ ì˜ ì´ë¦„ì€ "{ai_name}"ì…ë‹ˆë‹¤ ===
- **ìê¸°ì†Œê°œ ì§ˆë¬¸(INTRO)ì—ì„œë§Œ** "{ai_name}"ë¼ê³  ì´ë¦„ì„ ì–¸ê¸‰í•˜ì„¸ìš”
- **ë‹¤ë¥¸ ëª¨ë“  ì§ˆë¬¸ì—ì„œëŠ” ì ˆëŒ€ ì´ë¦„ì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”**
- "ì•ˆë…•í•˜ì„¸ìš”" ê°™ì€ ì¸ì‚¬ë§ë„ ìê¸°ì†Œê°œê°€ ì•„ë‹Œ ê²½ìš° ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ë‹¤ë¥¸ ì´ë¦„(ê¹€ë„¤ì´ë²„, ë°•ì¹´ì¹´ì˜¤ ë“±)ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”

ì˜ˆì‹œ:
- ìê¸°ì†Œê°œ: "ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” {ai_name}ë¼ê³  í•©ë‹ˆë‹¤. 5ë…„ì˜ ë°±ì—”ë“œ ê°œë°œ ê²½í—˜ì„..."
- ì§€ì›ë™ê¸°: "ì œê°€ ë„¤ì´ë²„ì— ì§€ì›í•˜ê²Œ ëœ ì´ìœ ëŠ”..." (ì´ë¦„/ì¸ì‚¬ ì—†ì´ ë°”ë¡œ ì‹œì‘)
- ê¸°ìˆ ì§ˆë¬¸: "ê·¸ ë¶€ë¶„ì— ëŒ€í•´ì„œëŠ” ì œ ê²½í—˜ì„ ë§ì”€ë“œë¦¬ë©´..." (ì´ë¦„/ì¸ì‚¬ ì—†ì´)
- ê¸°íƒ€ì§ˆë¬¸: "ì œ ìƒê°ì—ëŠ”..." ë˜ëŠ” "ì €ì˜ ê²½í—˜ìœ¼ë¡œëŠ”..." (ì´ë¦„/ì¸ì‚¬ ì—†ì´)

=== ë‹¹ì‹ ì˜ ë°°ê²½ ===
- ê²½ë ¥: {persona.background.get('career_years', '0')}ë…„
- í˜„ì¬ ì§ì±…: {persona.background.get('current_position', 'ì§€ì›ì')}
- ì„±ê²© íŠ¹ì„±: {', '.join(persona.personality_traits)}
- ë©´ì ‘ ìŠ¤íƒ€ì¼: {persona.interview_style}

=== ë‹¹ì‹ ì˜ ê°•ì  ===
{', '.join(persona.strengths)}

=== ë‹¹ì‹ ì˜ ëª©í‘œ ===
{persona.career_goal}"""

        if question_type == QuestionType.INTRO:
            return f"""{base_info}

=== ìê¸°ì†Œê°œ ì§ˆë¬¸ ë‹µë³€ ìŠ¤íƒ€ì¼ ===
- **ë°˜ë“œì‹œ "{ai_name}"ë¼ê³  ì´ë¦„ì„ ë¨¼ì € ì†Œê°œí•˜ì„¸ìš”**
- ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ìì‹ ì„ ì†Œê°œí•˜ì„¸ìš”
- ì£¼ìš” ê²½ë ¥ê³¼ ê°•ì ì„ ê°„ëµíˆ ì–¸ê¸‰í•˜ì„¸ìš”
- ë©´ì ‘ì— ëŒ€í•œ ê°ì‚¬ ì¸ì‚¬ë¥¼ í¬í•¨í•˜ì„¸ìš”
- ì˜ˆ: "ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” {ai_name}ë¼ê³  í•©ë‹ˆë‹¤. 5ë…„ì˜ ë°±ì—”ë“œ ê°œë°œ ê²½í—˜ì„ ê°€ì§€ê³  ìˆìœ¼ë©°..."

**ì¤‘ìš”**: ìê¸°ì†Œê°œ ì§ˆë¬¸ì—ì„œë§Œ ì´ë¦„ì„ ì–¸ê¸‰í•˜ì„¸ìš”. ë‹¤ë¥¸ ëª¨ë“  ì§ˆë¬¸ì—ì„œëŠ” ì´ë¦„ì„ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”."""
        
        elif question_type == QuestionType.HR:
            return f"""{base_info}

=== ì¸ì„± ì§ˆë¬¸ ë‹µë³€ ìŠ¤íƒ€ì¼ ===
- **ì ˆëŒ€ ì´ë¦„ì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”** (ì´ë¯¸ ìê¸°ì†Œê°œì—ì„œ í–ˆìŒ)
- **"ì•ˆë…•í•˜ì„¸ìš”" ê°™ì€ ì¸ì‚¬ë§ ì‚¬ìš© ê¸ˆì§€**
- ë°”ë¡œ ë‹µë³€ ë‚´ìš©ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”
- **ê°œì¸ì ì´ê³  ì§„ì •ì„± ìˆê²Œ** ë‹µë³€í•˜ì„¸ìš”
- ê¸°ìˆ ì /í”„ë¡œì íŠ¸ ê²½í—˜ë³´ë‹¤ëŠ” **ê°œì¸ì  ê²½í—˜ê³¼ ê°ì •**ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€
- ë‹¹ì‹ ì˜ **ê°€ì¹˜ê´€, ì„±ê²©, ì¸ìƒ ì² í•™**ì„ ë“œëŸ¬ë‚´ì„¸ìš”
- "ì œ ê²½í—˜ì„ ë§ì”€ë“œë¦¬ë©´..." "ì €ëŠ” ê°œì¸ì ìœ¼ë¡œ..." ê°™ì€ í‘œí˜„ ì‚¬ìš©
- **ì†”ì§í•˜ê³  ì¸ê°„ì ì¸** ë©´ëª¨ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”
- êµ¬ì²´ì ì¸ ê°œì¸ ê²½í—˜ê³¼ ê·¸ë•Œì˜ **ê°ì •, ìƒê°ì˜ ë³€í™”**ë¥¼ í¬í•¨í•˜ì„¸ìš”"""
        
        elif question_type == QuestionType.TECH:
            return f"""{base_info}

=== ê¸°ìˆ  ì§ˆë¬¸ ë‹µë³€ ìŠ¤íƒ€ì¼ ===
- **ì´ë¦„ì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”** (ì´ë¯¸ ìê¸°ì†Œê°œì—ì„œ í–ˆìŒ)
- ê¸°ìˆ ì  ì „ë¬¸ì„±ê³¼ ê²½í—˜ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- êµ¬ì²´ì ì¸ í”„ë¡œì íŠ¸ ì‚¬ë¡€ì™€ ê¸°ìˆ  ìŠ¤íƒì„ ì–¸ê¸‰í•˜ì„¸ìš”
- ë¬¸ì œ í•´ê²° ê³¼ì •ê³¼ ê¸°ìˆ ì  ì„ íƒì˜ ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”
- ì „ë¬¸ì ì´ë©´ì„œë„ ìì‹ ê° ìˆëŠ” í†¤ì„ ìœ ì§€í•˜ì„¸ìš”"""
        
        elif question_type == QuestionType.COLLABORATION:
            return f"""{base_info}

=== í˜‘ì—… ì§ˆë¬¸ ë‹µë³€ ìŠ¤íƒ€ì¼ ===
- **ì´ë¦„ì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”** (ì´ë¯¸ ìê¸°ì†Œê°œì—ì„œ í–ˆìŒ)
- íŒ€ì›Œí¬ì™€ í˜‘ì—… ê²½í—˜ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- êµ¬ì²´ì ì¸ í˜‘ì—… ìƒí™©ê³¼ í•´ê²° ê³¼ì •ì„ ì„¤ëª…í•˜ì„¸ìš”
- ë‹¤ë¥¸ íŒ€ì›ë“¤ê³¼ì˜ ì†Œí†µ ë°©ì‹ê³¼ ê°ˆë“± í•´ê²° ê²½í—˜ì„ í¬í•¨í•˜ì„¸ìš”
- í˜‘ë ¥ì ì´ê³  ë°°ë ¤ì‹¬ ìˆëŠ” ë©´ëª¨ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”"""
        
        else:  # MOTIVATION, FOLLOWUP ë“±
            return f"""{base_info}

=== ë©´ì ‘ íƒœë„ ===
- **ì ˆëŒ€ ì´ë¦„ì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”** (ìê¸°ì†Œê°œê°€ ì•„ë‹Œ ê²½ìš°)
- **"ì•ˆë…•í•˜ì„¸ìš”" ê°™ì€ ì¸ì‚¬ë§ ì‚¬ìš© ê¸ˆì§€**
- ë°”ë¡œ ë‹µë³€ ë‚´ìš©ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”
- ìì‹ ê° ìˆê³  ì„±ì‹¤í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
- êµ¬ì²´ì ì¸ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- {company_data.get('name', 'íšŒì‚¬')}ì— ëŒ€í•œ ì§„ì •ì„± ìˆëŠ” ê´€ì‹¬ì„ ë³´ì—¬ì£¼ì„¸ìš”
- ì „ë¬¸ì ì´ë©´ì„œë„ ìì—°ìŠ¤ëŸ¬ìš´ í†¤ì„ ìœ ì§€í•˜ì„¸ìš”

ë‹µë³€ ì‹œì‘ ì˜ˆì‹œ:
- ì§€ì›ë™ê¸°: "ì œê°€ ë„¤ì´ë²„ì— ì§€ì›í•˜ê²Œ ëœ ì´ìœ ëŠ”..."
- ì¼ë°˜ì§ˆë¬¸: "ê·¸ ë¶€ë¶„ì— ëŒ€í•´ì„œëŠ”..." "ì œ ê²½í—˜ìœ¼ë¡œëŠ”..." "ì €ëŠ” í•­ìƒ..."
- ê¸°ìˆ ì§ˆë¬¸: "í•´ë‹¹ ê¸°ìˆ ì— ëŒ€í•œ ì œ ê²½í—˜ì„ ë§ì”€ë“œë¦¬ë©´..."
- í˜‘ì—…ì§ˆë¬¸: "íŒ€ì›Œí¬ ê´€ë ¨í•´ì„œëŠ” ì œê°€ ê²ªì—ˆë˜ ì‚¬ë¡€ê°€..."
"""
    
    def _build_answer_prompt(self, request: AnswerRequest, persona: CandidatePersona, company_data: Dict) -> str:
        """ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        
        # í˜ë¥´ì†Œë‚˜ì˜ ê¸°ìˆ  ìŠ¤í‚¬ ë° í”„ë¡œì íŠ¸ ì •ë³´
        tech_info = f"ì£¼ìš” ê¸°ìˆ : {', '.join(persona.technical_skills[:5])}"
        
        projects_info = ""
        for i, project in enumerate(persona.projects[:2], 1):
            projects_info += f"\n{i}. {project.get('name', 'í”„ë¡œì íŠ¸')}: {project.get('description', '')}"
            if project.get('achievements'):
                projects_info += f" (ì„±ê³¼: {', '.join(project['achievements'])})"
        
        experiences_info = ""
        for exp in persona.experiences[:2]:
            experiences_info += f"\n- {exp.get('company', 'íšŒì‚¬')}: {exp.get('position', 'ê°œë°œì')} ({exp.get('period', 'ê¸°ê°„')})"
            if exp.get('achievements'):
                experiences_info += f" - {', '.join(exp['achievements'])}"
        
        # íšŒì‚¬ë³„ ë§ì¶¤ ì •ë³´
        company_focus = ""
        if company_data:
            company_focus = f"""
=== {company_data['name']} ê´€ë ¨ ì •ë³´ ===
- ì¸ì¬ìƒ: {company_data.get('talent_profile', '')}
- ê¸°ìˆ  ì¤‘ì : {', '.join(company_data.get('tech_focus', []))}
- í•µì‹¬ ì—­ëŸ‰: {', '.join(company_data.get('core_competencies', []))}"""
        
        # ì§ˆë¬¸ íƒ€ì…ë³„ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        if request.question_type == QuestionType.HR:
            # ê°œì¸ì  ê²½í—˜ ì„ ë³„ (ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê²½í—˜ ìš°ì„ )
            personal_experiences = self._get_relevant_personal_experiences(persona, request.question_content)
            life_philosophy = self._get_persona_attribute(persona, 'life_philosophy', 'ì§€ì†ì ì¸ í•™ìŠµê³¼ ì„±ì¥ì„ ì¶”êµ¬í•©ë‹ˆë‹¤.')
            core_values = self._get_persona_attribute(persona, 'core_values', ['ì„±ì¥', 'í˜‘ì—…', 'ë„ì „'])
            
            prompt = f"""
=== ë©´ì ‘ ìƒí™© ===
íšŒì‚¬: {company_data.get('name', request.company_id)}
ì§êµ°: {request.position}
ì§ˆë¬¸ ìœ í˜•: {request.question_type.value} (ì¸ì„± ì§ˆë¬¸)
ì§ˆë¬¸: {request.question_content}
ì§ˆë¬¸ ì˜ë„: {request.question_intent}

=== ë‹¹ì‹ ì˜ ê°œì¸ì  íŠ¹ì„± ===
- ì„±ê²© íŠ¹ì„±: {', '.join(persona.personality_traits)}
- ì¸ìƒ ì² í•™: {life_philosophy}
- í•µì‹¬ ê°€ì¹˜: {', '.join(core_values)}
- ë©´ì ‘ ìŠ¤íƒ€ì¼: {persona.interview_style}

=== í™œìš©í•  ìˆ˜ ìˆëŠ” ê°œì¸ ê²½í—˜ë“¤ ===
{personal_experiences}

=== ë‹µë³€ ë°©ì‹ (ë§¤ìš° ì¤‘ìš”) ===
ì´ ì§ˆë¬¸ì€ ë‹¹ì‹ ì˜ **ì¸ì„±ê³¼ ê°€ì¹˜ê´€**ì„ í‰ê°€í•˜ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤.

**ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ì›ì¹™:**
- âŒ í”„ë¡œì íŠ¸ ê²½í—˜ ì¤‘ì‹¬ ë‹µë³€ ê¸ˆì§€
- âœ… ê°œì¸ì  ê²½í—˜ê³¼ ê°ì •ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€
- âœ… ìœ„ì˜ ê°œì¸ ê²½í—˜ë“¤ì„ ì ê·¹ í™œìš©í•˜ì„¸ìš”
- âœ… í•™ì°½ì‹œì ˆ, ì¼ìƒìƒí™œ, ì¸ê°„ê´€ê³„, ê°œì¸ì  ë„ì „ ë“±ì˜ ê²½í—˜ í¬í•¨
- âœ… "ê°œì¸ì ìœ¼ë¡œ ì €ëŠ”...", "ì œê°€ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ê²ƒì€..." í‘œí˜„ ì‚¬ìš©
- âœ… ê°ì •ê³¼ ìƒê°ì˜ ë³€í™” ê³¼ì •ì„ êµ¬ì²´ì ìœ¼ë¡œ í‘œí˜„
- âœ… ì‹¤íŒ¨ì™€ ê·¹ë³µ ê²½í—˜, ê°€ì¹˜ê´€ í˜•ì„± ê³¼ì • í¬í•¨

**ë‹µë³€ êµ¬ì¡°:**
1. ê°œì¸ì  ê´€ì /ê°€ì¹˜ê´€ í‘œí˜„
2. êµ¬ì²´ì ì¸ ê°œì¸ ê²½í—˜ ì‚¬ë¡€ (ì—…ë¬´ ì™¸ ê²½í—˜ ìš°ì„ )
3. ê·¸ ê²½í—˜ì—ì„œ ëŠë‚€ ê°ì •ê³¼ ë°°ìš´ ì 
4. í˜„ì¬ ì‚¶/ì—…ë¬´ì— ì–´ë–»ê²Œ ì ìš©í•˜ê³  ìˆëŠ”ì§€

ìœ„ ì§€ì¹¨ì„ ë°”íƒ•ìœ¼ë¡œ ì§„ì •ì„± ìˆê³  ì¸ê°„ì ì¸ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.
"""
        elif request.question_type == QuestionType.COLLABORATION:
            # í˜‘ì—… ì§ˆë¬¸: ê°œì¸ì  ì†Œí†µ/ê´€ê³„ ê²½í—˜ í¬í•¨
            personal_experiences = self._get_relevant_personal_experiences(persona, request.question_content)
            core_values = self._get_persona_attribute(persona, 'core_values', ['í˜‘ì—…', 'ì†Œí†µ', 'ì„±ì¥'])
            
            prompt = f"""
=== ë©´ì ‘ ìƒí™© ===
íšŒì‚¬: {company_data.get('name', request.company_id)}
ì§êµ°: {request.position}
ì§ˆë¬¸ ìœ í˜•: {request.question_type.value} (í˜‘ì—… ëŠ¥ë ¥ í‰ê°€)
ì§ˆë¬¸: {request.question_content}
ì§ˆë¬¸ ì˜ë„: {request.question_intent}

=== ë‹¹ì‹ ì˜ ê°œì¸ì  íŠ¹ì„± ===
- ì„±ê²© íŠ¹ì„±: {', '.join(persona.personality_traits)}
- í•µì‹¬ ê°€ì¹˜: {', '.join(core_values)}
- ë©´ì ‘ ìŠ¤íƒ€ì¼: {persona.interview_style}

=== ì°¸ê³ í•  ê°œì¸ ê²½í—˜ë“¤ ===
{personal_experiences}

=== ë‹¹ì‹ ì˜ ë°°ê²½ ì •ë³´ ===
{tech_info}

=== ì£¼ìš” í”„ë¡œì íŠ¸ ê²½í—˜ ==={projects_info}

=== ë‹µë³€ ë°©ì‹ ===
ì´ ì§ˆë¬¸ì€ ë‹¹ì‹ ì˜ **í˜‘ì—… ëŠ¥ë ¥ê³¼ ì†Œí†µ ìŠ¤íƒ€ì¼**ì„ í‰ê°€í•˜ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤.

**ë‹µë³€ ë¹„ìœ¨ ê°€ì´ë“œ:**
- ì—…ë¬´/í”„ë¡œì íŠ¸ ê²½í—˜: 60%
- ê°œì¸ì  ê²½í—˜ (í•™ì°½ì‹œì ˆ, ì¼ìƒ ê´€ê³„): 40%

**í¬í•¨í•´ì•¼ í•  ìš”ì†Œ:**
- êµ¬ì²´ì ì¸ í˜‘ì—…/ì†Œí†µ ê²½í—˜ (ì—…ë¬´+ê°œì¸)
- ê·¸ ìƒí™©ì—ì„œì˜ ê°ì •ê³¼ ìƒê°
- ê°ˆë“± í•´ê²°ì´ë‚˜ ê´€ê³„ ê°œì„  ì‚¬ë¡€
- ê°œì¸ì  ì†Œí†µ ì² í•™ì´ë‚˜ ë°©ì‹
- íŒ€ì—ì„œì˜ ìì‹ ì˜ ì—­í• ê³¼ ê¸°ì—¬

ìœ„ì˜ ê°œì¸ ê²½í—˜ë“¤ë„ ì ì ˆíˆ í™œìš©í•˜ì—¬ ì¸ê°„ì ì´ê³  ì§„ì •ì„± ìˆëŠ” ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.
"""
        else:
            # ê¸°ìˆ  ì§ˆë¬¸ ë“± ê¸°íƒ€ ì§ˆë¬¸
            life_philosophy = self._get_persona_attribute(persona, 'life_philosophy', 'ì§€ì†ì ì¸ í•™ìŠµê³¼ ì„±ì¥ì„ ì¶”êµ¬í•©ë‹ˆë‹¤.')
            
            prompt = f"""
=== ë©´ì ‘ ìƒí™© ===
íšŒì‚¬: {company_data.get('name', request.company_id)}
ì§êµ°: {request.position}
ì§ˆë¬¸ ìœ í˜•: {request.question_type.value}
ì§ˆë¬¸: {request.question_content}
ì§ˆë¬¸ ì˜ë„: {request.question_intent}

=== ë‹¹ì‹ ì˜ íŠ¹ì„± ===
- ì„±ê²© íŠ¹ì„±: {', '.join(persona.personality_traits)}
- ì¸ìƒ ì² í•™: {life_philosophy}
- ë©´ì ‘ ìŠ¤íƒ€ì¼: {persona.interview_style}

=== ë‹¹ì‹ ì˜ ë°°ê²½ ì •ë³´ ===
{tech_info}

=== ì£¼ìš” í”„ë¡œì íŠ¸ ê²½í—˜ ==={projects_info}

=== ì—…ë¬´ ê²½í—˜ ==={experiences_info}

=== ì£¼ìš” ì„±ì·¨ ===
{', '.join(persona.achievements)}
{company_focus}

=== ë‹µë³€ ë°©ì‹ ===
**ë‹µë³€ êµ¬ì„± ë¹„ìœ¨:**
- ê¸°ìˆ ì /ì „ë¬¸ì  ë‚´ìš©: 70%
- ê°œì¸ì  í•™ìŠµ/ì„±ì¥ ê´€ì : 30%

**í¬í•¨ ìš”ì†Œ:**
- êµ¬ì²´ì ì¸ ê¸°ìˆ  ê²½í—˜ê³¼ ì„±ê³¼
- ê°œì¸ì  í•™ìŠµ ë™ê¸°ì™€ ê³¼ì •
- ê¸°ìˆ ì— ëŒ€í•œ ë³¸ì¸ë§Œì˜ ì² í•™ì´ë‚˜ ê´€ì 
- ì‹¤íŒ¨ì™€ ê·¹ë³µ ê²½í—˜
- ì§€ì†ì  ì„±ì¥ì„ ìœ„í•œ ë…¸ë ¥

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°ìˆ ì  ì „ë¬¸ì„±ê³¼ ê°œì¸ì  ì„±ì¥ ìŠ¤í† ë¦¬ë¥¼ ê· í˜•ìˆê²Œ í¬í•¨í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
"""
        
        if request.additional_context:
            prompt += f"\n\n=== ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ===\n{request.additional_context}"
        
        return prompt
    
    def _calculate_confidence_score(self, llm_response: LLMResponse, quality_level: QualityLevel) -> float:
        """ë‹µë³€ ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        if llm_response.error:
            return 0.0
        
        base_score = 0.7
        
        # í’ˆì§ˆ ë ˆë²¨ì— ë”°ë¥¸ ê°€ì‚°ì 
        quality_bonus = (quality_level.value - 5) * 0.05
        
        # ë‹µë³€ ê¸¸ì´ì— ë”°ë¥¸ ê°€ì‚°ì 
        length_bonus = min(len(llm_response.content) / 1000, 0.2)
        
        # ì‘ë‹µ ì‹œê°„ì— ë”°ë¥¸ ê°€ì‚°ì  (ë¹ ë¥¼ìˆ˜ë¡ ì¢‹ìŒ)
        time_bonus = 0.1 if llm_response.response_time and llm_response.response_time < 3.0 else 0.0
        
        confidence = min(base_score + quality_bonus + length_bonus + time_bonus, 1.0)
        return round(confidence, 2)
    
    def _post_process_answer(self, answer: str, quality_level: QualityLevel) -> str:
        """ë‹µë³€ í›„ì²˜ë¦¬"""
        if not answer:
            return ""
        
        # ê¸°ë³¸ ì •ë¦¬
        processed = answer.strip()
        
        # í’ˆì§ˆ ë ˆë²¨ì— ë”°ë¥¸ ì¶”ê°€ ì²˜ë¦¬
        config = self.quality_controller.get_quality_config(quality_level)
        
        # ê¸¸ì´ ì¡°ì •
        if len(processed) > config.answer_length_max:
            # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸°
            sentences = processed.split('. ')
            total_length = 0
            result_sentences = []
            
            for sentence in sentences:
                if total_length + len(sentence) <= config.answer_length_max:
                    result_sentences.append(sentence)
                    total_length += len(sentence) + 2
                else:
                    break
            
            processed = '. '.join(result_sentences)
            if not processed.endswith('.'):
                processed += '.'
        
        return processed
    
    def compare_answers(self, request: AnswerRequest, quality_levels: List[QualityLevel]) -> Dict[QualityLevel, AnswerResponse]:
        """ì—¬ëŸ¬ í’ˆì§ˆ ë ˆë²¨ë¡œ ë‹µë³€ ìƒì„± ë° ë¹„êµ"""
        results = {}
        
        for level in quality_levels:
            request.quality_level = level
            results[level] = self.generate_answer(request)
        
        return results
    
    def compare_llm_models(self, request: AnswerRequest, llm_providers: List[LLMProvider]) -> Dict[LLMProvider, AnswerResponse]:
        """ì—¬ëŸ¬ LLM ëª¨ë¸ë¡œ ë‹µë³€ ìƒì„± ë° ë¹„êµ"""
        results = {}
        
        for provider in llm_providers:
            request.llm_provider = provider
            results[provider] = self.generate_answer(request)
        
        return results
    
    def get_available_companies(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ íšŒì‚¬ ëª©ë¡"""
        return list(self.candidate_personas.keys())
    
    def evaluate_ai_interview(self, ai_session_id: str) -> Dict[str, Any]:
        """AI ì§€ì›ì ë©´ì ‘ í‰ê°€ (ë©´ì ‘ìì™€ ë™ì¼í•œ êµ¬ì¡°)"""
        ai_session = self.ai_sessions.get(ai_session_id)
        if not ai_session:
            return {"error": "AI ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        
        company_data = self._get_company_data(ai_session.company_id)
        
        # 1. ê° ë‹µë³€ì„ ê°œë³„ì ìœ¼ë¡œ í‰ê°€
        individual_feedbacks = []
        total_score = 0
        category_scores = {}
        
        for qa in ai_session.ai_answers:
            # ê°œë³„ ë‹µë³€ í‰ê°€ (ë©´ì ‘ìì™€ ë™ì¼í•œ ë¡œì§)
            individual_evaluation = self._evaluate_ai_single_answer(qa, company_data)
            
            # í‰ê°€ ê²°ê³¼ë¥¼ qa_pairì— ì €ì¥
            qa.individual_score = individual_evaluation["score"]
            qa.individual_feedback = individual_evaluation["feedback"]
            
            individual_feedbacks.append({
                "question_number": len(individual_feedbacks) + 1,
                "question_type": qa.question_type.value,
                "question": qa.question_content,
                "question_intent": qa.question_intent,
                "answer": qa.answer_content,
                "score": qa.individual_score,
                "feedback": qa.individual_feedback,
                "personalized": False  # AIëŠ” í‘œì¤€ ì§ˆë¬¸ ì‚¬ìš©
            })
            
            total_score += qa.individual_score
            
            # ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ê³„ì‚°
            category = qa.question_type.value
            if category not in category_scores:
                category_scores[category] = []
            category_scores[category].append(qa.individual_score)
        
        # ì „ì²´ í‰ê·  ê³„ì‚°
        overall_score = int(total_score / len(ai_session.ai_answers))
        
        # ì¹´í…Œê³ ë¦¬ë³„ í‰ê· 
        for category in category_scores:
            category_scores[category] = int(sum(category_scores[category]) / len(category_scores[category]))
        
        # 2. ì¢…í•© í‰ê°€ ìƒì„±
        overall_evaluation = self._generate_ai_overall_evaluation(ai_session, company_data, overall_score)
        
        return {
            "session_id": ai_session_id,
            "company": company_data.get("name", ""),
            "position": ai_session.position,
            "candidate": ai_session.persona.name,
            "candidate_type": "AI",
            "individual_feedbacks": individual_feedbacks,
            "evaluation": {
                "overall_score": overall_score,
                "category_scores": category_scores,
                **overall_evaluation
            },
            "completed_at": datetime.now().isoformat()
        }
    
    def _evaluate_ai_single_answer(self, qa: QuestionAnswer, company_data: Dict[str, Any]) -> Dict[str, Any]:
        """AI ë‹µë³€ ê°œë³„ í‰ê°€ (ë©´ì ‘ìì™€ ë™ì¼í•œ ì—„ê²©í•œ ê¸°ì¤€)"""
        
        answer = qa.answer_content.strip()
        
        # ê¸°ë³¸ ê²€ì¦
        if len(answer) < 10:
            return {
                "score": 20,
                "feedback": f"ğŸ“ ì§ˆë¬¸ ì˜ë„: {qa.question_intent}\n\nğŸ’¬ í‰ê°€: AI ë‹µë³€ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.\n\nğŸ”§ ê°œì„  ë°©ë²•: ë” êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ ë‹µë³€ì´ í•„ìš”í•©ë‹ˆë‹¤."
            }
        
        prompt = f"""
ë‹¤ìŒ AI ì§€ì›ìì˜ ë©´ì ‘ ë‹µë³€ì„ í‰ê°€í•´ì£¼ì„¸ìš”.

=== ì§ˆë¬¸ ì •ë³´ ===
ì§ˆë¬¸ ìœ í˜•: {qa.question_type.value}
ì§ˆë¬¸: {qa.question_content}
ì§ˆë¬¸ ì˜ë„: {qa.question_intent}

=== AI ì§€ì›ì ë‹µë³€ ===
{answer}

=== í‰ê°€ ê¸°ì¤€ ===
- 65-75ì : AI ë‹µë³€ì˜ ê¸°ë³¸ í’ˆì§ˆ ë²”ìœ„
- 75-85ì : êµ¬ì²´ì ì´ê³  ì¸ìƒì ì¸ ë‹µë³€
- 85-95ì : ë§¤ìš° ìš°ìˆ˜í•œ ë‹µë³€
- 95-100ì : ì™„ë²½ì— ê°€ê¹Œìš´ ë‹µë³€

í‰ê°€ ìš”ì†Œ:
1. ì§ˆë¬¸ ì˜ë„ ì´í•´ë„
2. ë‹µë³€ì˜ êµ¬ì²´ì„±ê³¼ ì‚¬ì‹¤ì„±
3. ë…¼ë¦¬ì  êµ¬ì„±
4. ì „ë¬¸ì„±ê³¼ ê¹Šì´
5. ì¼ê´€ì„±

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
  "score": ì ìˆ˜,
  "feedback": "ğŸ“ ì§ˆë¬¸ ì˜ë„: {qa.question_intent}\\n\\nğŸ’¬ í‰ê°€: êµ¬ì²´ì ì¸ í‰ê°€ ë‚´ìš©\\n\\nğŸ”§ ê°œì„  ë°©ë²•: ì‹¤ì§ˆì ì¸ ê°œì„  ì œì•ˆ"
}}
"""
        
        try:
            response = self.llm_manager.generate_response(
                LLMProvider.OPENAI_GPT4O_MINI,
                prompt,
                "ë‹¹ì‹ ì€ AI ì§€ì›ì ë‹µë³€ì„ í‰ê°€í•˜ëŠ” ë©´ì ‘ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
            )
            
            result = response.content.strip()
            
            # JSON íŒŒì‹±
            start_idx = result.find('{')
            end_idx = result.rfind('}') + 1
            
            if start_idx != -1 and end_idx != -1:
                json_str = result[start_idx:end_idx]
                evaluation = json.loads(json_str)
                
                # AI ë‹µë³€ì€ ì¼ë°˜ì ìœ¼ë¡œ ë†’ì€ í’ˆì§ˆì´ë¯€ë¡œ ê¸°ë³¸ ì ìˆ˜ ì¡°ì •
                score = max(evaluation["score"], 65)  # ìµœì†Œ 65ì 
                evaluation["score"] = score
                
                return evaluation
            else:
                raise ValueError("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            print(f"AI ë‹µë³€ í‰ê°€ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # ê¸°ë³¸ ì ìˆ˜ (AIëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì¢‹ì€ ë‹µë³€ì„ ìƒì„±)
            return {
                "score": 75,
                "feedback": f"ğŸ“ ì§ˆë¬¸ ì˜ë„: {qa.question_intent}\n\nğŸ’¬ í‰ê°€: AI ë‹µë³€ì´ ì ì ˆí•©ë‹ˆë‹¤.\n\nğŸ”§ ê°œì„  ë°©ë²•: ë” êµ¬ì²´ì ì¸ ê²½í—˜ê³¼ ì‚¬ë¡€ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            }
    
    def _generate_ai_overall_evaluation(self, ai_session: AICandidateSession, company_data: Dict[str, Any], overall_score: int) -> Dict[str, Any]:
        """AI ì§€ì›ì ì¢…í•© í‰ê°€ ìƒì„±"""
        
        conversation_summary = ""
        for qa in ai_session.ai_answers:
            conversation_summary += f"[{qa.question_type.value}] {qa.question_content}\në‹µë³€: {qa.answer_content}\nê°œë³„ ì ìˆ˜: {qa.individual_score}ì \n\n"
        
        prompt = f"""
{company_data.get('name', '')} {ai_session.position} AI ì§€ì›ì ì¢…í•© í‰ê°€ë¥¼ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.

=== AI ì§€ì›ì ì •ë³´ ===
- ì´ë¦„: {ai_session.persona.name}
- ì§€ì› ì§êµ°: {ai_session.position}
- ì „ì²´ í‰ê·  ì ìˆ˜: {overall_score}ì 
- í˜ë¥´ì†Œë‚˜ ìœ í˜•: AI ì§€ì›ì

=== ë©´ì ‘ ë‚´ìš© ===
{conversation_summary}

=== ê¸°ì—… ìš”êµ¬ì‚¬í•­ ===
- ì¸ì¬ìƒ: {company_data.get('talent_profile', '')}
- í•µì‹¬ ì—­ëŸ‰: {', '.join(company_data.get('core_competencies', []))}

AI ì§€ì›ìì˜ ë‹µë³€ í’ˆì§ˆê³¼ ì¼ê´€ì„±ì„ í‰ê°€í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
  "strengths": ["êµ¬ì²´ì ì¸ ê°•ì 1", "êµ¬ì²´ì ì¸ ê°•ì 2", "êµ¬ì²´ì ì¸ ê°•ì 3"],
  "improvements": ["êµ¬ì²´ì ì¸ ê°œì„ ì 1", "êµ¬ì²´ì ì¸ ê°œì„ ì 2", "êµ¬ì²´ì ì¸ ê°œì„ ì 3"],
  "recommendation": "AI ì§€ì›ì ì„±ëŠ¥ í‰ê°€",
  "next_steps": "ì‹¤ì œ ë©´ì ‘ ì¤€ë¹„ ë‹¨ê³„ ì œì•ˆ",
  "overall_assessment": "AI ì§€ì›ìì˜ ì „ì²´ì ì¸ ì„±ëŠ¥ í‰ê°€"
}}
"""
        
        try:
            response = self.llm_manager.generate_response(
                LLMProvider.OPENAI_GPT4O_MINI,
                prompt,
                f"{company_data.get('name', '')} AI ì§€ì›ì ë©´ì ‘ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
            )
            
            result = response.content.strip()
            
            start_idx = result.find('{')
            end_idx = result.rfind('}') + 1
            
            if start_idx != -1 and end_idx != -1:
                json_str = result[start_idx:end_idx]
                return json.loads(json_str)
            
        except Exception as e:
            print(f"AI ì¢…í•© í‰ê°€ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        # ê¸°ë³¸ í‰ê°€ (AIëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì¢‹ì€ ì„±ëŠ¥)
        return {
            "strengths": ["ì¼ê´€ëœ ë‹µë³€", "ë…¼ë¦¬ì  êµ¬ì„±", "ì „ë¬¸ì  í‘œí˜„"],
            "improvements": ["ê°œì¸ ê²½í—˜ êµ¬ì²´í™”", "ê°ì •ì  í‘œí˜„", "ì°½ì˜ì„± í–¥ìƒ"],
            "recommendation": f"AI ì§€ì›ì ì„±ëŠ¥: {overall_score}ì  ìˆ˜ì¤€",
            "next_steps": "ì‹¤ì œ ë©´ì ‘ ì¤€ë¹„ ì‹œ ì°¸ê³  ìë£Œë¡œ í™œìš©",
            "overall_assessment": f"AI ì§€ì›ìê°€ {overall_score}ì  ìˆ˜ì¤€ì˜ ë‹µë³€ì„ ì œê³µí–ˆìŠµë‹ˆë‹¤."
        }

    def get_persona_summary(self, company_id: str) -> Dict[str, Any]:
        """í˜ë¥´ì†Œë‚˜ ìš”ì•½ ì •ë³´"""
        persona = self.get_persona(company_id)
        if not persona:
            return {}
        
        return {
            "name": persona.name,
            "company": company_id,
            "career_years": persona.background.get("career_years", "0"),
            "current_position": persona.background.get("current_position", "ì§€ì›ì"),
            "position": persona.background.get("current_position", "ì§€ì›ì"),  # í˜¸í™˜ì„±ì„ ìœ„í•´ ë‘˜ ë‹¤ ì œê³µ
            "main_skills": persona.technical_skills[:5],
            "key_strengths": persona.strengths[:3],
            "interview_style": persona.interview_style,
            "success_factors": persona.success_factors
        }

if __name__ == "__main__":
    # AI ì§€ì›ì ëª¨ë¸ í…ŒìŠ¤íŠ¸
    print("ğŸ¤– AI ì§€ì›ì ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    
    # ëª¨ë¸ ì´ˆê¸°í™” (ìë™ìœ¼ë¡œ .envì—ì„œ API í‚¤ ë¡œë“œ)
    ai_candidate = AICandidateModel()
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ íšŒì‚¬ í™•ì¸
    companies = ai_candidate.get_available_companies()
    print(f"\nğŸ¢ ì‚¬ìš© ê°€ëŠ¥í•œ íšŒì‚¬: {companies}")
    
    # í˜ë¥´ì†Œë‚˜ ì •ë³´ í™•ì¸
    for company in companies[:2]:
        summary = ai_candidate.get_persona_summary(company)
        print(f"\nğŸ‘¤ {company} í˜ë¥´ì†Œë‚˜:")
        print(f"  ì´ë¦„: {summary.get('name')}")
        print(f"  ê²½ë ¥: {summary.get('career_years')}ë…„")
        print(f"  ì£¼ìš” ê¸°ìˆ : {summary.get('main_skills')}")
        print(f"  ë©´ì ‘ ìŠ¤íƒ€ì¼: {summary.get('interview_style')}")
    
    # ë‹µë³€ ìƒì„± í…ŒìŠ¤íŠ¸
    if companies:
        test_request = AnswerRequest(
            question_content="ê°„ë‹¨í•œ ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”.",
            question_type=QuestionType.INTRO,
            question_intent="ì§€ì›ìì˜ ê¸°ë³¸ ë°°ê²½ê³¼ ì—­ëŸ‰ íŒŒì•…",
            company_id=companies[0],
            position="ë°±ì—”ë“œ ê°œë°œì",
            quality_level=QualityLevel.GOOD,
            llm_provider=LLMProvider.OPENAI_GPT4O_MINI
        )
        
        print(f"\nğŸ“ ë‹µë³€ ìƒì„± í…ŒìŠ¤íŠ¸ ({companies[0]}):")
        response = ai_candidate.generate_answer(test_request)
        
        print(f"í˜ë¥´ì†Œë‚˜: {response.persona_name}")
        print(f"í’ˆì§ˆ ë ˆë²¨: {response.quality_level.value}ì ")
        print(f"ì‹ ë¢°ë„: {response.confidence_score}")
        print(f"ì‘ë‹µ ì‹œê°„: {response.response_time:.2f}ì´ˆ")
        print(f"ë‹µë³€: {response.answer_content[:200]}...")
        
        if response.error:
            print(f"ì˜¤ë¥˜: {response.error}")