#!/usr/bin/env python3
"""
AI ì§€ì›ì ëª¨ë¸ - LLM ê¸°ë°˜ ì‹¤ì‹œê°„ í˜ë¥´ì†Œë‚˜ ìƒì„±
ì‹¤ì œ ì´ë ¥ì„œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì´ ì¸ê°„ë¯¸ ë„˜ì¹˜ëŠ” í˜ë¥´ì†Œë‚˜ë¥¼ ì‹¤ì‹œê°„ ìƒì„±
"""

import os
import json
import sys
import random
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from dotenv import load_dotenv
from pydantic import BaseModel

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ database ëª¨ë“ˆ ì ‘ê·¼ì„ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
try:
    from database.supabase_client import get_supabase_client
except ImportError:
    print("âš ï¸ Supabase í´ë¼ì´ì–¸íŠ¸ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê¸°ë°˜ fallbackë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")
    get_supabase_client = None

from ..core.llm_manager import LLMManager, LLMProvider, LLMResponse
from .quality_controller import AnswerQualityController, QualityLevel
from ..shared.models import QuestionType, QuestionAnswer, AnswerRequest, AnswerResponse
from ..session.models import InterviewSession
from ..shared.utils import safe_json_load, get_fixed_questions

# ì§êµ° ë§¤í•‘ (position_name -> position_id)
POSITION_MAPPING = {
    "í”„ë¡ íŠ¸ì—”ë“œ": 1,
    "í”„ë¡ íŠ¸": 1,
    "frontend": 1,
    "ë°±ì—”ë“œ": 2,
    "ë°±ì—”ë“œê°œë°œì": 2,
    "backend": 2,
    "ê¸°íš": 3,
    "ê¸°íšì": 3,
    "pm": 3,
    "product manager": 3,
    "AI": 4,
    "ai": 4,
    "ì¸ê³µì§€ëŠ¥": 4,
    "ë¨¸ì‹ ëŸ¬ë‹": 4,
    "ml": 4,
    "ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤": 5,
    "ë°ì´í„°": 5,
    "data science": 5,
    "data scientist": 5,
    "ds": 5
}

# ìƒˆë¡œìš´ CandidatePersona ëª¨ë¸ (LLM ìƒì„±ìš©)
class CandidatePersona(BaseModel):
    """LLMì´ ìƒì„±í•˜ëŠ” ì¸ê°„ë¯¸ ë„˜ì¹˜ëŠ” í˜ë¥´ì†Œë‚˜ ëª¨ë¸"""
    # --- LLM ìƒì„± ì •ë³´ ---
    name: str
    summary: str  # ì˜ˆ: "5ë…„ì°¨ Java ë°±ì—”ë“œ ê°œë°œìë¡œ, ëŒ€ìš©ëŸ‰ íŠ¸ë˜í”½ ì²˜ë¦¬ì™€ MSA ì„¤ê³„ì— ê°•ì ì´ ìˆìŠµë‹ˆë‹¤."
    background: Dict[str, Any]
    technical_skills: List[str]
    projects: List[Dict[str, Any]]  # ê° í”„ë¡œì íŠ¸ì— 'achievements'ì™€ 'challenges' í¬í•¨
    experiences: List[Dict[str, Any]]
    strengths: List[str]
    weaknesses: List[str]  # ê°œì„ í•˜ê³  ì‹¶ì€ ì 
    motivation: str  # ê°œë°œì/ê¸°ìˆ ì— ëŒ€í•œ ê°œì¸ì  ë™ê¸°ë‚˜ ìŠ¤í† ë¦¬
    inferred_personal_experiences: List[Dict[str, str]]  # ì´ë ¥ì„œ ê¸°ë°˜ìœ¼ë¡œ ì¶”ë¡ ëœ ê°œì¸ì  êµí›ˆ
    career_goal: str
    personality_traits: List[str]
    interview_style: str
    
    # --- ë©”íƒ€ë°ì´í„° ---
    generated_by: str = "gpt-4o-mini"
    resume_id: int  # ì›ë³¸ ì´ë ¥ì„œ ID

# ëª¨ë¸ë³„ AI ì§€ì›ì ì´ë¦„ ë§¤í•‘ (í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
AI_CANDIDATE_NAMES = {
    LLMProvider.OPENAI_GPT4: "ì¶˜ì‹ì´",
    LLMProvider.OPENAI_GPT35: "ì¶˜ì‹ì´", 
    LLMProvider.OPENAI_GPT4O_MINI: "ì¶˜ì‹ì´",
    LLMProvider.GOOGLE_GEMINI_PRO: "ì œë¯¸ë‹ˆ",
    LLMProvider.GOOGLE_GEMINI_FLASH: "ì œë¯¸ë‹ˆ",
    LLMProvider.KT_BELIEF: "ë¯¿ìŒì´"
}

class AICandidateSession(InterviewSession):
    """AI ì§€ì›ì ì „ìš© ë©´ì ‘ ì„¸ì…˜ - ë©´ì ‘ìì™€ ë™ì¼í•œ í”Œë¡œìš°"""
    
    def __init__(self, company_id: str, position: str, persona: CandidatePersona):
        super().__init__(company_id, position, persona.name)
        self.persona = persona
        self.ai_answers: List[QuestionAnswer] = []
        
        # ë©´ì ‘ìì™€ ë™ì¼í•œ 20ê°œ ì§ˆë¬¸ ê³„íš ì‚¬ìš©
        # ì´ë¯¸ ë¶€ëª¨ í´ë˜ìŠ¤ì—ì„œ self.question_planì´ 20ê°œë¡œ ì„¤ì •ë¨
        
    def add_ai_answer(self, qa_pair: QuestionAnswer):
        """AI ë‹µë³€ ì¶”ê°€"""
        self.ai_answers.append(qa_pair)
        # ë¶€ëª¨ í´ë˜ìŠ¤ì˜ add_qa_pair ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ê´€ì„± ìœ ì§€
        super().add_qa_pair(qa_pair)
    
    @property
    def question_answers(self) -> List[QuestionAnswer]:
        """FeedbackService í˜¸í™˜ì„±ì„ ìœ„í•œ question_answers property - conversation_history ë°˜í™˜"""
        return super().question_answers
        
    def get_persona_context(self) -> str:
        """í˜ë¥´ì†Œë‚˜ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        context = f"""
=== AI ì§€ì›ì í˜ë¥´ì†Œë‚˜ ì •ë³´ ===
ì´ë¦„: {self.persona.name}
ê²½ë ¥: {self.persona.background.get('career_years', '0')}ë…„
í˜„ì¬ ì§ì±…: {self.persona.background.get('current_position', 'ì§€ì›ì')}
ì£¼ìš” ê¸°ìˆ : {', '.join(self.persona.technical_skills[:5])}
ê°•ì : {', '.join(self.persona.strengths[:3])}
ì»¤ë¦¬ì–´ ëª©í‘œ: {self.persona.career_goal}
ì„±ê²© íŠ¹ì„±: {', '.join(self.persona.personality_traits)}
ë©´ì ‘ ìŠ¤íƒ€ì¼: {self.persona.interview_style}

=== ì£¼ìš” í”„ë¡œì íŠ¸ ===
"""
        for i, project in enumerate(self.persona.projects[:2], 1):
            context += f"{i}. {project.get('name', 'í”„ë¡œì íŠ¸')}: {project.get('description', '')}\n"
            context += f"   ê¸°ìˆ ìŠ¤íƒ: {', '.join(project.get('tech_stack', []))}\n"
            if project.get('achievements'):
                context += f"   ì„±ê³¼: {', '.join(project['achievements'])}\n"
        
        context += f"""
=== ì—…ë¬´ ê²½í—˜ ===
"""
        for exp in self.persona.experiences[:2]:
            context += f"- {exp.get('company', 'íšŒì‚¬')}: {exp.get('position', 'ê°œë°œì')} ({exp.get('period', 'ê¸°ê°„')})\n"
            if exp.get('achievements'):
                context += f"  ì„±ê³¼: {', '.join(exp['achievements'])}\n"
        
        return context
    
    def get_previous_answers_context(self) -> str:
        """ì´ì „ ë‹µë³€ ì»¨í…ìŠ¤íŠ¸ (ì¼ê´€ì„± ìœ ì§€ìš©)"""
        if not self.ai_answers:
            return ""
        
        context = "\n=== ì´ì „ ë‹µë³€ ë‚´ì—­ (ì¼ê´€ì„± ìœ ì§€) ===\n"
        for i, qa in enumerate(self.ai_answers[-3:], 1):  # ìµœê·¼ 3ê°œë§Œ
            context += f"{i}. [{qa.question_type.value}] {qa.question_content}\n"
            context += f"   ë‹µë³€: {qa.answer_content[:100]}...\n\n"
        
        return context

class AICandidateModel:
    """AI ì§€ì›ì ëª¨ë¸ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, api_key: str = None):
        self.llm_manager = LLMManager()
        self.quality_controller = AnswerQualityController()
        self.companies_data = self._load_companies_data()
        
        # AI ì§€ì›ì ì„¸ì…˜ ê´€ë¦¬
        self.ai_sessions: Dict[str, 'AICandidateSession'] = {}
        self.fixed_questions = self._load_fixed_questions()
        
        # ìƒˆë¡œìš´ LLM ê¸°ë°˜ ì‹œìŠ¤í…œì—ì„œëŠ” í˜ë¥´ì†Œë‚˜ë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•˜ë¯€ë¡œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì´ˆê¸°í™”
        self.candidate_personas: Dict[str, CandidatePersona] = {}
        self.personas_data = {"personas": {}}
        
        # API í‚¤ ìë™ ë¡œë“œ (.env íŒŒì¼ì—ì„œ)
        if not api_key:
            api_key = os.getenv('OPENAI_API_KEY')
        
        # ê¸°ë³¸ OpenAI ëª¨ë¸ ë“±ë¡
        if api_key:
            self.llm_manager.register_model(LLMProvider.OPENAI_GPT4O_MINI, api_key=api_key)
            self.llm_manager.register_model(LLMProvider.OPENAI_GPT4, api_key=api_key)
            self.llm_manager.register_model(LLMProvider.OPENAI_GPT35, api_key=api_key)
        else:
            print("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ì§ì ‘ ì „ë‹¬í•˜ì„¸ìš”.")
    
    def create_persona_for_interview(self, company_name: str, position_name: str) -> Optional[CandidatePersona]:
        """
        ì£¼ì–´ì§„ íšŒì‚¬ì™€ ì§êµ°ì— ë§ëŠ” AI ì§€ì›ì í˜ë¥´ì†Œë‚˜ë¥¼ LLMìœ¼ë¡œ ì‹¤ì‹œê°„ ìƒì„±
        
        Args:
            company_name: íšŒì‚¬ëª… (ì˜ˆ: "ë„¤ì´ë²„", "ì¹´ì¹´ì˜¤")
            position_name: ì§êµ°ëª… (ì˜ˆ: "ë°±ì—”ë“œ", "í”„ë¡ íŠ¸ì—”ë“œ")
            
        Returns:
            ìƒì„±ëœ CandidatePersona ê°ì²´ ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
        """
        try:
            print(f"ğŸ¯ {company_name} {position_name} ì§êµ° í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹œì‘...")
            
            # 1ë‹¨ê³„: ì§êµ° ID ë§¤í•‘
            position_id = self._get_position_id(position_name)
            if not position_id:
                print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì§êµ°: {position_name}")
                return None
            
            print(f"ğŸ“Š ì§êµ° ë§¤í•‘: {position_name} -> {position_id}")
            
            # 2ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì´ë ¥ì„œ ì¡°íšŒ
            resume_data = self._get_random_resume_from_db(position_id)
            if not resume_data:
                print(f"âŒ position_id {position_id}ì— í•´ë‹¹í•˜ëŠ” ì´ë ¥ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            print(f"ğŸ“‹ ì´ë ¥ì„œ ë¡œë“œ ì„±ê³µ: ID {resume_data.get('ai_resume_id', 'unknown')}")
            
            # 3ë‹¨ê³„: íšŒì‚¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            company_info = self._get_company_info(company_name)
            
            # 4ë‹¨ê³„: LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._build_persona_generation_prompt(resume_data, company_name, position_name, company_info)
            
            # 5ë‹¨ê³„: LLM í˜¸ì¶œë¡œ í˜ë¥´ì†Œë‚˜ ìƒì„± (max_tokens ëŠ˜ë¦¼)
            print(f"ğŸ¤– LLMìœ¼ë¡œ í˜ë¥´ì†Œë‚˜ ìƒì„± ì¤‘...")
            llm_response = self._generate_persona_with_extended_tokens(
                prompt,
                self._build_system_prompt_for_persona_generation()
            )
            
            if llm_response.error:
                print(f"âŒ LLM ì‘ë‹µ ì˜¤ë¥˜: {llm_response.error}")
                return None
            
            # 6ë‹¨ê³„: JSON ì‘ë‹µì„ CandidatePersona ê°ì²´ë¡œ ë³€í™˜
            persona = self._parse_llm_response_to_persona(llm_response.content, resume_data.get('ai_resume_id', 0))
            
            if persona:
                print(f"âœ… í˜ë¥´ì†Œë‚˜ ìƒì„± ì™„ë£Œ: {persona.name} ({company_name} {position_name})")
                return persona
            else:
                print(f"âŒ í˜ë¥´ì†Œë‚˜ íŒŒì‹± ì‹¤íŒ¨")
                return None
                
        except Exception as e:
            print(f"âŒ í˜ë¥´ì†Œë‚˜ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
    
    def _get_position_id(self, position_name: str) -> Optional[int]:
        """ì§êµ°ëª…ì„ position_idë¡œ ë³€í™˜"""
        position_lower = position_name.lower().replace(" ", "")
        return POSITION_MAPPING.get(position_lower)
    
    def _get_random_resume_from_db(self, position_id: int) -> Optional[Dict[str, Any]]:
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í•´ë‹¹ ì§êµ°ì˜ ì´ë ¥ì„œë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ íƒ"""
        if get_supabase_client is None:
            print("âš ï¸ Supabase í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        try:
            supabase = get_supabase_client()
            
            # í•´ë‹¹ position_idì˜ ì´ë ¥ì„œë“¤ ì¡°íšŒ
            response = supabase.table('ai_resume').select('*').eq('position_id', position_id).execute()
            
            if not response.data:
                print(f"ğŸ“„ position_id {position_id}ì— í•´ë‹¹í•˜ëŠ” ì´ë ¥ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            # ë¬´ì‘ìœ„ë¡œ í•˜ë‚˜ ì„ íƒ
            selected_resume = random.choice(response.data)
            print(f"ğŸ² {len(response.data)}ê°œ ì´ë ¥ì„œ ì¤‘ ID {selected_resume.get('ai_resume_id', 'unknown')} ì„ íƒ")
            
            return selected_resume
            
        except Exception as e:
            print(f"âŒ ì´ë ¥ì„œ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _get_company_info(self, company_name: str) -> Dict[str, Any]:
        """íšŒì‚¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        # companies_data.jsonì—ì„œ íšŒì‚¬ ì •ë³´ ì°¾ê¸°
        for company in self.companies_data.get("companies", []):
            if company.get("name", "").lower() == company_name.lower() or company.get("id", "").lower() == company_name.lower():
                return company
        
        # ì°¾ì§€ ëª»í•œ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
        return {
            "name": company_name,
            "core_competencies": [],
            "tech_focus": [],
            "talent_profile": ""
        }
    
    def _build_persona_generation_prompt(self, resume_data: Dict[str, Any], company_name: str, position_name: str, company_info: Dict[str, Any]) -> str:
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ë ¥ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLM í˜ë¥´ì†Œë‚˜ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        
        # ì´ë ¥ì„œ ë°ì´í„° ì •ë¦¬
        career = resume_data.get('career', '')
        academic = resume_data.get('academic_record', '')
        tech_skills = resume_data.get('tech', '')
        activities = resume_data.get('activities', '')
        certificates = resume_data.get('certificate', '')
        awards = resume_data.get('awards', '')
        resume_id = resume_data.get('ai_resume_id', 0)
        
        # íšŒì‚¬ ì •ë³´ ì •ë¦¬
        company_profile = company_info.get('talent_profile', '')
        core_competencies = ', '.join(company_info.get('core_competencies', []))
        tech_focus = ', '.join(company_info.get('tech_focus', []))
        
        prompt = f"""
ë‹¤ìŒ ì´ë ¥ì„œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ {company_name} {position_name} ì§êµ°ì— ì§€ì›í•˜ëŠ” ì¸ê°„ë¯¸ ë„˜ì¹˜ëŠ” AI ì§€ì›ì í˜ë¥´ì†Œë‚˜ë¥¼ ìƒì„±í•˜ì„¸ìš”.

=== ì´ë ¥ì„œ ë°ì´í„° ===
- ê²½ë ¥: {career}
- í•™ë ¥: {academic}
- ê¸°ìˆ  ìŠ¤íƒ‰: {tech_skills}
- í™œë™: {activities}
- ìê²©ì¦: {certificates}
- ìˆ˜ìƒ: {awards}

=== {company_name} íšŒì‚¬ ì •ë³´ ===
- ì¸ì¬ìƒ: {company_profile}
- í•µì‹¬ ì—­ëŸ‰: {core_competencies}
- ê¸°ìˆ  ì¤‘ì : {tech_focus}

=== ì¸ê°„ë¯¸ ë˜ëŠ” ìƒì„± ì§€ì‹œì‚¬í•­ ===
1. **ì´ë¦„ ìƒì„±**: í•œêµ­ ì´ë¦„ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ìƒì„±í•˜ì„¸ìš”.

2. **ì¸ê°„ì  ì•½ì  í¬í•¨**: ì´ë ¥ì„œì˜ ê°•ì ê³¼ í•¨ê»˜ ê°œì„ ì´ í•„ìš”í•œ ì•½ì ì„ í•œ ê°€ì§€ í¬í•¨ì‹œì¼œë¼. (ì˜ˆ: "ë„ˆë¬´ ì™„ë²½ì£¼ì˜ì ì¸ ì„±í–¥", "ëŒ€ì¸ê´€ê³„ì—ì„œ ì†Œê·¹ì ì¸ ëª¨ìŠµ")

3. **í”„ë¡œì íŠ¸ ì„±ê³¼ì™€ ì–´ë ¤ì›€**: ê° í”„ë¡œì íŠ¸ì—ëŠ” ì„±ê³µì ì¸ ì„±ê³¼(achievements)ì™€ í•¨ê»˜ ê²ªì—ˆë˜ ì–´ë ¤ì›€(challenges)ì„ í¬í•¨ì‹œì¼œë¼.

4. **ê°œì¸ì  ë™ê¸°**: ì´ ì§€ì›ìê°€ ì™œ ì´ ì§ì—…ì„ ì„ íƒí–ˆëŠ”ì§€ì— ëŒ€í•œ ê°œì¸ì ì¸ ë™ê¸°(motivation)ë¥¼ ì´ë ¥ì„œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ë¡ í•´ë¼.

5. **ê°œì¸ì  êµí›ˆ**: ì´ë ¥ì„œì˜ í™œë™(ë¸”ë¡œê·¸, ì˜¤í”ˆì†ŒìŠ¤, í”„ë¡œì íŠ¸ ë“±)ì„ ë°”íƒ•ìœ¼ë¡œ ê°œì¸ì ì¸ êµí›ˆ(inferred_personal_experiences)ì„ ì¶”ë¡ í•´ë¼. **ì ˆëŒ€ ì—†ëŠ” ì‚¬ì‹¤ì„ ì§€ì–´ë‚´ì§€ ë§ˆë¼.**

6. **JSON ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜**: ë°˜ë“œì‹œ ì•„ë˜ ì§€ì •ëœ JSON ìŠ¤í‚¤ë§ˆì— ë§ì¶°ì„œ ì‘ë‹µí•´ì•¼ í•œë‹¤.

=== ì¶œë ¥ JSON ìŠ¤í‚¤ë§ˆ ===
{{
  "name": "ì¶˜ì‹ì´",
  "summary": "ì˜ˆ: 5ë…„ì°¨ Java ë°±ì—”ë“œ ê°œë°œìë¡œ, ëŒ€ìš©ëŸ‰ íŠ¸ë˜í”½ ì²˜ë¦¬ì™€ MSA ì„¤ê³„ì— ê°•ì ì´ ìˆìŠµë‹ˆë‹¤.",
  "background": {{
    "career_years": "ì˜ˆ: 5",
    "current_position": "ì˜ˆ: ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œì",
    "education": ["ì˜ˆ: OOëŒ€í•™êµ ì»´í“¨í„°ê³µí•™ê³¼ ì¡¸ì—…"]
  }},
  "technical_skills": ["ì˜ˆ: Java", "ì˜ˆ: Spring Boot"],
  "projects": [
    {{
      "name": "ì˜ˆ: ëŒ€ìš©ëŸ‰ ê²°ì œ ì‹œìŠ¤í…œ ê°œë°œ",
      "description": "ì˜ˆ: ì¼ì¼ 100ë§Œê±´ ê²°ì œ ì²˜ë¦¬ë¥¼ ìœ„í•œ ê³ ê°€ìš©ì„± ì‹œìŠ¤í…œ êµ¬ì¶•",
      "tech_stack": ["ì˜ˆ: Java", "ì˜ˆ: Redis"],
      "role": "ì˜ˆ: ë°±ì—”ë“œ ë¦¬ë“œ ê°œë°œì",
      "achievements": ["ì˜ˆ: ì²˜ë¦¬ ì†ë„ 40% í–¥ìƒ", "ì˜ˆ: ì‹œìŠ¤í…œ ì•ˆì •ì„± 99.9% ë‹¬ì„±"],
      "challenges": ["ì˜ˆ: ëŒ€ëŸ‰ íŠ¸ë˜í”½ ë°œìƒ ì‹œ ë°ì´í„°ë² ì´ìŠ¤ ë³‘ëª© í˜„ìƒ", "ì˜ˆ: ë ˆê±°ì‹œ ì‹œìŠ¤í…œê³¼ì˜ í˜¸í™˜ì„± ë¬¸ì œ"]
    }}
  ],
  "experiences": [
    {{
      "company": "ì˜ˆ: ABC í…Œí¬",
      "position": "ì˜ˆ: ì‹œë‹ˆì–´ ê°œë°œì",
      "period": "ì˜ˆ: 2020.03 - 2024.12",
      "achievements": ["ì˜ˆ: ê²°ì œ ì‹œìŠ¤í…œ ì„±ëŠ¥ ìµœì í™”", "ì˜ˆ: ì‹ ì… ê°œë°œì 3ëª… ë©˜í† ë§"]
    }}
  ],
  "strengths": ["ì˜ˆ: ëŒ€ìš©ëŸ‰ ì‹œìŠ¤í…œ ì„¤ê³„", "ì˜ˆ: ì„±ëŠ¥ ìµœì í™”"],
  "weaknesses": ["ì˜ˆ: ì™„ë²½ì£¼ì˜ì  ì„±í–¥ìœ¼ë¡œ ë•Œë¡œ ì¼ì • ì§€ì—°"],
  "motivation": "ì˜ˆ: ëŒ€í•™ ì‹œì ˆ ì²˜ìŒ ì½”ë”©ì„ ë°°ì› ì„ ë•Œì˜ ì„±ì·¨ê°ê³¼ ë¬¸ì œ í•´ê²°ì˜ ì¦‰ì‹œì— ë§¤ë ¥ì„ ëŠê»´ ê°œë°œìì˜ ê¸¸ì„ ì„ íƒí•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.",
  "inferred_personal_experiences": [
    {{
      "category": "ì˜ˆ: í•™ìŠµê²½í—˜",
      "experience": "ì˜ˆ: ê°œë°œ ë¸”ë¡œê·¸ë¥¼ ìš´ì˜í•˜ë©° ì§€ì‹ì„ ì •ë¦¬í•˜ê³  ê³µìœ í•˜ëŠ” í™œë™ì„ ì§€ì†í•´ì˜´",
      "lesson": "ì˜ˆ: ì§€ì‹ì„ ë‚¨ê³¼ ê³µìœ í•  ë•Œ ë” ê¹Šì´ ì´í•´í•˜ê²Œ ë˜ê³ , ë‹¤ë¥¸ ì‚¬ëŒë“¤ì˜ í”¼ë“œë°±ìœ¼ë¡œ ì„±ì¥í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ë°°ì› ìŠµë‹ˆë‹¤."
    }}
  ],
  "career_goal": "ì˜ˆ: {company_name}ì˜ ê³ ê°€ìš©ì„± ì‹œìŠ¤í…œì„ ì±…ì„ì§€ëŠ” ê¸°ìˆ  ë¦¬ë”ë¡œ ì„±ì¥í•˜ì—¬, ì „ ì„¸ê³„ ì‚¬ìš©ìë“¤ì—ê²Œ ì•ˆì •ì ì´ê³  ë¹ ë¥¸ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.",
  "personality_traits": ["ì˜ˆ: ë¶„ì„ì ", "ì˜ˆ: ì¶”ì§„ë ¥ ìˆëŠ”"],
  "interview_style": "ì˜ˆ: êµ¬ì²´ì ì¸ ê²½í—˜ê³¼ ìˆ˜ì¹˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì²´ê³„ì ìœ¼ë¡œ ì„¤ëª…í•˜ëŠ” ìŠ¤íƒ€ì¼",
  "generated_by": "gpt-4o-mini",
  "resume_id": {resume_id}
}}

**ì¤‘ìš”**: 
1. ì´ë¦„ì€ ë°˜ë“œì‹œ "ì¶˜ì‹ì´"ë¡œ ì„¤ì •í•˜ì„¸ìš”.
2. ì˜¤ì§ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ê³ , ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ì£¼ì„ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
"""
        return prompt.strip()
    
    def _build_system_prompt_for_persona_generation(self) -> str:
        """í˜ë¥´ì†Œë‚˜ ìƒì„±ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return """ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ AI í˜ë¥´ì†Œë‚˜ ìƒì„± ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
ì´ë ¥ì„œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸ê°„ì ì´ê³  í˜„ì‹¤ì ì¸ AI ì§€ì›ì í˜ë¥´ì†Œë‚˜ë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

í•€ìˆ˜ ì§€ì‹œì‚¬í•­:
1. ì´ë ¥ì„œì— ìˆëŠ” ì‚¬ì‹¤ë§Œ ê¸°ë°˜ìœ¼ë¡œ ì¶”ë¡ í•˜ê³ , ì—†ëŠ” ì‚¬ì‹¤ì€ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
2. ì¸ê°„ì ì¸ ë§¤ë ¥ê³¼ ì•½ì ì„ ëª¨ë‘ í¬í•¨í•˜ì—¬ í˜„ì‹¤ì ì¸ ì¸ë¬¼ë¡œ ë§Œë“œì„¸ìš”.
3. íšŒì‚¬ì™€ ì§êµ°ì˜ íŠ¹ì„±ì— ë§ëŠ” í˜ë¥´ì†Œë‚˜ë¥¼ ìƒì„±í•˜ì„¸ìš”.
4. ë°˜ë“œì‹œ ì§€ì •ëœ JSON ìŠ¤í‚¤ë§ˆì— ë§ì¶° ì‘ë‹µí•˜ì„¸ìš”.
5. JSON ì™¸ì˜ ë‹¤ë¥¸ ë‚´ìš©ì€ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”."""
    
    def _generate_persona_with_extended_tokens(self, prompt: str, system_prompt: str) -> LLMResponse:
        """í˜ë¥´ì†Œë‚˜ ìƒì„±ìš© í™•ì¥ëœ í† í°ìœ¼ë¡œ LLM í˜¸ì¶œ"""
        import openai
        import os
        import time
        
        try:
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ì§ì ‘ ìƒì„±
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                return LLMResponse(
                    content="",
                    provider=LLMProvider.OPENAI_GPT4O_MINI,
                    model_name="gpt-4o-mini",
                    error="OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                )
            
            client = openai.OpenAI(api_key=api_key)
            start_time = time.time()
            
            messages = []
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            messages.append({"role": "user", "content": prompt})
            
            # í˜ë¥´ì†Œë‚˜ ìƒì„±ìš© í™•ì¥ íŒŒë¼ë¯¸í„°
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                max_tokens=1500,  # í˜ë¥´ì†Œë‚˜ ìƒì„±ì„ ìœ„í•´ ì¶©ë¶„í•œ í† í° í• ë‹¹
                temperature=0.7,
                timeout=60.0
            )
            
            response_time = time.time() - start_time
            
            return LLMResponse(
                content=response.choices[0].message.content.strip(),
                provider=LLMProvider.OPENAI_GPT4O_MINI,
                model_name="gpt-4o-mini",
                token_count=response.usage.total_tokens if response.usage else None,
                response_time=response_time
            )
            
        except Exception as e:
            return LLMResponse(
                content="",
                provider=LLMProvider.OPENAI_GPT4O_MINI,
                model_name="gpt-4o-mini",
                error=f"í˜ë¥´ì†Œë‚˜ ìƒì„± LLM í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"
            )
    
    def _parse_llm_response_to_persona(self, llm_response: str, resume_id: int) -> Optional[CandidatePersona]:
        """LLM JSON ì‘ë‹µì„ CandidatePersona ê°ì²´ë¡œ íŒŒì‹±"""
        try:
            # JSON ì˜ì—­ë§Œ ì¶”ì¶œ (ì „í›„ ì„¤ëª… ì œê±°)
            response_clean = llm_response.strip()
            
            # JSON ë¸”ë¡ ì°¾ê¸°
            if response_clean.startswith('```json'):
                response_clean = response_clean.replace('```json', '').replace('```', '').strip()
            elif response_clean.startswith('```'):
                response_clean = response_clean.replace('```', '').strip()
            
            # JSON íŒŒì‹±
            persona_data = json.loads(response_clean)
            
            # í•„ìˆ˜ í•„ë“œ ê²€ì¦
            required_fields = ['name', 'summary', 'background', 'technical_skills', 'projects', 'experiences', 
                              'strengths', 'weaknesses', 'motivation', 'inferred_personal_experiences', 
                              'career_goal', 'personality_traits', 'interview_style']
            
            for field in required_fields:
                if field not in persona_data:
                    print(f"âŒ í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
                    return None
            
            # CandidatePersona ê°ì²´ ìƒì„±
            persona = CandidatePersona(
                name=persona_data['name'],
                summary=persona_data['summary'],
                background=persona_data['background'],
                technical_skills=persona_data['technical_skills'],
                projects=persona_data['projects'],
                experiences=persona_data['experiences'],
                strengths=persona_data['strengths'],
                weaknesses=persona_data['weaknesses'],
                motivation=persona_data['motivation'],
                inferred_personal_experiences=persona_data['inferred_personal_experiences'],
                career_goal=persona_data['career_goal'],
                personality_traits=persona_data['personality_traits'],
                interview_style=persona_data['interview_style'],
                generated_by=persona_data.get('generated_by', 'gpt-4o-mini'),
                resume_id=resume_id
            )
            
            return persona
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            print(f"LLM ì‘ë‹µ ê¸¸ì´: {len(llm_response)} ë¬¸ì")
            print(f"ì‘ë‹µ ë§ˆì§€ë§‰ 100ì: ...{llm_response[-100:]}")
            return None
        except Exception as e:
            print(f"âŒ í˜ë¥´ì†Œë‚˜ ê°ì²´ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _load_companies_data(self) -> Dict[str, Any]:
        """íšŒì‚¬ ë°ì´í„° ë¡œë“œ"""
        return safe_json_load("llm/data/companies_data.json", {"companies": []})
    
    def _load_fixed_questions(self) -> Dict[str, List[Dict]]:
        """ê³ ì • ì§ˆë¬¸ ë°ì´í„° ë¡œë“œ"""
        return get_fixed_questions()
    
    def start_ai_interview(self, company_id: str, position: str) -> str:
        """AI ì§€ì›ì ë©´ì ‘ ì‹œì‘ (ë©´ì ‘ìì™€ ë™ì¼í•œ í”Œë¡œìš°)"""
        persona = self.get_persona(company_id)
        if not persona:
            raise ValueError(f"íšŒì‚¬ {company_id}ì˜ AI ì§€ì›ì í˜ë¥´ì†Œë‚˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # AI ì„¸ì…˜ ìƒì„±
        ai_session = AICandidateSession(company_id, position, persona)
        self.ai_sessions[ai_session.session_id] = ai_session
        
        return ai_session.session_id
    
    def get_ai_next_question(self, ai_session_id: str) -> Optional[Dict[str, Any]]:
        """AI ì§€ì›ì ë‹¤ìŒ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸° (ë©´ì ‘ìì™€ ë™ì¼í•œ êµ¬ì¡°)"""
        ai_session = self.ai_sessions.get(ai_session_id)
        if not ai_session or ai_session.is_complete():
            return None
        
        # í˜„ì¬ ì§ˆë¬¸ ê³„íš ê°€ì ¸ì˜¤ê¸°
        question_plan = ai_session.get_next_question_plan()
        if not question_plan:
            return None
        
        # ë©´ì ‘ìì™€ ë™ì¼í•œ ì§ˆë¬¸ ìƒì„± ë¡œì§
        question_content, question_intent = self._generate_ai_question(
            ai_session, question_plan
        )
        
        return {
            "question_id": f"ai_q_{ai_session.current_question_count + 1}",
            "question_type": question_plan["type"].value,
            "question_content": question_content,
            "question_intent": question_intent,
            "progress": f"{ai_session.current_question_count + 1}/{len(ai_session.question_plan)}",
            "personalized": False  # AIëŠ” í‘œì¤€ ì§ˆë¬¸ ì‚¬ìš©
        }
    
    def _generate_ai_question(self, ai_session: AICandidateSession, question_plan: Dict) -> tuple[str, str]:
        """AI ì§€ì›ììš© ì§ˆë¬¸ ìƒì„± (ë©´ì ‘ìì™€ ë™ì¼í•œ ë¡œì§)"""
        question_type = question_plan["type"]
        
        # AI ì´ë¦„ ê°€ì ¸ì˜¤ê¸° (ì¶˜ì‹ì´)
        ai_name = self.get_ai_name(LLMProvider.OPENAI_GPT35)
        
        # ì²« ë‘ ì§ˆë¬¸ì€ ì™„ì „íˆ ê³ ì • (AI ì „ìš© - honorific í¬í•¨)
        if question_type == QuestionType.INTRO:
            return (
                f"{ai_name}ë‹˜, ìê¸°ì†Œê°œë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤.",
                "ì§€ì›ìì˜ ê¸°ë³¸ ë°°ê²½, ê²½ë ¥, ì„±ê²©ì„ íŒŒì•…í•˜ì—¬ ë©´ì ‘ ë¶„ìœ„ê¸°ë¥¼ ì¡°ì„±"
            )
        elif question_type == QuestionType.MOTIVATION:
            company_data = self._get_company_data(ai_session.company_id)
            return (
                f"{ai_name}ë‹˜ê»˜ì„œ {company_data.get('name', 'ì €í¬ íšŒì‚¬')}ì— ì§€ì›í•˜ê²Œ ëœ ë™ê¸°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                "íšŒì‚¬ì— ëŒ€í•œ ê´€ì‹¬ë„, ì§€ì› ì˜ì§€, íšŒì‚¬ ì´í•´ë„ë¥¼ í‰ê°€"
            )
        
        # ê³ ì • ì§ˆë¬¸ í’€ì—ì„œ ì„ íƒ
        if question_type == QuestionType.HR:
            questions = self.fixed_questions.get("hr_questions", [])
        elif question_type == QuestionType.TECH:
            questions = self.fixed_questions.get("technical_questions", [])
        elif question_type == QuestionType.COLLABORATION:
            questions = self.fixed_questions.get("collaboration_questions", [])
        else:
            # FOLLOWUPì´ë‚˜ ê¸°íƒ€ ì§ˆë¬¸ì€ ë™ì  ìƒì„±
            return self._generate_dynamic_question(ai_session, question_type)
        
        # ì´ë¯¸ ì‚¬ìš©ëœ ì§ˆë¬¸ ì œì™¸
        used_questions = set()
        for qa in ai_session.ai_answers:
            used_questions.add(qa.question_content)
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì§ˆë¬¸ í•„í„°ë§
        available_questions = [q for q in questions if q["content"] not in used_questions]
        
        if available_questions:
            # ë ˆë²¨ì— ë”°ë¼ ì •ë ¬ëœ ì§ˆë¬¸ ì„ íƒ
            current_question_index = ai_session.current_question_count
            if current_question_index < len(available_questions):
                selected_question = available_questions[current_question_index % len(available_questions)]
            else:
                selected_question = available_questions[0]
            
            # ì§ˆë¬¸ì— AI ì´ë¦„ í˜¸ì¹­ ì¶”ê°€
            ai_name = self.get_ai_name(LLMProvider.OPENAI_GPT35)
            question_content = self._add_honorific_to_question(selected_question["content"], ai_name)
            return question_content, selected_question["intent"]
        
        # í´ë°± ì§ˆë¬¸
        ai_name = self.get_ai_name(LLMProvider.OPENAI_GPT35)
        return self._get_fallback_question(question_type, ai_name)
    
    def _generate_dynamic_question(self, ai_session: AICandidateSession, question_type: QuestionType) -> tuple[str, str]:
        """ë™ì  ì§ˆë¬¸ ìƒì„± (ì‹¬í™” ì§ˆë¬¸ ë“±)"""
        context = ai_session.get_previous_answers_context()
        company_data = self._get_company_data(ai_session.company_id)
        
        if question_type == QuestionType.FOLLOWUP:
            # ì´ì „ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ì‹¬í™” ì§ˆë¬¸
            if ai_session.ai_answers:
                last_answer = ai_session.ai_answers[-1]
                return (
                    f"ë°©ê¸ˆ ë§ì”€í•˜ì‹  {last_answer.question_content[:30]}... ë¶€ë¶„ì— ëŒ€í•´ ì¢€ ë” ìì„¸íˆ ì„¤ëª…í•´ ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?",
                    "ì´ì „ ë‹µë³€ì˜ êµ¬ì²´ì ì¸ ì‚¬ë¡€ë‚˜ ê²½í—˜ì˜ ë””í…Œì¼ íƒêµ¬"
                )
        
        ai_name = self.get_ai_name(LLMProvider.OPENAI_GPT35)
        return f"{ai_name}ë‹˜ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ìŠµë‹ˆë‹¤.", "ì¼ë°˜ì ì¸ ì§ˆë¬¸"
    
    def _get_fallback_question(self, question_type: QuestionType, persona_name: str) -> tuple[str, str]:
        """í´ë°± ì§ˆë¬¸ (ë©´ì ‘ìì™€ ë™ì¼)"""
        fallback_questions = {
            QuestionType.INTRO: (f"{persona_name}ë‹˜, ê°„ë‹¨í•œ ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.", "ê¸°ë³¸ ë°°ê²½ íŒŒì•…"),
            QuestionType.MOTIVATION: (f"{persona_name}ë‹˜ì´ ì €í¬ íšŒì‚¬ì— ì§€ì›í•˜ê²Œ ëœ ë™ê¸°ê°€ ê¶ê¸ˆí•©ë‹ˆë‹¤.", "ì§€ì› ë™ê¸° íŒŒì•…"),
            QuestionType.HR: (f"{persona_name}ë‹˜ì˜ ì¥ì ê³¼ ì„±ì¥í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì€ ë¬´ì—‡ì¸ê°€ìš”?", "ê°œì¸ì  íŠ¹ì„± í‰ê°€"),
            QuestionType.TECH: (f"{persona_name}ë‹˜ì˜ ê¸°ìˆ ì  ê²½í—˜ì— ëŒ€í•´ ë§ì”€í•´ ì£¼ì„¸ìš”.", "ê¸°ìˆ  ì—­ëŸ‰ í‰ê°€"),
            QuestionType.COLLABORATION: (f"{persona_name}ë‹˜ì˜ íŒ€ í˜‘ì—… ê²½í—˜ì„ ê³µìœ í•´ ì£¼ì„¸ìš”.", "í˜‘ì—… ëŠ¥ë ¥ í‰ê°€"),
            QuestionType.FOLLOWUP: (f"{persona_name}ë‹˜ì´ ê°€ì¥ ìì‹  ìˆëŠ” ê²½í—˜ì„ ë” ìì„¸íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”.", "ì‹¬í™” íƒêµ¬")
        }
        return fallback_questions.get(question_type, (f"{persona_name}ë‹˜, ë³¸ì¸ì— ëŒ€í•´ ë§ì”€í•´ ì£¼ì„¸ìš”.", "ì¼ë°˜ì ì¸ ì§ˆë¬¸"))
    
    def _add_honorific_to_question(self, question_content: str, ai_name: str) -> str:
        """ì§ˆë¬¸ì— AI ì´ë¦„ í˜¸ì¹­ ì¶”ê°€"""
        # ì´ë¯¸ í˜¸ì¹­ì´ í¬í•¨ëœ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
        if "ë‹˜" in question_content or ai_name in question_content:
            return question_content
        
        # ì§ˆë¬¸ ì•ì— í˜¸ì¹­ ì¶”ê°€
        return f"{ai_name}ë‹˜, {question_content}"

    def generate_ai_answer_for_question(self, ai_session_id: str, question_data: Dict[str, Any]) -> AnswerResponse:
        """íŠ¹ì • ì§ˆë¬¸ì— ëŒ€í•œ AI ë‹µë³€ ìƒì„± (ì¼ê´€ì„± ìœ ì§€)"""
        ai_session = self.ai_sessions.get(ai_session_id)
        if not ai_session:
            return AnswerResponse(
                answer_content="",
                quality_level=QualityLevel(8),
                llm_provider=LLMProvider.OPENAI_GPT4O_MINI,
                persona_name="Unknown",
                confidence_score=0.0,
                response_time=0.0,
                reasoning="AI ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ",
                error=f"AI ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ai_session_id}"
            )
        
        # ì¼ê´€ì„± ìˆëŠ” ë‹µë³€ ìƒì„±ì„ ìœ„í•œ ìš”ì²­ êµ¬ì„±
        request = AnswerRequest(
            question_content=question_data["question_content"],
            question_type=QuestionType(question_data["question_type"]),
            question_intent=question_data["question_intent"],
            company_id=ai_session.company_id,
            position=ai_session.position,
            quality_level=QualityLevel(8),  # ê³ í’ˆì§ˆ ë‹µë³€
            llm_provider=LLMProvider.OPENAI_GPT4O_MINI,
            additional_context=ai_session.get_previous_answers_context()
        )
        
        # ë‹µë³€ ìƒì„±
        answer_response = self.generate_answer(request)
        
        # AI ì„¸ì…˜ì— ë‹µë³€ ì €ì¥
        if not answer_response.error:
            qa_pair = QuestionAnswer(
                question_id=question_data["question_id"],
                question_type=QuestionType(question_data["question_type"]),
                question_content=question_data["question_content"],
                answer_content=answer_response.answer_content,
                timestamp=datetime.now(),
                question_intent=question_data["question_intent"]
            )
            ai_session.add_ai_answer(qa_pair)
        
        return answer_response
    
    def _parse_personas_data(self, personas_data: Dict) -> Dict[str, CandidatePersona]:
        """í˜ë¥´ì†Œë‚˜ ë°ì´í„° íŒŒì‹±"""
        personas = {}
        for company_id, data in personas_data.items():
            personas[company_id] = CandidatePersona(
                company_id=company_id,
                name=data.get("name", f"ì§€ì›ì_{company_id}"),
                background=data.get("background", {}),
                technical_skills=data.get("technical_skills", []),
                projects=data.get("projects", []),
                experiences=data.get("experiences", []),
                strengths=data.get("strengths", []),
                achievements=data.get("achievements", []),
                career_goal=data.get("career_goal", ""),
                personality_traits=data.get("personality_traits", []),
                interview_style=data.get("interview_style", ""),
                success_factors=data.get("success_factors", [])
            )
        return personas
    
    def get_persona(self, company_id: str) -> Optional[CandidatePersona]:
        """íšŒì‚¬ë³„ í˜ë¥´ì†Œë‚˜ ì¡°íšŒ (ë™ì  ìƒì„± ì‹œìŠ¤í…œì—ì„œëŠ” deprecated)"""
        print(f"âš ï¸ get_persona() ë©”ì„œë“œëŠ” deprecatedì…ë‹ˆë‹¤. create_persona_for_interview()ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        print(f"ğŸ” í˜ë¥´ì†Œë‚˜ ì¡°íšŒ ìš”ì²­: {company_id}")
        print(f"ğŸ” ìºì‹œëœ í˜ë¥´ì†Œë‚˜: {list(self.candidate_personas.keys())}")
        persona = self.candidate_personas.get(company_id)
        if persona:
            print(f"âœ… ìºì‹œëœ í˜ë¥´ì†Œë‚˜ ì°¾ìŒ: {persona.name}")
        else:
            print(f"âŒ ìºì‹œëœ í˜ë¥´ì†Œë‚˜ ì—†ìŒ: {company_id}")
        return persona
    
    def generate_answer(self, request: AnswerRequest) -> AnswerResponse:
        """ì§ˆë¬¸ì— ëŒ€í•œ AI ì§€ì›ì ë‹µë³€ ìƒì„±"""
        start_time = datetime.now()
        
        # í˜ë¥´ì†Œë‚˜ ì¡°íšŒ
        persona = self.get_persona(request.company_id)
        if not persona:
            return AnswerResponse(
                answer_content="",
                quality_level=request.quality_level,
                llm_provider=request.llm_provider,
                persona_name="Unknown",
                confidence_score=0.0,
                response_time=0.0,
                reasoning="í˜ë¥´ì†Œë‚˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ",
                error=f"íšŒì‚¬ {request.company_id}ì˜ í˜ë¥´ì†Œë‚˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
        
        # íšŒì‚¬ ë°ì´í„° ì¡°íšŒ
        company_data = self._get_company_data(request.company_id)
        
        # ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self._build_answer_prompt(request, persona, company_data)
        system_prompt = self._build_system_prompt(persona, company_data, request.question_type, request.llm_provider)
        
        # í’ˆì§ˆ ë ˆë²¨ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ì¡°ì •
        quality_prompt = self.quality_controller.generate_quality_prompt(
            prompt, 
            request.quality_level,
            request.question_type.value
        )
        
        # LLM ì‘ë‹µ ìƒì„±
        llm_response = self.llm_manager.generate_response(
            request.llm_provider,
            quality_prompt,
            system_prompt
        )
        
        # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
        response_time = (datetime.now() - start_time).total_seconds()
        
        # ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
        confidence_score = self._calculate_confidence_score(llm_response, request.quality_level)
        
        # ë‹µë³€ í›„ì²˜ë¦¬
        processed_answer = self._post_process_answer(llm_response.content, request.quality_level)
        
        # ëª¨ë¸ì— ë”°ë¥¸ AI ì´ë¦„ ê²°ì •
        ai_name = self.get_ai_name(request.llm_provider)
        
        return AnswerResponse(
            answer_content=processed_answer,
            quality_level=request.quality_level,
            llm_provider=request.llm_provider,
            persona_name=ai_name,  # ëª¨ë¸ë³„ ê³ ì • ì´ë¦„ ì‚¬ìš©
            confidence_score=confidence_score,
            response_time=response_time,
            reasoning=f"{ai_name}ì˜ {request.company_id} ë©´ì ‘ ë‹µë³€ (í’ˆì§ˆ ë ˆë²¨: {request.quality_level.value})",
            error=llm_response.error,
            metadata={
                "token_count": llm_response.token_count,
                "company_id": request.company_id,
                "question_type": request.question_type.value,
                "original_prompt_length": len(prompt)
            }
        )
    
    def _get_relevant_personal_experiences(self, persona: CandidatePersona, question_content: str) -> str:
        """ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê°œì¸ì  ê²½í—˜ ì„ ë³„"""
        
        # í˜ë¥´ì†Œë‚˜ì—ì„œ ê°œì¸ ê²½í—˜ ì¶”ì¶œ
        personal_experiences = self._get_persona_attribute(persona, 'personal_experiences', [])
        if not personal_experiences:
            return "ê°œì¸ì  ê²½í—˜: ì„±ì‹¤í•˜ê³  ê¾¸ì¤€íˆ ë…¸ë ¥í•˜ëŠ” ì„±ê²©ìœ¼ë¡œ, ì–´ë ¤ìš´ ìƒí™©ì—ì„œë„ í¬ê¸°í•˜ì§€ ì•Šê³  ëê¹Œì§€ ìµœì„ ì„ ë‹¤í•˜ëŠ” ê²ƒì„ ì¤‘ìš”í•˜ê²Œ ìƒê°í•©ë‹ˆë‹¤."
        
        # ì§ˆë¬¸ ë‚´ìš©ì— ë”°ë¼ ê´€ë ¨ ê²½í—˜ ì„ ë³„
        question_lower = question_content.lower()
        relevant_experiences = []
        
        # í‚¤ì›Œë“œ ë§¤í•‘
        keyword_category_map = {
            "ê°€ì¹˜ê´€": ["ê°€ì¹˜ê´€í˜•ì„±", "ê°œì¸ë„ì „"],
            "ì„±ê²©": ["ì¸ê°„ê´€ê³„", "ê°œì¸ë„ì „"],
            "ê°•ì ": ["í•™ì°½ì‹œì ˆ", "ê°œì¸ë„ì „", "ì‹¤íŒ¨ê·¹ë³µ"],
            "ì•½ì ": ["ì‹¤íŒ¨ê·¹ë³µ", "ì¸ê°„ê´€ê³„"],
            "ì„±ì¥": ["ê°œì¸ë„ì „", "ì‹¤íŒ¨ê·¹ë³µ", "í•™ì°½ì‹œì ˆ"],
            "ëª©í‘œ": ["ê°€ì¹˜ê´€í˜•ì„±", "ê°œì¸ë„ì „"],
            "ë„ì „": ["ê°œì¸ë„ì „", "ì‹¤íŒ¨ê·¹ë³µ"],
            "í˜‘ì—…": ["ì¸ê°„ê´€ê³„", "í•™ì°½ì‹œì ˆ"],
            "ì†Œí†µ": ["ì¸ê°„ê´€ê³„", "í•™ì°½ì‹œì ˆ"],
            "ë¦¬ë”ì‹­": ["í•™ì°½ì‹œì ˆ", "ì¸ê°„ê´€ê³„"],
            "ì‹¤íŒ¨": ["ì‹¤íŒ¨ê·¹ë³µ"],
            "ì–´ë ¤ì›€": ["ì‹¤íŒ¨ê·¹ë³µ", "ê°€ì¹˜ê´€í˜•ì„±"]
        }
        
        # ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
        matched_categories = set()
        for keyword, categories in keyword_category_map.items():
            if keyword in question_lower:
                matched_categories.update(categories)
        
        # ê´€ë ¨ ê²½í—˜ ì„ ë³„
        for exp in personal_experiences:
            if not matched_categories or exp.get('category') in matched_categories:
                relevant_experiences.append(exp)
        
        # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ ì„ ë³„
        if not relevant_experiences:
            relevant_experiences = personal_experiences[:3]
        else:
            relevant_experiences = relevant_experiences[:3]
        
        # ê²½í—˜ë“¤ì„ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…
        experience_text = ""
        for i, exp in enumerate(relevant_experiences, 1):
            experience_text += f"""
{i}. [{exp.get('category', 'ê°œì¸ê²½í—˜')}] {exp.get('experience', '')}
   ë°°ìš´ ì : {exp.get('lesson', '')}
   ê°ì •: {exp.get('emotion', '')}
"""
        
        return experience_text.strip()
    
    def _get_persona_attribute(self, persona: CandidatePersona, attr_name: str, default_value):
        """í˜ë¥´ì†Œë‚˜ ì†ì„± ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # í˜ë¥´ì†Œë‚˜ ê°ì²´ì—ì„œ ì§ì ‘ ì†ì„± ì ‘ê·¼
            if hasattr(persona, attr_name):
                return getattr(persona, attr_name)
            
            # ì‚¬ì „ í˜•íƒœë¡œ ì ‘ê·¼ (í˜ë¥´ì†Œë‚˜ê°€ dictì¸ ê²½ìš°)
            if hasattr(persona, '__dict__') and attr_name in persona.__dict__:
                return persona.__dict__[attr_name]
            
            # JSON ë°ì´í„°ì—ì„œ ì§ì ‘ ë¡œë“œí•œ ê²½ìš° - _raw_data ì†ì„± í™•ì¸
            if hasattr(persona, '_raw_data') and attr_name in persona._raw_data:
                return persona._raw_data[attr_name]
            
            # í˜ë¥´ì†Œë‚˜ ë”•ì…”ë„ˆë¦¬ì—ì„œ ì§ì ‘ ì ‘ê·¼ ì‹œë„
            persona_dict = self._get_persona_dict(persona.company_id, persona.name)
            if persona_dict and attr_name in persona_dict:
                return persona_dict[attr_name]
                
            return default_value
        except:
            return default_value
    
    def _get_persona_dict(self, company_id: str, persona_name: str) -> Dict[str, Any]:
        """í˜ë¥´ì†Œë‚˜ ë”•ì…”ë„ˆë¦¬ ì§ì ‘ ì¡°íšŒ"""
        try:
            personas = self.personas_data.get("personas", {})
            if company_id in personas:
                return personas[company_id]
            return {}
        except:
            return {}
    
    def _get_company_data(self, company_id: str) -> Dict[str, Any]:
        """íšŒì‚¬ ë°ì´í„° ì¡°íšŒ"""
        for company in self.companies_data.get("companies", []):
            if company["id"] == company_id:
                return company
        return {}
    
    def get_ai_name(self, llm_provider: LLMProvider) -> str:
        """ëª¨ë¸ì— ë”°ë¥¸ AI ì§€ì›ì ì´ë¦„ ë°˜í™˜"""
        return AI_CANDIDATE_NAMES.get(llm_provider, "ì¶˜ì‹ì´")  # ê¸°ë³¸ê°’: ì¶˜ì‹ì´
    
    def _build_system_prompt(self, persona: CandidatePersona, company_data: Dict, question_type: QuestionType, llm_provider: LLMProvider = LLMProvider.OPENAI_GPT35) -> str:
        """ì§ˆë¬¸ íƒ€ì…ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        
        # AI ì´ë¦„ ê²°ì • (ëª¨ë¸ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì„¤ì •)
        ai_name = self.get_ai_name(llm_provider)
        
        base_info = f"""ë‹¹ì‹ ì€ {company_data.get('name', 'íšŒì‚¬')} ë©´ì ‘ì— ì°¸ì—¬í•œ ìš°ìˆ˜í•œ ì§€ì›ìì…ë‹ˆë‹¤.

=== ì¤‘ìš”: ë‹¹ì‹ ì˜ ì´ë¦„ì€ "{ai_name}"ì…ë‹ˆë‹¤ ===
- **ìê¸°ì†Œê°œ ì§ˆë¬¸(INTRO)ì—ì„œë§Œ** "{ai_name}"ë¼ê³  ì´ë¦„ì„ ì–¸ê¸‰í•˜ì„¸ìš”
- **ë‹¤ë¥¸ ëª¨ë“  ì§ˆë¬¸ì—ì„œëŠ” ì ˆëŒ€ ì´ë¦„ì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”**
- "ì•ˆë…•í•˜ì„¸ìš”" ê°™ì€ ì¸ì‚¬ë§ë„ ìê¸°ì†Œê°œê°€ ì•„ë‹Œ ê²½ìš° ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ë‹¤ë¥¸ ì´ë¦„(ê¹€ë„¤ì´ë²„, ë°•ì¹´ì¹´ì˜¤ ë“±)ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”

ì˜ˆì‹œ:
- ìê¸°ì†Œê°œ: "ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” {ai_name}ë¼ê³  í•©ë‹ˆë‹¤. 5ë…„ì˜ ë°±ì—”ë“œ ê°œë°œ ê²½í—˜ì„..."
- ì§€ì›ë™ê¸°: "ì œê°€ ë„¤ì´ë²„ì— ì§€ì›í•˜ê²Œ ëœ ì´ìœ ëŠ”..." (ì´ë¦„/ì¸ì‚¬ ì—†ì´ ë°”ë¡œ ì‹œì‘)
- ê¸°ìˆ ì§ˆë¬¸: "ê·¸ ë¶€ë¶„ì— ëŒ€í•´ì„œëŠ” ì œ ê²½í—˜ì„ ë§ì”€ë“œë¦¬ë©´..." (ì´ë¦„/ì¸ì‚¬ ì—†ì´)
- ê¸°íƒ€ì§ˆë¬¸: "ì œ ìƒê°ì—ëŠ”..." ë˜ëŠ” "ì €ì˜ ê²½í—˜ìœ¼ë¡œëŠ”..." (ì´ë¦„/ì¸ì‚¬ ì—†ì´)

=== ë‹¹ì‹ ì˜ ë°°ê²½ ===
- ê²½ë ¥: {persona.background.get('career_years', '0')}ë…„
- í˜„ì¬ ì§ì±…: {persona.background.get('current_position', 'ì§€ì›ì')}
- ì„±ê²© íŠ¹ì„±: {', '.join(persona.personality_traits)}
- ë©´ì ‘ ìŠ¤íƒ€ì¼: {persona.interview_style}

=== ë‹¹ì‹ ì˜ ê°•ì  ===
{', '.join(persona.strengths)}

=== ë‹¹ì‹ ì˜ ëª©í‘œ ===
{persona.career_goal}"""

        if question_type == QuestionType.INTRO:
            return f"""{base_info}

=== ìê¸°ì†Œê°œ ì§ˆë¬¸ ë‹µë³€ ìŠ¤íƒ€ì¼ ===
- **ë°˜ë“œì‹œ "{ai_name}"ë¼ê³  ì´ë¦„ì„ ë¨¼ì € ì†Œê°œí•˜ì„¸ìš”**
- ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ìì‹ ì„ ì†Œê°œí•˜ì„¸ìš”
- ì£¼ìš” ê²½ë ¥ê³¼ ê°•ì ì„ ê°„ëµíˆ ì–¸ê¸‰í•˜ì„¸ìš”
- ë©´ì ‘ì— ëŒ€í•œ ê°ì‚¬ ì¸ì‚¬ë¥¼ í¬í•¨í•˜ì„¸ìš”
- ì˜ˆ: "ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” {ai_name}ë¼ê³  í•©ë‹ˆë‹¤. 5ë…„ì˜ ë°±ì—”ë“œ ê°œë°œ ê²½í—˜ì„ ê°€ì§€ê³  ìˆìœ¼ë©°..."

**ì¤‘ìš”**: ìê¸°ì†Œê°œ ì§ˆë¬¸ì—ì„œë§Œ ì´ë¦„ì„ ì–¸ê¸‰í•˜ì„¸ìš”. ë‹¤ë¥¸ ëª¨ë“  ì§ˆë¬¸ì—ì„œëŠ” ì´ë¦„ì„ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”."""
        
        elif question_type == QuestionType.HR:
            return f"""{base_info}

=== ì¸ì„± ì§ˆë¬¸ ë‹µë³€ ìŠ¤íƒ€ì¼ ===
- **ì ˆëŒ€ ì´ë¦„ì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”** (ì´ë¯¸ ìê¸°ì†Œê°œì—ì„œ í–ˆìŒ)
- **"ì•ˆë…•í•˜ì„¸ìš”" ê°™ì€ ì¸ì‚¬ë§ ì‚¬ìš© ê¸ˆì§€**
- ë°”ë¡œ ë‹µë³€ ë‚´ìš©ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”
- **ê°œì¸ì ì´ê³  ì§„ì •ì„± ìˆê²Œ** ë‹µë³€í•˜ì„¸ìš”
- ê¸°ìˆ ì /í”„ë¡œì íŠ¸ ê²½í—˜ë³´ë‹¤ëŠ” **ê°œì¸ì  ê²½í—˜ê³¼ ê°ì •**ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€
- ë‹¹ì‹ ì˜ **ê°€ì¹˜ê´€, ì„±ê²©, ì¸ìƒ ì² í•™**ì„ ë“œëŸ¬ë‚´ì„¸ìš”
- "ì œ ê²½í—˜ì„ ë§ì”€ë“œë¦¬ë©´..." "ì €ëŠ” ê°œì¸ì ìœ¼ë¡œ..." ê°™ì€ í‘œí˜„ ì‚¬ìš©
- **ì†”ì§í•˜ê³  ì¸ê°„ì ì¸** ë©´ëª¨ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”
- êµ¬ì²´ì ì¸ ê°œì¸ ê²½í—˜ê³¼ ê·¸ë•Œì˜ **ê°ì •, ìƒê°ì˜ ë³€í™”**ë¥¼ í¬í•¨í•˜ì„¸ìš”"""
        
        elif question_type == QuestionType.TECH:
            return f"""{base_info}

=== ê¸°ìˆ  ì§ˆë¬¸ ë‹µë³€ ìŠ¤íƒ€ì¼ ===
- **ì´ë¦„ì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”** (ì´ë¯¸ ìê¸°ì†Œê°œì—ì„œ í–ˆìŒ)
- ê¸°ìˆ ì  ì „ë¬¸ì„±ê³¼ ê²½í—˜ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- êµ¬ì²´ì ì¸ í”„ë¡œì íŠ¸ ì‚¬ë¡€ì™€ ê¸°ìˆ  ìŠ¤íƒì„ ì–¸ê¸‰í•˜ì„¸ìš”
- ë¬¸ì œ í•´ê²° ê³¼ì •ê³¼ ê¸°ìˆ ì  ì„ íƒì˜ ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”
- ì „ë¬¸ì ì´ë©´ì„œë„ ìì‹ ê° ìˆëŠ” í†¤ì„ ìœ ì§€í•˜ì„¸ìš”"""
        
        elif question_type == QuestionType.COLLABORATION:
            return f"""{base_info}

=== í˜‘ì—… ì§ˆë¬¸ ë‹µë³€ ìŠ¤íƒ€ì¼ ===
- **ì´ë¦„ì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”** (ì´ë¯¸ ìê¸°ì†Œê°œì—ì„œ í–ˆìŒ)
- íŒ€ì›Œí¬ì™€ í˜‘ì—… ê²½í—˜ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- êµ¬ì²´ì ì¸ í˜‘ì—… ìƒí™©ê³¼ í•´ê²° ê³¼ì •ì„ ì„¤ëª…í•˜ì„¸ìš”
- ë‹¤ë¥¸ íŒ€ì›ë“¤ê³¼ì˜ ì†Œí†µ ë°©ì‹ê³¼ ê°ˆë“± í•´ê²° ê²½í—˜ì„ í¬í•¨í•˜ì„¸ìš”
- í˜‘ë ¥ì ì´ê³  ë°°ë ¤ì‹¬ ìˆëŠ” ë©´ëª¨ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”"""
        
        else:  # MOTIVATION, FOLLOWUP ë“±
            return f"""{base_info}

=== ë©´ì ‘ íƒœë„ ===
- **ì ˆëŒ€ ì´ë¦„ì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”** (ìê¸°ì†Œê°œê°€ ì•„ë‹Œ ê²½ìš°)
- **"ì•ˆë…•í•˜ì„¸ìš”" ê°™ì€ ì¸ì‚¬ë§ ì‚¬ìš© ê¸ˆì§€**
- ë°”ë¡œ ë‹µë³€ ë‚´ìš©ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”
- ìì‹ ê° ìˆê³  ì„±ì‹¤í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
- êµ¬ì²´ì ì¸ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- {company_data.get('name', 'íšŒì‚¬')}ì— ëŒ€í•œ ì§„ì •ì„± ìˆëŠ” ê´€ì‹¬ì„ ë³´ì—¬ì£¼ì„¸ìš”
- ì „ë¬¸ì ì´ë©´ì„œë„ ìì—°ìŠ¤ëŸ¬ìš´ í†¤ì„ ìœ ì§€í•˜ì„¸ìš”

ë‹µë³€ ì‹œì‘ ì˜ˆì‹œ:
- ì§€ì›ë™ê¸°: "ì œê°€ ë„¤ì´ë²„ì— ì§€ì›í•˜ê²Œ ëœ ì´ìœ ëŠ”..."
- ì¼ë°˜ì§ˆë¬¸: "ê·¸ ë¶€ë¶„ì— ëŒ€í•´ì„œëŠ”..." "ì œ ê²½í—˜ìœ¼ë¡œëŠ”..." "ì €ëŠ” í•­ìƒ..."
- ê¸°ìˆ ì§ˆë¬¸: "í•´ë‹¹ ê¸°ìˆ ì— ëŒ€í•œ ì œ ê²½í—˜ì„ ë§ì”€ë“œë¦¬ë©´..."
- í˜‘ì—…ì§ˆë¬¸: "íŒ€ì›Œí¬ ê´€ë ¨í•´ì„œëŠ” ì œê°€ ê²ªì—ˆë˜ ì‚¬ë¡€ê°€..."
"""
    
    def _build_answer_prompt(self, request: AnswerRequest, persona: CandidatePersona, company_data: Dict) -> str:
        """ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        
        # í˜ë¥´ì†Œë‚˜ì˜ ê¸°ìˆ  ìŠ¤í‚¬ ë° í”„ë¡œì íŠ¸ ì •ë³´
        tech_info = f"ì£¼ìš” ê¸°ìˆ : {', '.join(persona.technical_skills[:5])}"
        
        projects_info = ""
        for i, project in enumerate(persona.projects[:2], 1):
            projects_info += f"\n{i}. {project.get('name', 'í”„ë¡œì íŠ¸')}: {project.get('description', '')}"
            if project.get('achievements'):
                projects_info += f" (ì„±ê³¼: {', '.join(project['achievements'])})"
        
        experiences_info = ""
        for exp in persona.experiences[:2]:
            experiences_info += f"\n- {exp.get('company', 'íšŒì‚¬')}: {exp.get('position', 'ê°œë°œì')} ({exp.get('period', 'ê¸°ê°„')})"
            if exp.get('achievements'):
                experiences_info += f" - {', '.join(exp['achievements'])}"
        
        # íšŒì‚¬ë³„ ë§ì¶¤ ì •ë³´
        company_focus = ""
        if company_data:
            company_focus = f"""
=== {company_data['name']} ê´€ë ¨ ì •ë³´ ===
- ì¸ì¬ìƒ: {company_data.get('talent_profile', '')}
- ê¸°ìˆ  ì¤‘ì : {', '.join(company_data.get('tech_focus', []))}
- í•µì‹¬ ì—­ëŸ‰: {', '.join(company_data.get('core_competencies', []))}"""
        
        # ì§ˆë¬¸ íƒ€ì…ë³„ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        if request.question_type == QuestionType.HR:
            # ê°œì¸ì  ê²½í—˜ ì„ ë³„ (ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê²½í—˜ ìš°ì„ )
            personal_experiences = self._get_relevant_personal_experiences(persona, request.question_content)
            life_philosophy = self._get_persona_attribute(persona, 'life_philosophy', 'ì§€ì†ì ì¸ í•™ìŠµê³¼ ì„±ì¥ì„ ì¶”êµ¬í•©ë‹ˆë‹¤.')
            core_values = self._get_persona_attribute(persona, 'core_values', ['ì„±ì¥', 'í˜‘ì—…', 'ë„ì „'])
            
            prompt = f"""
=== ë©´ì ‘ ìƒí™© ===
íšŒì‚¬: {company_data.get('name', request.company_id)}
ì§êµ°: {request.position}
ì§ˆë¬¸ ìœ í˜•: {request.question_type.value} (ì¸ì„± ì§ˆë¬¸)
ì§ˆë¬¸: {request.question_content}
ì§ˆë¬¸ ì˜ë„: {request.question_intent}

=== ë‹¹ì‹ ì˜ ê°œì¸ì  íŠ¹ì„± ===
- ì„±ê²© íŠ¹ì„±: {', '.join(persona.personality_traits)}
- ì¸ìƒ ì² í•™: {life_philosophy}
- í•µì‹¬ ê°€ì¹˜: {', '.join(core_values)}
- ë©´ì ‘ ìŠ¤íƒ€ì¼: {persona.interview_style}

=== í™œìš©í•  ìˆ˜ ìˆëŠ” ê°œì¸ ê²½í—˜ë“¤ ===
{personal_experiences}

=== ë‹µë³€ ë°©ì‹ (ë§¤ìš° ì¤‘ìš”) ===
ì´ ì§ˆë¬¸ì€ ë‹¹ì‹ ì˜ **ì¸ì„±ê³¼ ê°€ì¹˜ê´€**ì„ í‰ê°€í•˜ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤.

**ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ì›ì¹™:**
- âŒ í”„ë¡œì íŠ¸ ê²½í—˜ ì¤‘ì‹¬ ë‹µë³€ ê¸ˆì§€
- âœ… ê°œì¸ì  ê²½í—˜ê³¼ ê°ì •ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€
- âœ… ìœ„ì˜ ê°œì¸ ê²½í—˜ë“¤ì„ ì ê·¹ í™œìš©í•˜ì„¸ìš”
- âœ… í•™ì°½ì‹œì ˆ, ì¼ìƒìƒí™œ, ì¸ê°„ê´€ê³„, ê°œì¸ì  ë„ì „ ë“±ì˜ ê²½í—˜ í¬í•¨
- âœ… "ê°œì¸ì ìœ¼ë¡œ ì €ëŠ”...", "ì œê°€ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ê²ƒì€..." í‘œí˜„ ì‚¬ìš©
- âœ… ê°ì •ê³¼ ìƒê°ì˜ ë³€í™” ê³¼ì •ì„ êµ¬ì²´ì ìœ¼ë¡œ í‘œí˜„
- âœ… ì‹¤íŒ¨ì™€ ê·¹ë³µ ê²½í—˜, ê°€ì¹˜ê´€ í˜•ì„± ê³¼ì • í¬í•¨

**ë‹µë³€ êµ¬ì¡°:**
1. ê°œì¸ì  ê´€ì /ê°€ì¹˜ê´€ í‘œí˜„
2. êµ¬ì²´ì ì¸ ê°œì¸ ê²½í—˜ ì‚¬ë¡€ (ì—…ë¬´ ì™¸ ê²½í—˜ ìš°ì„ )
3. ê·¸ ê²½í—˜ì—ì„œ ëŠë‚€ ê°ì •ê³¼ ë°°ìš´ ì 
4. í˜„ì¬ ì‚¶/ì—…ë¬´ì— ì–´ë–»ê²Œ ì ìš©í•˜ê³  ìˆëŠ”ì§€

ìœ„ ì§€ì¹¨ì„ ë°”íƒ•ìœ¼ë¡œ ì§„ì •ì„± ìˆê³  ì¸ê°„ì ì¸ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.
"""
        elif request.question_type == QuestionType.COLLABORATION:
            # í˜‘ì—… ì§ˆë¬¸: ê°œì¸ì  ì†Œí†µ/ê´€ê³„ ê²½í—˜ í¬í•¨
            personal_experiences = self._get_relevant_personal_experiences(persona, request.question_content)
            core_values = self._get_persona_attribute(persona, 'core_values', ['í˜‘ì—…', 'ì†Œí†µ', 'ì„±ì¥'])
            
            prompt = f"""
=== ë©´ì ‘ ìƒí™© ===
íšŒì‚¬: {company_data.get('name', request.company_id)}
ì§êµ°: {request.position}
ì§ˆë¬¸ ìœ í˜•: {request.question_type.value} (í˜‘ì—… ëŠ¥ë ¥ í‰ê°€)
ì§ˆë¬¸: {request.question_content}
ì§ˆë¬¸ ì˜ë„: {request.question_intent}

=== ë‹¹ì‹ ì˜ ê°œì¸ì  íŠ¹ì„± ===
- ì„±ê²© íŠ¹ì„±: {', '.join(persona.personality_traits)}
- í•µì‹¬ ê°€ì¹˜: {', '.join(core_values)}
- ë©´ì ‘ ìŠ¤íƒ€ì¼: {persona.interview_style}

=== ì°¸ê³ í•  ê°œì¸ ê²½í—˜ë“¤ ===
{personal_experiences}

=== ë‹¹ì‹ ì˜ ë°°ê²½ ì •ë³´ ===
{tech_info}

=== ì£¼ìš” í”„ë¡œì íŠ¸ ê²½í—˜ ==={projects_info}

=== ë‹µë³€ ë°©ì‹ ===
ì´ ì§ˆë¬¸ì€ ë‹¹ì‹ ì˜ **í˜‘ì—… ëŠ¥ë ¥ê³¼ ì†Œí†µ ìŠ¤íƒ€ì¼**ì„ í‰ê°€í•˜ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤.

**ë‹µë³€ ë¹„ìœ¨ ê°€ì´ë“œ:**
- ì—…ë¬´/í”„ë¡œì íŠ¸ ê²½í—˜: 60%
- ê°œì¸ì  ê²½í—˜ (í•™ì°½ì‹œì ˆ, ì¼ìƒ ê´€ê³„): 40%

**í¬í•¨í•´ì•¼ í•  ìš”ì†Œ:**
- êµ¬ì²´ì ì¸ í˜‘ì—…/ì†Œí†µ ê²½í—˜ (ì—…ë¬´+ê°œì¸)
- ê·¸ ìƒí™©ì—ì„œì˜ ê°ì •ê³¼ ìƒê°
- ê°ˆë“± í•´ê²°ì´ë‚˜ ê´€ê³„ ê°œì„  ì‚¬ë¡€
- ê°œì¸ì  ì†Œí†µ ì² í•™ì´ë‚˜ ë°©ì‹
- íŒ€ì—ì„œì˜ ìì‹ ì˜ ì—­í• ê³¼ ê¸°ì—¬

ìœ„ì˜ ê°œì¸ ê²½í—˜ë“¤ë„ ì ì ˆíˆ í™œìš©í•˜ì—¬ ì¸ê°„ì ì´ê³  ì§„ì •ì„± ìˆëŠ” ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.
"""
        else:
            # ê¸°ìˆ  ì§ˆë¬¸ ë“± ê¸°íƒ€ ì§ˆë¬¸
            life_philosophy = self._get_persona_attribute(persona, 'life_philosophy', 'ì§€ì†ì ì¸ í•™ìŠµê³¼ ì„±ì¥ì„ ì¶”êµ¬í•©ë‹ˆë‹¤.')
            
            prompt = f"""
=== ë©´ì ‘ ìƒí™© ===
íšŒì‚¬: {company_data.get('name', request.company_id)}
ì§êµ°: {request.position}
ì§ˆë¬¸ ìœ í˜•: {request.question_type.value}
ì§ˆë¬¸: {request.question_content}
ì§ˆë¬¸ ì˜ë„: {request.question_intent}

=== ë‹¹ì‹ ì˜ íŠ¹ì„± ===
- ì„±ê²© íŠ¹ì„±: {', '.join(persona.personality_traits)}
- ì¸ìƒ ì² í•™: {life_philosophy}
- ë©´ì ‘ ìŠ¤íƒ€ì¼: {persona.interview_style}

=== ë‹¹ì‹ ì˜ ë°°ê²½ ì •ë³´ ===
{tech_info}

=== ì£¼ìš” í”„ë¡œì íŠ¸ ê²½í—˜ ==={projects_info}

=== ì—…ë¬´ ê²½í—˜ ==={experiences_info}

=== ì£¼ìš” ì„±ì·¨ ===
{', '.join(getattr(persona, 'achievements', persona.strengths))}
{company_focus}

=== ë‹µë³€ ë°©ì‹ ===
**ë‹µë³€ êµ¬ì„± ë¹„ìœ¨:**
- ê¸°ìˆ ì /ì „ë¬¸ì  ë‚´ìš©: 70%
- ê°œì¸ì  í•™ìŠµ/ì„±ì¥ ê´€ì : 30%

**í¬í•¨ ìš”ì†Œ:**
- êµ¬ì²´ì ì¸ ê¸°ìˆ  ê²½í—˜ê³¼ ì„±ê³¼
- ê°œì¸ì  í•™ìŠµ ë™ê¸°ì™€ ê³¼ì •
- ê¸°ìˆ ì— ëŒ€í•œ ë³¸ì¸ë§Œì˜ ì² í•™ì´ë‚˜ ê´€ì 
- ì‹¤íŒ¨ì™€ ê·¹ë³µ ê²½í—˜
- ì§€ì†ì  ì„±ì¥ì„ ìœ„í•œ ë…¸ë ¥

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°ìˆ ì  ì „ë¬¸ì„±ê³¼ ê°œì¸ì  ì„±ì¥ ìŠ¤í† ë¦¬ë¥¼ ê· í˜•ìˆê²Œ í¬í•¨í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
"""
        
        if request.additional_context:
            prompt += f"\n\n=== ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ===\n{request.additional_context}"
        
        return prompt
    
    def _calculate_confidence_score(self, llm_response: LLMResponse, quality_level: QualityLevel) -> float:
        """ë‹µë³€ ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        if llm_response.error:
            return 0.0
        
        base_score = 0.7
        
        # í’ˆì§ˆ ë ˆë²¨ì— ë”°ë¥¸ ê°€ì‚°ì 
        quality_bonus = (quality_level.value - 5) * 0.05
        
        # ë‹µë³€ ê¸¸ì´ì— ë”°ë¥¸ ê°€ì‚°ì 
        length_bonus = min(len(llm_response.content) / 1000, 0.2)
        
        # ì‘ë‹µ ì‹œê°„ì— ë”°ë¥¸ ê°€ì‚°ì  (ë¹ ë¥¼ìˆ˜ë¡ ì¢‹ìŒ)
        time_bonus = 0.1 if llm_response.response_time and llm_response.response_time < 3.0 else 0.0
        
        confidence = min(base_score + quality_bonus + length_bonus + time_bonus, 1.0)
        return round(confidence, 2)
    
    def _post_process_answer(self, answer: str, quality_level: QualityLevel) -> str:
        """ë‹µë³€ í›„ì²˜ë¦¬"""
        if not answer:
            return ""
        
        # ê¸°ë³¸ ì •ë¦¬
        processed = answer.strip()
        
        # í’ˆì§ˆ ë ˆë²¨ì— ë”°ë¥¸ ì¶”ê°€ ì²˜ë¦¬
        config = self.quality_controller.get_quality_config(quality_level)
        
        # ê¸¸ì´ ì¡°ì •
        if len(processed) > config.answer_length_max:
            # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸°
            sentences = processed.split('. ')
            total_length = 0
            result_sentences = []
            
            for sentence in sentences:
                if total_length + len(sentence) <= config.answer_length_max:
                    result_sentences.append(sentence)
                    total_length += len(sentence) + 2
                else:
                    break
            
            processed = '. '.join(result_sentences)
            if not processed.endswith('.'):
                processed += '.'
        
        return processed
    
    def compare_answers(self, request: AnswerRequest, quality_levels: List[QualityLevel]) -> Dict[QualityLevel, AnswerResponse]:
        """ì—¬ëŸ¬ í’ˆì§ˆ ë ˆë²¨ë¡œ ë‹µë³€ ìƒì„± ë° ë¹„êµ"""
        results = {}
        
        for level in quality_levels:
            request.quality_level = level
            results[level] = self.generate_answer(request)
        
        return results
    
    def compare_llm_models(self, request: AnswerRequest, llm_providers: List[LLMProvider]) -> Dict[LLMProvider, AnswerResponse]:
        """ì—¬ëŸ¬ LLM ëª¨ë¸ë¡œ ë‹µë³€ ìƒì„± ë° ë¹„êµ"""
        results = {}
        
        for provider in llm_providers:
            request.llm_provider = provider
            results[provider] = self.generate_answer(request)
        
        return results
    
    def get_available_companies(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ íšŒì‚¬ ëª©ë¡ (companies_data.json ê¸°ë°˜)"""
        companies = []
        for company in self.companies_data.get("companies", []):
            companies.append(company.get("id", ""))
        return [c for c in companies if c]  # ë¹ˆ ë¬¸ìì—´ ì œê±°
    

    def get_persona_summary(self, company_id: str) -> Dict[str, Any]:
        """í˜ë¥´ì†Œë‚˜ ìš”ì•½ ì •ë³´ (ë™ì  ìƒì„± ì‹œìŠ¤í…œìš©)"""
        persona = self.get_persona(company_id)
        if not persona:
            # ë™ì  ìƒì„± ì‹œìŠ¤í…œì—ì„œëŠ” íšŒì‚¬ ì •ë³´ë§Œ ë°˜í™˜
            company_info = self._get_company_info(company_id)
            return {
                "company": company_id,
                "company_name": company_info.get("name", company_id),
                "available_positions": ["í”„ë¡ íŠ¸ì—”ë“œ", "ë°±ì—”ë“œ", "ê¸°íš", "AI", "ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤"],
                "note": "ì‹¤ì‹œê°„ LLM ìƒì„± í˜ë¥´ì†Œë‚˜ ì‚¬ìš©"
            }
        
        return {
            "name": persona.name,
            "company": company_id,
            "career_years": persona.background.get("career_years", "0"),
            "current_position": persona.background.get("current_position", "ì§€ì›ì"),
            "position": persona.background.get("current_position", "ì§€ì›ì"),  # í˜¸í™˜ì„±ì„ ìœ„í•´ ë‘˜ ë‹¤ ì œê³µ
            "main_skills": persona.technical_skills[:5],
            "key_strengths": persona.strengths[:3],
            "interview_style": persona.interview_style,
            "success_factors": getattr(persona, 'success_factors', [])
        }

if __name__ == "__main__":
    # AI ì§€ì›ì ëª¨ë¸ í…ŒìŠ¤íŠ¸
    print("ğŸ¤– AI ì§€ì›ì ëª¨ë¸ í…ŒìŠ¤íŠ¸ - LLM ê¸°ë°˜ ì‹¤ì‹œê°„ í˜ë¥´ì†Œë‚˜ ìƒì„±")
    
    # ëª¨ë¸ ì´ˆê¸°í™” (ìë™ìœ¼ë¡œ .envì—ì„œ API í‚¤ ë¡œë“œ)
    ai_candidate = AICandidateModel()
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ íšŒì‚¬ í™•ì¸
    companies = ai_candidate.get_available_companies()
    print(f"\nğŸ¢ ì‚¬ìš© ê°€ëŠ¥í•œ íšŒì‚¬: {companies}")
    
    # === ìƒˆë¡œìš´ LLM ê¸°ë°˜ í˜ë¥´ì†Œë‚˜ ìƒì„± í…ŒìŠ¤íŠ¸ ===
    print("\n" + "="*60)
    print("ğŸ¯ LLM ê¸°ë°˜ ì‹¤ì‹œê°„ í˜ë¥´ì†Œë‚˜ ìƒì„± í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    if companies:
        # ë„¤ì´ë²„ ë°±ì—”ë“œ ê°œë°œì í˜ë¥´ì†Œë‚˜ ìƒì„± í…ŒìŠ¤íŠ¸
        print("\nğŸ”¥ ë„¤ì´ë²„ ë°±ì—”ë“œ ê°œë°œì í˜ë¥´ì†Œë‚˜ ìƒì„± í…ŒìŠ¤íŠ¸")
        naver_persona = ai_candidate.create_persona_for_interview("ë„¤ì´ë²„", "ë°±ì—”ë“œ")
        
        if naver_persona:
            print(f"\n" + "="*80)
            print(f"ğŸ¯ ìƒì„±ëœ í˜ë¥´ì†Œë‚˜ ì „ì²´ ì •ë³´")
            print(f"="*80)
            print(f"ğŸ“› ì´ë¦„: {naver_persona.name}")
            print(f"ğŸ“ ìš”ì•½: {naver_persona.summary}")
            print(f"ğŸ¢ ì´ë ¥ì„œ ID: {naver_persona.resume_id}")
            print(f"ğŸ¤– ìƒì„± ëª¨ë¸: {naver_persona.generated_by}")
            
            print(f"\nğŸ“‹ ë°°ê²½ ì •ë³´:")
            print(f"  â€¢ ê²½ë ¥: {naver_persona.background.get('career_years', '0')}ë…„")
            print(f"  â€¢ í˜„ì¬ ì§ì±…: {naver_persona.background.get('current_position', 'ì§€ì›ì')}")
            print(f"  â€¢ í•™ë ¥: {', '.join(naver_persona.background.get('education', ['ì •ë³´ ì—†ìŒ']))}")
            
            print(f"\nğŸ’» ê¸°ìˆ  ìŠ¤í‚¬:")
            for i, skill in enumerate(naver_persona.technical_skills, 1):
                print(f"  {i}. {skill}")
            
            print(f"\nğŸš€ í”„ë¡œì íŠ¸ ê²½í—˜:")
            for i, project in enumerate(naver_persona.projects, 1):
                print(f"  {i}. {project.get('name', 'í”„ë¡œì íŠ¸')}")
                print(f"     ì„¤ëª…: {project.get('description', '')}")
                print(f"     ê¸°ìˆ : {', '.join(project.get('tech_stack', []))}")
                print(f"     ì—­í• : {project.get('role', '')}")
                if project.get('achievements'):
                    print(f"     ì„±ê³¼: {', '.join(project['achievements'])}")
                if project.get('challenges'):
                    print(f"     ì–´ë ¤ì›€: {', '.join(project['challenges'])}")
                print()
            
            print(f"ğŸ’¼ ì—…ë¬´ ê²½í—˜:")
            for i, exp in enumerate(naver_persona.experiences, 1):
                print(f"  {i}. {exp.get('company', 'íšŒì‚¬')}")
                print(f"     ì§ì±…: {exp.get('position', 'ê°œë°œì')}")
                print(f"     ê¸°ê°„: {exp.get('period', 'ê¸°ê°„')}")
                if exp.get('achievements'):
                    print(f"     ì„±ê³¼: {', '.join(exp['achievements'])}")
                print()
            
            print(f"ğŸ’ª ê°•ì :")
            for i, strength in enumerate(naver_persona.strengths, 1):
                print(f"  {i}. {strength}")
            
            print(f"\nğŸ¤” ì•½ì  (ê°œì„ ì ):")
            for i, weakness in enumerate(naver_persona.weaknesses, 1):
                print(f"  {i}. {weakness}")
            
            print(f"\nâ¤ï¸ ê°œì¸ì  ë™ê¸°:")
            print(f"  {naver_persona.motivation}")
            
            print(f"\nğŸ¯ ì»¤ë¦¬ì–´ ëª©í‘œ:")
            print(f"  {naver_persona.career_goal}")
            
            print(f"\nğŸ§  ê°œì¸ì  êµí›ˆ/ê²½í—˜:")
            for i, exp in enumerate(naver_persona.inferred_personal_experiences, 1):
                print(f"  {i}. [{exp.get('category', 'ê²½í—˜')}] {exp.get('experience', '')}")
                print(f"     êµí›ˆ: {exp.get('lesson', '')}")
                print()
            
            print(f"ğŸ­ ì„±ê²© íŠ¹ì„±:")
            print(f"  {', '.join(naver_persona.personality_traits)}")
            
            print(f"\nğŸ—£ï¸ ë©´ì ‘ ìŠ¤íƒ€ì¼:")
            print(f"  {naver_persona.interview_style}")
            
            print(f"="*80)
            
            # ì„ì‹œë¡œ í˜ë¥´ì†Œë‚˜ë¥¼ ìºì‹œì— ì €ì¥ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•´)
            ai_candidate.candidate_personas["naver"] = naver_persona
            
            # ìƒì„±ëœ í˜ë¥´ì†Œë‚˜ë¡œ ë‹µë³€ ìƒì„± í…ŒìŠ¤íŠ¸
            print(f"\nğŸ“ ìƒì„±ëœ í˜ë¥´ì†Œë‚˜ë¡œ ë‹µë³€ ìƒì„± í…ŒìŠ¤íŠ¸:")
            test_request = AnswerRequest(
                question_content="ê°„ë‹¨í•œ ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”.",
                question_type=QuestionType.INTRO,
                question_intent="ì§€ì›ìì˜ ê¸°ë³¸ ë°°ê²½ê³¼ ì—­ëŸ‰ íŒŒì•…",
                company_id="naver",
                position="ë°±ì—”ë“œ ê°œë°œì",
                quality_level=QualityLevel(8),
                llm_provider=LLMProvider.OPENAI_GPT4O_MINI
            )
            
            response = ai_candidate.generate_answer(test_request)
            
            print(f"í˜ë¥´ì†Œë‚˜: {response.persona_name}")
            print(f"í’ˆì§ˆ ë ˆë²¨: {response.quality_level.value}ì ")
            print(f"ì‹ ë¢°ë„: {response.confidence_score}")
            print(f"ì‘ë‹µ ì‹œê°„: {response.response_time:.2f}ì´ˆ")
            print(f"ë‹µë³€: {response.answer_content[:300]}...")
            
            if response.error:
                print(f"ì˜¤ë¥˜: {response.error}")
        else:
            print("âŒ í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹¤íŒ¨")
    
    # í˜ë¥´ì†Œë‚˜ ìš”ì•½ ì •ë³´ í™•ì¸ (ë™ì  ìƒì„± ì‹œìŠ¤í…œ)
    print(f"\nğŸ“Š íšŒì‚¬ë³„ ì •ë³´ í™•ì¸:")
    for company in companies[:3]:
        summary = ai_candidate.get_persona_summary(company)
        print(f"\nğŸ‘¤ {company}:")
        if summary.get('note'):
            print(f"  íƒ€ì…: {summary.get('note')}")
            print(f"  íšŒì‚¬ëª…: {summary.get('company_name')}")
            print(f"  ì§€ì› ê°€ëŠ¥ ì§êµ°: {', '.join(summary.get('available_positions', []))}")
        else:
            print(f"  ì´ë¦„: {summary.get('name', 'N/A')}")
            print(f"  ê²½ë ¥: {summary.get('career_years', 'N/A')}ë…„")
    
    print("\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ! LLM ê¸°ë°˜ í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.")