#!/usr/bin/env python3
"""
AI ì§€ì›ì ëª¨ë¸ - LLM ê¸°ë°˜ ì‹¤ì‹œê°„ í˜ë¥´ì†Œë‚˜ ìƒì„±
ì‹¤ì œ ì´ë ¥ì„œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì´ ì¸ê°„ë¯¸ ë„˜ì¹˜ëŠ” í˜ë¥´ì†Œë‚˜ë¥¼ ì‹¤ì‹œê°„ ìƒì„±
"""

import os
import json
import sys
import random
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from dotenv import load_dotenv
from pydantic import BaseModel

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ database ëª¨ë“ˆ ì ‘ê·¼ì„ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
try:
    from database.supabase_client import get_supabase_client
except ImportError:
    print("âš ï¸ Supabase í´ë¼ì´ì–¸íŠ¸ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê¸°ë°˜ fallbackë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")
    get_supabase_client = None

from ..shared.models import LLMProvider, LLMResponse
from .quality_controller import AnswerQualityController, QualityLevel
from ..shared.models import QuestionType, QuestionAnswer, AnswerRequest, AnswerResponse
from ..session.models import InterviewSession
from ..shared.utils import safe_json_load, get_fixed_questions

# ì§êµ° ë§¤í•‘ (position_name -> position_id)
POSITION_MAPPING = {
    "í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì": 1,
    "í”„ë¡ íŠ¸": 1,
    "frontend": 1,
    "ë°±ì—”ë“œ": 2,
    "ë°±ì—”ë“œ ê°œë°œì": 2,
    "backend": 2,
    "ê¸°íš": 3,
    "ê¸°íšì": 3,
    "pm": 3,
    "product manager": 3,
    "AI": 4,
    "ai": 4,
    "ì¸ê³µì§€ëŠ¥": 4,
    "ë¨¸ì‹ ëŸ¬ë‹": 4,
    "ml": 4,
    "ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤": 5,
    "ë°ì´í„°": 5,
    "data science": 5,
    "data scientist": 5,
    "ds": 5,
    # ğŸ†• ëª¨ë°”ì¼ ê°œë°œì ë§¤í•‘ ì¶”ê°€
    "ëª¨ë°”ì¼": 6,
    "ëª¨ë°”ì¼ê°œë°œì": 6,
    "ëª¨ë°”ì¼ê°œë°œìandroid": 6,
    "ëª¨ë°”ì¼ê°œë°œìios": 6,
    "android": 6,
    "ios": 6,
    "mobile": 6,
    "ì•±ê°œë°œì": 6,
    "ì•±": 6,
    # ğŸ†• ê¸°íƒ€ ì¼ë°˜ì ì¸ ì§êµ°ë“¤ ì¶”ê°€
    "í’€ìŠ¤íƒ": 7,
    "fullstack": 7,
    "í’€ìŠ¤íƒê°œë°œì": 7,
    "devops": 8,
    "ë°ë¸Œì˜µìŠ¤": 8,
    "ì¸í”„ë¼": 8,
    "qa": 9,
    "í…ŒìŠ¤í„°": 9,
    "í’ˆì§ˆê´€ë¦¬": 9
}

# ìƒˆë¡œìš´ CandidatePersona ëª¨ë¸ (LLM ìƒì„±ìš©)
class CandidatePersona(BaseModel):
    """LLMì´ ìƒì„±í•˜ëŠ” ì¸ê°„ë¯¸ ë„˜ì¹˜ëŠ” í˜ë¥´ì†Œë‚˜ ëª¨ë¸"""
    # --- LLM ìƒì„± ì •ë³´ ---
    name: str
    summary: str  # ì˜ˆ: "5ë…„ì°¨ Java ë°±ì—”ë“œ ê°œë°œìë¡œ, ëŒ€ìš©ëŸ‰ íŠ¸ë˜í”½ ì²˜ë¦¬ì™€ MSA ì„¤ê³„ì— ê°•ì ì´ ìˆìŠµë‹ˆë‹¤."
    background: Dict[str, Any]
    technical_skills: List[str]
    projects: List[Dict[str, Any]]  # ê° í”„ë¡œì íŠ¸ì— 'achievements'ì™€ 'challenges' í¬í•¨
    experiences: List[Dict[str, Any]]
    strengths: List[str]
    weaknesses: List[str]  # ê°œì„ í•˜ê³  ì‹¶ì€ ì 
    motivation: str  # ê°œë°œì/ê¸°ìˆ ì— ëŒ€í•œ ê°œì¸ì  ë™ê¸°ë‚˜ ìŠ¤í† ë¦¬
    inferred_personal_experiences: List[Dict[str, str]]  # ì´ë ¥ì„œ ê¸°ë°˜ìœ¼ë¡œ ì¶”ë¡ ëœ ê°œì¸ì  êµí›ˆ
    career_goal: str
    personality_traits: List[str]
    interview_style: str
    
    # --- ë©”íƒ€ë°ì´í„° ---
    generated_by: str = "gpt-4o-mini"
    resume_id: int  # ì›ë³¸ ì´ë ¥ì„œ ID

# ëª¨ë¸ë³„ AI ì§€ì›ì ì´ë¦„ ë§¤í•‘ (í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
AI_CANDIDATE_NAMES = {
    LLMProvider.OPENAI_GPT4: "ì¶˜ì‹ì´",
    LLMProvider.OPENAI_GPT35: "ì¶˜ì‹ì´", 
    LLMProvider.OPENAI_GPT4O_MINI: "ì¶˜ì‹ì´",
    LLMProvider.GOOGLE_GEMINI_PRO: "ì œë¯¸ë‹ˆ",
    LLMProvider.GOOGLE_GEMINI_FLASH: "ì œë¯¸ë‹ˆ",
    LLMProvider.KT_BELIEF: "ë¯¿ìŒì´"
}

class AICandidateSession(InterviewSession):
    """AI ì§€ì›ì ì „ìš© ë©´ì ‘ ì„¸ì…˜ - ë©´ì ‘ìì™€ ë™ì¼í•œ í”Œë¡œìš°"""
    
    def __init__(self, company_id: str, position: str, persona: CandidatePersona):
        super().__init__(company_id, position, persona.name)
        self.persona = persona
        self.ai_answers: List[QuestionAnswer] = []
        
        # ë©´ì ‘ìì™€ ë™ì¼í•œ 20ê°œ ì§ˆë¬¸ ê³„íš ì‚¬ìš©
        # ì´ë¯¸ ë¶€ëª¨ í´ë˜ìŠ¤ì—ì„œ self.question_planì´ 20ê°œë¡œ ì„¤ì •ë¨
        
    def add_ai_answer(self, qa_pair: QuestionAnswer):
        """AI ë‹µë³€ ì¶”ê°€"""
        self.ai_answers.append(qa_pair)
        # ë¶€ëª¨ í´ë˜ìŠ¤ì˜ add_qa_pair ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ê´€ì„± ìœ ì§€
        super().add_qa_pair(qa_pair)
    
    @property
    def question_answers(self) -> List[QuestionAnswer]:
        """FeedbackService í˜¸í™˜ì„±ì„ ìœ„í•œ question_answers property - conversation_history ë°˜í™˜"""
        return super().question_answers
        
    def get_persona_context(self) -> str:
        """í˜ë¥´ì†Œë‚˜ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        context = f"""
=== AI ì§€ì›ì í˜ë¥´ì†Œë‚˜ ì •ë³´ ===
ì´ë¦„: {self.persona.name}
ê²½ë ¥: {self.persona.background.get('career_years', '0')}ë…„
í˜„ì¬ ì§ì±…: {self.persona.background.get('current_position', 'ì§€ì›ì')}
ì£¼ìš” ê¸°ìˆ : {', '.join(self.persona.technical_skills[:5])}
ê°•ì : {', '.join(self.persona.strengths[:3])}
ì»¤ë¦¬ì–´ ëª©í‘œ: {self.persona.career_goal}
ì„±ê²© íŠ¹ì„±: {', '.join(self.persona.personality_traits)}
ë©´ì ‘ ìŠ¤íƒ€ì¼: {self.persona.interview_style}

=== ì£¼ìš” í”„ë¡œì íŠ¸ ===
"""
        for i, project in enumerate(self.persona.projects[:2], 1):
            context += f"{i}. {project.get('name', 'í”„ë¡œì íŠ¸')}: {project.get('description', '')}\n"
            context += f"   ê¸°ìˆ ìŠ¤íƒ: {', '.join(project.get('tech_stack', []))}\n"
            if project.get('achievements'):
                context += f"   ì„±ê³¼: {', '.join(project['achievements'])}\n"
        
        context += f"""
=== ì—…ë¬´ ê²½í—˜ ===
"""
        for exp in self.persona.experiences[:2]:
            context += f"- {exp.get('company', 'íšŒì‚¬')}: {exp.get('position', 'ê°œë°œì')} ({exp.get('period', 'ê¸°ê°„')})\n"
            if exp.get('achievements'):
                context += f"  ì„±ê³¼: {', '.join(exp['achievements'])}\n"
        
        return context
    
    def get_previous_answers_context(self) -> str:
        """ì´ì „ ë‹µë³€ ì»¨í…ìŠ¤íŠ¸ (ì¼ê´€ì„± ìœ ì§€ìš©)"""
        if not self.ai_answers:
            return ""
        
        context = "\n=== ì´ì „ ë‹µë³€ ë‚´ì—­ (ì¼ê´€ì„± ìœ ì§€) ===\n"
        for i, qa in enumerate(self.ai_answers[-3:], 1):  # ìµœê·¼ 3ê°œë§Œ
            context += f"{i}. [{qa.question_type.value}] {qa.question_content}\n"
            context += f"   ë‹µë³€: {qa.answer_content[:100]}...\n\n"
        
        return context

class AICandidateModel:
    """AI ì§€ì›ì ëª¨ë¸ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, api_key: str = None):
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì§ì ‘ ì´ˆê¸°í™”
        import openai
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        if self.api_key:
            self.openai_client = openai.OpenAI(api_key=self.api_key)
            print("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            self.openai_client = None
            print("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ì§ì ‘ ì „ë‹¬í•˜ì„¸ìš”.")
            
        self.quality_controller = AnswerQualityController()
        self.companies_data = self._load_companies_data()
        
        # AI ì§€ì›ì ì„¸ì…˜ ê´€ë¦¬
        self.ai_sessions: Dict[str, 'AICandidateSession'] = {}
        self.fixed_questions = self._load_fixed_questions()
        
        # ìƒˆë¡œìš´ LLM ê¸°ë°˜ ì‹œìŠ¤í…œì—ì„œëŠ” í˜ë¥´ì†Œë‚˜ë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•˜ë¯€ë¡œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì´ˆê¸°í™”
        self.candidate_personas: Dict[str, CandidatePersona] = {}
        self.personas_data = {"personas": {}}
    
    def create_persona_for_interview(self, company_name: str, position_name: str) -> Optional[CandidatePersona]:
        """
        ì£¼ì–´ì§„ íšŒì‚¬ì™€ ì§êµ°ì— ë§ëŠ” AI ì§€ì›ì í˜ë¥´ì†Œë‚˜ë¥¼ LLMìœ¼ë¡œ ì‹¤ì‹œê°„ ìƒì„±
        
        Args:
            company_name: íšŒì‚¬ëª… (ì˜ˆ: "naver", "kakao" ë˜ëŠ” "ë„¤ì´ë²„", "ì¹´ì¹´ì˜¤")
            position_name: ì§êµ°ëª… (ì˜ˆ: "ë°±ì—”ë“œ", "í”„ë¡ íŠ¸ì—”ë“œ")
            
        Returns:
            ìƒì„±ëœ CandidatePersona ê°ì²´ ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
        """
        try:
            print(f"ğŸ”¥ [PERSONA DEBUG] í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹œì‘: company='{company_name}', position='{position_name}'")
            
            # íšŒì‚¬ ì½”ë“œë¥¼ í•œêµ­ì–´ íšŒì‚¬ëª…ìœ¼ë¡œ ë³€í™˜
            company_korean_name = self._get_company_korean_name(company_name)
            print(f"ğŸ¯ [PERSONA DEBUG] íšŒì‚¬ëª… ë³€í™˜: {company_name} -> {company_korean_name}")
            
            # 1ë‹¨ê³„: ì§êµ° ID ë§¤í•‘ (DB ìš°ì„ , í•˜ë“œì½”ë”© fallback)
            position_id = self._get_position_id(position_name, company_korean_name)
            print(f"ğŸ“Š [PERSONA DEBUG] ì§êµ° ë§¤í•‘ ì‹œë„: {position_name} -> {position_id}")
            
            if not position_id:
                print(f"âŒ [PERSONA DEBUG] ì§€ì›í•˜ì§€ ì•ŠëŠ” ì§êµ°: {position_name}")
                print(f"ğŸ” [PERSONA DEBUG] fallbackìœ¼ë¡œ ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹œë„")
                # ğŸ†• fallback: ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„±
                return self._create_default_persona(company_korean_name, position_name)
            
            print(f"âœ… [PERSONA DEBUG] ì§êµ° ë§¤í•‘ ì„±ê³µ: {position_name} -> {position_id}")
            
            # 2ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì´ë ¥ì„œ ì¡°íšŒ
            print(f"ğŸ—„ï¸ [PERSONA DEBUG] DBì—ì„œ ì´ë ¥ì„œ ì¡°íšŒ ì‹œì‘: position_id={position_id}")
            resume_data = self._get_random_resume_from_db(position_id)
            
            if not resume_data:
                print(f"âŒ [PERSONA DEBUG] position_id {position_id}ì— í•´ë‹¹í•˜ëŠ” ì´ë ¥ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
                print(f"ğŸ” [PERSONA DEBUG] fallbackìœ¼ë¡œ ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹œë„")
                # ğŸ†• fallback: ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„±
                return self._create_default_persona(company_korean_name, position_name)
            
            print(f"âœ… [PERSONA DEBUG] ì´ë ¥ì„œ ë¡œë“œ ì„±ê³µ: ID {resume_data.get('ai_resume_id', 'unknown')}")
            
            # 3ë‹¨ê³„: íšŒì‚¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            print(f"ğŸ¢ [PERSONA DEBUG] íšŒì‚¬ ì •ë³´ ì¡°íšŒ: {company_name}")
            company_info = self._get_company_info(company_name)
            print(f"ğŸ“ [PERSONA DEBUG] íšŒì‚¬ ì •ë³´ ê²°ê³¼: {bool(company_info)}")
            
            # 4ë‹¨ê³„: LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
            print(f"ğŸ“ [PERSONA DEBUG] LLM í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
            prompt = self._build_persona_generation_prompt(resume_data, company_name, position_name, company_info)
            print(f"âœ… [PERSONA DEBUG] í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ (ê¸¸ì´: {len(prompt)} ë¬¸ì)")
            
            # 5ë‹¨ê³„: LLM í˜¸ì¶œë¡œ í˜ë¥´ì†Œë‚˜ ìƒì„± (max_tokens ëŠ˜ë¦¼)
            print(f"ğŸ¤– [PERSONA DEBUG] LLM API í˜¸ì¶œ ì‹œì‘...")
            llm_response = self._generate_persona_with_extended_tokens(
                prompt,
                self._build_system_prompt_for_persona_generation()
            )
            
            print(f"ğŸ“¡ [PERSONA DEBUG] LLM ì‘ë‹µ ìˆ˜ì‹ : error={llm_response.error}, content_length={len(llm_response.content) if llm_response.content else 0}")
            
            if llm_response.error:
                print(f"âŒ [PERSONA DEBUG] LLM ì‘ë‹µ ì˜¤ë¥˜: {llm_response.error}")
                return None
            
            # 6ë‹¨ê³„: JSON ì‘ë‹µì„ CandidatePersona ê°ì²´ë¡œ ë³€í™˜
            print(f"ğŸ”„ [PERSONA DEBUG] JSON íŒŒì‹± ì‹œì‘...")
            persona = self._parse_llm_response_to_persona(llm_response.content, resume_data.get('ai_resume_id', 0))
            
            if persona:
                print(f"âœ… [PERSONA DEBUG] í˜ë¥´ì†Œë‚˜ ìƒì„± ì™„ë£Œ: {persona.name} ({company_name} {position_name})")
                return persona
            else:
                print(f"âŒ [PERSONA DEBUG] í˜ë¥´ì†Œë‚˜ íŒŒì‹± ì‹¤íŒ¨ - LLM ì‘ë‹µ ë‚´ìš© í™•ì¸ í•„ìš”")
                print(f"ğŸ” [PERSONA DEBUG] LLM ì‘ë‹µ ìƒ˜í”Œ: {llm_response.content[:200]}...")
                return None
                
        except Exception as e:
            print(f"âŒ [PERSONA DEBUG] í˜ë¥´ì†Œë‚˜ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            print(f"ğŸ“ [PERSONA DEBUG] ì˜¤ë¥˜ ìœ„ì¹˜ ì¶”ì :")
            import traceback
            traceback.print_exc()
            return None
    
    def _get_position_id(self, position_name: str, company_name: str = None) -> Optional[int]:
        """ì§êµ°ëª…ì„ position_idë¡œ ë³€í™˜ - DB ìš°ì„ , í•˜ë“œì½”ë”© fallback"""
        try:
            # ğŸ†• 1ìˆœìœ„: DBì—ì„œ ì§ì ‘ ì¡°íšŒ (company_nameì´ ìˆëŠ” ê²½ìš°)
            if company_name and get_supabase_client:
                from database.services.existing_tables_service import existing_tables_service
                import asyncio
                
                # ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ë™ê¸°ë¡œ ì‹¤í–‰
                try:
                    loop = asyncio.get_event_loop()
                    posting_info = loop.run_until_complete(
                        existing_tables_service.find_posting_by_company_position(company_name, position_name)
                    )
                    if posting_info and posting_info.get('position', {}).get('position_id'):
                        position_id = posting_info['position']['position_id']
                        print(f"âœ… [DB] ì§êµ° ë§¤í•‘ ì„±ê³µ: {position_name} -> position_id={position_id}")
                        return position_id
                except Exception as db_error:
                    print(f"âš ï¸ [DB] ì§êµ° ì¡°íšŒ ì‹¤íŒ¨: {str(db_error)}")
            
            # ğŸ†• 2ìˆœìœ„: í•˜ë“œì½”ë”©ëœ ë§¤í•‘ ì‚¬ìš© (ê¸°ì¡´ í˜¸í™˜ì„±)
            position_lower = position_name.lower().replace(" ", "").replace("(", "").replace(")", "")
            mapped_id = POSITION_MAPPING.get(position_lower)
            if mapped_id:
                print(f"âœ… [MAPPING] ì§êµ° ë§¤í•‘ ì„±ê³µ: {position_name} -> position_id={mapped_id}")
                return mapped_id
            
            print(f"âŒ [MAPPING] ì§€ì›í•˜ì§€ ì•ŠëŠ” ì§êµ°: {position_name}")
            print(f"ğŸ” [MAPPING] ê°€ëŠ¥í•œ ì§êµ° ëª©ë¡: {list(POSITION_MAPPING.keys())}")
            return None
            
        except Exception as e:
            print(f"âŒ [POSITION] ì§êµ° ID ë³€í™˜ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _get_random_resume_from_db(self, position_id: int) -> Optional[Dict[str, Any]]:
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í•´ë‹¹ ì§êµ°ì˜ ì´ë ¥ì„œë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ íƒ"""
        if get_supabase_client is None:
            print("âš ï¸ Supabase í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        try:
            supabase = get_supabase_client()
            
            # í•´ë‹¹ position_idì˜ ì´ë ¥ì„œë“¤ ì¡°íšŒ
            response = supabase.table('ai_resume').select('*').eq('position_id', position_id).execute()
            
            if not response.data:
                print(f"ğŸ“„ position_id {position_id}ì— í•´ë‹¹í•˜ëŠ” ì´ë ¥ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            # ë¬´ì‘ìœ„ë¡œ í•˜ë‚˜ ì„ íƒ
            selected_resume = random.choice(response.data)
            print(f"ğŸ² {len(response.data)}ê°œ ì´ë ¥ì„œ ì¤‘ ID {selected_resume.get('ai_resume_id', 'unknown')} ì„ íƒ")
            
            return selected_resume
            
        except Exception as e:
            print(f"âŒ ì´ë ¥ì„œ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _get_company_info(self, company_name: str) -> Dict[str, Any]:
        """íšŒì‚¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        # companies_data.jsonì—ì„œ íšŒì‚¬ ì •ë³´ ì°¾ê¸°
        for company in self.companies_data.get("companies", []):
            if company.get("name", "").lower() == company_name.lower() or company.get("id", "").lower() == company_name.lower():
                return company
        
        # ì°¾ì§€ ëª»í•œ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
        return {
            "name": company_name,
            "core_competencies": [],
            "tech_focus": [],
            "talent_profile": ""
        }
    
    def _build_persona_generation_prompt(self, resume_data: Dict[str, Any], company_name: str, position_name: str, company_info: Dict[str, Any]) -> str:
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ë ¥ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLM í˜ë¥´ì†Œë‚˜ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        
        # ì´ë ¥ì„œ ë°ì´í„° ì •ë¦¬
        career = resume_data.get('career', '')
        academic = resume_data.get('academic_record', '')
        tech_skills = resume_data.get('tech', '')
        activities = resume_data.get('activities', '')
        certificates = resume_data.get('certificate', '')
        awards = resume_data.get('awards', '')
        resume_id = resume_data.get('ai_resume_id', 0)
        
        # íšŒì‚¬ ì •ë³´ ì •ë¦¬
        company_profile = company_info.get('talent_profile', '')
        core_competencies = ', '.join(company_info.get('core_competencies', []))
        tech_focus = ', '.join(company_info.get('tech_focus', []))
        
        prompt = f"""
ë‹¤ìŒ ì´ë ¥ì„œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ {company_name} {position_name} ì§êµ°ì— ì§€ì›í•˜ëŠ” ì¸ê°„ë¯¸ ë„˜ì¹˜ëŠ” AI ì§€ì›ì í˜ë¥´ì†Œë‚˜ë¥¼ ìƒì„±í•˜ì„¸ìš”.

=== ì´ë ¥ì„œ ë°ì´í„° ===
- ê²½ë ¥: {career}
- í•™ë ¥: {academic}
- ê¸°ìˆ  ìŠ¤íƒ‰: {tech_skills}
- í™œë™: {activities}
- ìê²©ì¦: {certificates}
- ìˆ˜ìƒ: {awards}

=== {company_name} íšŒì‚¬ ì •ë³´ ===
- ì¸ì¬ìƒ: {company_profile}
- í•µì‹¬ ì—­ëŸ‰: {core_competencies}
- ê¸°ìˆ  ì¤‘ì : {tech_focus}

=== ì¸ê°„ë¯¸ ë˜ëŠ” ìƒì„± ì§€ì‹œì‚¬í•­ ===
1. **ì´ë¦„ ìƒì„±**: í•œêµ­ ì´ë¦„ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ìƒì„±í•˜ì„¸ìš”.

2. **ë‹¤ì–‘í•œ ì•½ì  ì¹´í…Œê³ ë¦¬**: ì´ë ¥ì„œì˜ ê°•ì ê³¼ í•¨ê»˜ ê°œì„ ì´ í•„ìš”í•œ ì•½ì ì„ í•œ ê°€ì§€ í¬í•¨ì‹œì¼œë¼. 
   ì•„ë˜ 5ê°€ì§€ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬ ìì—°ìŠ¤ëŸ½ê³  í˜„ì‹¤ì ì¸ ì•½ì ì„ ìƒì„±í•˜ì„¸ìš”:

   ğŸ”§ **ê¸°ìˆ ì  ì•½ì **: 
   - "ìƒˆë¡œìš´ ê¸°ìˆ  ìŠµë“ì— ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” í¸"
   - "ì½”ë“œ ë¬¸ì„œí™”ë¥¼ ì†Œí™€íˆ í•˜ëŠ” ê²½í–¥"
   - "ë ˆê±°ì‹œ ì½”ë“œ ë¦¬íŒ©í† ë§ì— ëŒ€í•œ ë‘ë ¤ì›€"

   ğŸ’¼ **ì—…ë¬´ ìŠ¤íƒ€ì¼ ì•½ì **:
   - "ì™„ë²½ì£¼ì˜ ì„±í–¥ìœ¼ë¡œ ì¸í•œ ì¼ì • ì§€ì—°"
   - "ì—…ë¬´ ìš°ì„ ìˆœìœ„ ì„¤ì •ì— ì–´ë ¤ì›€ì„ ê²ªìŒ"
   - "ë©€í‹°íƒœìŠ¤í‚¹ë³´ë‹¤ ì§‘ì¤‘ë ¥ì„ ìš”í•˜ëŠ” ì—…ë¬´ ì„ í˜¸"

   ğŸ—£ï¸ **ì†Œí†µ ê´€ë ¨ ì•½ì **:
   - "ëŒ€ì¤‘ ì• ë°œí‘œì— ëŒ€í•œ ë¶€ë‹´ê°"
   - "ìì‹ ì˜ ì˜ê²¬ì„ í‘œí˜„í•  ë•Œ ì£¼ì €í•˜ëŠ” í¸"
   - "ê¸°ìˆ ì  ë‚´ìš©ì„ ë¹„ê°œë°œìì—ê²Œ ì„¤ëª…í•˜ëŠ” ì–´ë ¤ì›€"

   ğŸŒ± **ê°œì¸ì  ì„±í–¥ ì•½ì **:
   - "ìƒˆë¡œìš´ í™˜ê²½ ì ì‘ì— ì‹œê°„ì´ í•„ìš”"
   - "ê¸‰ê²©í•œ ë³€í™”ë³´ë‹¤ ì ì§„ì  ë³€í™” ì„ í˜¸"
   - "í˜¼ì ì‘ì—…í•  ë•Œ ë” ë†’ì€ ì§‘ì¤‘ë ¥ ë°œíœ˜"

   ğŸ‘¥ **ëŒ€ì¸ê´€ê³„ ì•½ì ** (ê¸°ì¡´ ì¹´í…Œê³ ë¦¬, ì„ íƒ ì‹œ ì‹ ì¤‘í•˜ê²Œ):
   - "ëŒ€ì¸ê´€ê³„ì—ì„œ ì†Œê·¹ì ì¸ ëª¨ìŠµ"
   - "íƒ€ì¸ì—ê²Œ ë„ì›€ì„ ìš”ì²­í•˜ëŠ” ê²ƒì„ ì–´ë ¤ì›Œí•¨"

   ìœ„ ì¹´í…Œê³ ë¦¬ë“¤ì„ ê· ë“±í•˜ê²Œ í™œìš©í•˜ì—¬ ë‹¤ì–‘ì„±ì„ í™•ë³´í•˜ì„¸ìš”.

3. **í”„ë¡œì íŠ¸ ì„±ê³¼ì™€ ì–´ë ¤ì›€**: ê° í”„ë¡œì íŠ¸ì—ëŠ” ì„±ê³µì ì¸ ì„±ê³¼(achievements)ì™€ í•¨ê»˜ ê²ªì—ˆë˜ ì–´ë ¤ì›€(challenges)ì„ í¬í•¨ì‹œì¼œë¼.

4. **ê°œì¸ì  ë™ê¸°**: ì´ ì§€ì›ìê°€ ì™œ ì´ ì§ì—…ì„ ì„ íƒí–ˆëŠ”ì§€ì— ëŒ€í•œ ê°œì¸ì ì¸ ë™ê¸°(motivation)ë¥¼ ì´ë ¥ì„œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ë¡ í•´ë¼.

5. **ê°œì¸ì  êµí›ˆ**: ì´ë ¥ì„œì˜ í™œë™(ë¸”ë¡œê·¸, ì˜¤í”ˆì†ŒìŠ¤, í”„ë¡œì íŠ¸ ë“±)ì„ ë°”íƒ•ìœ¼ë¡œ ê°œì¸ì ì¸ êµí›ˆ(inferred_personal_experiences)ì„ ì¶”ë¡ í•´ë¼. **ì ˆëŒ€ ì—†ëŠ” ì‚¬ì‹¤ì„ ì§€ì–´ë‚´ì§€ ë§ˆë¼.**

6. **JSON ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜**: ë°˜ë“œì‹œ ì•„ë˜ ì§€ì •ëœ JSON ìŠ¤í‚¤ë§ˆì— ë§ì¶°ì„œ ì‘ë‹µí•´ì•¼ í•œë‹¤.

=== ì¶œë ¥ JSON ìŠ¤í‚¤ë§ˆ ===
{{
  "name": "ì¶˜ì‹ì´",
  "summary": "ì˜ˆ: 5ë…„ì°¨ Java ë°±ì—”ë“œ ê°œë°œìë¡œ, ëŒ€ìš©ëŸ‰ íŠ¸ë˜í”½ ì²˜ë¦¬ì™€ MSA ì„¤ê³„ì— ê°•ì ì´ ìˆìŠµë‹ˆë‹¤.",
  "background": {{
    "career_years": "ì˜ˆ: 5",
    "current_position": "ì˜ˆ: ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œì",
    "education": ["ì˜ˆ: OOëŒ€í•™êµ ì»´í“¨í„°ê³µí•™ê³¼ ì¡¸ì—…"]
  }},
  "technical_skills": ["ì˜ˆ: Java", "ì˜ˆ: Spring Boot"],
  "projects": [
    {{
      "name": "ì˜ˆ: ëŒ€ìš©ëŸ‰ ê²°ì œ ì‹œìŠ¤í…œ ê°œë°œ",
      "description": "ì˜ˆ: ì¼ì¼ 100ë§Œê±´ ê²°ì œ ì²˜ë¦¬ë¥¼ ìœ„í•œ ê³ ê°€ìš©ì„± ì‹œìŠ¤í…œ êµ¬ì¶•",
      "tech_stack": ["ì˜ˆ: Java", "ì˜ˆ: Redis"],
      "role": "ì˜ˆ: ë°±ì—”ë“œ ë¦¬ë“œ ê°œë°œì",
      "achievements": ["ì˜ˆ: ì²˜ë¦¬ ì†ë„ 40% í–¥ìƒ", "ì˜ˆ: ì‹œìŠ¤í…œ ì•ˆì •ì„± 99.9% ë‹¬ì„±"],
      "challenges": ["ì˜ˆ: ëŒ€ëŸ‰ íŠ¸ë˜í”½ ë°œìƒ ì‹œ ë°ì´í„°ë² ì´ìŠ¤ ë³‘ëª© í˜„ìƒ", "ì˜ˆ: ë ˆê±°ì‹œ ì‹œìŠ¤í…œê³¼ì˜ í˜¸í™˜ì„± ë¬¸ì œ"]
    }}
  ],
  "experiences": [
    {{
      "company": "ì˜ˆ: ABC í…Œí¬",
      "position": "ì˜ˆ: ì‹œë‹ˆì–´ ê°œë°œì",
      "period": "ì˜ˆ: 2020.03 - 2024.12",
      "achievements": ["ì˜ˆ: ê²°ì œ ì‹œìŠ¤í…œ ì„±ëŠ¥ ìµœì í™”", "ì˜ˆ: ì‹ ì… ê°œë°œì 3ëª… ë©˜í† ë§"]
    }}
  ],
  "strengths": ["ì˜ˆ: ëŒ€ìš©ëŸ‰ ì‹œìŠ¤í…œ ì„¤ê³„", "ì˜ˆ: ì„±ëŠ¥ ìµœì í™”"],
  "weaknesses": ["ì˜ˆ: ì™„ë²½ì£¼ì˜ì  ì„±í–¥ìœ¼ë¡œ ë•Œë¡œ ì¼ì • ì§€ì—°"],
  "motivation": "ì˜ˆ: ëŒ€í•™ ì‹œì ˆ ì²˜ìŒ ì½”ë”©ì„ ë°°ì› ì„ ë•Œì˜ ì„±ì·¨ê°ê³¼ ë¬¸ì œ í•´ê²°ì˜ ì¦‰ì‹œì— ë§¤ë ¥ì„ ëŠê»´ ê°œë°œìì˜ ê¸¸ì„ ì„ íƒí•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.",
  "inferred_personal_experiences": [
    {{
      "category": "ì˜ˆ: í•™ìŠµê²½í—˜",
      "experience": "ì˜ˆ: ê°œë°œ ë¸”ë¡œê·¸ë¥¼ ìš´ì˜í•˜ë©° ì§€ì‹ì„ ì •ë¦¬í•˜ê³  ê³µìœ í•˜ëŠ” í™œë™ì„ ì§€ì†í•´ì˜´",
      "lesson": "ì˜ˆ: ì§€ì‹ì„ ë‚¨ê³¼ ê³µìœ í•  ë•Œ ë” ê¹Šì´ ì´í•´í•˜ê²Œ ë˜ê³ , ë‹¤ë¥¸ ì‚¬ëŒë“¤ì˜ í”¼ë“œë°±ìœ¼ë¡œ ì„±ì¥í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ë°°ì› ìŠµë‹ˆë‹¤."
    }}
  ],
  "career_goal": "ì˜ˆ: {company_name}ì˜ ê³ ê°€ìš©ì„± ì‹œìŠ¤í…œì„ ì±…ì„ì§€ëŠ” ê¸°ìˆ  ë¦¬ë”ë¡œ ì„±ì¥í•˜ì—¬, ì „ ì„¸ê³„ ì‚¬ìš©ìë“¤ì—ê²Œ ì•ˆì •ì ì´ê³  ë¹ ë¥¸ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.",
  "personality_traits": ["ì˜ˆ: ë¶„ì„ì ", "ì˜ˆ: ì¶”ì§„ë ¥ ìˆëŠ”"],
  "interview_style": "ì˜ˆ: êµ¬ì²´ì ì¸ ê²½í—˜ê³¼ ìˆ˜ì¹˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì²´ê³„ì ìœ¼ë¡œ ì„¤ëª…í•˜ëŠ” ìŠ¤íƒ€ì¼",
  "generated_by": "gpt-4o-mini",
  "resume_id": {resume_id}
}}

**ì¤‘ìš”**: 
1. ì´ë¦„ì€ ë°˜ë“œì‹œ "ì¶˜ì‹ì´"ë¡œ ì„¤ì •í•˜ì„¸ìš”.
2. ì˜¤ì§ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ê³ , ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ì£¼ì„ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
"""
        return prompt.strip()
    
    def _build_system_prompt_for_persona_generation(self) -> str:
        """í˜ë¥´ì†Œë‚˜ ìƒì„±ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return """ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ AI í˜ë¥´ì†Œë‚˜ ìƒì„± ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
ì´ë ¥ì„œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸ê°„ì ì´ê³  í˜„ì‹¤ì ì¸ AI ì§€ì›ì í˜ë¥´ì†Œë‚˜ë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

í•€ìˆ˜ ì§€ì‹œì‚¬í•­:
1. ì´ë ¥ì„œì— ìˆëŠ” ì‚¬ì‹¤ë§Œ ê¸°ë°˜ìœ¼ë¡œ ì¶”ë¡ í•˜ê³ , ì—†ëŠ” ì‚¬ì‹¤ì€ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
2. ì¸ê°„ì ì¸ ë§¤ë ¥ê³¼ ì•½ì ì„ ëª¨ë‘ í¬í•¨í•˜ì—¬ í˜„ì‹¤ì ì¸ ì¸ë¬¼ë¡œ ë§Œë“œì„¸ìš”.
3. íšŒì‚¬ì™€ ì§êµ°ì˜ íŠ¹ì„±ì— ë§ëŠ” í˜ë¥´ì†Œë‚˜ë¥¼ ìƒì„±í•˜ì„¸ìš”.
4. ë°˜ë“œì‹œ ì§€ì •ëœ JSON ìŠ¤í‚¤ë§ˆì— ë§ì¶° ì‘ë‹µí•˜ì„¸ìš”.
5. JSON ì™¸ì˜ ë‹¤ë¥¸ ë‚´ìš©ì€ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”."""
    
    def _generate_persona_with_extended_tokens(self, prompt: str, system_prompt: str) -> LLMResponse:
        """í˜ë¥´ì†Œë‚˜ ìƒì„±ìš© í™•ì¥ëœ í† í°ìœ¼ë¡œ LLM í˜¸ì¶œ"""
        import time
        
        try:
            # OpenAI í´ë¼ì´ì–¸íŠ¸ í™•ì¸
            if not self.openai_client:
                return LLMResponse(
                    content="",
                    provider=LLMProvider.OPENAI_GPT4O_MINI,
                    model_name="gpt-4o-mini",
                    error="OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                )
            
            start_time = time.time()
            
            messages = []
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            messages.append({"role": "user", "content": prompt})
            
            # í˜ë¥´ì†Œë‚˜ ìƒì„±ìš© í™•ì¥ íŒŒë¼ë¯¸í„°
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                max_tokens=1500,  # í˜ë¥´ì†Œë‚˜ ìƒì„±ì„ ìœ„í•´ ì¶©ë¶„í•œ í† í° í• ë‹¹
                temperature=0.7,
                timeout=60.0
            )
            
            response_time = time.time() - start_time
            
            return LLMResponse(
                content=response.choices[0].message.content.strip(),
                provider=LLMProvider.OPENAI_GPT4O_MINI,
                model_name="gpt-4o-mini",
                token_count=response.usage.total_tokens if response.usage else None,
                response_time=response_time
            )
            
        except Exception as e:
            return LLMResponse(
                content="",
                provider=LLMProvider.OPENAI_GPT4O_MINI,
                model_name="gpt-4o-mini",
                error=f"í˜ë¥´ì†Œë‚˜ ìƒì„± LLM í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"
            )
    
    def _parse_llm_response_to_persona(self, llm_response: str, resume_id: int) -> Optional[CandidatePersona]:
        """LLM JSON ì‘ë‹µì„ CandidatePersona ê°ì²´ë¡œ íŒŒì‹±"""
        try:
            # JSON ì˜ì—­ë§Œ ì¶”ì¶œ (ì „í›„ ì„¤ëª… ì œê±°)
            response_clean = llm_response.strip()
            
            # JSON ë¸”ë¡ ì°¾ê¸°
            if response_clean.startswith('```json'):
                response_clean = response_clean.replace('```json', '').replace('```', '').strip()
            elif response_clean.startswith('```'):
                response_clean = response_clean.replace('```', '').strip()
            
            # JSON íŒŒì‹±
            persona_data = json.loads(response_clean)
            
            # í•„ìˆ˜ í•„ë“œ ê²€ì¦
            required_fields = ['name', 'summary', 'background', 'technical_skills', 'projects', 'experiences', 
                              'strengths', 'weaknesses', 'motivation', 'inferred_personal_experiences', 
                              'career_goal', 'personality_traits', 'interview_style']
            
            for field in required_fields:
                if field not in persona_data:
                    print(f"âŒ í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
                    return None
            
            # CandidatePersona ê°ì²´ ìƒì„±
            persona = CandidatePersona(
                name=persona_data['name'],
                summary=persona_data['summary'],
                background=persona_data['background'],
                technical_skills=persona_data['technical_skills'],
                projects=persona_data['projects'],
                experiences=persona_data['experiences'],
                strengths=persona_data['strengths'],
                weaknesses=persona_data['weaknesses'],
                motivation=persona_data['motivation'],
                inferred_personal_experiences=persona_data['inferred_personal_experiences'],
                career_goal=persona_data['career_goal'],
                personality_traits=persona_data['personality_traits'],
                interview_style=persona_data['interview_style'],
                generated_by=persona_data.get('generated_by', 'gpt-4o-mini'),
                resume_id=resume_id
            )
            
            return persona
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            print(f"LLM ì‘ë‹µ ê¸¸ì´: {len(llm_response)} ë¬¸ì")
            print(f"ì‘ë‹µ ë§ˆì§€ë§‰ 100ì: ...{llm_response[-100:]}")
            return None
        except Exception as e:
            print(f"âŒ í˜ë¥´ì†Œë‚˜ ê°ì²´ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _load_companies_data(self) -> Dict[str, Any]:
        """íšŒì‚¬ ë°ì´í„° ë¡œë“œ"""
        return safe_json_load("llm/data/companies_data.json", {"companies": []})
    
    def _create_default_persona(self, company_name: str, position_name: str) -> Optional[CandidatePersona]:
        """fallback: ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„± (DBì—ì„œ ì´ë ¥ì„œë¥¼ ì°¾ì§€ ëª»í–ˆì„ ë•Œ)"""
        try:
            print(f"ğŸ”„ [DEFAULT PERSONA] ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹œì‘: {company_name} - {position_name}")
            
            # ê¸°ë³¸ ì´ë ¥ì„œ ë°ì´í„° ìƒì„±
            default_resume = {
                "ai_resume_id": -1,
                "title": f"{position_name} ì§€ì›ì",
                "content": f"""
ì´ë¦„: ê¹€ê°œë°œ
ì§ë¬´: {position_name}
ê²½ë ¥: 3ë…„ì°¨

[ê²½ë ¥ ì‚¬í•­]
- {company_name} ê´€ë ¨ í”„ë¡œì íŠ¸ ê²½í—˜ ë‹¤ìˆ˜
- {position_name} ë¶„ì•¼ ì „ë¬¸ì„± ë³´ìœ 
- íŒ€ í˜‘ì—… ë° ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ ìš°ìˆ˜

[ê¸°ìˆ  ìŠ¤íƒ]
- {position_name} ê´€ë ¨ í•µì‹¬ ê¸°ìˆ 
- í˜‘ì—… ë„êµ¬ í™œìš© ëŠ¥ë ¥
- ì§€ì†ì ì¸ í•™ìŠµ ë° ì„±ì¥ ë§ˆì¸ë“œ

[í”„ë¡œì íŠ¸ ê²½í—˜]
- {company_name} ìŠ¤íƒ€ì¼ì˜ ì„œë¹„ìŠ¤ ê°œë°œ ê²½í—˜
- ì‚¬ìš©ì ì¤‘ì‹¬ì˜ ì„œë¹„ìŠ¤ ì„¤ê³„ ë° ê°œë°œ
- ì„±ëŠ¥ ìµœì í™” ë° ìœ ì§€ë³´ìˆ˜ ê²½í—˜
                """.strip(),
                "position_id": 99  # ê¸°ë³¸ê°’
            }
            
            # LLMìœ¼ë¡œ í˜ë¥´ì†Œë‚˜ ìƒì„±
            company_info = self._get_company_info(company_name)
            persona = self._generate_persona_with_llm(default_resume, company_info, position_name)
            
            if persona:
                print(f"âœ… [DEFAULT PERSONA] ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„± ì„±ê³µ: {persona.name}")
                return persona
            else:
                print(f"âŒ [DEFAULT PERSONA] ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹¤íŒ¨")
                return None
                
        except Exception as e:
            print(f"âŒ [DEFAULT PERSONA] ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return None

    def _get_company_korean_name(self, company_code: str) -> str:
        """íšŒì‚¬ ì½”ë“œë¥¼ í•œêµ­ì–´ íšŒì‚¬ëª…ìœ¼ë¡œ ë³€í™˜"""
        company_mapping = {
            "naver": "ë„¤ì´ë²„",
            "kakao": "ì¹´ì¹´ì˜¤", 
            "toss": "í† ìŠ¤",
            "line": "ë¼ì¸",
            "ë¼ì¸í”ŒëŸ¬ìŠ¤": "ë¼ì¸í”ŒëŸ¬ìŠ¤",
            "coupang": "ì¿ íŒ¡",
            "baemin": "ë°°ë‹¬ì˜ë¯¼ì¡±",
            "daangn": "ë‹¹ê·¼ë§ˆì¼“",
            # ì´ë¯¸ í•œêµ­ì–´ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
            "ë„¤ì´ë²„": "ë„¤ì´ë²„",
            "ì¹´ì¹´ì˜¤": "ì¹´ì¹´ì˜¤",
            "í† ìŠ¤": "í† ìŠ¤",
            "ë¼ì¸": "ë¼ì¸", 
            "ì¿ íŒ¡": "ì¿ íŒ¡",
            "ë°°ë‹¬ì˜ë¯¼ì¡±": "ë°°ë‹¬ì˜ë¯¼ì¡±",
            "ë‹¹ê·¼ë§ˆì¼“": "ë‹¹ê·¼ë§ˆì¼“"
        }
        
        return company_mapping.get(company_code.lower(), company_code.capitalize())
    
    def _load_fixed_questions(self) -> Dict[str, List[Dict]]:
        """ê³ ì • ì§ˆë¬¸ ë°ì´í„° ë¡œë“œ"""
        return get_fixed_questions()
    
    def start_ai_interview(self, company_id: str, position: str) -> str:
        """AI ì§€ì›ì ë©´ì ‘ ì‹œì‘ (ë©´ì ‘ìì™€ ë™ì¼í•œ í”Œë¡œìš°)"""
        persona = self.get_persona(company_id)
        if not persona:
            raise ValueError(f"íšŒì‚¬ {company_id}ì˜ AI ì§€ì›ì í˜ë¥´ì†Œë‚˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # AI ì„¸ì…˜ ìƒì„±
        ai_session = AICandidateSession(company_id, position, persona)
        self.ai_sessions[ai_session.session_id] = ai_session
        
        return ai_session.session_id
    
    def get_ai_next_question(self, ai_session_id: str) -> Optional[Dict[str, Any]]:
        """AI ì§€ì›ì ë‹¤ìŒ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸° (ë©´ì ‘ìì™€ ë™ì¼í•œ êµ¬ì¡°)"""
        ai_session = self.ai_sessions.get(ai_session_id)
        if not ai_session or ai_session.is_complete():
            return None
        
        # í˜„ì¬ ì§ˆë¬¸ ê³„íš ê°€ì ¸ì˜¤ê¸°
        question_plan = ai_session.get_next_question_plan()
        if not question_plan:
            return None
        
        # ë©´ì ‘ìì™€ ë™ì¼í•œ ì§ˆë¬¸ ìƒì„± ë¡œì§
        question_content, question_intent = self._generate_ai_question(
            ai_session, question_plan
        )
        
        return {
            "question_id": f"ai_q_{ai_session.current_question_count + 1}",
            "question_type": question_plan["type"].value,
            "question_content": question_content,
            "question_intent": question_intent,
            "progress": f"{ai_session.current_question_count + 1}/{len(ai_session.question_plan)}",
            "personalized": False  # AIëŠ” í‘œì¤€ ì§ˆë¬¸ ì‚¬ìš©
        }
    
    def _generate_ai_question(self, ai_session: AICandidateSession, question_plan: Dict) -> tuple[str, str]:
        """AI ì§€ì›ììš© ì§ˆë¬¸ ìƒì„± (ë©´ì ‘ìì™€ ë™ì¼í•œ ë¡œì§)"""
        question_type = question_plan["type"]
        
        # AI ì´ë¦„ ê°€ì ¸ì˜¤ê¸° (ì¶˜ì‹ì´)
        ai_name = self.get_ai_name(LLMProvider.OPENAI_GPT35)
        
        # ì²« ë‘ ì§ˆë¬¸ì€ ì™„ì „íˆ ê³ ì • (AI ì „ìš© - honorific í¬í•¨)
        if question_type == QuestionType.INTRO:
            return (
                f"{ai_name}ë‹˜, ìê¸°ì†Œê°œë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤.",
                "ì§€ì›ìì˜ ê¸°ë³¸ ë°°ê²½, ê²½ë ¥, ì„±ê²©ì„ íŒŒì•…í•˜ì—¬ ë©´ì ‘ ë¶„ìœ„ê¸°ë¥¼ ì¡°ì„±"
            )
        elif question_type == QuestionType.MOTIVATION:
            company_data = self._get_company_data(ai_session.company_id)
            return (
                f"{ai_name}ë‹˜ê»˜ì„œ {company_data.get('name', 'ì €í¬ íšŒì‚¬')}ì— ì§€ì›í•˜ê²Œ ëœ ë™ê¸°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                "íšŒì‚¬ì— ëŒ€í•œ ê´€ì‹¬ë„, ì§€ì› ì˜ì§€, íšŒì‚¬ ì´í•´ë„ë¥¼ í‰ê°€"
            )
        
        # ê³ ì • ì§ˆë¬¸ í’€ì—ì„œ ì„ íƒ
        if question_type == QuestionType.HR:
            questions = self.fixed_questions.get("hr_questions", [])
        elif question_type == QuestionType.TECH:
            questions = self.fixed_questions.get("technical_questions", [])
        elif question_type == QuestionType.COLLABORATION:
            questions = self.fixed_questions.get("collaboration_questions", [])
        else:
            # FOLLOWUPì´ë‚˜ ê¸°íƒ€ ì§ˆë¬¸ì€ ë™ì  ìƒì„±
            return self._generate_dynamic_question(ai_session, question_type)
        
        # ì´ë¯¸ ì‚¬ìš©ëœ ì§ˆë¬¸ ì œì™¸
        used_questions = set()
        for qa in ai_session.ai_answers:
            used_questions.add(qa.question_content)
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì§ˆë¬¸ í•„í„°ë§
        available_questions = [q for q in questions if q["content"] not in used_questions]
        
        if available_questions:
            # ë ˆë²¨ì— ë”°ë¼ ì •ë ¬ëœ ì§ˆë¬¸ ì„ íƒ
            current_question_index = ai_session.current_question_count
            if current_question_index < len(available_questions):
                selected_question = available_questions[current_question_index % len(available_questions)]
            else:
                selected_question = available_questions[0]
            
            # ì§ˆë¬¸ì— AI ì´ë¦„ í˜¸ì¹­ ì¶”ê°€
            ai_name = self.get_ai_name(LLMProvider.OPENAI_GPT35)
            question_content = self._add_honorific_to_question(selected_question["content"], ai_name)
            return question_content, selected_question["intent"]
        
        # í´ë°± ì§ˆë¬¸
        ai_name = self.get_ai_name(LLMProvider.OPENAI_GPT35)
        return self._get_fallback_question(question_type, ai_name)
    
    def _generate_dynamic_question(self, ai_session: AICandidateSession, question_type: QuestionType) -> tuple[str, str]:
        """ë™ì  ì§ˆë¬¸ ìƒì„± (ì‹¬í™” ì§ˆë¬¸ ë“±)"""
        context = ai_session.get_previous_answers_context()
        company_data = self._get_company_data(ai_session.company_id)
        
        if question_type == QuestionType.FOLLOWUP:
            # ì´ì „ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ì‹¬í™” ì§ˆë¬¸
            if ai_session.ai_answers:
                last_answer = ai_session.ai_answers[-1]
                return (
                    f"ë°©ê¸ˆ ë§ì”€í•˜ì‹  {last_answer.question_content[:30]}... ë¶€ë¶„ì— ëŒ€í•´ ì¢€ ë” ìì„¸íˆ ì„¤ëª…í•´ ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?",
                    "ì´ì „ ë‹µë³€ì˜ êµ¬ì²´ì ì¸ ì‚¬ë¡€ë‚˜ ê²½í—˜ì˜ ë””í…Œì¼ íƒêµ¬"
                )
        
        ai_name = self.get_ai_name(LLMProvider.OPENAI_GPT35)
        return f"{ai_name}ë‹˜ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ìŠµë‹ˆë‹¤.", "ì¼ë°˜ì ì¸ ì§ˆë¬¸"
    
    def _get_fallback_question(self, question_type: QuestionType, persona_name: str) -> tuple[str, str]:
        """í´ë°± ì§ˆë¬¸ (ë©´ì ‘ìì™€ ë™ì¼)"""
        fallback_questions = {
            QuestionType.INTRO: (f"{persona_name}ë‹˜, ê°„ë‹¨í•œ ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.", "ê¸°ë³¸ ë°°ê²½ íŒŒì•…"),
            QuestionType.MOTIVATION: (f"{persona_name}ë‹˜ì´ ì €í¬ íšŒì‚¬ì— ì§€ì›í•˜ê²Œ ëœ ë™ê¸°ê°€ ê¶ê¸ˆí•©ë‹ˆë‹¤.", "ì§€ì› ë™ê¸° íŒŒì•…"),
            QuestionType.HR: (f"{persona_name}ë‹˜ì˜ ì¥ì ê³¼ ì„±ì¥í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì€ ë¬´ì—‡ì¸ê°€ìš”?", "ê°œì¸ì  íŠ¹ì„± í‰ê°€"),
            QuestionType.TECH: (f"{persona_name}ë‹˜ì˜ ê¸°ìˆ ì  ê²½í—˜ì— ëŒ€í•´ ë§ì”€í•´ ì£¼ì„¸ìš”.", "ê¸°ìˆ  ì—­ëŸ‰ í‰ê°€"),
            QuestionType.COLLABORATION: (f"{persona_name}ë‹˜ì˜ íŒ€ í˜‘ì—… ê²½í—˜ì„ ê³µìœ í•´ ì£¼ì„¸ìš”.", "í˜‘ì—… ëŠ¥ë ¥ í‰ê°€"),
            QuestionType.FOLLOWUP: (f"{persona_name}ë‹˜ì´ ê°€ì¥ ìì‹  ìˆëŠ” ê²½í—˜ì„ ë” ìì„¸íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”.", "ì‹¬í™” íƒêµ¬")
        }
        return fallback_questions.get(question_type, (f"{persona_name}ë‹˜, ë³¸ì¸ì— ëŒ€í•´ ë§ì”€í•´ ì£¼ì„¸ìš”.", "ì¼ë°˜ì ì¸ ì§ˆë¬¸"))
    
    def _add_honorific_to_question(self, question_content: str, ai_name: str) -> str:
        """ì§ˆë¬¸ì— AI ì´ë¦„ í˜¸ì¹­ ì¶”ê°€"""
        # ì´ë¯¸ í˜¸ì¹­ì´ í¬í•¨ëœ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
        if "ë‹˜" in question_content or ai_name in question_content:
            return question_content
        
        # ì§ˆë¬¸ ì•ì— í˜¸ì¹­ ì¶”ê°€
        return f"{ai_name}ë‹˜, {question_content}"

    def generate_ai_answer_for_question(self, ai_session_id: str, question_data: Dict[str, Any]) -> AnswerResponse:
        """íŠ¹ì • ì§ˆë¬¸ì— ëŒ€í•œ AI ë‹µë³€ ìƒì„± (ì¼ê´€ì„± ìœ ì§€)"""
        ai_session = self.ai_sessions.get(ai_session_id)
        if not ai_session:
            return AnswerResponse(
                answer_content="",
                quality_level=QualityLevel(8),
                llm_provider=LLMProvider.OPENAI_GPT4O_MINI,
                persona_name="Unknown",
                confidence_score=0.0,
                response_time=0.0,
                reasoning="AI ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ",
                error=f"AI ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ai_session_id}"
            )
        
        # í˜ë¥´ì†Œë‚˜ë¥¼ ì„¸ì…˜ì— 1íšŒë§Œ ìƒì„±/ì €ì¥
        if not hasattr(ai_session, 'persona') or ai_session.persona is None:
            # ğŸ†• LLM ê¸°ë°˜ ì‹¤ì‹œê°„ í˜ë¥´ì†Œë‚˜ ìƒì„± ì‚¬ìš©
            print(f"ğŸ¯ LLMìœ¼ë¡œ {ai_session.company_id} í˜ë¥´ì†Œë‚˜ ì‹¤ì‹œê°„ ìƒì„± ì¤‘...")
            ai_session.persona = self.create_persona_for_interview(ai_session.company_id, ai_session.position)
        persona = ai_session.persona
        
        if not persona:
            # Fallback: ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„±
            print(f"âš ï¸ {ai_session.company_id} í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹¤íŒ¨, ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ë¡œ fallback")
            persona = self._create_default_persona(ai_session.company_id, ai_session.position)
            ai_session.persona = persona
        
        if not persona:
            # ìµœì¢… fallback: í•˜ë“œì½”ë”©ëœ ê¸°ë³¸ ë‹µë³€ ìƒì„±
            print(f"ğŸ”„ ëª¨ë“  í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹¤íŒ¨, ê¸°ë³¸ ë‹µë³€ìœ¼ë¡œ fallback")
            return AnswerResponse(
                answer_content=f"ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” {ai_session.company_id}ì— ì§€ì›í•œ {ai_session.position} ê°œë°œìì…ë‹ˆë‹¤. 3ë…„ê°„ì˜ ê°œë°œ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ {self._get_company_korean_name(ai_session.company_id)}ì—ì„œ ë” í° ì„±ì¥ì„ ì´ë£¨ê³  ì‹¶ì–´ ì§€ì›í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ê¸°ìˆ  ìŠµë“ì— ì—´ì •ì ì´ë©°, íŒ€ì›Œí¬ë¥¼ ì¤‘ì‹œí•˜ëŠ” ê°œë°œìì…ë‹ˆë‹¤.",
                quality_level=QualityLevel(8),
                llm_provider=LLMProvider.OPENAI_GPT4O_MINI,
                persona_name=f"{self._get_company_korean_name(ai_session.company_id)} ì§€ì›ì",
                confidence_score=0.8,
                response_time=0.5,
                reasoning="ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ì‚¬ìš©",
                error=None
            )
        
        # ì¼ê´€ì„± ìˆëŠ” ë‹µë³€ ìƒì„±ì„ ìœ„í•œ ìš”ì²­ êµ¬ì„±
        request = AnswerRequest(
            question_content=question_data["question_content"],
            question_type=QuestionType(question_data["question_type"]),
            question_intent=question_data["question_intent"],
            company_id=ai_session.company_id,
            position=ai_session.position,
            quality_level=QualityLevel(8),  # ê³ í’ˆì§ˆ ë‹µë³€
            llm_provider=LLMProvider.OPENAI_GPT4O_MINI,
            additional_context=ai_session.get_previous_answers_context()
        )
        
        # ë‹µë³€ ìƒì„±
        answer_response = self.generate_answer(request, persona=persona)
        
        # AI ì„¸ì…˜ì— ë‹µë³€ ì €ì¥
        if not answer_response.error:
            qa_pair = QuestionAnswer(
                question_id=question_data["question_id"],
                question_type=QuestionType(question_data["question_type"]),
                question_content=question_data["question_content"],
                answer_content=answer_response.answer_content,
                timestamp=datetime.now(),
                question_intent=question_data["question_intent"]
            )
            ai_session.add_ai_answer(qa_pair)
        
        return answer_response
    
    def _parse_personas_data(self, personas_data: Dict) -> Dict[str, CandidatePersona]:
        """í˜ë¥´ì†Œë‚˜ ë°ì´í„° íŒŒì‹±"""
        personas = {}
        for company_id, data in personas_data.items():
            personas[company_id] = CandidatePersona(
                company_id=company_id,
                name=data.get("name", f"ì§€ì›ì_{company_id}"),
                background=data.get("background", {}),
                technical_skills=data.get("technical_skills", []),
                projects=data.get("projects", []),
                experiences=data.get("experiences", []),
                strengths=data.get("strengths", []),
                achievements=data.get("achievements", []),
                career_goal=data.get("career_goal", ""),
                personality_traits=data.get("personality_traits", []),
                interview_style=data.get("interview_style", ""),
                success_factors=data.get("success_factors", [])
            )
        return personas
    
    def get_persona(self, company_id: str) -> Optional[CandidatePersona]:
        """íšŒì‚¬ë³„ í˜ë¥´ì†Œë‚˜ ì¡°íšŒ (ë™ì  ìƒì„± ì‹œìŠ¤í…œì—ì„œëŠ” deprecated)"""
        print(f"âš ï¸ get_persona() ë©”ì„œë“œëŠ” deprecatedì…ë‹ˆë‹¤. create_persona_for_interview()ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        print(f"ğŸ” í˜ë¥´ì†Œë‚˜ ì¡°íšŒ ìš”ì²­: {company_id}")
        print(f"ğŸ” ìºì‹œëœ í˜ë¥´ì†Œë‚˜: {list(self.candidate_personas.keys())}")
        persona = self.candidate_personas.get(company_id)
        if persona:
            print(f"âœ… ìºì‹œëœ í˜ë¥´ì†Œë‚˜ ì°¾ìŒ: {persona.name}")
        else:
            print(f"âŒ ìºì‹œëœ í˜ë¥´ì†Œë‚˜ ì—†ìŒ: {company_id}")
        return persona
    
    def generate_answer(self, request: AnswerRequest, persona: CandidatePersona = None) -> AnswerResponse:
        """ì§ˆë¬¸ì— ëŒ€í•œ AI ì§€ì›ì ë‹µë³€ ìƒì„±"""
        start_time = datetime.now()
        
        # ğŸ†• í˜ë¥´ì†Œë‚˜ ì‚¬ìš© íŒ¨í„´ ì¶”ì 
        persona_source = "unknown"
        
        # í˜ë¥´ì†Œë‚˜ ì¡°íšŒ (íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬ëœ ê²½ìš° ìš°ì„  ì‚¬ìš©)
        if persona:
            persona_source = "provided_parameter"
            print(f"âœ… [GENERATE ANSWER] ì „ë‹¬ë°›ì€ í˜ë¥´ì†Œë‚˜ ì‚¬ìš©: {persona.name} (company: {request.company_id})")
        else:
            # ğŸ†• LLM ê¸°ë°˜ ì‹¤ì‹œê°„ í˜ë¥´ì†Œë‚˜ ìƒì„± ì‚¬ìš©
            persona_source = "created_new"
            print(f"ğŸ”„ [GENERATE ANSWER] í˜ë¥´ì†Œë‚˜ ì—†ìŒ - ìƒˆë¡œ ìƒì„±: {request.company_id}")
            persona = self.create_persona_for_interview(request.company_id, request.position)
            
        if not persona:
            # Fallback: ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„±
            persona_source = "fallback_default"
            print(f"âš ï¸ [GENERATE ANSWER] LLM í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹¤íŒ¨ - ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ë¡œ fallback")
            persona = self._create_default_persona(request.company_id, request.position)
            
        if not persona:
            # ìµœì¢… fallback: í•˜ë“œì½”ë”©ëœ ê¸°ë³¸ ë‹µë³€ ìƒì„±
            persona_source = "fallback_hardcoded"
            print(f"ğŸ”„ [GENERATE ANSWER] ëª¨ë“  í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹¤íŒ¨ - í•˜ë“œì½”ë”© ë‹µë³€ìœ¼ë¡œ fallback")
            return AnswerResponse(
                answer_content=f"ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” {request.company_id}ì— ì§€ì›í•œ {request.position} ê°œë°œìì…ë‹ˆë‹¤. 3ë…„ê°„ì˜ ê°œë°œ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ {self._get_company_korean_name(request.company_id)}ì—ì„œ ë” í° ì„±ì¥ì„ ì´ë£¨ê³  ì‹¶ì–´ ì§€ì›í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ê¸°ìˆ  ìŠµë“ì— ì—´ì •ì ì´ë©°, íŒ€ì›Œí¬ë¥¼ ì¤‘ì‹œí•˜ëŠ” ê°œë°œìì…ë‹ˆë‹¤.",
                quality_level=request.quality_level,
                llm_provider=request.llm_provider,
                persona_name=f"{self._get_company_korean_name(request.company_id)} ì§€ì›ì",
                confidence_score=0.7,
                response_time=0.1,
                reasoning="ê¸°ë³¸ ë‹µë³€ ì‚¬ìš© (API í‚¤ ì—†ìŒ)",
                error=None
            )
        
        # íšŒì‚¬ ë°ì´í„° ì¡°íšŒ
        company_data = self._get_company_data(request.company_id)
        
        # ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ì í•©í•œ í”„ë¡¬í”„íŠ¸ ë¹Œë”ë¥¼ í˜¸ì¶œí•˜ë„ë¡ ë¶„ê¸° ë¡œì§ ì¶”ê°€
        prompt_builders = {
            QuestionType.INTRO: self._build_intro_prompt,
            QuestionType.MOTIVATION: self._build_motivation_prompt,
            QuestionType.HR: self._build_hr_prompt,
            QuestionType.TECH: self._build_tech_prompt,
            QuestionType.COLLABORATION: self._build_collaboration_prompt,
        }
        
        # ì í•©í•œ ë¹Œë”ë¥¼ ì°¾ê±°ë‚˜, ì—†ìœ¼ë©´ ê¸°ë³¸ ë¹Œë” ì‚¬ìš©
        builder = prompt_builders.get(request.question_type, self._build_default_prompt)
        prompt = builder(request, persona, company_data)
        
        system_prompt = self._build_system_prompt(persona, company_data, request.question_type, request.llm_provider)
        
        # í’ˆì§ˆ ë ˆë²¨ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ì¡°ì •
        quality_prompt = self.quality_controller.generate_quality_prompt(
            prompt, 
            request.quality_level,
            request.question_type.value
        )
        
        # LLM ì‘ë‹µ ìƒì„± - OpenAI í´ë¼ì´ì–¸íŠ¸ ì§ì ‘ ì‚¬ìš©
        if not self.openai_client:
            llm_response = LLMResponse(
                content="",
                provider=LLMProvider.OPENAI_GPT4O_MINI,
                model_name="gpt-4o-mini",
                error="OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            )
        else:
            try:
                import time
                api_start_time = time.time()
                
                messages = []
                if system_prompt:
                    messages.append({"role": "system", "content": system_prompt})
                messages.append({"role": "user", "content": quality_prompt})
                
                response = self.openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=messages,
                    max_tokens=400,
                    temperature=0.6,
                    timeout=60.0
                )
                
                api_response_time = time.time() - api_start_time
                
                llm_response = LLMResponse(
                    content=response.choices[0].message.content.strip(),
                    provider=LLMProvider.OPENAI_GPT4O_MINI,
                    model_name="gpt-4o-mini",
                    token_count=response.usage.total_tokens if response.usage else None,
                    response_time=api_response_time
                )
                
            except Exception as e:
                llm_response = LLMResponse(
                    content="",
                    provider=LLMProvider.OPENAI_GPT4O_MINI,
                    model_name="gpt-4o-mini",
                    error=f"API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"
                )
        
        # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
        response_time = (datetime.now() - start_time).total_seconds()
        
        # ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
        confidence_score = self._calculate_confidence_score(llm_response, request.quality_level)
        
        # ë‹µë³€ í›„ì²˜ë¦¬
        processed_answer = self._post_process_answer(llm_response.content, request.quality_level)
        
        # ëª¨ë¸ì— ë”°ë¥¸ AI ì´ë¦„ ê²°ì •
        ai_name = self.get_ai_name(request.llm_provider)
        
        # ğŸ†• í˜ë¥´ì†Œë‚˜ ì¼ê´€ì„± ë¡œê·¸
        print(f"ğŸ“Š [ANSWER COMPLETE] ë‹µë³€ ìƒì„± ì™„ë£Œ:")
        print(f"   - í˜ë¥´ì†Œë‚˜: {persona.name}")
        print(f"   - í˜ë¥´ì†Œë‚˜ ì†ŒìŠ¤: {persona_source}")
        print(f"   - íšŒì‚¬: {request.company_id}")
        print(f"   - ì§ˆë¬¸ íƒ€ì…: {request.question_type}")
        print(f"   - ì‘ë‹µì‹œê°„: {response_time:.2f}ì´ˆ")
        print(f"   - ë‹µë³€ ë‚´ìš©: {processed_answer[:100]}..." if len(processed_answer) > 100 else f"   - ë‹µë³€ ë‚´ìš©: {processed_answer}")
        
        return AnswerResponse(
            answer_content=processed_answer,
            quality_level=request.quality_level,
            llm_provider=request.llm_provider,
            persona_name=ai_name,  # ëª¨ë¸ë³„ ê³ ì • ì´ë¦„ ì‚¬ìš©
            confidence_score=confidence_score,
            response_time=response_time,
            reasoning=f"{ai_name}ì˜ {request.company_id} ë©´ì ‘ ë‹µë³€ (í’ˆì§ˆ ë ˆë²¨: {request.quality_level.value})",
            error=llm_response.error,
            metadata={
                "token_count": llm_response.token_count,
                "company_id": request.company_id,
                "question_type": request.question_type.value,
                "original_prompt_length": len(prompt),
                "persona_source": persona_source,  # ğŸ†• í˜ë¥´ì†Œë‚˜ ì†ŒìŠ¤ ì¶”ê°€
                "persona_name_internal": persona.name if persona else "Unknown"  # ğŸ†• ì‹¤ì œ í˜ë¥´ì†Œë‚˜ ì´ë¦„
            }
        )
    
    def _get_relevant_personal_experiences(self, persona: CandidatePersona, question_content: str) -> str:
        """ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê°œì¸ì  ê²½í—˜ ì„ ë³„"""
        
        # í˜ë¥´ì†Œë‚˜ì—ì„œ ê°œì¸ ê²½í—˜ ì¶”ì¶œ
        personal_experiences = self._get_persona_attribute(persona, 'personal_experiences', [])
        if not personal_experiences:
            return "ê°œì¸ì  ê²½í—˜: ì„±ì‹¤í•˜ê³  ê¾¸ì¤€íˆ ë…¸ë ¥í•˜ëŠ” ì„±ê²©ìœ¼ë¡œ, ì–´ë ¤ìš´ ìƒí™©ì—ì„œë„ í¬ê¸°í•˜ì§€ ì•Šê³  ëê¹Œì§€ ìµœì„ ì„ ë‹¤í•˜ëŠ” ê²ƒì„ ì¤‘ìš”í•˜ê²Œ ìƒê°í•©ë‹ˆë‹¤."
        
        # ì§ˆë¬¸ ë‚´ìš©ì— ë”°ë¼ ê´€ë ¨ ê²½í—˜ ì„ ë³„
        question_lower = question_content.lower()
        relevant_experiences = []
        
        # í‚¤ì›Œë“œ ë§¤í•‘
        keyword_category_map = {
            "ê°€ì¹˜ê´€": ["ê°€ì¹˜ê´€í˜•ì„±", "ê°œì¸ë„ì „"],
            "ì„±ê²©": ["ì¸ê°„ê´€ê³„", "ê°œì¸ë„ì „"],
            "ê°•ì ": ["í•™ì°½ì‹œì ˆ", "ê°œì¸ë„ì „", "ì‹¤íŒ¨ê·¹ë³µ"],
            "ì•½ì ": ["ì‹¤íŒ¨ê·¹ë³µ", "ì¸ê°„ê´€ê³„"],
            "ì„±ì¥": ["ê°œì¸ë„ì „", "ì‹¤íŒ¨ê·¹ë³µ", "í•™ì°½ì‹œì ˆ"],
            "ëª©í‘œ": ["ê°€ì¹˜ê´€í˜•ì„±", "ê°œì¸ë„ì „"],
            "ë„ì „": ["ê°œì¸ë„ì „", "ì‹¤íŒ¨ê·¹ë³µ"],
            "í˜‘ì—…": ["ì¸ê°„ê´€ê³„", "í•™ì°½ì‹œì ˆ"],
            "ì†Œí†µ": ["ì¸ê°„ê´€ê³„", "í•™ì°½ì‹œì ˆ"],
            "ë¦¬ë”ì‹­": ["í•™ì°½ì‹œì ˆ", "ì¸ê°„ê´€ê³„"],
            "ì‹¤íŒ¨": ["ì‹¤íŒ¨ê·¹ë³µ"],
            "ì–´ë ¤ì›€": ["ì‹¤íŒ¨ê·¹ë³µ", "ê°€ì¹˜ê´€í˜•ì„±"]
        }
        
        # ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
        matched_categories = set()
        for keyword, categories in keyword_category_map.items():
            if keyword in question_lower:
                matched_categories.update(categories)
        
        # ê´€ë ¨ ê²½í—˜ ì„ ë³„
        for exp in personal_experiences:
            if not matched_categories or exp.get('category') in matched_categories:
                relevant_experiences.append(exp)
        
        # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ ì„ ë³„
        if not relevant_experiences:
            relevant_experiences = personal_experiences[:3]
        else:
            relevant_experiences = relevant_experiences[:3]
        
        # ê²½í—˜ë“¤ì„ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…
        experience_text = ""
        for i, exp in enumerate(relevant_experiences, 1):
            experience_text += f"""
{i}. [{exp.get('category', 'ê°œì¸ê²½í—˜')}] {exp.get('experience', '')}
   ë°°ìš´ ì : {exp.get('lesson', '')}
   ê°ì •: {exp.get('emotion', '')}
"""
        
        return experience_text.strip()
    
    def _get_persona_attribute(self, persona: CandidatePersona, attr_name: str, default_value):
        """í˜ë¥´ì†Œë‚˜ ì†ì„± ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # í˜ë¥´ì†Œë‚˜ ê°ì²´ì—ì„œ ì§ì ‘ ì†ì„± ì ‘ê·¼
            if hasattr(persona, attr_name):
                return getattr(persona, attr_name)
            
            # ì‚¬ì „ í˜•íƒœë¡œ ì ‘ê·¼ (í˜ë¥´ì†Œë‚˜ê°€ dictì¸ ê²½ìš°)
            if hasattr(persona, '__dict__') and attr_name in persona.__dict__:
                return persona.__dict__[attr_name]
            
            # JSON ë°ì´í„°ì—ì„œ ì§ì ‘ ë¡œë“œí•œ ê²½ìš° - _raw_data ì†ì„± í™•ì¸
            if hasattr(persona, '_raw_data') and attr_name in persona._raw_data:
                return persona._raw_data[attr_name]
            
            # í˜ë¥´ì†Œë‚˜ ë”•ì…”ë„ˆë¦¬ì—ì„œ ì§ì ‘ ì ‘ê·¼ ì‹œë„
            persona_dict = self._get_persona_dict(persona.company_id, persona.name)
            if persona_dict and attr_name in persona_dict:
                return persona_dict[attr_name]
                
            return default_value
        except:
            return default_value
    
    def _get_persona_dict(self, company_id: str, persona_name: str) -> Dict[str, Any]:
        """í˜ë¥´ì†Œë‚˜ ë”•ì…”ë„ˆë¦¬ ì§ì ‘ ì¡°íšŒ"""
        try:
            personas = self.personas_data.get("personas", {})
            if company_id in personas:
                return personas[company_id]
            return {}
        except:
            return {}
    
    def _get_company_data(self, company_id: str) -> Dict[str, Any]:
        """íšŒì‚¬ ë°ì´í„° ì¡°íšŒ"""
        for company in self.companies_data.get("companies", []):
            if company["id"] == company_id:
                return company
        return {}
    
    def get_ai_name(self, llm_provider: LLMProvider) -> str:
        """ëª¨ë¸ì— ë”°ë¥¸ AI ì§€ì›ì ì´ë¦„ ë°˜í™˜"""
        return AI_CANDIDATE_NAMES.get(llm_provider, "ì¶˜ì‹ì´")  # ê¸°ë³¸ê°’: ì¶˜ì‹ì´
    
    def _build_system_prompt(self, persona: CandidatePersona, company_data: Dict, question_type: QuestionType, llm_provider: LLMProvider = LLMProvider.OPENAI_GPT35) -> str:
        """ì§ˆë¬¸ íƒ€ì…ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        
        # AI ì´ë¦„ ê²°ì • (ëª¨ë¸ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì„¤ì •)
        ai_name = self.get_ai_name(llm_provider)
        
        base_info = f"""ë‹¹ì‹ ì€ {company_data.get('name', 'íšŒì‚¬')} ë©´ì ‘ì— ì°¸ì—¬í•œ ìš°ìˆ˜í•œ ì§€ì›ìì…ë‹ˆë‹¤.

=== ì¤‘ìš”: ë‹¹ì‹ ì˜ ì´ë¦„ì€ "{ai_name}"ì…ë‹ˆë‹¤ ===
- **ìê¸°ì†Œê°œ ì§ˆë¬¸(INTRO)ì—ì„œë§Œ** "{ai_name}"ë¼ê³  ì´ë¦„ì„ ì–¸ê¸‰í•˜ì„¸ìš”
- **ë‹¤ë¥¸ ëª¨ë“  ì§ˆë¬¸ì—ì„œëŠ” ì ˆëŒ€ ì´ë¦„ì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”**
- "ì•ˆë…•í•˜ì„¸ìš”" ê°™ì€ ì¸ì‚¬ë§ë„ ìê¸°ì†Œê°œê°€ ì•„ë‹Œ ê²½ìš° ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ë‹¤ë¥¸ ì´ë¦„(ê¹€ë„¤ì´ë²„, ë°•ì¹´ì¹´ì˜¤ ë“±)ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”

ì˜ˆì‹œ:
- ìê¸°ì†Œê°œ: "ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” {ai_name}ë¼ê³  í•©ë‹ˆë‹¤. 5ë…„ì˜ ë°±ì—”ë“œ ê°œë°œ ê²½í—˜ì„..."
- ì§€ì›ë™ê¸°: "ì œê°€ ë„¤ì´ë²„ì— ì§€ì›í•˜ê²Œ ëœ ì´ìœ ëŠ”..." (ì´ë¦„/ì¸ì‚¬ ì—†ì´ ë°”ë¡œ ì‹œì‘)
- ê¸°ìˆ ì§ˆë¬¸: "ê·¸ ë¶€ë¶„ì— ëŒ€í•´ì„œëŠ” ì œ ê²½í—˜ì„ ë§ì”€ë“œë¦¬ë©´..." (ì´ë¦„/ì¸ì‚¬ ì—†ì´)
- ê¸°íƒ€ì§ˆë¬¸: "ì œ ìƒê°ì—ëŠ”..." ë˜ëŠ” "ì €ì˜ ê²½í—˜ìœ¼ë¡œëŠ”..." (ì´ë¦„/ì¸ì‚¬ ì—†ì´)

=== ë‹¹ì‹ ì˜ ë°°ê²½ ===
- ê²½ë ¥: {persona.background.get('career_years', '0')}ë…„
- í˜„ì¬ ì§ì±…: {persona.background.get('current_position', 'ì§€ì›ì')}
- ì„±ê²© íŠ¹ì„±: {', '.join(persona.personality_traits)}
- ë©´ì ‘ ìŠ¤íƒ€ì¼: {persona.interview_style}

=== ë‹¹ì‹ ì˜ ê°•ì  ===
{', '.join(persona.strengths)}

=== ë‹¹ì‹ ì˜ ëª©í‘œ ===
{persona.career_goal}"""

        if question_type == QuestionType.INTRO:
            return f"""{base_info}

=== ìê¸°ì†Œê°œ ì§ˆë¬¸ ë‹µë³€ ìŠ¤íƒ€ì¼ ===
- **ë°˜ë“œì‹œ "{ai_name}"ë¼ê³  ì´ë¦„ì„ ë¨¼ì € ì†Œê°œí•˜ì„¸ìš”**
- ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ìì‹ ì„ ì†Œê°œí•˜ì„¸ìš”
- ì£¼ìš” ê²½ë ¥ê³¼ ê°•ì ì„ ê°„ëµíˆ ì–¸ê¸‰í•˜ì„¸ìš”
- ë©´ì ‘ì— ëŒ€í•œ ê°ì‚¬ ì¸ì‚¬ë¥¼ í¬í•¨í•˜ì„¸ìš”
- ì˜ˆ: "ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” {ai_name}ë¼ê³  í•©ë‹ˆë‹¤. 5ë…„ì˜ ë°±ì—”ë“œ ê°œë°œ ê²½í—˜ì„ ê°€ì§€ê³  ìˆìœ¼ë©°..."

**ì¤‘ìš”**: ìê¸°ì†Œê°œ ì§ˆë¬¸ì—ì„œë§Œ ì´ë¦„ì„ ì–¸ê¸‰í•˜ì„¸ìš”. ë‹¤ë¥¸ ëª¨ë“  ì§ˆë¬¸ì—ì„œëŠ” ì´ë¦„ì„ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”."""
        
        elif question_type == QuestionType.HR:
            return f"""{base_info}

=== ì¸ì„± ì§ˆë¬¸ ë‹µë³€ ìŠ¤íƒ€ì¼ ===
- **ì ˆëŒ€ ì´ë¦„ì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”** (ì´ë¯¸ ìê¸°ì†Œê°œì—ì„œ í–ˆìŒ)
- **"ì•ˆë…•í•˜ì„¸ìš”" ê°™ì€ ì¸ì‚¬ë§ ì‚¬ìš© ê¸ˆì§€**
- ë°”ë¡œ ë‹µë³€ ë‚´ìš©ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”
- **ê°œì¸ì ì´ê³  ì§„ì •ì„± ìˆê²Œ** ë‹µë³€í•˜ì„¸ìš”
- ê¸°ìˆ ì /í”„ë¡œì íŠ¸ ê²½í—˜ë³´ë‹¤ëŠ” **ê°œì¸ì  ê²½í—˜ê³¼ ê°ì •**ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€
- ë‹¹ì‹ ì˜ **ê°€ì¹˜ê´€, ì„±ê²©, ì¸ìƒ ì² í•™**ì„ ë“œëŸ¬ë‚´ì„¸ìš”
- "ì œ ê²½í—˜ì„ ë§ì”€ë“œë¦¬ë©´..." "ì €ëŠ” ê°œì¸ì ìœ¼ë¡œ..." ê°™ì€ í‘œí˜„ ì‚¬ìš©
- **ì†”ì§í•˜ê³  ì¸ê°„ì ì¸** ë©´ëª¨ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”
- êµ¬ì²´ì ì¸ ê°œì¸ ê²½í—˜ê³¼ ê·¸ë•Œì˜ **ê°ì •, ìƒê°ì˜ ë³€í™”**ë¥¼ í¬í•¨í•˜ì„¸ìš”"""
        
        elif question_type == QuestionType.TECH:
            return f"""{base_info}

=== ê¸°ìˆ  ì§ˆë¬¸ ë‹µë³€ ìŠ¤íƒ€ì¼ ===
- **ì´ë¦„ì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”** (ì´ë¯¸ ìê¸°ì†Œê°œì—ì„œ í–ˆìŒ)
- ê¸°ìˆ ì  ì „ë¬¸ì„±ê³¼ ê²½í—˜ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- êµ¬ì²´ì ì¸ í”„ë¡œì íŠ¸ ì‚¬ë¡€ì™€ ê¸°ìˆ  ìŠ¤íƒì„ ì–¸ê¸‰í•˜ì„¸ìš”
- ë¬¸ì œ í•´ê²° ê³¼ì •ê³¼ ê¸°ìˆ ì  ì„ íƒì˜ ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”
- ì „ë¬¸ì ì´ë©´ì„œë„ ìì‹ ê° ìˆëŠ” í†¤ì„ ìœ ì§€í•˜ì„¸ìš”"""
        
        elif question_type == QuestionType.COLLABORATION:
            return f"""{base_info}

=== í˜‘ì—… ì§ˆë¬¸ ë‹µë³€ ìŠ¤íƒ€ì¼ ===
- **ì´ë¦„ì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”** (ì´ë¯¸ ìê¸°ì†Œê°œì—ì„œ í–ˆìŒ)
- íŒ€ì›Œí¬ì™€ í˜‘ì—… ê²½í—˜ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- êµ¬ì²´ì ì¸ í˜‘ì—… ìƒí™©ê³¼ í•´ê²° ê³¼ì •ì„ ì„¤ëª…í•˜ì„¸ìš”
- ë‹¤ë¥¸ íŒ€ì›ë“¤ê³¼ì˜ ì†Œí†µ ë°©ì‹ê³¼ ê°ˆë“± í•´ê²° ê²½í—˜ì„ í¬í•¨í•˜ì„¸ìš”
- í˜‘ë ¥ì ì´ê³  ë°°ë ¤ì‹¬ ìˆëŠ” ë©´ëª¨ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”"""
        
        else:  # MOTIVATION, FOLLOWUP ë“±
            return f"""{base_info}

=== ë©´ì ‘ íƒœë„ ===
- **ì ˆëŒ€ ì´ë¦„ì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”** (ìê¸°ì†Œê°œê°€ ì•„ë‹Œ ê²½ìš°)
- **"ì•ˆë…•í•˜ì„¸ìš”" ê°™ì€ ì¸ì‚¬ë§ ì‚¬ìš© ê¸ˆì§€**
- ë°”ë¡œ ë‹µë³€ ë‚´ìš©ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”
- ìì‹ ê° ìˆê³  ì„±ì‹¤í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
- êµ¬ì²´ì ì¸ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- {company_data.get('name', 'íšŒì‚¬')}ì— ëŒ€í•œ ì§„ì •ì„± ìˆëŠ” ê´€ì‹¬ì„ ë³´ì—¬ì£¼ì„¸ìš”
- ì „ë¬¸ì ì´ë©´ì„œë„ ìì—°ìŠ¤ëŸ¬ìš´ í†¤ì„ ìœ ì§€í•˜ì„¸ìš”

ë‹µë³€ ì‹œì‘ ì˜ˆì‹œ:
- ì§€ì›ë™ê¸°: "ì œê°€ ë„¤ì´ë²„ì— ì§€ì›í•˜ê²Œ ëœ ì´ìœ ëŠ”..."
- ì¼ë°˜ì§ˆë¬¸: "ê·¸ ë¶€ë¶„ì— ëŒ€í•´ì„œëŠ”..." "ì œ ê²½í—˜ìœ¼ë¡œëŠ”..." "ì €ëŠ” í•­ìƒ..."
- ê¸°ìˆ ì§ˆë¬¸: "í•´ë‹¹ ê¸°ìˆ ì— ëŒ€í•œ ì œ ê²½í—˜ì„ ë§ì”€ë“œë¦¬ë©´..."
- í˜‘ì—…ì§ˆë¬¸: "íŒ€ì›Œí¬ ê´€ë ¨í•´ì„œëŠ” ì œê°€ ê²ªì—ˆë˜ ì‚¬ë¡€ê°€..."
"""
    
    def _build_intro_prompt(self, request: AnswerRequest, persona: CandidatePersona, company_data: Dict) -> str:
        """ìê¸°ì†Œê°œ ì§ˆë¬¸ ì „ìš© í”„ë¡¬í”„íŠ¸ ë¹Œë”"""
        
        # í˜ë¥´ì†Œë‚˜ì˜ í•µì‹¬ ì •ë³´ ì¶”ì¶œ
        summary = persona.summary
        name = persona.name
        background = persona.background
        main_strengths = persona.strengths[:2]  # ì£¼ìš” ê°•ì  1-2ê°œ
        career_goal = persona.career_goal
        
        # êµ¬ì²´ì  ê²½í—˜ê³¼ ì—°ê²°í•  í”„ë¡œì íŠ¸/ê²½í—˜ ì„ ë³„
        key_project = persona.projects[0] if persona.projects else {}
        key_experience = persona.experiences[0] if persona.experiences else {}
        
        prompt = f"""
=== ë©´ì ‘ ìƒí™© ===
íšŒì‚¬: {company_data.get('name', request.company_id)}
ì§êµ°: {request.position}
ì§ˆë¬¸ ìœ í˜•: {request.question_type.value} (ìê¸°ì†Œê°œ)
ì§ˆë¬¸: {request.question_content}
ì§ˆë¬¸ ì˜ë„: {request.question_intent}

=== ë‹¹ì‹ ì˜ ê¸°ë³¸ ì •ë³´ ===
- ì´ë¦„: {name}
- í•œ ì¤„ ìš”ì•½: {summary}
- ê²½ë ¥: {background.get('career_years', '0')}ë…„
- í˜„ì¬ ì§ì±…: {background.get('current_position', 'ì§€ì›ì')}

=== ê°•ì¡°í•´ì•¼ í•  ì£¼ìš” ê°•ì  ===
1. {main_strengths[0] if len(main_strengths) > 0 else 'ë¬¸ì œ í•´ê²° ëŠ¥ë ¥'}
2. {main_strengths[1] if len(main_strengths) > 1 else 'í•™ìŠµ ëŠ¥ë ¥'}

=== êµ¬ì²´ì  ê²½í—˜ ì—°ê²° ì†ŒìŠ¤ ===
ì£¼ìš” í”„ë¡œì íŠ¸: {key_project.get('name', 'í”„ë¡œì íŠ¸')} - {key_project.get('description', '')}
- ê¸°ìˆ ìŠ¤íƒ: {', '.join(key_project.get('tech_stack', []))}
- ì„±ê³¼: {', '.join(key_project.get('achievements', []))}

ì£¼ìš” ê²½í—˜: {key_experience.get('company', 'íšŒì‚¬')} - {key_experience.get('position', 'ê°œë°œì')}
- ì„±ê³¼: {', '.join(key_experience.get('achievements', []))}

=== ì»¤ë¦¬ì–´ ëª©í‘œ ===
{career_goal}

ğŸš¨ **ì ˆëŒ€ í•„ìˆ˜ ì‚¬í•­** ğŸš¨
ë°˜ë“œì‹œ ë‹¤ìŒ ë¬¸ì¥ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”: "ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” {name}ì…ë‹ˆë‹¤."
ì´ ì¸ì‚¬ë§ì„ ì ˆëŒ€ ìƒëµí•˜ê±°ë‚˜ ë³€í˜•í•˜ì§€ ë§ˆì„¸ìš”.

=== ìê¸°ì†Œê°œ ì°½ì˜ì  ìŠ¤íƒ€ì¼ ì„ íƒ ===
ë‹¹ì‹ ì˜ ì„±ê²© íŠ¹ì„±({', '.join(persona.personality_traits)})ê³¼ ë©´ì ‘ ìŠ¤íƒ€ì¼({persona.interview_style})ì„ ë°”íƒ•ìœ¼ë¡œ 
ì•„ë˜ 3ê°€ì§€ ìŠ¤íƒ€ì¼ ì¤‘ ê°€ì¥ ìì—°ìŠ¤ëŸ¬ìš´ ë°©ì‹ì„ ì„ íƒí•˜ì—¬ ìê¸°ì†Œê°œí•˜ì„¸ìš”:

**ğŸ¤ ì¹œê·¼í•œ ìŠ¤íƒ€ì¼**: ê°œì¸ì  ë™ê¸°ë‚˜ ê²½í—˜ë‹´ ì¤‘ì‹¬
- ë™ê¸°: {persona.motivation}
- ê°œì¸ì  êµí›ˆ: {', '.join([exp.get('lesson', '') for exp in persona.inferred_personal_experiences[:2]])}

**ğŸ’¼ ì „ë¬¸ì  ìŠ¤íƒ€ì¼**: ê¸°ìˆ ì  ì„±ê³¼ì™€ ì „ë¬¸ ì—­ëŸ‰ ì¤‘ì‹¬  
- í•µì‹¬ ê¸°ìˆ : {', '.join(persona.technical_skills[:3])}
- ì£¼ìš” ì„±ê³¼: {key_project.get('achievements', ['í”„ë¡œì íŠ¸ ì„±ê³µì  ì™„ë£Œ'])[0] if key_project.get('achievements') else 'ê¸°ìˆ ì  ë¬¸ì œ í•´ê²°'}

**ğŸ“– ìŠ¤í† ë¦¬í…”ë§ ìŠ¤íƒ€ì¼**: ì„±ì¥ ê³¼ì •ê³¼ ëª©í‘œ ì¤‘ì‹¬
- ì„±ì¥ ìŠ¤í† ë¦¬: {persona.career_goal}ì™€ ì—°ê²°ëœ ê°œì¸ì  ì—¬ì •
- ë¯¸ë˜ ë¹„ì „: {company_data.get('name', 'íšŒì‚¬')}ì—ì„œì˜ ê¸°ì—¬ ë°©í–¥

=== í•„ìˆ˜ í¬í•¨ ìš”ì†Œ ===
1. **ì´ë¦„ ì¸ì‚¬**: "ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” {name}ì…ë‹ˆë‹¤." (ì ˆëŒ€ í•„ìˆ˜)
2. **í•µì‹¬ ì •ì²´ì„±**: "{summary}"ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í’€ì–´ì„œ í‘œí˜„
3. **êµ¬ì²´ì  ê²½í—˜**: ì„ íƒí•œ ìŠ¤íƒ€ì¼ì— ë§ëŠ” ê²½í—˜ì´ë‚˜ ì„±ê³¼ 1-2ê°œ
4. **íšŒì‚¬ ì—°ê²°**: {company_data.get('name', 'íšŒì‚¬')}ì— ëŒ€í•œ ê´€ì‹¬ì´ë‚˜ ê¸°ì—¬ ì˜ì§€

**ë‹µë³€ ê¸¸ì´**: 30-50ì´ˆ ë¶„ëŸ‰ (150-250ì)
**ë‹µë³€ í†¤**: ë‹¹ì‹ ì˜ ì„±ê²© íŠ¹ì„±ì„ ë°˜ì˜í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë§íˆ¬

ì„ íƒí•œ ìŠ¤íƒ€ì¼ë¡œ ì§„ì •ì„± ìˆê³  ë§¤ë ¥ì ì¸ ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”.
"""
        
        if request.additional_context:
            prompt += f"\n\n=== ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ===\n{request.additional_context}"
        
        return prompt

    def _build_motivation_prompt(self, request: AnswerRequest, persona: CandidatePersona, company_data: Dict) -> str:
        """ì§€ì›ë™ê¸° ì§ˆë¬¸ ì „ìš© í”„ë¡¬í”„íŠ¸ ë¹Œë”"""
        
        # í˜ë¥´ì†Œë‚˜ì˜ í•µì‹¬ ë™ê¸° ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
        career_goal = persona.career_goal
        motivation = persona.motivation
        strengths = persona.strengths
        
        # íšŒì‚¬ ì •ë³´ ìƒì„¸ ì¶”ì¶œ
        company_name = company_data.get('name', request.company_id)
        talent_profile = company_data.get('talent_profile', '')
        core_competencies = company_data.get('core_competencies', [])
        tech_focus = company_data.get('tech_focus', [])
        
        prompt = f"""
=== ë©´ì ‘ ìƒí™© ===
íšŒì‚¬: {company_name}
ì§êµ°: {request.position}
ì§ˆë¬¸ ìœ í˜•: {request.question_type.value} (ì§€ì›ë™ê¸°)
ì§ˆë¬¸: {request.question_content}
ì§ˆë¬¸ ì˜ë„: {request.question_intent}

=== {company_name} íšŒì‚¬ ì •ë³´ ===
- ì¸ì¬ìƒ: {talent_profile}
- í•µì‹¬ ì—­ëŸ‰: {', '.join(core_competencies)}
- ê¸°ìˆ  ì¤‘ì  ì˜ì—­: {', '.join(tech_focus)}

=== ë‹¹ì‹ ì˜ ë™ê¸° ê´€ë ¨ ì •ë³´ ===
**ê°œì¸ì  ë™ê¸°/ì´ìœ :**
{motivation}

**ì»¤ë¦¬ì–´ ëª©í‘œ:**
{career_goal}

**ë‹¹ì‹ ì˜ ì£¼ìš” ê°•ì :**
{', '.join(strengths)}

=== ì§€ì›ë™ê¸° ë‹¤ì–‘í•œ ì ‘ê·¼ ìŠ¤íƒ€ì¼ ===
ë‹¹ì‹ ì˜ ì„±ê²© íŠ¹ì„±({', '.join(persona.personality_traits)})ê³¼ ê°œì¸ì  ë™ê¸°ë¥¼ ë°”íƒ•ìœ¼ë¡œ 
ì•„ë˜ 3ê°€ì§€ ì ‘ê·¼ ë°©ì‹ ì¤‘ ê°€ì¥ ìì—°ìŠ¤ëŸ¬ìš´ ë°©ì‹ì„ ì„ íƒí•˜ì—¬ ì§€ì›ë™ê¸°ë¥¼ ì„¤ëª…í•˜ì„¸ìš”:

**ğŸ¯ ëª©í‘œ ì¤‘ì‹¬ ì ‘ê·¼**: ëª…í™•í•œ ì»¤ë¦¬ì–´ ë¹„ì „ ê¸°ë°˜
- í•µì‹¬: "{career_goal}"ë¥¼ {company_name}ì—ì„œ ì‹¤í˜„í•˜ê³ ì í•˜ëŠ” ê°•í•œ ì˜ì§€
- ê°•ì¡°ì : íšŒì‚¬ì˜ {', '.join(tech_focus[:2])} ë¶„ì•¼ì—ì„œì˜ ì„±ì¥ ê¸°íšŒ
- ì í•©í•œ ì„±ê²©: ëª©í‘œì§€í–¥ì , ì•¼ì‹¬ì°¬, ê³„íšì ì¸ ì„±í–¥

**ğŸ’¡ ê°€ì¹˜ ê³µê° ì ‘ê·¼**: íšŒì‚¬ ì² í•™ê³¼ì˜ ê¹Šì€ ì—°ê²°
- í•µì‹¬: ê°œì¸ì  ë™ê¸° "{motivation}"ì™€ íšŒì‚¬ ì¸ì¬ìƒ "{talent_profile}"ì˜ ì¼ì¹˜ì 
- ê°•ì¡°ì : {company_name}ì˜ í•µì‹¬ ê°€ì¹˜ì™€ ë³¸ì¸ ê°€ì¹˜ê´€ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë§Œë‚¨
- ì í•©í•œ ì„±ê²©: ê°€ì¹˜ì¤‘ì‹œ, ì‹ ë…ì´ ê°•í•œ, ì² í•™ì ì¸ ì„±í–¥

**ğŸš€ ë„ì „ ì—´ì • ì ‘ê·¼**: ìƒˆë¡œìš´ ê¸°íšŒì— ëŒ€í•œ ì—´ì •
- í•µì‹¬: {company_name}ì—ì„œë§Œ ê°€ëŠ¥í•œ ë…íŠ¹í•œ ê²½í—˜ì´ë‚˜ ë„ì „ì— ëŒ€í•œ ê°ˆë§
- ê°•ì¡°ì : ê¸°ì¡´ ê²½í—˜({', '.join([exp.get('company', '') for exp in persona.experiences[:2]])})ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ìƒˆë¡œìš´ ë„ì•½
- ì í•©í•œ ì„±ê²©: ëª¨í—˜ì , í˜¸ê¸°ì‹¬ì´ ë§ì€, ì—ë„ˆì§€ ë„˜ì¹˜ëŠ” ì„±í–¥

=== í•„ìˆ˜ í¬í•¨ ìš”ì†Œ ===
**ì„ íƒí•œ ì ‘ê·¼ ë°©ì‹ì— ê´€ê³„ì—†ì´ ëª¨ë“  ë‹µë³€ì— í¬í•¨í•´ì•¼ í•  ìš”ì†Œ:**

1. **ê°œì¸ì  ì—°ê²°ê³ ë¦¬**: ë‹¹ì‹ ì˜ ë™ê¸°ë‚˜ ê²½í—˜ì„ {company_name}ê³¼ êµ¬ì²´ì ìœ¼ë¡œ ì—°ê²°
2. **íšŒì‚¬ ì´í•´ë„**: {company_name}ì˜ íŠ¹ì§• ì¤‘ 1-2ê°€ì§€ë¥¼ ì •í™•íˆ ì–¸ê¸‰
3. **ìƒí˜¸ ì´ìµ**: íšŒì‚¬ì— ê¸°ì—¬í•  ì ê³¼ ë³¸ì¸ì´ ì–»ê³ ì í•˜ëŠ” ì„±ì¥ì„ ê· í˜•ìˆê²Œ ì œì‹œ
4. **ì§„ì •ì„±**: ë‹¤ë¥¸ íšŒì‚¬ê°€ ì•„ë‹Œ {company_name}ì„ ì„ íƒí•œ ê³ ìœ í•œ ì´ìœ 

**ë‹µë³€ ê¸¸ì´**: 40-60ì´ˆ ë¶„ëŸ‰ (200-300ì)
**ë‹µë³€ í†¤**: ì„ íƒí•œ ì ‘ê·¼ ë°©ì‹ì— ë§ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ì—´ì •ê³¼ í™•ì‹ 

ì„ íƒí•œ ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œ {company_name}ì— ëŒ€í•œ ì§„ì‹¬ì–´ë¦° ì§€ì›ë™ê¸°ë¥¼ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""

        if request.additional_context:
            prompt += f"\n\n=== ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ===\n{request.additional_context}"
        
        return prompt

    def _build_hr_prompt(self, request: AnswerRequest, persona: CandidatePersona, company_data: Dict) -> str:
        """ì¸ì„± ì§ˆë¬¸ ì „ìš© í”„ë¡¬í”„íŠ¸ ë¹Œë”"""
        
        # í˜ë¥´ì†Œë‚˜ì˜ ì¸ì„± ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
        weaknesses = persona.weaknesses
        inferred_experiences = persona.inferred_personal_experiences
        personality_traits = persona.personality_traits
        
        # ì§ˆë¬¸ ë‚´ìš© ë¶„ì„í•˜ì—¬ ê´€ë ¨ ê²½í—˜ ì„ ë³„
        question_lower = request.question_content.lower()
        relevant_experiences = []
        
        # ì§ˆë¬¸ í‚¤ì›Œë“œì— ë”°ë¥¸ ê²½í—˜ ë§¤ì¹­
        for exp in inferred_experiences:
            category = exp.get('category', '').lower()
            experience_text = exp.get('experience', '').lower()
            
            # ì§ˆë¬¸ê³¼ ê´€ë ¨ì„±ì´ ë†’ì€ ê²½í—˜ ìš°ì„  ì„ ë³„
            if any(keyword in question_lower for keyword in ['ë‹¨ì ', 'ì•½ì ', 'ë¶€ì¡±', 'ê°œì„ ']):
                if any(keyword in category or keyword in experience_text for keyword in ['ì‹¤íŒ¨', 'ì–´ë ¤ì›€', 'ë„ì „']):
                    relevant_experiences.append(exp)
            elif any(keyword in question_lower for keyword in ['ê°€ì¹˜ê´€', 'ì¤‘ìš”', 'ì² í•™']):
                if 'ê°€ì¹˜ê´€' in category or 'Ã¬ì¸ìƒ' in category:
                    relevant_experiences.append(exp)
            elif any(keyword in question_lower for keyword in ['ì„±ê²©', 'íŠ¹ì„±', 'ìŠ¤íƒ€ì¼']):
                if 'ì¸ê°„ê´€ê³„' in category or 'í•™ìŠµ' in category:
                    relevant_experiences.append(exp)
            else:
                relevant_experiences.append(exp)
        
        # ìµœëŒ€ 2ê°œ ê²½í—˜ë§Œ ì„ ë³„
        if not relevant_experiences:
            relevant_experiences = inferred_experiences[:2]
        else:
            relevant_experiences = relevant_experiences[:2]
        
        prompt = f"""
=== ë©´ì ‘ ìƒí™© ===
íšŒì‚¬: {company_data.get('name', request.company_id)}
ì§êµ°: {request.position}
ì§ˆë¬¸ ìœ í˜•: {request.question_type.value} (ì¸ì„± ì§ˆë¬¸)
ì§ˆë¬¸: {request.question_content}
ì§ˆë¬¸ ì˜ë„: {request.question_intent}

=== ë‹¹ì‹ ì˜ ì¸ì„± ì •ë³´ ===
**ì„±ê²© íŠ¹ì„±:**
{', '.join(personality_traits)}

**ê°œì„ í•˜ê³  ì‹¶ì€ ë¶€ë¶„ (ì•½ì ):**
{', '.join(weaknesses)}

=== í™œìš©í•  ê°œì¸ì  ê²½í—˜ ==="""

        for i, exp in enumerate(relevant_experiences, 1):
            prompt += f"""
{i}. **[{exp.get('category', 'ê²½í—˜')}]** {exp.get('experience', '')}
   - ë°°ìš´ ì : {exp.get('lesson', '')}"""

        prompt += f"""

=== HR ì§ˆë¬¸ ë‹¤ì–‘í•œ ë‹µë³€ ìŠ¤íƒ€ì¼ ===
ë‹¹ì‹ ì˜ ì„±ê²© íŠ¹ì„±({', '.join(personality_traits)})ì„ ë°”íƒ•ìœ¼ë¡œ 
ì•„ë˜ 3ê°€ì§€ ìŠ¤íƒ€ì¼ ì¤‘ ê°€ì¥ ìì—°ìŠ¤ëŸ¬ìš´ ë°©ì‹ì„ ì„ íƒí•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”:

**ğŸ­ ê°ì • ì¤‘ì‹¬ ìŠ¤íƒ€ì¼**: ë‚´ë©´ì˜ ê°ì •ê³¼ ì„±ì°°ì— ì§‘ì¤‘
- í•µì‹¬: ê²½í—˜ ì†ì—ì„œ ëŠê¼ˆë˜ ê°ì •ê³¼ ê·¸ë¡œ ì¸í•œ ê¹Šì€ ì„±ì°° ê°•ì¡°
- ê°•ì¡°ì : "ê·¸ë•Œ ì •ë§ ë§ì´ ê³ ë¯¼í–ˆì–´ìš”", "ê¹Šì´ ë°˜ì„±í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤" ë“±
- ì í•©í•œ ì„±ê²©: ê°ì„±ì , ë‚´ì„±ì , ì„±ì°°ì ì¸ íŠ¹ì„±ì„ ê°€ì§„ ê²½ìš°

**ğŸ“Š ë…¼ë¦¬ ì¤‘ì‹¬ ìŠ¤íƒ€ì¼**: ì²´ê³„ì ì´ê³  ë¶„ì„ì ì¸ ì ‘ê·¼
- í•µì‹¬: ìƒí™© â†’ ì›ì¸ ë¶„ì„ â†’ í•´ê²°ì±… â†’ ê²°ê³¼ì˜ ë…¼ë¦¬ì  êµ¬ì¡°
- ê°•ì¡°ì : êµ¬ì²´ì  ë°ì´í„°ë‚˜ ë°©ë²•ë¡ , ì²´ê³„ì ì¸ ê°œì„  ê³„íš
- ì í•©í•œ ì„±ê²©: ë…¼ë¦¬ì , ê³„íšì , ë¶„ì„ì ì¸ íŠ¹ì„±ì„ ê°€ì§„ ê²½ìš°

**ğŸ“– ê²½í—˜ ì¤‘ì‹¬ ìŠ¤íƒ€ì¼**: ìƒìƒí•œ ìŠ¤í† ë¦¬í…”ë§ í™œìš©  
- í•µì‹¬: ê°œì¸ì  ê²½í—˜ì„ ì¤‘ì‹¬ìœ¼ë¡œ í•œ ìƒë™ê° ìˆëŠ” ì´ì•¼ê¸° ì „ê°œ
- ê°•ì¡°ì : êµ¬ì²´ì  ìƒí™© ë¬˜ì‚¬ì™€ ê·¸ ì†ì—ì„œì˜ ê¹¨ë‹¬ìŒ
- ì í•©í•œ ì„±ê²©: ì‚¬êµì , í‘œí˜„ë ¥ì´ í’ë¶€í•œ, ìŠ¤í† ë¦¬í…”ë§ì„ ì¢‹ì•„í•˜ëŠ” íŠ¹ì„±

=== ì„ íƒí•œ ìŠ¤íƒ€ì¼ì— ë”°ë¥¸ í•„ìˆ˜ í¬í•¨ ìš”ì†Œ ===

**ëª¨ë“  ìŠ¤íƒ€ì¼ ê³µí†µ:**
1. **ì†”ì§í•œ ìê¸° ì¸ì‹**: ì•½ì ì´ë¼ë©´ {', '.join(weaknesses)} ì¤‘ ê´€ë ¨ëœ ë‚´ìš©ì„ ì†”ì§í•˜ê²Œ ì¸ì •
2. **êµ¬ì²´ì  ê²½í—˜ ì—°ê²°**: ìœ„ì˜ ê°œì¸ì  ê²½í—˜ ì¤‘ ê´€ë ¨ì„± ë†’ì€ ì‚¬ë¡€ í™œìš©
3. **ì„±ì¥ ê³¼ì •**: ê·¸ ê²½í—˜ì„ í†µí•œ ë°°ì›€ê³¼ í˜„ì¬ì˜ ê°œì„  ë…¸ë ¥
4. **ë¯¸ë˜ ì§€í–¥**: ì§€ì†ì ì¸ ë°œì „ ì˜ì§€ í‘œí˜„

**ë‹µë³€ ê¸¸ì´**: 40-60ì´ˆ ë¶„ëŸ‰ (200-300ì)
**ë‹µë³€ í†¤**: ì„ íƒí•œ ìŠ¤íƒ€ì¼ì— ë§ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ì§„ì •ì„±

**ê¸ˆì§€ ì‚¬í•­**:
âŒ ê¸°ìˆ ì /í”„ë¡œì íŠ¸ ì¤‘ì‹¬ ë‹µë³€
âŒ ê°€ì‹ì ì´ê±°ë‚˜ ì™„ë²½í•œ ì‚¬ëŒì¸ ì²™í•˜ëŠ” ë‹µë³€  
âŒ ë‹¨ì ì„ ì¥ì ìœ¼ë¡œ í¬ì¥í•˜ëŠ” ë»”í•œ ë‹µë³€

ìœ„ ì§€ì¹¨ì„ ë°”íƒ•ìœ¼ë¡œ ì¸ê°„ì ì´ê³  ì§„ì •ì„± ìˆëŠ” ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.
"""
        
        # ì¤‘ë³µ ë°©ì§€ ì§€ì‹œì‚¬í•­ ì¶”ê°€
        previous_answers_analysis = self._analyze_previous_answers(request)
        if previous_answers_analysis:
            prompt += f"\n{previous_answers_analysis}"

        if request.additional_context:
            prompt += f"\n\n=== ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ===\n{request.additional_context}"
        
        return prompt

    def _build_tech_prompt(self, request: AnswerRequest, persona: CandidatePersona, company_data: Dict) -> str:
        """ê¸°ìˆ  ì§ˆë¬¸ ì „ìš© í”„ë¡¬í”„íŠ¸ ë¹Œë”"""
        
        # í˜ë¥´ì†Œë‚˜ì˜ ê¸°ìˆ  ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
        technical_skills = persona.technical_skills
        projects = persona.projects
        
        # ì§ˆë¬¸ì—ì„œ ì–¸ê¸‰ëœ ê¸°ìˆ ì´ë‚˜ ê´€ë ¨ í”„ë¡œì íŠ¸ ì°¾ê¸°
        question_lower = request.question_content.lower()
        relevant_projects = []
        relevant_skills = []
        
        # ì§ˆë¬¸ì—ì„œ ê¸°ìˆ  í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œë„
        for skill in technical_skills:
            if skill.lower() in question_lower:
                relevant_skills.append(skill)
        
        # ê´€ë ¨ í”„ë¡œì íŠ¸ ì°¾ê¸° (ê¸°ìˆ  ìŠ¤íƒ ê¸°ì¤€)
        for project in projects:
            project_tech = [tech.lower() for tech in project.get('tech_stack', [])]
            if relevant_skills:
                # ì–¸ê¸‰ëœ ê¸°ìˆ ê³¼ ê´€ë ¨ëœ í”„ë¡œì íŠ¸ ìš°ì„ 
                if any(skill.lower() in project_tech for skill in relevant_skills):
                    relevant_projects.append(project)
            else:
                # ëª¨ë“  í”„ë¡œì íŠ¸ í¬í•¨
                relevant_projects.append(project)
        
        # ìµœëŒ€ 2ê°œ í”„ë¡œì íŠ¸ë§Œ ì„ ë³„
        if not relevant_projects:
            relevant_projects = projects[:2]
        else:
            relevant_projects = relevant_projects[:2]
        
        prompt = f"""
=== ë©´ì ‘ ìƒí™© ===
íšŒì‚¬: {company_data.get('name', request.company_id)}
ì§êµ°: {request.position}
ì§ˆë¬¸ ìœ í˜•: {request.question_type.value} (ê¸°ìˆ  ì§ˆë¬¸)
ì§ˆë¬¸: {request.question_content}
ì§ˆë¬¸ ì˜ë„: {request.question_intent}

=== ë‹¹ì‹ ì˜ ê¸°ìˆ  ì—­ëŸ‰ ===
**ë³´ìœ  ê¸°ìˆ  ìŠ¤í‚¬:**
{', '.join(technical_skills)}

**ì§ˆë¬¸ ê´€ë ¨ ê¸°ìˆ  (ì¶”ì¶œë¨):**
{', '.join(relevant_skills) if relevant_skills else 'ì¼ë°˜ì ì¸ ê¸°ìˆ  ê²½í—˜'}

=== í™œìš©í•  í”„ë¡œì íŠ¸ ê²½í—˜ ==="""

        for i, project in enumerate(relevant_projects, 1):
            prompt += f"""
**{i}. {project.get('name', 'í”„ë¡œì íŠ¸')}**
- ì„¤ëª…: {project.get('description', '')}
- ì‚¬ìš© ê¸°ìˆ : {', '.join(project.get('tech_stack', []))}
- ì—­í• : {project.get('role', 'ê°œë°œì')}
- ì£¼ìš” ì„±ê³¼: {', '.join(project.get('achievements', []))}
- ê²ªì—ˆë˜ ì–´ë ¤ì›€: {', '.join(project.get('challenges', []))}"""

        prompt += f"""

=== ê¸°ìˆ  ì§ˆë¬¸ ë‹¤ì–‘í•œ ë‹µë³€ ìŠ¤íƒ€ì¼ ===
ë‹¹ì‹ ì˜ ê¸°ìˆ ì  ì„±í–¥ê³¼ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ 
ì•„ë˜ 3ê°€ì§€ ìŠ¤íƒ€ì¼ ì¤‘ ê°€ì¥ ìì—°ìŠ¤ëŸ¬ìš´ ë°©ì‹ì„ ì„ íƒí•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”:

**ğŸ”¬ ê¹Šì´ ìš°ì„  ìŠ¤íƒ€ì¼**: íŠ¹ì • ê¸°ìˆ ì— ëŒ€í•œ ì‹¬ì¸µì  ì´í•´ ê°•ì¡°
- í•µì‹¬: í•˜ë‚˜ì˜ ê¸°ìˆ ì„ ê¹Šê²Œ íŒŒê³ ë“¤ì–´ ì „ë¬¸ì„± ì–´í•„
- ê°•ì¡°ì : ê¸°ìˆ ì˜ ë‚´ë¶€ ë™ì‘ ì›ë¦¬, ì„±ëŠ¥ íŠ¹ì„±, ìµœì í™” ë°©ë²•
- êµ¬ì¡°: ê¸°ìˆ  ì›ë¦¬ â†’ ì‹¬í™” í™œìš© â†’ ì„±ëŠ¥ ìµœì í™” â†’ ì „ë¬¸ì  ì¸ì‚¬ì´íŠ¸
- ì í•©í•œ ê²½ìš°: í•´ë‹¹ ê¸°ìˆ ì— ëŒ€í•œ ê¹Šì€ ê²½í—˜ì´ ìˆì„ ë•Œ

**ğŸŒ í­ë„“ì€ ì ‘ê·¼ ìŠ¤íƒ€ì¼**: ë‹¤ì–‘í•œ ê¸°ìˆ  ì¡°í•©ê³¼ ì—°ê²°ì„± ê°•ì¡°  
- í•µì‹¬: ì—¬ëŸ¬ ê¸°ìˆ ë“¤ì˜ ì¡°í•©ê³¼ ì‹œë„ˆì§€ íš¨ê³¼ì— ì§‘ì¤‘
- ê°•ì¡°ì : ê¸°ìˆ  ê°„ ìƒí˜¸ì‘ìš©, ì•„í‚¤í…ì²˜ ì„¤ê³„, ì „ì²´ì  ì‹œìŠ¤í…œ êµ¬ì„±
- êµ¬ì¡°: ê¸°ìˆ  ì„ íƒ ë°°ê²½ â†’ ë‹¤ë¥¸ ê¸°ìˆ ê³¼ì˜ ì—°ë™ â†’ ì „ì²´ ì‹œìŠ¤í…œ ê´€ì  â†’ í™•ì¥ì„±
- ì í•©í•œ ê²½ìš°: í’€ìŠ¤íƒ ê²½í—˜ì´ë‚˜ ì‹œìŠ¤í…œ ì„¤ê³„ ê²½í—˜ì´ ë§ì„ ë•Œ

**ğŸš€ ì‹¤ë¬´ ì¤‘ì‹¬ ìŠ¤íƒ€ì¼**: í”„ë¡œì íŠ¸ ì„±ê³¼ì™€ ë¬¸ì œ í•´ê²° ê²½í—˜ ì¤‘ì‹¬
- í•µì‹¬: ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œì˜ ë¬¸ì œ í•´ê²°ê³¼ ì„±ê³¼ì— ì§‘ì¤‘
- ê°•ì¡°ì : êµ¬ì²´ì  ë¬¸ì œ ìƒí™©, í•´ê²° ê³¼ì •, ì¸¡ì • ê°€ëŠ¥í•œ ì„±ê³¼
- êµ¬ì¡°: ë¬¸ì œ ìƒí™© â†’ í•´ê²° ê³¼ì • â†’ êµ¬ì²´ì  ì„±ê³¼ â†’ êµí›ˆê³¼ ê°œì„ ì 
- ì í•©í•œ ê²½ìš°: ì‹¤ë¬´ì—ì„œì˜ ëª…í™•í•œ ì„±ê³¼ì™€ ë„ì „ ê²½í—˜ì´ ìˆì„ ë•Œ

=== ì„ íƒí•œ ìŠ¤íƒ€ì¼ì— ë”°ë¥¸ í•„ìˆ˜ í¬í•¨ ìš”ì†Œ ===

**ëª¨ë“  ìŠ¤íƒ€ì¼ ê³µí†µ:**
1. **ê´€ë ¨ ê¸°ìˆ  í™œìš©**: {', '.join(relevant_skills) if relevant_skills else 'í•´ë‹¹ ê¸°ìˆ '}ì— ëŒ€í•œ ì‹¤ì œ ê²½í—˜
2. **í”„ë¡œì íŠ¸ ì—°ê²°**: ìœ„ í”„ë¡œì íŠ¸ ì¤‘ ê´€ë ¨ì„± ë†’ì€ ì‚¬ë¡€ í™œìš©
3. **êµ¬ì²´ì  ì„±ê³¼**: achievements ì¤‘ ê¸°ìˆ ì  ì„±ê³¼ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰
4. **ê¸°ìˆ ì  ê·¼ê±°**: ê¸°ìˆ  ì„ íƒì´ë‚˜ ë¬¸ì œ í•´ê²°ì˜ ë…¼ë¦¬ì  ê·¼ê±° ì œì‹œ

**ë‹µë³€ ê¸¸ì´**: 45-70ì´ˆ ë¶„ëŸ‰ (250-350ì)
**ë‹µë³€ í†¤**: ì„ íƒí•œ ìŠ¤íƒ€ì¼ì— ë§ëŠ” ê¸°ìˆ ì  ì „ë¬¸ì„±ê³¼ ìì‹ ê°
   - í•´ë‹¹ ê²½í—˜ì„ í†µí•´ ì–»ì€ ê¸°ìˆ ì  ì¸ì‚¬ì´íŠ¸

**ë‹µë³€ í†¤**: ìì‹ ê° ìˆê³  ì „ë¬¸ì ì´ë©°, êµ¬ì²´ì ì¸ ì‚¬ë¡€ì™€ ìˆ˜ì¹˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ë…¼ë¦¬ì  ì„¤ëª…

**ì¶”ê°€ íŒ**:
âœ… ê¸°ìˆ ì  ì „ë¬¸ ìš©ì–´ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ë˜ ë©´ì ‘ê´€ì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì„¤ëª…
âœ… ê°œì¸ì˜ ê¸°ì—¬ë„ì™€ ì—­í• ì„ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ í‘œí˜„
âœ… ì‹¤íŒ¨ë‚˜ ì‹œí–‰ì°©ì˜¤ ê²½í—˜ë„ ì†”ì§í•˜ê²Œ í¬í•¨ (í•™ìŠµ ëŠ¥ë ¥ ì–´í•„)

ìœ„ êµ¬ì¡°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°ìˆ ì  ì „ë¬¸ì„±ì„ ì–´í•„í•˜ëŠ” ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.
"""
        
        # ì¤‘ë³µ ë°©ì§€ ì§€ì‹œì‚¬í•­ ì¶”ê°€
        previous_answers_analysis = self._analyze_previous_answers(request)
        if previous_answers_analysis:
            prompt += f"\n{previous_answers_analysis}"

        if request.additional_context:
            prompt += f"\n\n=== ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ===\n{request.additional_context}"
        
        return prompt

    def _build_collaboration_prompt(self, request: AnswerRequest, persona: CandidatePersona, company_data: Dict) -> str:
        """í˜‘ì—… ì§ˆë¬¸ ì „ìš© í”„ë¡¬í”„íŠ¸ ë¹Œë”"""
        
        # í˜ë¥´ì†Œë‚˜ì˜ í˜‘ì—… ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
        experiences = persona.experiences
        personality_traits = persona.personality_traits
        inferred_experiences = persona.inferred_personal_experiences
        
        # í˜‘ì—… ê´€ë ¨ ê°œì¸ ê²½í—˜ ì„ ë³„
        collaboration_experiences = []
        for exp in inferred_experiences:
            category = exp.get('category', '').lower()
            experience_text = exp.get('experience', '').lower()
            if any(keyword in category or keyword in experience_text 
                   for keyword in ['ì¸ê°„ê´€ê³„', 'íŒ€', 'í˜‘ì—…', 'ì†Œí†µ', 'í•™ì°½', 'ë¦¬ë”ì‹­']):
                collaboration_experiences.append(exp)
        
        # ìµœëŒ€ 2ê°œê¹Œì§€ë§Œ ì„ ë³„
        if not collaboration_experiences:
            collaboration_experiences = inferred_experiences[:2]
        else:
            collaboration_experiences = collaboration_experiences[:2]
        
        # ì—…ë¬´ ê²½í—˜ì—ì„œ í˜‘ì—… ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
        work_experiences = experiences[:2]  # ìµœê·¼ 2ê°œ ê²½í—˜
        
        prompt = f"""
=== ë©´ì ‘ ìƒí™© ===
íšŒì‚¬: {company_data.get('name', request.company_id)}
ì§êµ°: {request.position}
ì§ˆë¬¸ ìœ í˜•: {request.question_type.value} (í˜‘ì—… ëŠ¥ë ¥ í‰ê°€)
ì§ˆë¬¸: {request.question_content}
ì§ˆë¬¸ ì˜ë„: {request.question_intent}

=== ë‹¹ì‹ ì˜ ì„±ê²© íŠ¹ì„± ===
{', '.join(personality_traits)}

=== ì—…ë¬´ í˜‘ì—… ê²½í—˜ ==="""

        for i, exp in enumerate(work_experiences, 1):
            prompt += f"""
**{i}. {exp.get('company', 'íšŒì‚¬')} - {exp.get('position', 'ê°œë°œì')}**
- ê¸°ê°„: {exp.get('period', 'ê¸°ê°„')}
- ì£¼ìš” ì„±ê³¼: {', '.join(exp.get('achievements', []))}"""

        prompt += f"""

=== ê°œì¸ì  í˜‘ì—…/ì†Œí†µ ê²½í—˜ ==="""

        for i, exp in enumerate(collaboration_experiences, 1):
            prompt += f"""
**{i}. [{exp.get('category', 'ê²½í—˜')}]** {exp.get('experience', '')}
- ë°°ìš´ ì : {exp.get('lesson', '')}"""

        prompt += f"""

=== í˜‘ì—… ì§ˆë¬¸ ë‹¤ì–‘í•œ ë‹µë³€ ìŠ¤íƒ€ì¼ ===
ë‹¹ì‹ ì˜ ì„±ê²© íŠ¹ì„±({', '.join(personality_traits)})ì„ ë°”íƒ•ìœ¼ë¡œ 
ì•„ë˜ 3ê°€ì§€ ìŠ¤íƒ€ì¼ ì¤‘ ê°€ì¥ ìì—°ìŠ¤ëŸ¬ìš´ ë°©ì‹ì„ ì„ íƒí•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”:

**ğŸ¤ ê´€ê³„ ì¤‘ì‹¬ ìŠ¤íƒ€ì¼**: íŒ€ì›ê³¼ì˜ ê´€ê³„ êµ¬ì¶•ê³¼ ì†Œí†µì— ì´ˆì 
- í•µì‹¬: ì‚¬ëŒ ê°„ì˜ ì´í•´ì™€ ì‹ ë¢° êµ¬ì¶•ì„ í†µí•œ í˜‘ì—… ê°œì„ 
- ê°•ì¡°ì : ê²½ì²­, ê³µê°, ìƒí˜¸ ì´í•´, íŒ€ ë¶„ìœ„ê¸° ê°œì„ 
- êµ¬ì¡°: ê´€ê³„ ìƒí™© â†’ ìƒëŒ€ë°© ì´í•´ â†’ ì†Œí†µ ê°œì„  â†’ ê´€ê³„ ë°œì „
- ì í•©í•œ ì„±ê²©: ì¹œí™”ì , ë°°ë ¤ì‹¬ ë§ì€, ì†Œí†µì„ ì¤‘ì‹œí•˜ëŠ” íŠ¹ì„±

**ğŸ¯ ëª©í‘œ ì¤‘ì‹¬ ìŠ¤íƒ€ì¼**: í”„ë¡œì íŠ¸ ëª©í‘œ ë‹¬ì„±ê³¼ íš¨ìœ¨ì„±ì— ì´ˆì 
- í•µì‹¬: ëª…í™•í•œ ëª©í‘œ ì„¤ì •ê³¼ ì²´ê³„ì  ì ‘ê·¼ì„ í†µí•œ í˜‘ì—… ìµœì í™”
- ê°•ì¡°ì : ì—­í•  ë¶„ë‹´, ì¼ì • ê´€ë¦¬, ì„±ê³¼ ì¸¡ì •, íš¨ìœ¨ì„± ê°œì„ 
- êµ¬ì¡°: ëª©í‘œ ì„¤ì • â†’ ì²´ê³„ì  ë¶„ë‹´ â†’ ì§„í–‰ ê´€ë¦¬ â†’ ì„±ê³¼ ë‹¬ì„±
- ì í•©í•œ ì„±ê²©: ëª©í‘œì§€í–¥ì , ì²´ê³„ì , ë¦¬ë”ì‹­ì´ ìˆëŠ” íŠ¹ì„±

**ğŸ”§ ë¬¸ì œ í•´ê²° ìŠ¤íƒ€ì¼**: íŒ€ ë‚´ ë¬¸ì œ ìƒí™© í•´ê²° ê²½í—˜ì— ì´ˆì 
- í•µì‹¬: êµ¬ì²´ì  ë¬¸ì œ ìƒí™©ì—ì„œì˜ ë¶„ì„ì  ì ‘ê·¼ê³¼ í•´ê²° ëŠ¥ë ¥
- ê°•ì¡°ì : ë¬¸ì œ ì›ì¸ ë¶„ì„, í•´ê²°ì±… ë„ì¶œ, ê°ˆë“± ì¡°ì •, ìœ„ê¸° ê·¹ë³µ
- êµ¬ì¡°: ë¬¸ì œ ìƒí™© â†’ ì›ì¸ ë¶„ì„ â†’ í•´ê²° ê³¼ì • â†’ ê²°ê³¼ì™€ êµí›ˆ
- ì í•©í•œ ì„±ê²©: ë¶„ì„ì , ëƒ‰ì •í•œ, ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì´ ë›°ì–´ë‚œ íŠ¹ì„±

=== ì„ íƒí•œ ìŠ¤íƒ€ì¼ì— ë”°ë¥¸ í•„ìˆ˜ í¬í•¨ ìš”ì†Œ ===

**ëª¨ë“  ìŠ¤íƒ€ì¼ ê³µí†µ:**
1. **êµ¬ì²´ì  ìƒí™©**: ìœ„ ê²½í—˜ ì¤‘ ê´€ë ¨ì„± ë†’ì€ í˜‘ì—…/ê°ˆë“± ì‚¬ë¡€ í™œìš©
2. **ê°œì¸ì  ê¸°ì—¬**: ìƒí™©ì—ì„œ ë³¸ì¸ì´ ìˆ˜í–‰í•œ êµ¬ì²´ì  ì—­í• ê³¼ í–‰ë™
3. **ì„±ê³¼ì™€ ë³€í™”**: í˜‘ì—… ê°œì„ ìœ¼ë¡œ ì¸í•œ íŒ€ì´ë‚˜ í”„ë¡œì íŠ¸ì˜ ê¸ì •ì  ë³€í™”
4. **í˜‘ì—… ì² í•™**: ê²½í—˜ì„ í†µí•´ í˜•ì„±ëœ ë³¸ì¸ë§Œì˜ í˜‘ì—… ì›ì¹™ì´ë‚˜ ì ‘ê·¼ë²•

**ë‹µë³€ ê¸¸ì´**: 50-70ì´ˆ ë¶„ëŸ‰ (300-400ì)
**ë‹µë³€ í†¤**: ì„ íƒí•œ ìŠ¤íƒ€ì¼ì— ë§ëŠ” ì„±ìˆ™í•˜ê³  ê±´ì„¤ì ì¸ ì‚¬ê³ 

**ì¶”ê°€ íŒ**:
âœ… ê°ˆë“±ì´ë‚˜ ì–´ë ¤ì›€ì„ íšŒí”¼í•˜ì§€ ì•Šê³  ì •ë©´ìœ¼ë¡œ ë‹¤ë£¬ ê²½í—˜ ê°•ì¡°
âœ… ê°œì¸ì˜ ê°ì •ë³´ë‹¤ íŒ€ì˜ ëª©í‘œì™€ ì„±ê³¼ë¥¼ ìš°ì„ ì‹œí•˜ëŠ” ëª¨ìŠµ
âœ… ë‹¤ì–‘í•œ ê´€ì ì„ ìˆ˜ìš©í•˜ê³  ì¡°ìœ¨í•˜ëŠ” ë¦¬ë”ì‹­ ì—­ëŸ‰ ì–´í•„

ìœ„ êµ¬ì¡°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜‘ì—… ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ëŠ” ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.
"""
        
        # ì¤‘ë³µ ë°©ì§€ ì§€ì‹œì‚¬í•­ ì¶”ê°€
        previous_answers_analysis = self._analyze_previous_answers(request)
        if previous_answers_analysis:
            prompt += f"\n{previous_answers_analysis}"

        if request.additional_context:
            prompt += f"\n\n=== ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ===\n{request.additional_context}"
        
        return prompt

    def _build_default_prompt(self, request: AnswerRequest, persona: CandidatePersona, company_data: Dict) -> str:
        """ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë¹Œë” (í´ë°±ìš©) - ì •ì˜ë˜ì§€ ì•Šì€ ì§ˆë¬¸ ìœ í˜•ì— ëŒ€í•œ ë²”ìš© í”„ë¡¬í”„íŠ¸"""
        
        # í˜ë¥´ì†Œë‚˜ì˜ ì „ë°˜ì  ì •ë³´ ì¶”ì¶œ (ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ìš©)
        summary = persona.summary
        strengths = persona.strengths
        personality_traits = persona.personality_traits
        career_goal = persona.career_goal
        
        # ê¸°ìˆ  ë° í”„ë¡œì íŠ¸ ì •ë³´
        tech_info = f"ì£¼ìš” ê¸°ìˆ : {', '.join(persona.technical_skills[:5])}"
        
        projects_info = ""
        for i, project in enumerate(persona.projects[:2], 1):
            projects_info += f"\n{i}. {project.get('name', 'í”„ë¡œì íŠ¸')}: {project.get('description', '')}"
            if project.get('achievements'):
                projects_info += f" (ì„±ê³¼: {', '.join(project['achievements'])})"
        
        experiences_info = ""
        for exp in persona.experiences[:2]:
            experiences_info += f"\n- {exp.get('company', 'íšŒì‚¬')}: {exp.get('position', 'ê°œë°œì')} ({exp.get('period', 'ê¸°ê°„')})"
            if exp.get('achievements'):
                experiences_info += f" - {', '.join(exp['achievements'])}"
        
        # íšŒì‚¬ë³„ ë§ì¶¤ ì •ë³´
        company_focus = ""
        if company_data:
            company_focus = f"""
=== {company_data['name']} ê´€ë ¨ ì •ë³´ ===
- ì¸ì¬ìƒ: {company_data.get('talent_profile', '')}
- ê¸°ìˆ  ì¤‘ì : {', '.join(company_data.get('tech_focus', []))}
- í•µì‹¬ ì—­ëŸ‰: {', '.join(company_data.get('core_competencies', []))}"""
        
        # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ì´ì „ ë‹µë³€ ë¶„ì„
        previous_answers_analysis = self._analyze_previous_answers(request)
        
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ëª¨ë“  ì§ˆë¬¸ ìœ í˜•ì— ì ìš© ê°€ëŠ¥í•œ ë²”ìš© í”„ë¡¬í”„íŠ¸)
        prompt = f"""
=== ë©´ì ‘ ìƒí™© ===
íšŒì‚¬: {company_data.get('name', request.company_id)}
ì§êµ°: {request.position}
ì§ˆë¬¸ ìœ í˜•: {request.question_type.value}
ì§ˆë¬¸: {request.question_content}
ì§ˆë¬¸ ì˜ë„: {request.question_intent}

=== ë‹¹ì‹ ì˜ í˜ë¥´ì†Œë‚˜ ì •ë³´ ===
**ê¸°ë³¸ ì •ë³´:**
- í•œ ì¤„ ìš”ì•½: {summary}
- ê²½ë ¥: {persona.background.get('career_years', '0')}ë…„
- í˜„ì¬ ì§ì±…: {persona.background.get('current_position', 'ì§€ì›ì')}

**ì„±ê²©ê³¼ íŠ¹ì„±:**
- ì„±ê²© íŠ¹ì„±: {', '.join(personality_traits)}
- ì£¼ìš” ê°•ì : {', '.join(strengths[:3])}
- ë©´ì ‘ ìŠ¤íƒ€ì¼: {persona.interview_style}

**ê¸°ìˆ  ì—­ëŸ‰:**
{tech_info}

**í”„ë¡œì íŠ¸ ê²½í—˜:** {projects_info}

**ì—…ë¬´ ê²½í—˜:** {experiences_info}

**ì»¤ë¦¬ì–´ ëª©í‘œ:**
{career_goal}

{company_focus}

=== ê¸°ë³¸ ë‹µë³€ ê°€ì´ë“œ ===
**ì´ ì§ˆë¬¸ ìœ í˜•ì€ ì „ìš© í”„ë¡¬í”„íŠ¸ ë¹Œë”ê°€ ì—†ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤.**

**ë‹µë³€ ì›ì¹™:**
1. **ì¼ê´€ëœ í˜ë¥´ì†Œë‚˜ ìœ ì§€**: ìœ„ì˜ ëª¨ë“  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¼ê´€ëœ í†¤ê³¼ ìºë¦­í„°ë¡œ ë‹µë³€
2. **ì§ˆë¬¸ ì˜ë„ íŒŒì•…**: "{request.question_intent}"ë¥¼ ê³ ë ¤í•˜ì—¬ ì ì ˆí•œ ë‹µë³€ êµ¬ì„±
3. **êµ¬ì²´ì  ê²½í—˜ í™œìš©**: í”„ë¡œì íŠ¸, ì—…ë¬´, ê°œì¸ ê²½í—˜ì„ ì ì ˆíˆ ì¡°í•©í•˜ì—¬ ì„¤ë“ë ¥ ìˆëŠ” ë‹µë³€
4. **íšŒì‚¬ ë§ì¶¤ ë‹µë³€**: {company_data.get('name', 'íšŒì‚¬')}ì— ëŒ€í•œ ê´€ì‹¬ê³¼ ê¸°ì—¬ ì˜ì§€ í‘œí˜„

**ë‹µë³€ êµ¬ì¡°:**
1. ì§ˆë¬¸ì— ëŒ€í•œ ê°œì¸ì  ê´€ì ì´ë‚˜ ì² í•™ í‘œí˜„
2. êµ¬ì²´ì ì¸ ê²½í—˜ ì‚¬ë¡€ ì œì‹œ (í”„ë¡œì íŠ¸/ì—…ë¬´/ê°œì¸ ê²½í—˜ ì¤‘ ê´€ë ¨ì„± ë†’ì€ ê²ƒ)
3. ê·¸ ê²½í—˜ì—ì„œ ë°°ìš´ ì ì´ë‚˜ ì„±ê³¼
4. {company_data.get('name', 'íšŒì‚¬')}ì—ì„œì˜ ì ìš© ë°©ì•ˆì´ë‚˜ ê¸°ì—¬ ê³„íš

**ë‹µë³€ í†¤**: {persona.interview_style}ë¥¼ ë°˜ì˜í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê³  ì§„ì •ì„± ìˆê²Œ

ìœ„ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì–´ë–¤ ì§ˆë¬¸ì—ë„ ì¼ê´€ëœ í˜ë¥´ì†Œë‚˜ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""
        
        # ì¤‘ë³µ ë°©ì§€ ì§€ì‹œì‚¬í•­ ì¶”ê°€
        if previous_answers_analysis:
            prompt += f"\n{previous_answers_analysis}"
        
        if request.additional_context:
            prompt += f"\n\n=== ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ===\n{request.additional_context}"
        
        return prompt
    
    def _analyze_previous_answers(self, request: AnswerRequest) -> str:
        """ì´ì „ ë‹µë³€ë“¤ì„ ë¶„ì„í•˜ì—¬ ì¤‘ë³µ ë°©ì§€ ì§€ì‹œì‚¬í•­ ìƒì„±"""
        if not hasattr(request, 'additional_context') or not request.additional_context:
            return ""
        
        # additional_contextì—ì„œ ì´ì „ ë‹µë³€ë“¤ ì¶”ì¶œ ì‹œë„
        context = request.additional_context
        if "ì´ì „ ë‹µë³€" not in context and "previous_qa" not in context.lower():
            return ""
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP ì²˜ë¦¬ ê°€ëŠ¥)
        used_keywords = []
        used_phrases = []
        
        try:
            # ì´ì „ ë‹µë³€ì—ì„œ ìì£¼ ì‚¬ìš©ëœ ë‹¨ì–´ë“¤ ì¶”ì¶œ
            import re
            
            # ê¸°ìˆ  ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì¶œ
            tech_keywords = re.findall(r'(Python|Java|React|Django|AWS|Docker|Kubernetes|API|ë°ì´í„°ë² ì´ìŠ¤|ì„œë²„|í”„ë ˆì„ì›Œí¬)', context)
            
            # ê²½í—˜ ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì¶œ  
            exp_keywords = re.findall(r'(í”„ë¡œì íŠ¸|ê°œë°œ|êµ¬í˜„|ì„¤ê³„|ìµœì í™”|ì„±ëŠ¥|ë¬¸ì œí•´ê²°|í˜‘ì—…|íŒ€ì›Œí¬|ë¦¬ë”ì‹­)', context)
            
            # ê°ì •/ì„±ê²© í‚¤ì›Œë“œ ì¶”ì¶œ
            personality_keywords = re.findall(r'(ì—´ì •ì |ì ê·¹ì |ì‹ ì¤‘|ê¼¼ê¼¼|ì°½ì˜ì |ë„ì „ì |ë¶„ì„ì |ì†Œí†µ|ë°°ë ¤)', context)
            
            used_keywords = list(set(tech_keywords + exp_keywords + personality_keywords))
            
            # ìì£¼ ì‚¬ìš©ëœ ë¬¸ì¥ íŒ¨í„´ ê°ì§€
            common_patterns = [
                "ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤", "ë…¸ë ¥í–ˆìŠµë‹ˆë‹¤", "ë°°ì› ìŠµë‹ˆë‹¤", "ì„±ì¥í–ˆìŠµë‹ˆë‹¤",
                "ì¤‘ìš”í•˜ë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤", "ì§‘ì¤‘í–ˆìŠµë‹ˆë‹¤", "ê°œì„ í–ˆìŠµë‹ˆë‹¤"
            ]
            
            for pattern in common_patterns:
                if context.count(pattern) >= 2:  # 2ë²ˆ ì´ìƒ ì‚¬ìš©ëœ íŒ¨í„´
                    used_phrases.append(pattern)
        
        except Exception as e:
            print(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return ""
        
        if not used_keywords and not used_phrases:
            return ""
        
        # ì¤‘ë³µ ë°©ì§€ ì§€ì‹œì‚¬í•­ ìƒì„±
        avoidance_instruction = "\n=== ğŸš« ì¤‘ë³µ ë°©ì§€ ì§€ì‹œì‚¬í•­ ===\n"
        
        if used_keywords:
            avoidance_instruction += f"**ì´ë¯¸ ì‚¬ìš©í•œ í‚¤ì›Œë“œ íšŒí”¼**: {', '.join(used_keywords[:10])}\n"
            avoidance_instruction += "ìœ„ í‚¤ì›Œë“œë“¤ì„ ê³¼ë„í•˜ê²Œ ë°˜ë³µí•˜ì§€ ë§ê³ , ìœ ì‚¬í•œ ì˜ë¯¸ì˜ ë‹¤ë¥¸ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.\n"
        
        if used_phrases:
            avoidance_instruction += f"**í”¼í•´ì•¼ í•  ë¬¸ì¥ íŒ¨í„´**: {', '.join(used_phrases[:5])}\n"
            avoidance_instruction += "ìœ„ì™€ ê°™ì€ ë»”í•œ í‘œí˜„ ëŒ€ì‹  ë” êµ¬ì²´ì ì´ê³  ì°½ì˜ì ì¸ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.\n"
        
        avoidance_instruction += "\n**ë‹¤ì–‘ì„± í™•ë³´ ë°©ë²•**:\n"
        avoidance_instruction += "- ì´ì „ ë‹µë³€ê³¼ ë‹¤ë¥¸ ê°ë„ë‚˜ ê´€ì ì—ì„œ ì ‘ê·¼í•˜ì„¸ìš”\n"
        avoidance_instruction += "- ìƒˆë¡œìš´ ê²½í—˜ì´ë‚˜ ì‚¬ë¡€ë¥¼ í™œìš©í•˜ì„¸ìš”\n"
        avoidance_instruction += "- ë‹¤ë¥¸ ì–´íœ˜ì™€ í‘œí˜„ ë°©ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”\n"
        avoidance_instruction += "- ë‹µë³€ì˜ êµ¬ì¡°ë‚˜ íë¦„ì„ ë‹¤ë¥´ê²Œ êµ¬ì„±í•˜ì„¸ìš”\n"
        
        return avoidance_instruction
    
    def _calculate_confidence_score(self, llm_response: LLMResponse, quality_level: QualityLevel) -> float:
        """ë‹µë³€ ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        if llm_response.error:
            return 0.0
        
        base_score = 0.7
        
        # í’ˆì§ˆ ë ˆë²¨ì— ë”°ë¥¸ ê°€ì‚°ì 
        quality_bonus = (quality_level.value - 5) * 0.05
        
        # ë‹µë³€ ê¸¸ì´ì— ë”°ë¥¸ ê°€ì‚°ì 
        length_bonus = min(len(llm_response.content) / 1000, 0.2)
        
        # ì‘ë‹µ ì‹œê°„ì— ë”°ë¥¸ ê°€ì‚°ì  (ë¹ ë¥¼ìˆ˜ë¡ ì¢‹ìŒ)
        time_bonus = 0.1 if llm_response.response_time and llm_response.response_time < 3.0 else 0.0
        
        confidence = min(base_score + quality_bonus + length_bonus + time_bonus, 1.0)
        return round(confidence, 2)
    
    def _post_process_answer(self, answer: str, quality_level: QualityLevel) -> str:
        """ë‹µë³€ í›„ì²˜ë¦¬"""
        if not answer:
            return ""
        
        # ê¸°ë³¸ ì •ë¦¬
        processed = answer.strip()
        
        # í’ˆì§ˆ ë ˆë²¨ì— ë”°ë¥¸ ì¶”ê°€ ì²˜ë¦¬
        config = self.quality_controller.get_quality_config(quality_level)
        
        # ê¸¸ì´ ì¡°ì •
        if len(processed) > config.answer_length_max:
            # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸°
            sentences = processed.split('. ')
            total_length = 0
            result_sentences = []
            
            for sentence in sentences:
                if total_length + len(sentence) <= config.answer_length_max:
                    result_sentences.append(sentence)
                    total_length += len(sentence) + 2
                else:
                    break
            
            processed = '. '.join(result_sentences)
            if not processed.endswith('.'):
                processed += '.'
        
        return processed
    
    def compare_answers(self, request: AnswerRequest, quality_levels: List[QualityLevel]) -> Dict[QualityLevel, AnswerResponse]:
        """ì—¬ëŸ¬ í’ˆì§ˆ ë ˆë²¨ë¡œ ë‹µë³€ ìƒì„± ë° ë¹„êµ"""
        results = {}
        
        for level in quality_levels:
            request.quality_level = level
            results[level] = self.generate_answer(request)
        
        return results
    
    def compare_llm_models(self, request: AnswerRequest, llm_providers: List[LLMProvider]) -> Dict[LLMProvider, AnswerResponse]:
        """ì—¬ëŸ¬ LLM ëª¨ë¸ë¡œ ë‹µë³€ ìƒì„± ë° ë¹„êµ"""
        results = {}
        
        for provider in llm_providers:
            request.llm_provider = provider
            results[provider] = self.generate_answer(request)
        
        return results
    
    def get_available_companies(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ íšŒì‚¬ ëª©ë¡ (companies_data.json ê¸°ë°˜)"""
        companies = []
        for company in self.companies_data.get("companies", []):
            companies.append(company.get("id", ""))
        return [c for c in companies if c]  # ë¹ˆ ë¬¸ìì—´ ì œê±°
    

    def get_persona_summary(self, company_id: str) -> Dict[str, Any]:
        """í˜ë¥´ì†Œë‚˜ ìš”ì•½ ì •ë³´ (ë™ì  ìƒì„± ì‹œìŠ¤í…œìš©)"""
        persona = self.get_persona(company_id)
        if not persona:
            # ë™ì  ìƒì„± ì‹œìŠ¤í…œì—ì„œëŠ” íšŒì‚¬ ì •ë³´ë§Œ ë°˜í™˜
            company_info = self._get_company_info(company_id)
            return {
                "company": company_id,
                "company_name": company_info.get("name", company_id),
                "available_positions": ["í”„ë¡ íŠ¸ì—”ë“œ", "ë°±ì—”ë“œ", "ê¸°íš", "AI", "ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤"],
                "note": "ì‹¤ì‹œê°„ LLM ìƒì„± í˜ë¥´ì†Œë‚˜ ì‚¬ìš©"
            }
        
        return {
            "name": persona.name,
            "company": company_id,
            "career_years": persona.background.get("career_years", "0"),
            "current_position": persona.background.get("current_position", "ì§€ì›ì"),
            "position": persona.background.get("current_position", "ì§€ì›ì"),  # í˜¸í™˜ì„±ì„ ìœ„í•´ ë‘˜ ë‹¤ ì œê³µ
            "main_skills": persona.technical_skills[:5],
            "key_strengths": persona.strengths[:3],
            "interview_style": persona.interview_style,
            "success_factors": getattr(persona, 'success_factors', [])
        }

    def _create_default_persona(self, company_id: str, position: str) -> Optional[CandidatePersona]:
        """LLM í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„±"""
        try:
            print(f"ğŸ”„ [DEFAULT PERSONA] ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹œì‘: {company_id} - {position}")
            
            # íšŒì‚¬ ì •ë³´ ì¡°íšŒ
            company_info = self._get_company_info(company_id)
            company_name = company_info.get("name", company_id.capitalize())
            print(f"âœ… [DEFAULT PERSONA] íšŒì‚¬ ì •ë³´ ì¡°íšŒ ì™„ë£Œ: {company_name}")
            
            # ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ë°ì´í„°
            default_persona = CandidatePersona(
                name=f"{company_name} ì§€ì›ì",
                summary=f"{position} ê°œë°œìë¡œ {company_name}ì— ì§€ì›í•˜ëŠ” ê²½ë ¥ 3ë…„ì°¨ ê°œë°œìì…ë‹ˆë‹¤.",
                background={
                    "career_years": "3",
                    "current_position": f"{position} ê°œë°œì",
                    "education": ["ëŒ€í•™êµ ì»´í“¨í„°ê³µí•™ê³¼ ì¡¸ì—…"],
                    "total_experience": "3ë…„"
                },
                technical_skills=self._get_default_tech_skills(position),
                projects=[{
                    "name": f"{position} í”„ë¡œì íŠ¸",
                    "description": f"{position} ê°œë°œ í”„ë¡œì íŠ¸ ê²½í—˜",
                    "tech_stack": self._get_default_tech_skills(position)[:3],
                    "achievements": ["ì„±ê³µì ì¸ í”„ë¡œì íŠ¸ ì™„ìˆ˜", "íŒ€ì›Œí¬ í–¥ìƒì— ê¸°ì—¬"]
                }],
                experiences=[{
                    "company": "ê¸°ì¡´ íšŒì‚¬",
                    "position": f"{position} ê°œë°œì",
                    "period": "2021 - í˜„ì¬",
                    "achievements": ["í”„ë¡œì íŠ¸ ì„±ê³µì  ì™„ìˆ˜", "ê¸°ìˆ  ì—­ëŸ‰ í–¥ìƒ"]
                }],
                strengths=["ë¬¸ì œ í•´ê²° ëŠ¥ë ¥", "íŒ€ì›Œí¬", "í•™ìŠµ ì˜ì§€"],
                weaknesses=["ì™„ë²½ì£¼ì˜ì  ì„±í–¥"],
                motivation=f"{company_name}ì—ì„œ {position} ê°œë°œìë¡œ ì„±ì¥í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.",
                inferred_personal_experiences=[{
                    "category": "í•™ìŠµ",
                    "experience": "ì§€ì†ì ì¸ ê¸°ìˆ  í•™ìŠµì„ í†µí•´ ì„±ì¥í•´ì™”ìŠµë‹ˆë‹¤.",
                    "lesson": "ê¾¸ì¤€í•œ í•™ìŠµì˜ ì¤‘ìš”ì„±ì„ ê¹¨ë‹¬ì•˜ìŠµë‹ˆë‹¤."
                }],
                career_goal=f"{company_name}ì—ì„œ {position} ì „ë¬¸ê°€ë¡œ ì„±ì¥í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.",
                personality_traits=["ì„±ì‹¤í•¨", "ì ê·¹ì„±", "í˜‘ë ¥ì "],
                interview_style="ì§„ì •ì„± ìˆê³  ë…¼ë¦¬ì ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ìŠ¤íƒ€ì¼",
                resume_id=0  # ê¸°ë³¸ê°’
            )
            
            print(f"âœ… [DEFAULT PERSONA] ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„± ì™„ë£Œ: {default_persona.name}")
            return default_persona
            
        except Exception as e:
            print(f"âŒ [DEFAULT PERSONA] ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
    
    def _get_default_tech_skills(self, position: str) -> List[str]:
        """ì§êµ°ë³„ ê¸°ë³¸ ê¸°ìˆ  ìŠ¤íƒ"""
        tech_mapping = {
            "í”„ë¡ íŠ¸ì—”ë“œ": ["JavaScript", "React", "HTML/CSS", "TypeScript", "Vue.js"],
            "ë°±ì—”ë“œ": ["Java", "Spring Boot", "MySQL", "Python", "Node.js"],
            "í’€ìŠ¤íƒ": ["JavaScript", "React", "Node.js", "MySQL", "TypeScript"],
            "AI": ["Python", "TensorFlow", "PyTorch", "Machine Learning", "Data Science"],
            "ë°ì´í„°": ["Python", "SQL", "Pandas", "Tableau", "R"],
            "ê¸°íš": ["Product Management", "ê¸°íš", "ë¶„ì„", "Communication", "Strategy"]
        }
        
        # ì§êµ° ë§¤í•‘ì—ì„œ ì°¾ì§€ ëª»í•˜ë©´ ë°±ì—”ë“œ ê¸°ë³¸ê°’ ì‚¬ìš©
        return tech_mapping.get(position, tech_mapping["ë°±ì—”ë“œ"])

if __name__ == "__main__":
    # AI ì§€ì›ì ëª¨ë¸ í…ŒìŠ¤íŠ¸
    print("ğŸ¤– AI ì§€ì›ì ëª¨ë¸ í…ŒìŠ¤íŠ¸ - LLM ê¸°ë°˜ ì‹¤ì‹œê°„ í˜ë¥´ì†Œë‚˜ ìƒì„±")
    
    # ëª¨ë¸ ì´ˆê¸°í™” (ìë™ìœ¼ë¡œ .envì—ì„œ API í‚¤ ë¡œë“œ)
    ai_candidate = AICandidateModel()
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ íšŒì‚¬ í™•ì¸
    companies = ai_candidate.get_available_companies()
    print(f"\nğŸ¢ ì‚¬ìš© ê°€ëŠ¥í•œ íšŒì‚¬: {companies}")
    
    # === ìƒˆë¡œìš´ LLM ê¸°ë°˜ í˜ë¥´ì†Œë‚˜ ìƒì„± í…ŒìŠ¤íŠ¸ ===
    print("\n" + "="*60)
    print("ğŸ¯ LLM ê¸°ë°˜ ì‹¤ì‹œê°„ í˜ë¥´ì†Œë‚˜ ìƒì„± í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    if companies:
        # ë„¤ì´ë²„ ë°±ì—”ë“œ ê°œë°œì í˜ë¥´ì†Œë‚˜ ìƒì„± í…ŒìŠ¤íŠ¸
        print("\nğŸ”¥ ë„¤ì´ë²„ ë°±ì—”ë“œ ê°œë°œì í˜ë¥´ì†Œë‚˜ ìƒì„± í…ŒìŠ¤íŠ¸")
        naver_persona = ai_candidate.create_persona_for_interview("ë„¤ì´ë²„", "ë°±ì—”ë“œ")
        
        if naver_persona:
            print(f"\n" + "="*80)
            print(f"ğŸ¯ ìƒì„±ëœ í˜ë¥´ì†Œë‚˜ ì „ì²´ ì •ë³´")
            print(f"="*80)
            print(f"ğŸ“› ì´ë¦„: {naver_persona.name}")
            print(f"ğŸ“ ìš”ì•½: {naver_persona.summary}")
            print(f"ğŸ¢ ì´ë ¥ì„œ ID: {naver_persona.resume_id}")
            print(f"ğŸ¤– ìƒì„± ëª¨ë¸: {naver_persona.generated_by}")
            
            print(f"\nğŸ“‹ ë°°ê²½ ì •ë³´:")
            print(f"  â€¢ ê²½ë ¥: {naver_persona.background.get('career_years', '0')}ë…„")
            print(f"  â€¢ í˜„ì¬ ì§ì±…: {naver_persona.background.get('current_position', 'ì§€ì›ì')}")
            print(f"  â€¢ í•™ë ¥: {', '.join(naver_persona.background.get('education', ['ì •ë³´ ì—†ìŒ']))}")
            
            print(f"\nğŸ’» ê¸°ìˆ  ìŠ¤í‚¬:")
            for i, skill in enumerate(naver_persona.technical_skills, 1):
                print(f"  {i}. {skill}")
            
            print(f"\nğŸš€ í”„ë¡œì íŠ¸ ê²½í—˜:")
            for i, project in enumerate(naver_persona.projects, 1):
                print(f"  {i}. {project.get('name', 'í”„ë¡œì íŠ¸')}")
                print(f"     ì„¤ëª…: {project.get('description', '')}")
                print(f"     ê¸°ìˆ : {', '.join(project.get('tech_stack', []))}")
                print(f"     ì—­í• : {project.get('role', '')}")
                if project.get('achievements'):
                    print(f"     ì„±ê³¼: {', '.join(project['achievements'])}")
                if project.get('challenges'):
                    print(f"     ì–´ë ¤ì›€: {', '.join(project['challenges'])}")
                print()
            
            print(f"ğŸ’¼ ì—…ë¬´ ê²½í—˜:")
            for i, exp in enumerate(naver_persona.experiences, 1):
                print(f"  {i}. {exp.get('company', 'íšŒì‚¬')}")
                print(f"     ì§ì±…: {exp.get('position', 'ê°œë°œì')}")
                print(f"     ê¸°ê°„: {exp.get('period', 'ê¸°ê°„')}")
                if exp.get('achievements'):
                    print(f"     ì„±ê³¼: {', '.join(exp['achievements'])}")
                print()
            
            print(f"ğŸ’ª ê°•ì :")
            for i, strength in enumerate(naver_persona.strengths, 1):
                print(f"  {i}. {strength}")
            
            print(f"\nğŸ¤” ì•½ì  (ê°œì„ ì ):")
            for i, weakness in enumerate(naver_persona.weaknesses, 1):
                print(f"  {i}. {weakness}")
            
            print(f"\nâ¤ï¸ ê°œì¸ì  ë™ê¸°:")
            print(f"  {naver_persona.motivation}")
            
            print(f"\nğŸ¯ ì»¤ë¦¬ì–´ ëª©í‘œ:")
            print(f"  {naver_persona.career_goal}")
            
            print(f"\nğŸ§  ê°œì¸ì  êµí›ˆ/ê²½í—˜:")
            for i, exp in enumerate(naver_persona.inferred_personal_experiences, 1):
                print(f"  {i}. [{exp.get('category', 'ê²½í—˜')}] {exp.get('experience', '')}")
                print(f"     êµí›ˆ: {exp.get('lesson', '')}")
                print()
            
            print(f"ğŸ­ ì„±ê²© íŠ¹ì„±:")
            print(f"  {', '.join(naver_persona.personality_traits)}")
            
            print(f"\nğŸ—£ï¸ ë©´ì ‘ ìŠ¤íƒ€ì¼:")
            print(f"  {naver_persona.interview_style}")
            
            print(f"="*80)
            
            # ì„ì‹œë¡œ í˜ë¥´ì†Œë‚˜ë¥¼ ìºì‹œì— ì €ì¥ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•´)
            ai_candidate.candidate_personas["naver"] = naver_persona
            
            # ìƒì„±ëœ í˜ë¥´ì†Œë‚˜ë¡œ ë‹µë³€ ìƒì„± í…ŒìŠ¤íŠ¸
            print(f"\nğŸ“ ìƒì„±ëœ í˜ë¥´ì†Œë‚˜ë¡œ ë‹µë³€ ìƒì„± í…ŒìŠ¤íŠ¸:")
            test_request = AnswerRequest(
                question_content="ê°„ë‹¨í•œ ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”.",
                question_type=QuestionType.INTRO,
                question_intent="ì§€ì›ìì˜ ê¸°ë³¸ ë°°ê²½ê³¼ ì—­ëŸ‰ íŒŒì•…",
                company_id="naver",
                position="ë°±ì—”ë“œ ê°œë°œì",
                quality_level=QualityLevel(8),
                llm_provider=LLMProvider.OPENAI_GPT4O_MINI
            )
            
            response = ai_candidate.generate_answer(test_request)
            
            print(f"í˜ë¥´ì†Œë‚˜: {response.persona_name}")
            print(f"í’ˆì§ˆ ë ˆë²¨: {response.quality_level.value}ì ")
            print(f"ì‹ ë¢°ë„: {response.confidence_score}")
            print(f"ì‘ë‹µ ì‹œê°„: {response.response_time:.2f}ì´ˆ")
            print(f"ë‹µë³€: {response.answer_content[:300]}...")
            
            if response.error:
                print(f"ì˜¤ë¥˜: {response.error}")
        else:
            print("âŒ í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹¤íŒ¨")
    
    # í˜ë¥´ì†Œë‚˜ ìš”ì•½ ì •ë³´ í™•ì¸ (ë™ì  ìƒì„± ì‹œìŠ¤í…œ)
    print(f"\nğŸ“Š íšŒì‚¬ë³„ ì •ë³´ í™•ì¸:")
    for company in companies[:3]:
        summary = ai_candidate.get_persona_summary(company)
        print(f"\nğŸ‘¤ {company}:")
        if summary.get('note'):
            print(f"  íƒ€ì…: {summary.get('note')}")
            print(f"  íšŒì‚¬ëª…: {summary.get('company_name')}")
            print(f"  ì§€ì› ê°€ëŠ¥ ì§êµ°: {', '.join(summary.get('available_positions', []))}")
        else:
            print(f"  ì´ë¦„: {summary.get('name', 'N/A')}")
            print(f"  ê²½ë ¥: {summary.get('career_years', 'N/A')}ë…„")
    
    print("\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ! LLM ê¸°ë°˜ í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.")